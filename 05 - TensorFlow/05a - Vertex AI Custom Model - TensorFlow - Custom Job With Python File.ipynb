{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59ca3f21",
   "metadata": {},
   "source": [
    "![tracker](https://us-central1-vertex-ai-mlops-369716.cloudfunctions.net/pixel-tracking?path=statmike%2Fvertex-ai-mlops%2F05+-+TensorFlow&file=05a+-+Vertex+AI+Custom+Model+-+TensorFlow+-+Custom+Job+With+Python+File.ipynb)\n",
    "<!--- header table --->\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/statmike/vertex-ai-mlops/blob/main/05%20-%20TensorFlow/05a%20-%20Vertex%20AI%20Custom%20Model%20-%20TensorFlow%20-%20Custom%20Job%20With%20Python%20File.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\">\n",
    "      <br>Run in<br>Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https%3A%2F%2Fraw.githubusercontent.com%2Fstatmike%2Fvertex-ai-mlops%2Fmain%2F05%2520-%2520TensorFlow%2F05a%2520-%2520Vertex%2520AI%2520Custom%2520Model%2520-%2520TensorFlow%2520-%2520Custom%2520Job%2520With%2520Python%2520File.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\">\n",
    "      <br>Run in<br>Colab Enterprise\n",
    "    </a>\n",
    "  </td>      \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/statmike/vertex-ai-mlops/blob/main/05%20-%20TensorFlow/05a%20-%20Vertex%20AI%20Custom%20Model%20-%20TensorFlow%20-%20Custom%20Job%20With%20Python%20File.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      <br>View on<br>GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/statmike/vertex-ai-mlops/main/05%20-%20TensorFlow/05a%20-%20Vertex%20AI%20Custom%20Model%20-%20TensorFlow%20-%20Custom%20Job%20With%20Python%20File.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      <br>Open in<br>Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c3fa3d",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "**Changes In Progress**\n",
    "\n",
    "Every attempt is being made to ensure the public version of this notebook runs without error while the follow enhancements are being made:\n",
    "- The workflow of the notebook is being adapted to a Kubeflow Pipeline running on Vertex AI Pipelines\n",
    "- Including Evaluation data within Vertex AI Model Registry\n",
    "- Update the Vertex AI Experiments integration which has been great simplified within the API over the past few months\n",
    "- add client library reference links to each section\n",
    "\n",
    "Order: notebook 05 and 05a will be updated first.  Then 05b-05i will follow quickly.\n",
    "\n",
    "This note will be removed once these changes are complete.\n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    "# 05a - Vertex AI Custom Model - TensorFlow - Custom Job With Python File\n",
    "\n",
    "**05 Series Overview**\n",
    "\n",
    ">**NOTE:** The notebooks in the `05 - TensorFlow` series demonstrate training, serving and operations for TensorFlow models and take advantage of [Vertex AI TensorBoard](https://cloud.google.com/vertex-ai/docs/experiments/tensorboard-overview) to track training across experiments.  Running these notebooks will create a Vertex AI TensorBoard instance which previously (before August 2023) had a subscription cost but is now priced based on storage of which this notebook will create minimal size (<2MB). - [Vertex AI Pricing](https://cloud.google.com/vertex-ai/pricing#tensorboard).\n",
    "\n",
    "Where a model gets trained is where it consumes computing resources.  With Vertex AI, you have choices for configuring the computing resources available at training.  This notebook is an example of an execution environment.  When it was set up there were choices for machine type and accelerators (GPUs).  \n",
    "\n",
    "In the [05 - Vertex AI Custom Model - TensorFlow - in Notebook](./05%20-%20Vertex%20AI%20Custom%20Model%20-%20TensorFlow%20-%20in%20Notebook.ipynb) notebook, the model training happened directly in the notebook.  The model was then imported to Vertex AI and deployed to an endpoint for online predictions. \n",
    "\n",
    "In this `05a-05i` series of demonstrations, the same model is trained using managed computing resources in Vertex AI Training as managed jobs.  These jobs will be demonstrated as:\n",
    "\n",
    "-  [Custom Job](https://cloud.google.com/vertex-ai/docs/training/create-custom-job) that trains and saves (to GCS) a model from a python script (`05a`), python source distribution (`05b`), and custom container (`05c`)\n",
    "-  [Training Pipeline](https://cloud.google.com/vertex-ai/docs/training/hyperparameter-tuning-overview) that trains and registers a model from a python script (`05d`), python source distribution (`05e`), and custom container (`05f`)\n",
    "-  [Hyperparameter Tuning Jobs](https://cloud.google.com/vertex-ai/docs/training/create-training-pipeline) from a python script (`05g`), python source distribution (`05h`), and custom container (`05i`)\n",
    "\n",
    "**This Notebook (`05a`): An extension of `05` that runs a Custom Job using a script as an input**\n",
    "\n",
    "This notebook trains the same Tensorflow Keras model from [05 - Vertex AI Custom Model - TensorFlow - in Notebook](./05%20-%20Vertex%20AI%20Custom%20Model%20-%20TensorFlow%20-%20in%20Notebook.ipynb) by first modifying and saving the training code to a Python script as shown in [05 - Vertex AI Custom Model - TensorFlow - Notebook to Script](./05%20-%20Vertex%20AI%20Custom%20Model%20-%20TensorFlow%20-%20Notebook%20to%20Script.ipynb).  \n",
    "\n",
    "The script is then used as an input for a Vertex AI > Training > Custom Job that is also assigned compute resources and a [pre-built container for custom training](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers) for executing the training in a managed service. \n",
    "\n",
    "This job is launched using the Vertex AI client library:\n",
    "- [Python Cloud Client Libraries](https://cloud.google.com/python/docs/reference)\n",
    "    - [google-cloud-aiplatform](https://cloud.google.com/python/docs/reference/aiplatform/latest)\n",
    "        - [`aiplatform` package](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform)\n",
    "            - [`aiplatform.CustomJob.from_local_script()`](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.CustomJob#google_cloud_aiplatform_CustomJob_from_local_script)\n",
    "\n",
    "\n",
    "|Custom Job|Workflow With Custom Job|\n",
    "|:---:|:---:|\n",
    "|![](../architectures/architectures/images/custom%20training/a_job.png)|![](../architectures/architectures/images/custom%20training/a_workflow.png)|\n",
    "\n",
    "**Vertex AI Training**\n",
    "\n",
    "In Vertex AI Training you can run your training code as a job where you specify the compute resources to use. For tips on preparing code, running training jobs, and workflows for building custom containers with software and training code combined please visit these [tips notebooks](../Tips/readme.md) in this repository:\n",
    "- [Python Packages](../Tips/Python%20Packages.ipynb)\n",
    "- [Python Custom Containers](../Tips/Python%20Custom%20Containers.ipynb)\n",
    "- [Python Training](../Tips/Python%20Training.ipynb)\n",
    "- [Python Job Parameters](../Tips/Python%20Job%20Parameters.ipybnd)\n",
    "\n",
    "<p align=\"center\" width=\"100%\">\n",
    "    <img src=\"../architectures/overview/training.png\" width=\"45%\">\n",
    "    &nbsp; &nbsp; &nbsp; &nbsp;\n",
    "    <img src=\"../architectures/overview/training2.png\" width=\"45%\">\n",
    "</p>\n",
    "\n",
    "**Prerequisites:**\n",
    "-  [01 - BigQuery - Table Data Source](../01%20-%20Data%20Sources/01%20-%20BigQuery%20-%20Table%20Data%20Source.ipynb)\n",
    "-  Understanding:\n",
    "    -  Model overview in [05 - Vertex AI Custom Model - TensorFlow - in Notebook](./05%20-%20Vertex%20AI%20Custom%20Model%20-%20TensorFlow%20-%20in%20Notebook.ipynb)\n",
    "    -  Convert notebook code to Python Script in [05 - Vertex AI Custom Model - TensorFlow - Notebook to Script](./05%20-%20Vertex%20AI%20Custom%20Model%20-%20TensorFlow%20-%20Notebook%20to%20Script.ipynb)\n",
    "\n",
    "**Resources:**\n",
    "-  [BigQuery Tensorflow Reader](https://www.tensorflow.org/io/tutorials/bigquery)\n",
    "-  [Keras Sequential](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential)\n",
    "   -  [Keras API](https://www.tensorflow.org/api_docs/python/tf/keras)\n",
    "-  [Python Client For Google BigQuery](https://googleapis.dev/python/bigquery/latest/index.html)\n",
    "-  [Tensorflow Python Client](https://www.tensorflow.org/api_docs/python/tf)\n",
    "-  [Tensorflow I/O Python Client](https://www.tensorflow.org/io/api_docs/python/tfio/bigquery)\n",
    "-  [Python Client for Vertex AI](https://googleapis.dev/python/aiplatform/latest/aiplatform.html)\n",
    "-  Containers for training (Pre-Built)\n",
    "   -  [Overview](https://cloud.google.com/vertex-ai/docs/training/create-python-pre-built-container)\n",
    "    - Pre-built Containers for Vertex AI\n",
    "        - [Training](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers)\n",
    "        - [Prediction & Explaination](https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers)\n",
    "\n",
    "<!--\n",
    "**Conceptual Flow & Workflow**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img alt=\"Conceptual Flow\" src=\"../architectures/slides/05a_arch.png\" width=\"45%\">\n",
    "&nbsp; &nbsp; &nbsp; &nbsp;\n",
    "  <img alt=\"Workflow\" src=\"../architectures/slides/05a_console.png\" width=\"45%\">\n",
    "</p>\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c121b1b3-36eb-41d5-aa8f-2b06079eaf57",
   "metadata": {
    "id": "od_UkDpvRmgD",
    "tags": []
   },
   "source": [
    "---\n",
    "## Colab Setup\n",
    "\n",
    "To run this notebook in Colab click [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/statmike/vertex-ai-mlops/blob/main/05%20-%20TensorFlow/05a%20-%20Vertex%20AI%20Custom%20Model%20-%20TensorFlow%20-%20Custom%20Job%20With%20Python%20File.ipynb) and run the cells in this section.  Otherwise, skip this section.\n",
    "\n",
    "This cell will authenticate to GCP (follow prompts in the popup)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba94a1bf-0fc9-470c-bd8c-cff8ccedec1a",
   "metadata": {
    "executionInfo": {
     "elapsed": 195,
     "status": "ok",
     "timestamp": 1683726184843,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "8UO9FnqyKBlF"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'statmike-mlops-349915' # replace with project ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19c62346-8bb4-4c8b-8aff-75c53d49fac1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68869,
     "status": "ok",
     "timestamp": 1683726253709,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "N98-KK7LRkjm",
    "outputId": "09ec5008-0def-4e1a-c349-c598ee752f78"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    !gcloud config set project {PROJECT_ID}\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6160c966-d65a-4ee5-b622-356565614ee6",
   "metadata": {},
   "source": [
    "---\n",
    "## Installs\n",
    "\n",
    "The list `packages` contains tuples of package import names and install names.  If the import name is not found then the install name is used to install quitely for the current user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "068b535b-b8c3-4606-855b-78c98bee464e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tuples of (import name, install name, min_version)\n",
    "packages = [\n",
    "    ('google.cloud.aiplatform', 'google-cloud-aiplatform'),\n",
    "    ('kfp', 'kfp'),\n",
    "    ('google_cloud_pipeline_components', 'google-cloud-pipeline-components')\n",
    "]\n",
    "\n",
    "import importlib\n",
    "install = False\n",
    "for package in packages:\n",
    "    if not importlib.util.find_spec(package[0]):\n",
    "        print(f'installing package {package[1]}')\n",
    "        install = True\n",
    "        !pip install {package[1]} -U -q --user\n",
    "    elif len(package) == 3:\n",
    "        if importlib.metadata.version(package[0]) < package[2]:\n",
    "            print(f'updating package {package[1]}')\n",
    "            install = True\n",
    "            !pip install {package[1]} -U -q --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4b5303-b37b-48a0-882c-99d17511811b",
   "metadata": {},
   "source": [
    "### Restart Kernel (If Installs Occured)\n",
    "\n",
    "After a kernel restart the code submission can start with the next cell after this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4e84dc8-8d67-481c-be36-49f8a8406aa9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if install:\n",
    "    import IPython\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe7eba1",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edae2fa7",
   "metadata": {},
   "source": [
    "inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b7c610a-c325-4975-a4ec-425dc6eae1f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'statmike-mlops-349915'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54eea9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "EXPERIMENT = '05a'\n",
    "SERIES = '05'\n",
    "\n",
    "# source data\n",
    "BQ_PROJECT = PROJECT_ID\n",
    "BQ_DATASET = 'fraud'\n",
    "BQ_TABLE = 'fraud_prepped'\n",
    "\n",
    "# specify a GCS Bucket\n",
    "GCS_BUCKET = PROJECT_ID\n",
    "\n",
    "# Model Training\n",
    "VAR_TARGET = 'Class'\n",
    "VAR_OMIT = 'transaction_id,splits' # add more variables to the string with comma delimiters\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7253fe4",
   "metadata": {},
   "source": [
    "packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d13322b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "from datetime import datetime\n",
    "import importlib\n",
    "from IPython.display import Markdown as md\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "#from google.protobuf import json_format\n",
    "#from google.protobuf.struct_pb2 import Value\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d19b58",
   "metadata": {},
   "source": [
    "clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23a2b8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project = PROJECT_ID, location = REGION)\n",
    "bq = bigquery.Client(project = PROJECT_ID)\n",
    "gcs = storage.Client(project = PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dac43d0",
   "metadata": {},
   "source": [
    "parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cc1c101",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "URI = f\"gs://{GCS_BUCKET}/{SERIES}/{EXPERIMENT}\"\n",
    "DIR = f\"temp/{EXPERIMENT}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58ab4db3-aef7-4474-a883-7d706db02f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1026793852137-compute@developer.gserviceaccount.com'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SERVICE_ACCOUNT = !gcloud config list --format='value(core.account)' \n",
    "SERVICE_ACCOUNT = SERVICE_ACCOUNT[0]\n",
    "SERVICE_ACCOUNT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057608d0-e6bd-4b39-b3a2-e550be5c03b1",
   "metadata": {},
   "source": [
    "List the service accounts current roles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ea23cc7-e81f-4829-a2c7-786ea7967709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROLE\n",
      "roles/bigquery.admin\n",
      "roles/owner\n",
      "roles/run.admin\n",
      "roles/secretmanager.secretAccessor\n",
      "roles/storage.objectAdmin\n"
     ]
    }
   ],
   "source": [
    "!gcloud projects get-iam-policy $PROJECT_ID --filter=\"bindings.members:$SERVICE_ACCOUNT\" --format='table(bindings.role)' --flatten=\"bindings[].members\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50b31ac-8788-4285-b5c5-90ca037e4945",
   "metadata": {},
   "source": [
    ">Note: If the resulting list is missing [roles/storage.objectAdmin](https://cloud.google.com/storage/docs/access-control/iam-roles) then [revisit the setup notebook](../00%20-%20Setup/00%20-%20Environment%20Setup.ipynb#permissions) and add this permission to the service account with the provided instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4f3430",
   "metadata": {},
   "source": [
    "environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb70c0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(DIR):\n",
    "    os.makedirs(DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bde8db-df0c-4b94-a8f7-5717166fa2c3",
   "metadata": {},
   "source": [
    "Experiment Tracking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a193ab9-2d7e-4c58-9eaa-b93c6e242fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAMEWORK = 'tf'\n",
    "TASK = 'classification'\n",
    "MODEL_TYPE = 'dnn'\n",
    "EXPERIMENT_NAME = f'experiment-{SERIES}-{EXPERIMENT}-{FRAMEWORK}-{TASK}-{MODEL_TYPE}'\n",
    "RUN_NAME = f'run-{TIMESTAMP}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f450631f",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Get Vertex AI Experiments Tensorboard Instance Name\n",
    "[Vertex AI Experiments](https://cloud.google.com/vertex-ai/docs/experiments/tensorboard-overview) has managed [Tensorboard](https://www.tensorflow.org/tensorboard) instances that you can track Tensorboard Experiments (a training run or hyperparameter tuning sweep).  \n",
    "\n",
    "The training job will show up as an experiment for the Tensorboard instance and have the same name as the training job ID.\n",
    "\n",
    "This code checks to see if a Tensorboard Instance has been created in the project, retrieves it if so, creates it otherwise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c0cfc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = aiplatform.Tensorboard.list(filter=f\"labels.series={SERIES}\")\n",
    "if tb:\n",
    "    tb = tb[0]\n",
    "else: \n",
    "    tb = aiplatform.Tensorboard.create(display_name = SERIES, labels = {'series' : f'{SERIES}'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7bdbeab-553f-4715-980e-da14bd9c264a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/1026793852137/locations/us-central1/tensorboards/7876136041294331904'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb.resource_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4336405b-e02b-40e9-a988-12f4ebf6ef60",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup Vertex AI Experiments\n",
    "\n",
    "The code in this section initializes the experiment and starts a run that represents this notebook.  Throughout the notebook sections for model training and evaluation information will be logged to the experiment using:\n",
    "- [.log_params](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform#google_cloud_aiplatform_log_params)\n",
    "- [.log_metrics](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform#google_cloud_aiplatform_log_metrics)\n",
    "- [.log_time_series_metrics](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform#google_cloud_aiplatform_log_time_series_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b50688f8-8c11-462a-9a37-6f503a7cd85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(experiment = EXPERIMENT_NAME, experiment_tensorboard = tb.resource_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd86168",
   "metadata": {},
   "source": [
    "---\n",
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3570cd60",
   "metadata": {},
   "source": [
    "### Python File for Training\n",
    "\n",
    "This notebook trains the same Tensorflow Keras model from [05 - Vertex AI Custom Model - TensorFlow - in Notebook](./05%20-%20Vertex%20AI%20Custom%20Model%20-%20TensorFlow%20-%20in%20Notebook.ipynb) by first modifying and saving the training code to a python script as shown in [05 - Vertex AI Custom Model - TensorFlow - Notebook to Script](./05%20-%20Vertex%20AI%20Custom%20Model%20-%20TensorFlow%20-%20Notebook%20to%20Script.ipynb) which stores the script in [`./code/train.py`](./code/train.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a091c6d7-180d-4f35-a701-389f237f1bb3",
   "metadata": {},
   "source": [
    "Retrieve the training script (if not already included in a clone of this repository):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa2d3147-8f8b-4f08-b429-1f391a0d42a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Found at `./code/train.py`\n"
     ]
    }
   ],
   "source": [
    "file = \"./code/train.py\"\n",
    "if not os.path.exists(file):\n",
    "    print('Retrieving document...')\n",
    "    if not os.path.exists(os.path.dirname(file)):\n",
    "      os.makedirs(os.path.dirname(file))\n",
    "    import requests, urllib.parse\n",
    "    r = requests.get(f'https://raw.githubusercontent.com/statmike/vertex-ai-mlops/main/05%20-%20TensorFlow/{urllib.parse.quote(file[2:])}')\n",
    "    open(file, 'wb').write(r.content)\n",
    "    print(f'Document now at `{file}`')\n",
    "else:\n",
    "    print(f'Document Found at `{file}`')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac53018-a3e0-427f-9b76-508bb99e17d5",
   "metadata": {},
   "source": [
    "**Review the script:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b59ef69-fb65-4f4a-ad00-d0ea4e1572d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "\n",
       "\n",
       "# package import\n",
       "from tensorflow.python.framework import dtypes\n",
       "from tensorflow_io.bigquery import BigQueryClient\n",
       "import tensorflow as tf\n",
       "from google.cloud import bigquery\n",
       "from google.cloud import aiplatform\n",
       "import argparse\n",
       "import os\n",
       "\n",
       "# import argument to local variables\n",
       "parser = argparse.ArgumentParser()\n",
       "# the passed param, dest: a name for the param, default: if absent fetch this param from the OS, type: type to convert to, help: description of argument\n",
       "parser.add_argument('--epochs', dest = 'epochs', default = 10, type = int, help = 'Number of Epochs')\n",
       "parser.add_argument('--batch_size', dest = 'batch_size', default = 32, type = int, help = 'Batch Size')\n",
       "parser.add_argument('--var_target', dest = 'var_target', type=str)\n",
       "parser.add_argument('--var_omit', dest = 'var_omit', type=str)#, nargs='*')\n",
       "parser.add_argument('--project_id', dest = 'project_id', type=str)\n",
       "parser.add_argument('--bq_project', dest = 'bq_project', type=str)\n",
       "parser.add_argument('--bq_dataset', dest = 'bq_dataset', type=str)\n",
       "parser.add_argument('--bq_table', dest = 'bq_table', type=str)\n",
       "parser.add_argument('--region', dest = 'region', type=str)\n",
       "parser.add_argument('--experiment', dest = 'experiment', type=str)\n",
       "parser.add_argument('--series', dest = 'series', type=str)\n",
       "parser.add_argument('--experiment_name', dest = 'experiment_name', type=str)\n",
       "parser.add_argument('--run_name', dest = 'run_name', type=str)\n",
       "args = parser.parse_args()\n",
       "\n",
       "# clients\n",
       "bq = bigquery.Client(project = args.project_id)\n",
       "aiplatform.init(project = args.project_id, location = args.region)\n",
       "\n",
       "# Vertex AI Experiment\n",
       "if args.run_name in [run.name for run in aiplatform.ExperimentRun.list(experiment = args.experiment_name)]:\n",
       "    expRun = aiplatform.ExperimentRun(run_name = args.run_name, experiment = args.experiment_name)\n",
       "else:\n",
       "    expRun = aiplatform.ExperimentRun.create(run_name = args.run_name, experiment = args.experiment_name)\n",
       "expRun.log_params({'experiment': args.experiment, 'series': args.series, 'project_id': args.project_id})\n",
       "\n",
       "# get schema from bigquery source\n",
       "query = f\"SELECT * FROM {args.bq_project}.{args.bq_dataset}.INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '{args.bq_table}'\"\n",
       "schema = bq.query(query).to_dataframe()\n",
       "\n",
       "# get number of classes from bigquery source\n",
       "nclasses = bq.query(query = f'SELECT DISTINCT {args.var_target} FROM {args.bq_project}.{args.bq_dataset}.{args.bq_table} WHERE {args.var_target} is not null').to_dataframe()\n",
       "nclasses = nclasses.shape[0]\n",
       "expRun.log_params({'data_source': f'bq://{args.bq_project}.{args.bq_dataset}.{args.bq_table}', 'nclasses': nclasses, 'var_split': 'splits', 'var_target': args.var_target})\n",
       "\n",
       "# Make a list of columns to omit\n",
       "OMIT = [x for x in args.var_omit.split(',') if x != '']\n",
       "\n",
       "# use schema to prepare a list of columns to read from BigQuery\n",
       "selected_fields = schema[~schema.column_name.isin(OMIT)].column_name.tolist()\n",
       "\n",
       "# all the columns in this data source are either float64 or int64\n",
       "output_types = [dtypes.float64 if x=='FLOAT64' else dtypes.int64 for x in schema[~schema.column_name.isin(OMIT)].data_type.tolist()]\n",
       "\n",
       "# remap input data to Tensorflow inputs of features and target\n",
       "def transTable(row_dict):\n",
       "    target = row_dict.pop(args.var_target)\n",
       "    target = tf.one_hot(tf.cast(target, tf.int64), nclasses)\n",
       "    target = tf.cast(target, tf.float32)\n",
       "    return(row_dict, target)\n",
       "\n",
       "# function to setup a bigquery reader with Tensorflow I/O\n",
       "def bq_reader(split):\n",
       "    reader = BigQueryClient()\n",
       "\n",
       "    training = reader.read_session(\n",
       "        parent = f\"projects/{args.project_id}\",\n",
       "        project_id = args.bq_project,\n",
       "        table_id = args.bq_table,\n",
       "        dataset_id = args.bq_dataset,\n",
       "        selected_fields = selected_fields,\n",
       "        output_types = output_types,\n",
       "        row_restriction = f\"splits='{split}'\",\n",
       "        requested_streams = 3\n",
       "    )\n",
       "    \n",
       "    return training\n",
       "\n",
       "# setup feed for train, validate and test\n",
       "train = bq_reader('TRAIN').parallel_read_rows().prefetch(1).map(transTable).shuffle(args.batch_size*10).batch(args.batch_size)\n",
       "validate = bq_reader('VALIDATE').parallel_read_rows().prefetch(1).map(transTable).batch(args.batch_size)\n",
       "test = bq_reader('TEST').parallel_read_rows().prefetch(1).map(transTable).batch(args.batch_size)\n",
       "expRun.log_params({'training.batch_size': args.batch_size, 'training.shuffle': 10*args.batch_size, 'training.prefetch': 1})\n",
       "# Logistic Regression\n",
       "\n",
       "# feature list\n",
       "numeric_features = [feature for feature in schema[~schema.column_name.isin(OMIT + [args.var_target])]['column_name'].to_list()]\n",
       "\n",
       "# feature inputs\n",
       "features = [tf.keras.Input(shape = (1,), dtype = dtypes.float64, name = feature) for feature in numeric_features]\n",
       "\n",
       "# normalize features - before training\n",
       "#normalized_features = []\n",
       "#for feature in features:\n",
       "#    normalizer = tf.keras.layers.Normalization(axis = None, name = feature.name + '_normalized')\n",
       "#    feature_data = train.map(lambda x, y: x[feature.name])\n",
       "#    normalizer.adapt(feature_data)\n",
       "#    normalized_features.append(normalizer(feature))\n",
       "\n",
       "# concatenate features\n",
       "all_features = tf.keras.layers.Concatenate(name = 'feature_layer')(features)\n",
       "#all_features = tf.keras.layers.Concatenate(name = 'feature_layer')(normalized_features) # (features)\n",
       "\n",
       "# batch normalization of inputs - during training\n",
       "all_features = tf.keras.layers.BatchNormalization(name = 'batch_normalization_layer')(all_features)\n",
       "\n",
       "# logistic - using softmax activation to nclasses\n",
       "logistic = tf.keras.layers.Dense(nclasses, activation = tf.nn.softmax, name = 'logistic')(all_features)\n",
       "\n",
       "# the model\n",
       "model = tf.keras.Model(\n",
       "    inputs = features,\n",
       "    outputs = logistic,\n",
       "    name = args.experiment\n",
       ")\n",
       "\n",
       "# compile the model\n",
       "model.compile(\n",
       "    optimizer = tf.keras.optimizers.SGD(), #SGD or Adam\n",
       "    loss = tf.keras.losses.CategoricalCrossentropy(),\n",
       "    metrics = ['accuracy', tf.keras.metrics.AUC(curve = 'PR', name = 'auprc')]\n",
       ")\n",
       "\n",
       "# setup tensorboard logs and train\n",
       "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=os.environ['AIP_TENSORBOARD_LOG_DIR'], histogram_freq=1)\n",
       "history = model.fit(train, epochs = args.epochs, callbacks = [tensorboard_callback], validation_data = validate)\n",
       "expRun.log_params({'training.epochs': history.params['epochs']})\n",
       "for e in range(0, history.params['epochs']):\n",
       "    expRun.log_time_series_metrics(\n",
       "        {\n",
       "            'train_loss': history.history['loss'][e],\n",
       "            'train_accuracy': history.history['accuracy'][e],\n",
       "            'train_auprc': history.history['auprc'][e],\n",
       "            'val_loss': history.history['val_loss'][e],\n",
       "            'val_accuracy': history.history['val_accuracy'][e],\n",
       "            'val_auprc': history.history['val_auprc'][e]\n",
       "        }\n",
       "    )\n",
       "\n",
       "# test evaluations:\n",
       "loss, accuracy, auprc = model.evaluate(test)\n",
       "expRun.log_metrics({'test_loss': loss, 'test_accuracy': accuracy, 'test_auprc': auprc})\n",
       "\n",
       "# val evaluations:\n",
       "loss, accuracy, auprc = model.evaluate(validate)\n",
       "expRun.log_metrics({'val_loss': loss, 'val_accuracy': accuracy, 'val_auprc': auprc})\n",
       "\n",
       "# training evaluations:\n",
       "loss, accuracy, auprc = model.evaluate(train)\n",
       "expRun.log_metrics({'train_loss': loss, 'train_accuracy': accuracy, 'train_auprc': auprc})\n",
       "\n",
       "# output the model save files\n",
       "model.save(os.getenv(\"AIP_MODEL_DIR\"))\n",
       "expRun.log_params({'model.save': os.getenv(\"AIP_MODEL_DIR\")})\n",
       "expRun.end_run()\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCRIPT_PATH = './code/train.py'\n",
    "\n",
    "with open(SCRIPT_PATH, 'r') as file:\n",
    "    data = file.read()\n",
    "md(f\"```python\\n\\n{data}\\n```\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab9f9cf-e2ee-4b83-82b9-645f7fa5d32a",
   "metadata": {},
   "source": [
    "### Choose Computing Environment\n",
    "\n",
    "When using [custom training on Vertex AI](https://cloud.google.com/vertex-ai/docs/training/custom-training-methods) the compute environment is specified as parameters.  At a minimum this will include the [compute resources](https://cloud.google.com/vertex-ai/docs/training/configure-compute) and [container](https://cloud.google.com/vertex-ai/docs/training/configure-container-settings) URIs.\n",
    "\n",
    "This example uses minimal compute with a single node and no accelerators (GPU).\n",
    "\n",
    "For a container, a [pre-built custome training container](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers) for TensorFlow is being used and additional packages are being specified in the jobs parameters. This leads to two important considerations:\n",
    "- What is the Python version on the container? \n",
    "    - This will have an impact when additional packages are being installed and the packages may have version requirments.\n",
    "- What is the framework version on the container?\n",
    "    - Make sure the options you need from a framework are included in the version you pick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32be1d60-1c1f-4bff-bedb-4df5cf87f77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resources\n",
    "TRAIN_COMPUTE = 'n1-standard-4'\n",
    "DEPLOY_COMPUTE = 'n1-standard-4'\n",
    "TRAIN_IMAGE = 'us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-12.py310:latest'\n",
    "DEPLOY_IMAGE ='us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-12:latest'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440e1238",
   "metadata": {},
   "source": [
    "### Setup Training Job\n",
    "\n",
    "Run the job with [`aiplatform.CustomJob.from_local_script()`](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.CustomJob#google_cloud_aiplatform_CustomJob_from_local_script)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c305011",
   "metadata": {},
   "outputs": [],
   "source": [
    "CMDARGS = [\n",
    "    \"--epochs=\" + str(EPOCHS),\n",
    "    \"--batch_size=\" + str(BATCH_SIZE),\n",
    "    \"--var_target=\" + VAR_TARGET,\n",
    "    \"--var_omit=\" + VAR_OMIT,\n",
    "    \"--project_id=\" + PROJECT_ID,\n",
    "    \"--bq_project=\" + BQ_PROJECT,\n",
    "    \"--bq_dataset=\" + BQ_DATASET,\n",
    "    \"--bq_table=\" + BQ_TABLE,\n",
    "    \"--region=\" + REGION,\n",
    "    \"--experiment=\" + EXPERIMENT,\n",
    "    \"--series=\" + SERIES,\n",
    "    \"--experiment_name=\" + EXPERIMENT_NAME,\n",
    "    \"--run_name=\" + RUN_NAME\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a5c364a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training script copied to:\n",
      "gs://statmike-mlops-349915/05/05a/models/20240222135907/aiplatform-2024-02-22-13:59:13.980-aiplatform_custom_trainer_script-0.1.tar.gz.\n"
     ]
    }
   ],
   "source": [
    "customJob = aiplatform.CustomJob.from_local_script(\n",
    "    display_name = f'{SERIES}_{EXPERIMENT}_{TIMESTAMP}',\n",
    "    script_path = SCRIPT_PATH,\n",
    "    container_uri = TRAIN_IMAGE,\n",
    "    args = CMDARGS,\n",
    "    requirements = ['tensorflow_io', f'google-cloud-aiplatform>={aiplatform.__version__}', 'db-dtypes', f\"protobuf>={importlib.metadata.version('protobuf')}\"],\n",
    "    replica_count = 1,\n",
    "    machine_type = TRAIN_COMPUTE,\n",
    "    accelerator_count = 0,\n",
    "    base_output_dir = f\"{URI}/models/{TIMESTAMP}\",\n",
    "    staging_bucket = f\"{URI}/models/{TIMESTAMP}\",\n",
    "    labels = {'series' : f'{SERIES}', 'experiment' : f'{EXPERIMENT}', 'experiment_name' : f'{EXPERIMENT_NAME}', 'run_name' : f'{RUN_NAME}'}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e0e344",
   "metadata": {},
   "source": [
    "### Run Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f75aeea",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating CustomJob\n",
      "CustomJob created. Resource name: projects/1026793852137/locations/us-central1/customJobs/5645855250712625152\n",
      "To use this CustomJob in another session:\n",
      "custom_job = aiplatform.CustomJob.get('projects/1026793852137/locations/us-central1/customJobs/5645855250712625152')\n",
      "View Custom Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/5645855250712625152?project=1026793852137\n",
      "View Tensorboard:\n",
      "https://us-central1.tensorboard.googleusercontent.com/experiment/projects+1026793852137+locations+us-central1+tensorboards+7876136041294331904+experiments+5645855250712625152\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_QUEUED\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/5645855250712625152 current state:\n",
      "JobState.JOB_STATE_SUCCEEDED\n",
      "CustomJob run completed. Resource name: projects/1026793852137/locations/us-central1/customJobs/5645855250712625152\n"
     ]
    }
   ],
   "source": [
    "customJob.run(\n",
    "    service_account = SERVICE_ACCOUNT,\n",
    "    tensorboard = tb.resource_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df3733c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'05_05a_20240222135907'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customJob.display_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59b8bc85-064e-4af4-be7a-86f73c91cabe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/1026793852137/locations/us-central1/customJobs/5645855250712625152'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customJob.resource_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7359cf-9c8d-4d25-8091-0c69d6824fa4",
   "metadata": {},
   "source": [
    "Create hyperlinks to job and tensorboard here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b926f13e-593a-49c8-ac32-d877fef73015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review the Custom Job here:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/training/5645855250712625152/cpu?cloudshell=false&project=statmike-mlops-349915\n",
      "Review the TensorBoard From the Job here:\n",
      "https://us-central1.tensorboard.googleusercontent.com/experiment/projects+1026793852137+locations+us-central1+tensorboards+7876136041294331904+experiments+5645855250712625152\n"
     ]
    }
   ],
   "source": [
    "job_link = f\"https://console.cloud.google.com/vertex-ai/locations/{REGION}/training/{customJob.resource_name.split('/')[-1]}/cpu?cloudshell=false&project={PROJECT_ID}\"\n",
    "board_link = f\"https://{REGION}.tensorboard.googleusercontent.com/experiment/{tb.resource_name.replace('/', '+')}+experiments+{customJob.resource_name.split('/')[-1]}\"\n",
    "\n",
    "print(f'Review the Custom Job here:\\n{job_link}')\n",
    "print(f'Review the TensorBoard From the Job here:\\n{board_link}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a809833",
   "metadata": {},
   "source": [
    "---\n",
    "## Serving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fd1f7c",
   "metadata": {},
   "source": [
    "### Upload The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40653522-1017-45a0-94d7-2995c7e8374a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Already in Registry:\n",
      "Loading model as new default version.\n",
      "Creating Model\n",
      "Create Model backing LRO: projects/1026793852137/locations/us-central1/models/model_05_05a/operations/7205917767826931712\n",
      "Model created. Resource name: projects/1026793852137/locations/us-central1/models/model_05_05a@22\n",
      "To use this Model in another session:\n",
      "model = aiplatform.Model('projects/1026793852137/locations/us-central1/models/model_05_05a@22')\n"
     ]
    }
   ],
   "source": [
    "modelmatch = aiplatform.Model.list(filter = f'display_name={SERIES}_{EXPERIMENT} AND labels.series={SERIES} AND labels.experiment={EXPERIMENT}')\n",
    "\n",
    "upload_model = True\n",
    "if modelmatch:\n",
    "    print(\"Model Already in Registry:\")\n",
    "    if RUN_NAME in modelmatch[0].version_aliases:\n",
    "        print(\"This version already loaded, no action taken.\")\n",
    "        upload_model = False\n",
    "        model = aiplatform.Model(model_name = modelmatch[0].resource_name)\n",
    "    else:\n",
    "        print('Loading model as new default version.')\n",
    "        parent_model = modelmatch[0].resource_name\n",
    "\n",
    "else:\n",
    "    print('This is a new model, creating in model registry')\n",
    "    parent_model = ''\n",
    "\n",
    "if upload_model:\n",
    "    model = aiplatform.Model.upload(\n",
    "        display_name = f'{SERIES}_{EXPERIMENT}',\n",
    "        model_id = f'model_{SERIES}_{EXPERIMENT}',\n",
    "        parent_model =  parent_model,\n",
    "        serving_container_image_uri = DEPLOY_IMAGE,\n",
    "        artifact_uri = f\"{URI}/models/{TIMESTAMP}/model\",\n",
    "        is_default_version = True,\n",
    "        version_aliases = [RUN_NAME],\n",
    "        version_description = RUN_NAME,\n",
    "        labels = {'series' : f'{SERIES}', 'experiment' : f'{EXPERIMENT}', 'experiment_name' : f'{EXPERIMENT_NAME}', 'run_name' : f'{RUN_NAME}'}        \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aec367e-16a2-478a-8d56-5b849e258c3e",
   "metadata": {},
   "source": [
    ">**Note** on Version Aliases:\n",
    ">Expectation is a name starting with `a-z` that can include `[a-zA-Z0-9-]`\n",
    ">\n",
    ">**Retrieve a Model Resource**\n",
    ">[aiplatform.Model()](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.Model)\n",
    ">```Python\n",
    "model = aiplatform.Model(model_name = f'model_{SERIES}_{EXPERIMENT}') # retrieves default version\n",
    "model = aiplatform.Model(model_name = f'model_{SERIES}_{EXPERIMENT}@time-{TIMESTAMP}') # retrieves specific version\n",
    "model = aiplatform.Model(model_name = f'model_{SERIES}_{EXPERIMENT}', version = f'time-{TIMESTAMP}') # retrieves specific version\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f6403f1d-c1a7-44a4-89ab-4ce322ac6ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review the model in the Vertex AI Model Registry:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/models/model_05_05a?project=statmike-mlops-349915\n"
     ]
    }
   ],
   "source": [
    "print(f'Review the model in the Vertex AI Model Registry:\\nhttps://console.cloud.google.com/vertex-ai/locations/{REGION}/models/{model.name}?project={PROJECT_ID}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9ffc84-db1e-419b-8cd5-9cfcf027523f",
   "metadata": {},
   "source": [
    "### Vertex AI Experiment Update and Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a2373fd9-f25b-4377-9022-f72127b14c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "expRun = aiplatform.ExperimentRun(run_name = RUN_NAME, experiment = EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c435dfbe-69ba-4778-9d98-9ae59556373d",
   "metadata": {},
   "outputs": [],
   "source": [
    "expRun.log_params({\n",
    "    'model.uri': model.uri,\n",
    "    'model.display_name': model.display_name,\n",
    "    'model.name': model.name,\n",
    "    'model.resource_name': model.resource_name,\n",
    "    'model.version_id': model.version_id,\n",
    "    'model.versioned_resource_name': model.versioned_resource_name,\n",
    "    'customJobs.display_name': customJob.display_name,\n",
    "    'customJobs.resource_name': customJob.resource_name,\n",
    "    'customJobs.link': job_link,\n",
    "    'customJobs.tensorboard': board_link\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5882d87-50dc-42c6-9eab-bcc95f7d981c",
   "metadata": {},
   "source": [
    "Complete the experiment run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f4134d53-cea2-42da-a4d6-b6c71e835b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "expRun.update_state(state = aiplatform.gapic.Execution.State.COMPLETE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a436b46-67e8-484e-af81-917dced1f51d",
   "metadata": {},
   "source": [
    "Retrieve the experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57b4e1d3-9836-4aac-9286-c0a07d4ccdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = aiplatform.Experiment(experiment_name = EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "65d603e1-b034-4469-a245-de9ab1334d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>run_name</th>\n",
       "      <th>run_type</th>\n",
       "      <th>state</th>\n",
       "      <th>param.training.epochs</th>\n",
       "      <th>param.training.shuffle</th>\n",
       "      <th>param.customJobs.resource_name</th>\n",
       "      <th>param.model.version_id</th>\n",
       "      <th>param.customJobs.tensorboard</th>\n",
       "      <th>param.model.name</th>\n",
       "      <th>...</th>\n",
       "      <th>metric.train_loss</th>\n",
       "      <th>metric.test_accuracy</th>\n",
       "      <th>metric.train_auprc</th>\n",
       "      <th>metric.train_accuracy</th>\n",
       "      <th>time_series_metric.val_auprc</th>\n",
       "      <th>time_series_metric.train_auprc</th>\n",
       "      <th>time_series_metric.val_accuracy</th>\n",
       "      <th>time_series_metric.train_accuracy</th>\n",
       "      <th>time_series_metric.train_loss</th>\n",
       "      <th>time_series_metric.val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>experiment-05-05a-tf-classification-dnn</td>\n",
       "      <td>run-20240222135907</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>projects/1026793852137/locations/us-central1/c...</td>\n",
       "      <td>22</td>\n",
       "      <td>https://us-central1.tensorboard.googleusercont...</td>\n",
       "      <td>model_05_05a</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006899</td>\n",
       "      <td>0.999263</td>\n",
       "      <td>0.999374</td>\n",
       "      <td>0.999237</td>\n",
       "      <td>0.999483</td>\n",
       "      <td>0.999453</td>\n",
       "      <td>0.999115</td>\n",
       "      <td>0.999241</td>\n",
       "      <td>0.005181</td>\n",
       "      <td>0.006963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>experiment-05-05a-tf-classification-dnn</td>\n",
       "      <td>run-20231221182010</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>projects/1026793852137/locations/us-central1/c...</td>\n",
       "      <td>21</td>\n",
       "      <td>https://us-central1.tensorboard.googleusercont...</td>\n",
       "      <td>model_05_05a</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006786</td>\n",
       "      <td>0.999123</td>\n",
       "      <td>0.999431</td>\n",
       "      <td>0.999066</td>\n",
       "      <td>0.999431</td>\n",
       "      <td>0.999560</td>\n",
       "      <td>0.999009</td>\n",
       "      <td>0.999202</td>\n",
       "      <td>0.004724</td>\n",
       "      <td>0.006656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>experiment-05-05a-tf-classification-dnn</td>\n",
       "      <td>run-20231221175611</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>RUNNING</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>experiment-05-05a-tf-classification-dnn</td>\n",
       "      <td>run-20231221013301</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>projects/1026793852137/locations/us-central1/c...</td>\n",
       "      <td>20</td>\n",
       "      <td>https://us-central1.tensorboard.googleusercont...</td>\n",
       "      <td>model_05_05a</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006357</td>\n",
       "      <td>0.999439</td>\n",
       "      <td>0.999430</td>\n",
       "      <td>0.999320</td>\n",
       "      <td>0.999528</td>\n",
       "      <td>0.999522</td>\n",
       "      <td>0.999079</td>\n",
       "      <td>0.999290</td>\n",
       "      <td>0.004386</td>\n",
       "      <td>0.006117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>experiment-05-05a-tf-classification-dnn</td>\n",
       "      <td>run-20231221010255</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>projects/1026793852137/locations/us-central1/c...</td>\n",
       "      <td>19</td>\n",
       "      <td>https://us-central1.tensorboard.googleusercont...</td>\n",
       "      <td>model_05_05a</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006426</td>\n",
       "      <td>0.999298</td>\n",
       "      <td>0.999371</td>\n",
       "      <td>0.999237</td>\n",
       "      <td>0.999388</td>\n",
       "      <td>0.999436</td>\n",
       "      <td>0.999186</td>\n",
       "      <td>0.999110</td>\n",
       "      <td>0.005539</td>\n",
       "      <td>0.005936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>experiment-05-05a-tf-classification-dnn</td>\n",
       "      <td>run-20231220223853</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>RUNNING</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>experiment-05-05a-tf-classification-dnn</td>\n",
       "      <td>run-20231220223157</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>RUNNING</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>experiment-05-05a-tf-classification-dnn</td>\n",
       "      <td>run-20231220220654</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>RUNNING</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>experiment-05-05a-tf-classification-dnn</td>\n",
       "      <td>run-20231217142807</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>projects/1026793852137/locations/us-central1/c...</td>\n",
       "      <td>18</td>\n",
       "      <td>https://us-central1.tensorboard.googleusercont...</td>\n",
       "      <td>model_05_05a</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005391</td>\n",
       "      <td>0.999368</td>\n",
       "      <td>0.999529</td>\n",
       "      <td>0.999180</td>\n",
       "      <td>0.999523</td>\n",
       "      <td>0.999640</td>\n",
       "      <td>0.999221</td>\n",
       "      <td>0.999189</td>\n",
       "      <td>0.004216</td>\n",
       "      <td>0.005396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>experiment-05-05a-tf-classification-dnn</td>\n",
       "      <td>run-20231217134246</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>projects/1026793852137/locations/us-central1/c...</td>\n",
       "      <td>17</td>\n",
       "      <td>https://us-central1.tensorboard.googleusercont...</td>\n",
       "      <td>model_05_05a</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005509</td>\n",
       "      <td>0.999263</td>\n",
       "      <td>0.999432</td>\n",
       "      <td>0.999228</td>\n",
       "      <td>0.999484</td>\n",
       "      <td>0.999559</td>\n",
       "      <td>0.999009</td>\n",
       "      <td>0.999158</td>\n",
       "      <td>0.004695</td>\n",
       "      <td>0.005886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>experiment-05-05a-tf-classification-dnn</td>\n",
       "      <td>run-20231216020305</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007175</td>\n",
       "      <td>0.999263</td>\n",
       "      <td>0.999445</td>\n",
       "      <td>0.999228</td>\n",
       "      <td>0.999435</td>\n",
       "      <td>0.999487</td>\n",
       "      <td>0.999186</td>\n",
       "      <td>0.999233</td>\n",
       "      <td>0.005041</td>\n",
       "      <td>0.006313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>experiment-05-05a-tf-classification-dnn</td>\n",
       "      <td>run-20231003202509</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>projects/1026793852137/locations/us-central1/c...</td>\n",
       "      <td>16</td>\n",
       "      <td>https://us-central1.tensorboard.googleusercont...</td>\n",
       "      <td>model_05_05a</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007199</td>\n",
       "      <td>0.999088</td>\n",
       "      <td>0.999318</td>\n",
       "      <td>0.999132</td>\n",
       "      <td>0.999335</td>\n",
       "      <td>0.999501</td>\n",
       "      <td>0.999009</td>\n",
       "      <td>0.999241</td>\n",
       "      <td>0.004726</td>\n",
       "      <td>0.007048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>experiment-05-05a-tf-classification-dnn</td>\n",
       "      <td>run-20231003161407</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>projects/1026793852137/locations/us-central1/c...</td>\n",
       "      <td>15</td>\n",
       "      <td>https://us-central1.tensorboard.googleusercont...</td>\n",
       "      <td>model_05_05a</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.999368</td>\n",
       "      <td>0.999374</td>\n",
       "      <td>0.999294</td>\n",
       "      <td>0.999252</td>\n",
       "      <td>0.999462</td>\n",
       "      <td>0.999150</td>\n",
       "      <td>0.999176</td>\n",
       "      <td>0.005013</td>\n",
       "      <td>0.006658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>experiment-05-05a-tf-classification-dnn</td>\n",
       "      <td>run-20231002164113</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>projects/1026793852137/locations/us-central1/c...</td>\n",
       "      <td>14</td>\n",
       "      <td>https://us-central1.tensorboard.googleusercont...</td>\n",
       "      <td>model_05_05a</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007809</td>\n",
       "      <td>0.999193</td>\n",
       "      <td>0.999357</td>\n",
       "      <td>0.999189</td>\n",
       "      <td>0.999243</td>\n",
       "      <td>0.999408</td>\n",
       "      <td>0.999079</td>\n",
       "      <td>0.999255</td>\n",
       "      <td>0.005275</td>\n",
       "      <td>0.008391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>experiment-05-05a-tf-classification-dnn</td>\n",
       "      <td>run-20231002112215</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>projects/1026793852137/locations/us-central1/c...</td>\n",
       "      <td>13</td>\n",
       "      <td>https://us-central1.tensorboard.googleusercont...</td>\n",
       "      <td>model_05_05a</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006074</td>\n",
       "      <td>0.999368</td>\n",
       "      <td>0.999431</td>\n",
       "      <td>0.999320</td>\n",
       "      <td>0.999531</td>\n",
       "      <td>0.999532</td>\n",
       "      <td>0.999292</td>\n",
       "      <td>0.999241</td>\n",
       "      <td>0.004682</td>\n",
       "      <td>0.005645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>experiment-05-05a-tf-classification-dnn</td>\n",
       "      <td>run-20231002102623</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>projects/1026793852137/locations/us-central1/c...</td>\n",
       "      <td>12</td>\n",
       "      <td>https://us-central1.tensorboard.googleusercont...</td>\n",
       "      <td>model_05_05a</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007651</td>\n",
       "      <td>0.999228</td>\n",
       "      <td>0.999355</td>\n",
       "      <td>0.999228</td>\n",
       "      <td>0.999436</td>\n",
       "      <td>0.999441</td>\n",
       "      <td>0.999044</td>\n",
       "      <td>0.999259</td>\n",
       "      <td>0.005233</td>\n",
       "      <td>0.006887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>experiment-05-05a-tf-classification-dnn</td>\n",
       "      <td>run-20231001235637</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>projects/1026793852137/locations/us-central1/c...</td>\n",
       "      <td>11</td>\n",
       "      <td>https://us-central1.tensorboard.googleusercont...</td>\n",
       "      <td>model_05_05a</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006229</td>\n",
       "      <td>0.999263</td>\n",
       "      <td>0.999392</td>\n",
       "      <td>0.999294</td>\n",
       "      <td>0.999343</td>\n",
       "      <td>0.999493</td>\n",
       "      <td>0.999115</td>\n",
       "      <td>0.999290</td>\n",
       "      <td>0.004556</td>\n",
       "      <td>0.007068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>experiment-05-05a-tf-classification-dnn</td>\n",
       "      <td>run-20230930133138</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>projects/1026793852137/locations/us-central1/c...</td>\n",
       "      <td>10</td>\n",
       "      <td>https://us-central1.tensorboard.googleusercont...</td>\n",
       "      <td>model_05_05a</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006334</td>\n",
       "      <td>0.999298</td>\n",
       "      <td>0.999454</td>\n",
       "      <td>0.999320</td>\n",
       "      <td>0.999437</td>\n",
       "      <td>0.999498</td>\n",
       "      <td>0.999221</td>\n",
       "      <td>0.999277</td>\n",
       "      <td>0.004906</td>\n",
       "      <td>0.005926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>experiment-05-05a-tf-classification-dnn</td>\n",
       "      <td>run-20230929134956</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>projects/1026793852137/locations/us-central1/c...</td>\n",
       "      <td>9</td>\n",
       "      <td>https://us-central1.tensorboard.googleusercont...</td>\n",
       "      <td>model_05_05a</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008223</td>\n",
       "      <td>0.999123</td>\n",
       "      <td>0.999181</td>\n",
       "      <td>0.998970</td>\n",
       "      <td>0.999069</td>\n",
       "      <td>0.999402</td>\n",
       "      <td>0.998902</td>\n",
       "      <td>0.999114</td>\n",
       "      <td>0.005439</td>\n",
       "      <td>0.009168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>experiment-05-05a-tf-classification-dnn</td>\n",
       "      <td>run-20230928172600</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>0.999333</td>\n",
       "      <td>0.999449</td>\n",
       "      <td>0.999320</td>\n",
       "      <td>0.999531</td>\n",
       "      <td>0.999475</td>\n",
       "      <td>0.999256</td>\n",
       "      <td>0.999255</td>\n",
       "      <td>0.004837</td>\n",
       "      <td>0.005145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>experiment-05-05a-tf-classification-dnn</td>\n",
       "      <td>run-20230925162315</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>projects/1026793852137/locations/us-central1/c...</td>\n",
       "      <td>8</td>\n",
       "      <td>https://us-central1.tensorboard.googleusercont...</td>\n",
       "      <td>model_05_05a</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006491</td>\n",
       "      <td>0.999298</td>\n",
       "      <td>0.999357</td>\n",
       "      <td>0.999233</td>\n",
       "      <td>0.999250</td>\n",
       "      <td>0.999514</td>\n",
       "      <td>0.999079</td>\n",
       "      <td>0.999263</td>\n",
       "      <td>0.004704</td>\n",
       "      <td>0.006934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>experiment-05-05a-tf-classification-dnn</td>\n",
       "      <td>run-20230214162254</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>projects/1026793852137/locations/us-central1/c...</td>\n",
       "      <td>7</td>\n",
       "      <td>https://us-central1.tensorboard.googleusercont...</td>\n",
       "      <td>model_05_05a</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006769</td>\n",
       "      <td>0.999298</td>\n",
       "      <td>0.999427</td>\n",
       "      <td>0.999241</td>\n",
       "      <td>0.999527</td>\n",
       "      <td>0.999518</td>\n",
       "      <td>0.999186</td>\n",
       "      <td>0.999250</td>\n",
       "      <td>0.004856</td>\n",
       "      <td>0.005850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>experiment-05-05a-tf-classification-dnn</td>\n",
       "      <td>run-20230210132930</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>projects/1026793852137/locations/us-central1/c...</td>\n",
       "      <td>6</td>\n",
       "      <td>https://us-central1.tensorboard.googleusercont...</td>\n",
       "      <td>model_05_05a</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005908</td>\n",
       "      <td>0.999333</td>\n",
       "      <td>0.999469</td>\n",
       "      <td>0.999176</td>\n",
       "      <td>0.999433</td>\n",
       "      <td>0.999531</td>\n",
       "      <td>0.999115</td>\n",
       "      <td>0.999123</td>\n",
       "      <td>0.004924</td>\n",
       "      <td>0.005735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>experiment-05-05a-tf-classification-dnn</td>\n",
       "      <td>run-20230210122632</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>projects/1026793852137/locations/us-central1/c...</td>\n",
       "      <td>5</td>\n",
       "      <td>https://us-central1.tensorboard.googleusercont...</td>\n",
       "      <td>model_05_05a</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009487</td>\n",
       "      <td>0.999053</td>\n",
       "      <td>0.999199</td>\n",
       "      <td>0.999005</td>\n",
       "      <td>0.999049</td>\n",
       "      <td>0.999341</td>\n",
       "      <td>0.998973</td>\n",
       "      <td>0.999000</td>\n",
       "      <td>0.007158</td>\n",
       "      <td>0.010253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24 rows  41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            experiment_name            run_name  \\\n",
       "0   experiment-05-05a-tf-classification-dnn  run-20240222135907   \n",
       "1   experiment-05-05a-tf-classification-dnn  run-20231221182010   \n",
       "2   experiment-05-05a-tf-classification-dnn  run-20231221175611   \n",
       "3   experiment-05-05a-tf-classification-dnn  run-20231221013301   \n",
       "4   experiment-05-05a-tf-classification-dnn  run-20231221010255   \n",
       "5   experiment-05-05a-tf-classification-dnn  run-20231220223853   \n",
       "6   experiment-05-05a-tf-classification-dnn  run-20231220223157   \n",
       "7   experiment-05-05a-tf-classification-dnn  run-20231220220654   \n",
       "8   experiment-05-05a-tf-classification-dnn  run-20231217142807   \n",
       "9   experiment-05-05a-tf-classification-dnn  run-20231217134246   \n",
       "10  experiment-05-05a-tf-classification-dnn  run-20231216020305   \n",
       "11  experiment-05-05a-tf-classification-dnn  run-20231003202509   \n",
       "12  experiment-05-05a-tf-classification-dnn  run-20231003161407   \n",
       "13  experiment-05-05a-tf-classification-dnn  run-20231002164113   \n",
       "14  experiment-05-05a-tf-classification-dnn  run-20231002112215   \n",
       "15  experiment-05-05a-tf-classification-dnn  run-20231002102623   \n",
       "16  experiment-05-05a-tf-classification-dnn  run-20231001235637   \n",
       "17  experiment-05-05a-tf-classification-dnn  run-20230930133138   \n",
       "18  experiment-05-05a-tf-classification-dnn  run-20230929134956   \n",
       "19  experiment-05-05a-tf-classification-dnn  run-20230928172600   \n",
       "20  experiment-05-05a-tf-classification-dnn  run-20230925162315   \n",
       "21  experiment-05-05a-tf-classification-dnn  run-20230214162254   \n",
       "22  experiment-05-05a-tf-classification-dnn  run-20230210132930   \n",
       "23  experiment-05-05a-tf-classification-dnn  run-20230210122632   \n",
       "\n",
       "                run_type     state  param.training.epochs  \\\n",
       "0   system.ExperimentRun  COMPLETE                   10.0   \n",
       "1   system.ExperimentRun  COMPLETE                   10.0   \n",
       "2   system.ExperimentRun   RUNNING                    NaN   \n",
       "3   system.ExperimentRun  COMPLETE                   10.0   \n",
       "4   system.ExperimentRun  COMPLETE                   10.0   \n",
       "5   system.ExperimentRun   RUNNING                    NaN   \n",
       "6   system.ExperimentRun   RUNNING                    NaN   \n",
       "7   system.ExperimentRun   RUNNING                    NaN   \n",
       "8   system.ExperimentRun  COMPLETE                   10.0   \n",
       "9   system.ExperimentRun  COMPLETE                   10.0   \n",
       "10  system.ExperimentRun  COMPLETE                   10.0   \n",
       "11  system.ExperimentRun  COMPLETE                   10.0   \n",
       "12  system.ExperimentRun  COMPLETE                   10.0   \n",
       "13  system.ExperimentRun  COMPLETE                   10.0   \n",
       "14  system.ExperimentRun  COMPLETE                   10.0   \n",
       "15  system.ExperimentRun  COMPLETE                   10.0   \n",
       "16  system.ExperimentRun  COMPLETE                   10.0   \n",
       "17  system.ExperimentRun  COMPLETE                   10.0   \n",
       "18  system.ExperimentRun  COMPLETE                   10.0   \n",
       "19  system.ExperimentRun  COMPLETE                   10.0   \n",
       "20  system.ExperimentRun  COMPLETE                   10.0   \n",
       "21  system.ExperimentRun  COMPLETE                   10.0   \n",
       "22  system.ExperimentRun  COMPLETE                   10.0   \n",
       "23  system.ExperimentRun  COMPLETE                   10.0   \n",
       "\n",
       "    param.training.shuffle                     param.customJobs.resource_name  \\\n",
       "0                   1000.0  projects/1026793852137/locations/us-central1/c...   \n",
       "1                   1000.0  projects/1026793852137/locations/us-central1/c...   \n",
       "2                   1000.0                                                NaN   \n",
       "3                   1000.0  projects/1026793852137/locations/us-central1/c...   \n",
       "4                   1000.0  projects/1026793852137/locations/us-central1/c...   \n",
       "5                   1000.0                                                NaN   \n",
       "6                   1000.0                                                NaN   \n",
       "7                      NaN                                                NaN   \n",
       "8                   1000.0  projects/1026793852137/locations/us-central1/c...   \n",
       "9                   1000.0  projects/1026793852137/locations/us-central1/c...   \n",
       "10                  1000.0                                                NaN   \n",
       "11                  1000.0  projects/1026793852137/locations/us-central1/c...   \n",
       "12                  1000.0  projects/1026793852137/locations/us-central1/c...   \n",
       "13                  1000.0  projects/1026793852137/locations/us-central1/c...   \n",
       "14                  1000.0  projects/1026793852137/locations/us-central1/c...   \n",
       "15                  1000.0  projects/1026793852137/locations/us-central1/c...   \n",
       "16                  1000.0  projects/1026793852137/locations/us-central1/c...   \n",
       "17                  1000.0  projects/1026793852137/locations/us-central1/c...   \n",
       "18                  1000.0  projects/1026793852137/locations/us-central1/c...   \n",
       "19                  1000.0                                                NaN   \n",
       "20                  1000.0  projects/1026793852137/locations/us-central1/c...   \n",
       "21                  1000.0  projects/1026793852137/locations/us-central1/c...   \n",
       "22                  1000.0  projects/1026793852137/locations/us-central1/c...   \n",
       "23                  1000.0  projects/1026793852137/locations/us-central1/c...   \n",
       "\n",
       "   param.model.version_id                       param.customJobs.tensorboard  \\\n",
       "0                      22  https://us-central1.tensorboard.googleusercont...   \n",
       "1                      21  https://us-central1.tensorboard.googleusercont...   \n",
       "2                     NaN                                                NaN   \n",
       "3                      20  https://us-central1.tensorboard.googleusercont...   \n",
       "4                      19  https://us-central1.tensorboard.googleusercont...   \n",
       "5                     NaN                                                NaN   \n",
       "6                     NaN                                                NaN   \n",
       "7                     NaN                                                NaN   \n",
       "8                      18  https://us-central1.tensorboard.googleusercont...   \n",
       "9                      17  https://us-central1.tensorboard.googleusercont...   \n",
       "10                    NaN                                                NaN   \n",
       "11                     16  https://us-central1.tensorboard.googleusercont...   \n",
       "12                     15  https://us-central1.tensorboard.googleusercont...   \n",
       "13                     14  https://us-central1.tensorboard.googleusercont...   \n",
       "14                     13  https://us-central1.tensorboard.googleusercont...   \n",
       "15                     12  https://us-central1.tensorboard.googleusercont...   \n",
       "16                     11  https://us-central1.tensorboard.googleusercont...   \n",
       "17                     10  https://us-central1.tensorboard.googleusercont...   \n",
       "18                      9  https://us-central1.tensorboard.googleusercont...   \n",
       "19                    NaN                                                NaN   \n",
       "20                      8  https://us-central1.tensorboard.googleusercont...   \n",
       "21                      7  https://us-central1.tensorboard.googleusercont...   \n",
       "22                      6  https://us-central1.tensorboard.googleusercont...   \n",
       "23                      5  https://us-central1.tensorboard.googleusercont...   \n",
       "\n",
       "   param.model.name  ...  metric.train_loss metric.test_accuracy  \\\n",
       "0      model_05_05a  ...           0.006899             0.999263   \n",
       "1      model_05_05a  ...           0.006786             0.999123   \n",
       "2               NaN  ...                NaN                  NaN   \n",
       "3      model_05_05a  ...           0.006357             0.999439   \n",
       "4      model_05_05a  ...           0.006426             0.999298   \n",
       "5               NaN  ...                NaN                  NaN   \n",
       "6               NaN  ...                NaN                  NaN   \n",
       "7               NaN  ...                NaN                  NaN   \n",
       "8      model_05_05a  ...           0.005391             0.999368   \n",
       "9      model_05_05a  ...           0.005509             0.999263   \n",
       "10              NaN  ...           0.007175             0.999263   \n",
       "11     model_05_05a  ...           0.007199             0.999088   \n",
       "12     model_05_05a  ...           0.006399             0.999368   \n",
       "13     model_05_05a  ...           0.007809             0.999193   \n",
       "14     model_05_05a  ...           0.006074             0.999368   \n",
       "15     model_05_05a  ...           0.007651             0.999228   \n",
       "16     model_05_05a  ...           0.006229             0.999263   \n",
       "17     model_05_05a  ...           0.006334             0.999298   \n",
       "18     model_05_05a  ...           0.008223             0.999123   \n",
       "19              NaN  ...           0.005700             0.999333   \n",
       "20     model_05_05a  ...           0.006491             0.999298   \n",
       "21     model_05_05a  ...           0.006769             0.999298   \n",
       "22     model_05_05a  ...           0.005908             0.999333   \n",
       "23     model_05_05a  ...           0.009487             0.999053   \n",
       "\n",
       "    metric.train_auprc metric.train_accuracy time_series_metric.val_auprc  \\\n",
       "0             0.999374              0.999237                     0.999483   \n",
       "1             0.999431              0.999066                     0.999431   \n",
       "2                  NaN                   NaN                          NaN   \n",
       "3             0.999430              0.999320                     0.999528   \n",
       "4             0.999371              0.999237                     0.999388   \n",
       "5                  NaN                   NaN                          NaN   \n",
       "6                  NaN                   NaN                          NaN   \n",
       "7                  NaN                   NaN                          NaN   \n",
       "8             0.999529              0.999180                     0.999523   \n",
       "9             0.999432              0.999228                     0.999484   \n",
       "10            0.999445              0.999228                     0.999435   \n",
       "11            0.999318              0.999132                     0.999335   \n",
       "12            0.999374              0.999294                     0.999252   \n",
       "13            0.999357              0.999189                     0.999243   \n",
       "14            0.999431              0.999320                     0.999531   \n",
       "15            0.999355              0.999228                     0.999436   \n",
       "16            0.999392              0.999294                     0.999343   \n",
       "17            0.999454              0.999320                     0.999437   \n",
       "18            0.999181              0.998970                     0.999069   \n",
       "19            0.999449              0.999320                     0.999531   \n",
       "20            0.999357              0.999233                     0.999250   \n",
       "21            0.999427              0.999241                     0.999527   \n",
       "22            0.999469              0.999176                     0.999433   \n",
       "23            0.999199              0.999005                     0.999049   \n",
       "\n",
       "   time_series_metric.train_auprc time_series_metric.val_accuracy  \\\n",
       "0                        0.999453                        0.999115   \n",
       "1                        0.999560                        0.999009   \n",
       "2                             NaN                             NaN   \n",
       "3                        0.999522                        0.999079   \n",
       "4                        0.999436                        0.999186   \n",
       "5                             NaN                             NaN   \n",
       "6                             NaN                             NaN   \n",
       "7                             NaN                             NaN   \n",
       "8                        0.999640                        0.999221   \n",
       "9                        0.999559                        0.999009   \n",
       "10                       0.999487                        0.999186   \n",
       "11                       0.999501                        0.999009   \n",
       "12                       0.999462                        0.999150   \n",
       "13                       0.999408                        0.999079   \n",
       "14                       0.999532                        0.999292   \n",
       "15                       0.999441                        0.999044   \n",
       "16                       0.999493                        0.999115   \n",
       "17                       0.999498                        0.999221   \n",
       "18                       0.999402                        0.998902   \n",
       "19                       0.999475                        0.999256   \n",
       "20                       0.999514                        0.999079   \n",
       "21                       0.999518                        0.999186   \n",
       "22                       0.999531                        0.999115   \n",
       "23                       0.999341                        0.998973   \n",
       "\n",
       "   time_series_metric.train_accuracy time_series_metric.train_loss  \\\n",
       "0                           0.999241                      0.005181   \n",
       "1                           0.999202                      0.004724   \n",
       "2                                NaN                           NaN   \n",
       "3                           0.999290                      0.004386   \n",
       "4                           0.999110                      0.005539   \n",
       "5                                NaN                           NaN   \n",
       "6                                NaN                           NaN   \n",
       "7                                NaN                           NaN   \n",
       "8                           0.999189                      0.004216   \n",
       "9                           0.999158                      0.004695   \n",
       "10                          0.999233                      0.005041   \n",
       "11                          0.999241                      0.004726   \n",
       "12                          0.999176                      0.005013   \n",
       "13                          0.999255                      0.005275   \n",
       "14                          0.999241                      0.004682   \n",
       "15                          0.999259                      0.005233   \n",
       "16                          0.999290                      0.004556   \n",
       "17                          0.999277                      0.004906   \n",
       "18                          0.999114                      0.005439   \n",
       "19                          0.999255                      0.004837   \n",
       "20                          0.999263                      0.004704   \n",
       "21                          0.999250                      0.004856   \n",
       "22                          0.999123                      0.004924   \n",
       "23                          0.999000                      0.007158   \n",
       "\n",
       "   time_series_metric.val_loss  \n",
       "0                     0.006963  \n",
       "1                     0.006656  \n",
       "2                          NaN  \n",
       "3                     0.006117  \n",
       "4                     0.005936  \n",
       "5                          NaN  \n",
       "6                          NaN  \n",
       "7                          NaN  \n",
       "8                     0.005396  \n",
       "9                     0.005886  \n",
       "10                    0.006313  \n",
       "11                    0.007048  \n",
       "12                    0.006658  \n",
       "13                    0.008391  \n",
       "14                    0.005645  \n",
       "15                    0.006887  \n",
       "16                    0.007068  \n",
       "17                    0.005926  \n",
       "18                    0.009168  \n",
       "19                    0.005145  \n",
       "20                    0.006934  \n",
       "21                    0.005850  \n",
       "22                    0.005735  \n",
       "23                    0.010253  \n",
       "\n",
       "[24 rows x 41 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.get_data_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bed1ff3-0338-4576-b68b-9716593c254a",
   "metadata": {},
   "source": [
    "Review the Experiments TensorBoard to compare runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3ce18389-8484-4d5d-a30e-c4841eb52e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Experiment TensorBoard Link:\n",
      "https://us-central1.tensorboard.googleusercontent.com/experiment/projects+1026793852137+locations+us-central1+tensorboards+7876136041294331904+experiments+experiment-05-05a-tf-classification-dnn\n"
     ]
    }
   ],
   "source": [
    "print(f\"The Experiment TensorBoard Link:\\nhttps://{REGION}.tensorboard.googleusercontent.com/experiment/{tb.resource_name.replace('/', '+')}+experiments+{exp.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "37b9fded-da22-4c24-8d8c-54fefb07e1db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>wall_time</th>\n",
       "      <th>val_auprc</th>\n",
       "      <th>train_auprc</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-02-22 14:09:29.956000+00:00</td>\n",
       "      <td>0.998944</td>\n",
       "      <td>0.997525</td>\n",
       "      <td>0.998902</td>\n",
       "      <td>0.984982</td>\n",
       "      <td>0.058303</td>\n",
       "      <td>0.013537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-02-22 14:09:30.064000+00:00</td>\n",
       "      <td>0.999274</td>\n",
       "      <td>0.999278</td>\n",
       "      <td>0.999009</td>\n",
       "      <td>0.999167</td>\n",
       "      <td>0.009147</td>\n",
       "      <td>0.010164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2024-02-22 14:09:30.184000+00:00</td>\n",
       "      <td>0.999317</td>\n",
       "      <td>0.999353</td>\n",
       "      <td>0.999009</td>\n",
       "      <td>0.999255</td>\n",
       "      <td>0.007136</td>\n",
       "      <td>0.009021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2024-02-22 14:09:30.281000+00:00</td>\n",
       "      <td>0.999378</td>\n",
       "      <td>0.999386</td>\n",
       "      <td>0.999044</td>\n",
       "      <td>0.999277</td>\n",
       "      <td>0.006365</td>\n",
       "      <td>0.008441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2024-02-22 14:09:30.368000+00:00</td>\n",
       "      <td>0.999430</td>\n",
       "      <td>0.999402</td>\n",
       "      <td>0.999044</td>\n",
       "      <td>0.999285</td>\n",
       "      <td>0.006013</td>\n",
       "      <td>0.007969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2024-02-22 14:09:30.469000+00:00</td>\n",
       "      <td>0.999432</td>\n",
       "      <td>0.999389</td>\n",
       "      <td>0.999044</td>\n",
       "      <td>0.999294</td>\n",
       "      <td>0.005725</td>\n",
       "      <td>0.007686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2024-02-22 14:09:30.569000+00:00</td>\n",
       "      <td>0.999481</td>\n",
       "      <td>0.999397</td>\n",
       "      <td>0.999079</td>\n",
       "      <td>0.999259</td>\n",
       "      <td>0.005534</td>\n",
       "      <td>0.007394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>2024-02-22 14:09:30.667000+00:00</td>\n",
       "      <td>0.999482</td>\n",
       "      <td>0.999387</td>\n",
       "      <td>0.999115</td>\n",
       "      <td>0.999237</td>\n",
       "      <td>0.005395</td>\n",
       "      <td>0.007210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>2024-02-22 14:09:30.761000+00:00</td>\n",
       "      <td>0.999482</td>\n",
       "      <td>0.999446</td>\n",
       "      <td>0.999115</td>\n",
       "      <td>0.999233</td>\n",
       "      <td>0.005186</td>\n",
       "      <td>0.007098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2024-02-22 14:09:30.847000+00:00</td>\n",
       "      <td>0.999483</td>\n",
       "      <td>0.999453</td>\n",
       "      <td>0.999115</td>\n",
       "      <td>0.999241</td>\n",
       "      <td>0.005181</td>\n",
       "      <td>0.006963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step                        wall_time  val_auprc  train_auprc  \\\n",
       "0     1 2024-02-22 14:09:29.956000+00:00   0.998944     0.997525   \n",
       "1     2 2024-02-22 14:09:30.064000+00:00   0.999274     0.999278   \n",
       "2     3 2024-02-22 14:09:30.184000+00:00   0.999317     0.999353   \n",
       "3     4 2024-02-22 14:09:30.281000+00:00   0.999378     0.999386   \n",
       "4     5 2024-02-22 14:09:30.368000+00:00   0.999430     0.999402   \n",
       "5     6 2024-02-22 14:09:30.469000+00:00   0.999432     0.999389   \n",
       "6     7 2024-02-22 14:09:30.569000+00:00   0.999481     0.999397   \n",
       "7     8 2024-02-22 14:09:30.667000+00:00   0.999482     0.999387   \n",
       "8     9 2024-02-22 14:09:30.761000+00:00   0.999482     0.999446   \n",
       "9    10 2024-02-22 14:09:30.847000+00:00   0.999483     0.999453   \n",
       "\n",
       "   val_accuracy  train_accuracy  train_loss  val_loss  \n",
       "0      0.998902        0.984982    0.058303  0.013537  \n",
       "1      0.999009        0.999167    0.009147  0.010164  \n",
       "2      0.999009        0.999255    0.007136  0.009021  \n",
       "3      0.999044        0.999277    0.006365  0.008441  \n",
       "4      0.999044        0.999285    0.006013  0.007969  \n",
       "5      0.999044        0.999294    0.005725  0.007686  \n",
       "6      0.999079        0.999259    0.005534  0.007394  \n",
       "7      0.999115        0.999237    0.005395  0.007210  \n",
       "8      0.999115        0.999233    0.005186  0.007098  \n",
       "9      0.999115        0.999241    0.005181  0.006963  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expRun.get_time_series_data_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f74b90d-24da-4434-a187-7206170080ce",
   "metadata": {},
   "source": [
    "### Review Experiment and Run in Console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "28f78adc-51ae-4e04-957d-1449d6f7dc6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review The Experiment in the Console:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/experiments/experiment-05-05a-tf-classification-dnn?project=statmike-mlops-349915\n"
     ]
    }
   ],
   "source": [
    "print(f'Review The Experiment in the Console:\\nhttps://console.cloud.google.com/vertex-ai/locations/{REGION}/experiments/{EXPERIMENT_NAME}?project={PROJECT_ID}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c393d11a-46fc-4dcd-889b-d09cda962889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review The Experiment Run in the Console:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/experiments/experiment-05-05a-tf-classification-dnn/runs/experiment-05-05a-tf-classification-dnn-run-20240222135907?project=statmike-mlops-349915\n"
     ]
    }
   ],
   "source": [
    "print(f'Review The Experiment Run in the Console:\\nhttps://console.cloud.google.com/vertex-ai/locations/{REGION}/experiments/{EXPERIMENT_NAME}/runs/{EXPERIMENT_NAME}-{RUN_NAME}?project={PROJECT_ID}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323255a7-7a2b-4fbc-903d-99f8acccbefd",
   "metadata": {},
   "source": [
    "### Compare This Run Using Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71018f73-89c9-4929-b7d6-dd358d894840",
   "metadata": {
    "tags": []
   },
   "source": [
    "Get a list of all experiments in this project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bb42949a-a4ab-4ef0-b163-ce89d2b58c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = aiplatform.Experiment.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7190cdbb-96b8-41b2-b724-f0580225990f",
   "metadata": {},
   "source": [
    "Remove experiments not in the SERIES:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d9fd9424-3b50-4921-868e-e08eb6e2c033",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [e for e in experiments if e.name.split('-')[0:2] == ['experiment', SERIES]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286f472c-7584-45ef-906d-1c1ca1bbba57",
   "metadata": {},
   "source": [
    "Combine the runs from all experiments in SERIES into a single dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eb7352f4-d50a-43c1-a342-a15ba06b1ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment-05-05f-tf-classification-dnn\n",
      "experiment-05-05f2-tf-classification-dnn\n",
      "experiment-05-05i-tf-classification-dnn\n",
      "experiment-05-05h-tf-classification-dnn\n",
      "experiment-05-05g-tf-classification-dnn\n",
      "experiment-05-05e-tf-classification-dnn\n",
      "experiment-05-05d-tf-classification-dnn\n",
      "experiment-05-05c-tf-classification-dnn\n",
      "experiment-05-05b-tf-classification-dnn\n",
      "experiment-05-05a-tf-classification-dnn\n",
      "experiment-05-05-tf-classification-dnn\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for experiment in experiments:\n",
    "        results.append(experiment.get_data_frame())\n",
    "        print(experiment.name)\n",
    "results = pd.concat(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b13ca3-4180-4d40-b007-49b7229ca784",
   "metadata": {},
   "source": [
    "Create ranks for models within experiment and across the entire SERIES:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7cd876a4-7984-4687-b42b-c829952c2ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>run_name</th>\n",
       "      <th>param.model.display_name</th>\n",
       "      <th>param.model.version_id</th>\n",
       "      <th>metric.test_auprc</th>\n",
       "      <th>series_rank</th>\n",
       "      <th>experiment_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>experiment-05-05-tf-classification-dnn</td>\n",
       "      <td>run-20230210115433</td>\n",
       "      <td>05_05</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999130</td>\n",
       "      <td>44.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>experiment-05-05-tf-classification-dnn</td>\n",
       "      <td>run-20230308225745</td>\n",
       "      <td>05_05</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999469</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>experiment-05-05-tf-classification-dnn</td>\n",
       "      <td>run-20230324103811</td>\n",
       "      <td>05_05</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999299</td>\n",
       "      <td>38.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>experiment-05-05-tf-classification-dnn</td>\n",
       "      <td>run-20230327111418</td>\n",
       "      <td>05_05</td>\n",
       "      <td>12</td>\n",
       "      <td>0.999431</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>experiment-05-05-tf-classification-dnn</td>\n",
       "      <td>run-20231220191718</td>\n",
       "      <td>05_05</td>\n",
       "      <td>14</td>\n",
       "      <td>0.999236</td>\n",
       "      <td>42.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>experiment-05-05-tf-classification-dnn</td>\n",
       "      <td>run-20231220203613</td>\n",
       "      <td>05_05</td>\n",
       "      <td>15</td>\n",
       "      <td>0.999511</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>experiment-05-05-tf-classification-dnn</td>\n",
       "      <td>run-20231220214331</td>\n",
       "      <td>05_05</td>\n",
       "      <td>16</td>\n",
       "      <td>0.999377</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>experiment-05-05-tf-classification-dnn</td>\n",
       "      <td>run-20231221021319</td>\n",
       "      <td>05_05</td>\n",
       "      <td>17</td>\n",
       "      <td>0.999453</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>experiment-05-05-tf-classification-dnn</td>\n",
       "      <td>run-20231221123117</td>\n",
       "      <td>05_05</td>\n",
       "      <td>18</td>\n",
       "      <td>0.999649</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>experiment-05-05a-tf-classification-dnn</td>\n",
       "      <td>run-20230210122632</td>\n",
       "      <td>05_05a</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999154</td>\n",
       "      <td>43.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>experiment-05-05a-tf-classification-dnn</td>\n",
       "      <td>run-20230210132930</td>\n",
       "      <td>05_05a</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999578</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>experiment-05-05a-tf-classification-dnn</td>\n",
       "      <td>run-20230214162254</td>\n",
       "      <td>05_05a</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999484</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>experiment-05-05a-tf-classification-dnn</td>\n",
       "      <td>run-20230925162315</td>\n",
       "      <td>05_05a</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999259</td>\n",
       "      <td>40.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>experiment-05-05a-tf-classification-dnn</td>\n",
       "      <td>run-20230929134956</td>\n",
       "      <td>05_05a</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999123</td>\n",
       "      <td>45.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>experiment-05-05a-tf-classification-dnn</td>\n",
       "      <td>run-20230930133138</td>\n",
       "      <td>05_05a</td>\n",
       "      <td>10</td>\n",
       "      <td>0.999397</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>experiment-05-05a-tf-classification-dnn</td>\n",
       "      <td>run-20231001235637</td>\n",
       "      <td>05_05a</td>\n",
       "      <td>11</td>\n",
       "      <td>0.999351</td>\n",
       "      <td>32.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>experiment-05-05a-tf-classification-dnn</td>\n",
       "      <td>run-20231002102623</td>\n",
       "      <td>05_05a</td>\n",
       "      <td>12</td>\n",
       "      <td>0.999395</td>\n",
       "      <td>27.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>experiment-05-05a-tf-classification-dnn</td>\n",
       "      <td>run-20231002112215</td>\n",
       "      <td>05_05a</td>\n",
       "      <td>13</td>\n",
       "      <td>0.999534</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>experiment-05-05a-tf-classification-dnn</td>\n",
       "      <td>run-20231002164113</td>\n",
       "      <td>05_05a</td>\n",
       "      <td>14</td>\n",
       "      <td>0.999346</td>\n",
       "      <td>34.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>experiment-05-05a-tf-classification-dnn</td>\n",
       "      <td>run-20231003161407</td>\n",
       "      <td>05_05a</td>\n",
       "      <td>15</td>\n",
       "      <td>0.999397</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>experiment-05-05a-tf-classification-dnn</td>\n",
       "      <td>run-20231003202509</td>\n",
       "      <td>05_05a</td>\n",
       "      <td>16</td>\n",
       "      <td>0.999341</td>\n",
       "      <td>36.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>experiment-05-05a-tf-classification-dnn</td>\n",
       "      <td>run-20231217134246</td>\n",
       "      <td>05_05a</td>\n",
       "      <td>17</td>\n",
       "      <td>0.999535</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>experiment-05-05a-tf-classification-dnn</td>\n",
       "      <td>run-20231217142807</td>\n",
       "      <td>05_05a</td>\n",
       "      <td>18</td>\n",
       "      <td>0.999576</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>experiment-05-05a-tf-classification-dnn</td>\n",
       "      <td>run-20231221010255</td>\n",
       "      <td>05_05a</td>\n",
       "      <td>19</td>\n",
       "      <td>0.999349</td>\n",
       "      <td>33.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>experiment-05-05a-tf-classification-dnn</td>\n",
       "      <td>run-20231221013301</td>\n",
       "      <td>05_05a</td>\n",
       "      <td>20</td>\n",
       "      <td>0.999533</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>experiment-05-05a-tf-classification-dnn</td>\n",
       "      <td>run-20231221182010</td>\n",
       "      <td>05_05a</td>\n",
       "      <td>21</td>\n",
       "      <td>0.999483</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>experiment-05-05a-tf-classification-dnn</td>\n",
       "      <td>run-20240222135907</td>\n",
       "      <td>05_05a</td>\n",
       "      <td>22</td>\n",
       "      <td>0.999397</td>\n",
       "      <td>26.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>experiment-05-05b-tf-classification-dnn</td>\n",
       "      <td>run-20230210130602</td>\n",
       "      <td>05_05b</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999341</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>experiment-05-05b-tf-classification-dnn</td>\n",
       "      <td>run-20231220154420</td>\n",
       "      <td>05_05b</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999261</td>\n",
       "      <td>39.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>experiment-05-05b-tf-classification-dnn</td>\n",
       "      <td>run-20231221012719</td>\n",
       "      <td>05_05b</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999483</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>experiment-05-05b-tf-classification-dnn</td>\n",
       "      <td>run-20231221020002</td>\n",
       "      <td>05_05b</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999389</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>experiment-05-05b-tf-classification-dnn</td>\n",
       "      <td>run-20231221183939</td>\n",
       "      <td>05_05b</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999337</td>\n",
       "      <td>37.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>experiment-05-05c-tf-classification-dnn</td>\n",
       "      <td>run-20230210130701</td>\n",
       "      <td>05_05c</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999533</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>experiment-05-05c-tf-classification-dnn</td>\n",
       "      <td>run-20231220172443</td>\n",
       "      <td>05_05c</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>experiment-05-05c-tf-classification-dnn</td>\n",
       "      <td>run-20231221015345</td>\n",
       "      <td>05_05c</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999531</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>experiment-05-05c-tf-classification-dnn</td>\n",
       "      <td>run-20231221185424</td>\n",
       "      <td>05_05c</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999393</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>experiment-05-05d-tf-classification-dnn</td>\n",
       "      <td>run-20230211141913</td>\n",
       "      <td>05_05d</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999527</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>experiment-05-05d-tf-classification-dnn</td>\n",
       "      <td>run-20231223160024</td>\n",
       "      <td>05_05d</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999387</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>experiment-05-05e-tf-classification-dnn</td>\n",
       "      <td>run-20230211141838</td>\n",
       "      <td>05_05e</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999532</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>experiment-05-05e-tf-classification-dnn</td>\n",
       "      <td>run-20231223160116</td>\n",
       "      <td>05_05e</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999530</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>experiment-05-05f-tf-classification-dnn</td>\n",
       "      <td>run-20230211141850</td>\n",
       "      <td>05_05f</td>\n",
       "      <td>19</td>\n",
       "      <td>0.999443</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>experiment-05-05f-tf-classification-dnn</td>\n",
       "      <td>run-20231223162317</td>\n",
       "      <td>05_05f</td>\n",
       "      <td>66</td>\n",
       "      <td>0.999530</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>experiment-05-05g-tf-classification-dnn</td>\n",
       "      <td>run-20230211145013-5</td>\n",
       "      <td>05_05g</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999539</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20230211221917-3</td>\n",
       "      <td>05_05h</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999658</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>experiment-05-05i-tf-classification-dnn</td>\n",
       "      <td>run-20230211221928-11</td>\n",
       "      <td>05_05i</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999584</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             experiment_name               run_name  \\\n",
       "173   experiment-05-05-tf-classification-dnn     run-20230210115433   \n",
       "171   experiment-05-05-tf-classification-dnn     run-20230308225745   \n",
       "170   experiment-05-05-tf-classification-dnn     run-20230324103811   \n",
       "155   experiment-05-05-tf-classification-dnn     run-20230327111418   \n",
       "147   experiment-05-05-tf-classification-dnn     run-20231220191718   \n",
       "146   experiment-05-05-tf-classification-dnn     run-20231220203613   \n",
       "145   experiment-05-05-tf-classification-dnn     run-20231220214331   \n",
       "144   experiment-05-05-tf-classification-dnn     run-20231221021319   \n",
       "143   experiment-05-05-tf-classification-dnn     run-20231221123117   \n",
       "142  experiment-05-05a-tf-classification-dnn     run-20230210122632   \n",
       "141  experiment-05-05a-tf-classification-dnn     run-20230210132930   \n",
       "140  experiment-05-05a-tf-classification-dnn     run-20230214162254   \n",
       "139  experiment-05-05a-tf-classification-dnn     run-20230925162315   \n",
       "137  experiment-05-05a-tf-classification-dnn     run-20230929134956   \n",
       "136  experiment-05-05a-tf-classification-dnn     run-20230930133138   \n",
       "135  experiment-05-05a-tf-classification-dnn     run-20231001235637   \n",
       "134  experiment-05-05a-tf-classification-dnn     run-20231002102623   \n",
       "133  experiment-05-05a-tf-classification-dnn     run-20231002112215   \n",
       "132  experiment-05-05a-tf-classification-dnn     run-20231002164113   \n",
       "131  experiment-05-05a-tf-classification-dnn     run-20231003161407   \n",
       "130  experiment-05-05a-tf-classification-dnn     run-20231003202509   \n",
       "128  experiment-05-05a-tf-classification-dnn     run-20231217134246   \n",
       "127  experiment-05-05a-tf-classification-dnn     run-20231217142807   \n",
       "123  experiment-05-05a-tf-classification-dnn     run-20231221010255   \n",
       "122  experiment-05-05a-tf-classification-dnn     run-20231221013301   \n",
       "120  experiment-05-05a-tf-classification-dnn     run-20231221182010   \n",
       "119  experiment-05-05a-tf-classification-dnn     run-20240222135907   \n",
       "118  experiment-05-05b-tf-classification-dnn     run-20230210130602   \n",
       "117  experiment-05-05b-tf-classification-dnn     run-20231220154420   \n",
       "116  experiment-05-05b-tf-classification-dnn     run-20231221012719   \n",
       "115  experiment-05-05b-tf-classification-dnn     run-20231221020002   \n",
       "114  experiment-05-05b-tf-classification-dnn     run-20231221183939   \n",
       "113  experiment-05-05c-tf-classification-dnn     run-20230210130701   \n",
       "112  experiment-05-05c-tf-classification-dnn     run-20231220172443   \n",
       "111  experiment-05-05c-tf-classification-dnn     run-20231221015345   \n",
       "110  experiment-05-05c-tf-classification-dnn     run-20231221185424   \n",
       "109  experiment-05-05d-tf-classification-dnn     run-20230211141913   \n",
       "108  experiment-05-05d-tf-classification-dnn     run-20231223160024   \n",
       "107  experiment-05-05e-tf-classification-dnn     run-20230211141838   \n",
       "106  experiment-05-05e-tf-classification-dnn     run-20231223160116   \n",
       "56   experiment-05-05f-tf-classification-dnn     run-20230211141850   \n",
       "9    experiment-05-05f-tf-classification-dnn     run-20231223162317   \n",
       "101  experiment-05-05g-tf-classification-dnn   run-20230211145013-5   \n",
       "93   experiment-05-05h-tf-classification-dnn   run-20230211221917-3   \n",
       "65   experiment-05-05i-tf-classification-dnn  run-20230211221928-11   \n",
       "\n",
       "    param.model.display_name param.model.version_id  metric.test_auprc  \\\n",
       "173                    05_05                      6           0.999130   \n",
       "171                    05_05                      7           0.999469   \n",
       "170                    05_05                      8           0.999299   \n",
       "155                    05_05                     12           0.999431   \n",
       "147                    05_05                     14           0.999236   \n",
       "146                    05_05                     15           0.999511   \n",
       "145                    05_05                     16           0.999377   \n",
       "144                    05_05                     17           0.999453   \n",
       "143                    05_05                     18           0.999649   \n",
       "142                   05_05a                      5           0.999154   \n",
       "141                   05_05a                      6           0.999578   \n",
       "140                   05_05a                      7           0.999484   \n",
       "139                   05_05a                      8           0.999259   \n",
       "137                   05_05a                      9           0.999123   \n",
       "136                   05_05a                     10           0.999397   \n",
       "135                   05_05a                     11           0.999351   \n",
       "134                   05_05a                     12           0.999395   \n",
       "133                   05_05a                     13           0.999534   \n",
       "132                   05_05a                     14           0.999346   \n",
       "131                   05_05a                     15           0.999397   \n",
       "130                   05_05a                     16           0.999341   \n",
       "128                   05_05a                     17           0.999535   \n",
       "127                   05_05a                     18           0.999576   \n",
       "123                   05_05a                     19           0.999349   \n",
       "122                   05_05a                     20           0.999533   \n",
       "120                   05_05a                     21           0.999483   \n",
       "119                   05_05a                     22           0.999397   \n",
       "118                   05_05b                      4           0.999341   \n",
       "117                   05_05b                      5           0.999261   \n",
       "116                   05_05b                      6           0.999483   \n",
       "115                   05_05b                      7           0.999389   \n",
       "114                   05_05b                      8           0.999337   \n",
       "113                   05_05c                      3           0.999533   \n",
       "112                   05_05c                      4           0.999252   \n",
       "111                   05_05c                      5           0.999531   \n",
       "110                   05_05c                      6           0.999393   \n",
       "109                   05_05d                      3           0.999527   \n",
       "108                   05_05d                      4           0.999387   \n",
       "107                   05_05e                      3           0.999532   \n",
       "106                   05_05e                      4           0.999530   \n",
       "56                    05_05f                     19           0.999443   \n",
       "9                     05_05f                     66           0.999530   \n",
       "101                   05_05g                      3           0.999539   \n",
       "93                    05_05h                      3           0.999658   \n",
       "65                    05_05i                      4           0.999584   \n",
       "\n",
       "     series_rank  experiment_rank  \n",
       "173         44.0              9.0  \n",
       "171         20.0              3.0  \n",
       "170         38.0              7.0  \n",
       "155         23.0              5.0  \n",
       "147         42.0              8.0  \n",
       "146         16.0              2.0  \n",
       "145         31.0              6.0  \n",
       "144         21.0              4.0  \n",
       "143          2.0              1.0  \n",
       "142         43.0             17.0  \n",
       "141          4.0              1.0  \n",
       "140         17.0              6.0  \n",
       "139         40.0             16.0  \n",
       "137         45.0             18.0  \n",
       "136         24.0              8.0  \n",
       "135         32.0             12.0  \n",
       "134         27.0             11.0  \n",
       "133          8.0              4.0  \n",
       "132         34.0             14.0  \n",
       "131         25.0              9.0  \n",
       "130         36.0             15.0  \n",
       "128          7.0              3.0  \n",
       "127          5.0              2.0  \n",
       "123         33.0             13.0  \n",
       "122          9.0              5.0  \n",
       "120         18.0              7.0  \n",
       "119         26.0             10.0  \n",
       "118         35.0              3.0  \n",
       "117         39.0              5.0  \n",
       "116         19.0              1.0  \n",
       "115         29.0              2.0  \n",
       "114         37.0              4.0  \n",
       "113         10.0              1.0  \n",
       "112         41.0              4.0  \n",
       "111         12.0              2.0  \n",
       "110         28.0              3.0  \n",
       "109         15.0              1.0  \n",
       "108         30.0              2.0  \n",
       "107         11.0              1.0  \n",
       "106         13.0              2.0  \n",
       "56          22.0              2.0  \n",
       "9           14.0              1.0  \n",
       "101          6.0              1.0  \n",
       "93           1.0              1.0  \n",
       "65           3.0              1.0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ranker(metric = 'metric.test_auprc'):\n",
    "    ranks = results[['experiment_name', 'run_name', 'param.model.display_name', 'param.model.version_id', metric]].copy().reset_index(drop = True)\n",
    "    ranks = ranks[ranks['param.model.display_name'].notnull()]\n",
    "    ranks['series_rank'] = ranks[metric].rank(method = 'dense', ascending = False)\n",
    "    ranks['experiment_rank'] = ranks.groupby('experiment_name')[metric].rank(method = 'dense', ascending = False)\n",
    "    return ranks.sort_values(by = ['experiment_name', 'run_name'])\n",
    "    \n",
    "ranks = ranker('metric.test_auprc')\n",
    "ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dae6903c-1986-47f8-b1e7-f05777ca6fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>run_name</th>\n",
       "      <th>param.model.display_name</th>\n",
       "      <th>param.model.version_id</th>\n",
       "      <th>metric.test_auprc</th>\n",
       "      <th>series_rank</th>\n",
       "      <th>experiment_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>experiment-05-05a-tf-classification-dnn</td>\n",
       "      <td>run-20240222135907</td>\n",
       "      <td>05_05a</td>\n",
       "      <td>22</td>\n",
       "      <td>0.999397</td>\n",
       "      <td>26.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             experiment_name            run_name  \\\n",
       "119  experiment-05-05a-tf-classification-dnn  run-20240222135907   \n",
       "\n",
       "    param.model.display_name param.model.version_id  metric.test_auprc  \\\n",
       "119                   05_05a                     22           0.999397   \n",
       "\n",
       "     series_rank  experiment_rank  \n",
       "119         26.0             10.0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_rank = ranks.loc[(ranks['param.model.display_name'] == model.display_name) & (ranks['param.model.version_id'] == model.version_id)]\n",
    "current_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1e45ccb7-8f93-4c12-9b7d-666fd8fa238c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current model is ranked 10.0 within this experiment and 26.0 across this series.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The current model is ranked {current_rank['experiment_rank'].iloc[0]} within this experiment and {current_rank['series_rank'].iloc[0]} across this series.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec24c18-b0f7-4b31-a147-ae6d9e8986b2",
   "metadata": {},
   "source": [
    "### Create/Retrieve The Endpoint For This Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2cc28d98-b525-4385-9b95-489bf574f967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Exists: projects/1026793852137/locations/us-central1/endpoints/725723853820526592\n",
      "Review the Endpoint in the Console:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/endpoints/725723853820526592?project=statmike-mlops-349915\n"
     ]
    }
   ],
   "source": [
    "endpoints = aiplatform.Endpoint.list(filter = f\"labels.series={SERIES} AND display_name={SERIES}\")\n",
    "if endpoints:\n",
    "    endpoint = endpoints[0]\n",
    "    print(f\"Endpoint Exists: {endpoints[0].resource_name}\")\n",
    "else:\n",
    "    endpoint = aiplatform.Endpoint.create(\n",
    "        display_name = f\"{SERIES}\",\n",
    "        labels = {'series' : f\"{SERIES}\"}    \n",
    "    )\n",
    "    print(f\"Endpoint Created: {endpoint.resource_name}\")\n",
    "    \n",
    "print(f'Review the Endpoint in the Console:\\nhttps://console.cloud.google.com/vertex-ai/locations/{REGION}/endpoints/{endpoint.name}?project={PROJECT_ID}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0a538bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'05'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint.display_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0a0029bd-9744-4449-91f0-56ef7ca5e535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2423682068408958976': 100}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint.traffic_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "85d06eba-82dc-4d50-8405-800d756e3584",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployed_models = endpoint.list_models()\n",
    "#deployed_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8444d1-27e1-4784-b783-4da885b56114",
   "metadata": {},
   "source": [
    "### Should This Model Be Deployed?\n",
    "Is it better than the model already deployed on the endpoint?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5db9b246-2b03-4313-b620-5fc8029280b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current model is ranked worse (26.0) than a currently deployed model (2.0)\n"
     ]
    }
   ],
   "source": [
    "deploy = False\n",
    "if deployed_models:\n",
    "    for deployed_model in endpoint.list_models():\n",
    "        deployed_rank = ranks.loc[(ranks['param.model.display_name'] == deployed_model.display_name) & (ranks['param.model.version_id'] == deployed_model.model_version_id)]['series_rank'].iloc[0]\n",
    "        model_rank = current_rank['series_rank'].iloc[0]\n",
    "        if deployed_model.display_name == model.display_name and deployed_model.model_version_id == model.version_id:\n",
    "            print(f'The current model/version is already deployed.')\n",
    "            break\n",
    "        elif model_rank <= deployed_rank:\n",
    "            deploy = True\n",
    "            print(f'The current model is ranked better ({model_rank}) than a currently deployed model ({deployed_rank}).')\n",
    "            break\n",
    "    if deploy == False: print(f'The current model is ranked worse ({model_rank}) than a currently deployed model ({deployed_rank})')\n",
    "else: \n",
    "    deploy = True\n",
    "    print('No models currently deployed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8547856b-e322-4561-9c4a-a1b87f99ae9a",
   "metadata": {},
   "source": [
    "### Deploy Model To Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2aa50205-0f93-423e-a622-4659f81e8674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not deploying - current model is worse (26.0) than the currently deployed model (2.0)\n"
     ]
    }
   ],
   "source": [
    "if deploy:\n",
    "    print(f'Deploying model with 100% of traffic...')\n",
    "    endpoint.deploy(\n",
    "        model = model,\n",
    "        deployed_model_display_name = model.display_name,\n",
    "        traffic_percentage = 100,\n",
    "        machine_type = DEPLOY_COMPUTE,\n",
    "        min_replica_count = 1,\n",
    "        max_replica_count = 1\n",
    "    )\n",
    "else: print(f'Not deploying - current model is worse ({model_rank}) than the currently deployed model ({deployed_rank})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023dcd5e-33af-4dd8-9fe4-ef0ab3078460",
   "metadata": {},
   "source": [
    "### Remove Deployed Models without Traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6945f51a-0c06-4760-bbfe-f2b9d1e7d38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 05_05 with version 18 has traffic = 100\n"
     ]
    }
   ],
   "source": [
    "for deployed_model in endpoint.list_models():\n",
    "    if deployed_model.id in endpoint.traffic_split:\n",
    "        print(f\"Model {deployed_model.display_name} with version {deployed_model.model_version_id} has traffic = {endpoint.traffic_split[deployed_model.id]}\")\n",
    "    else:\n",
    "        endpoint.undeploy(deployed_model_id = deployed_model.id)\n",
    "        print(f\"Undeploying {deployed_model.display_name} with version {deployed_model.model_version_id} because it has no traffic.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d90c6900-de81-4fcd-af0b-ba6b3925724d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2423682068408958976': 100}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint.traffic_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "14cbf4a3-9e32-4158-a9ee-0cfca92e8574",
   "metadata": {},
   "outputs": [],
   "source": [
    "#endpoint.list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a887ca03-f92f-4605-b1a5-f796c4716b08",
   "metadata": {},
   "source": [
    "---\n",
    "## Prediction\n",
    "\n",
    "See many more details on requesting predictions in the [05Tools - Prediction](./05Tools%20-%20Prediction.ipynb) notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7522828b-f611-4bae-a66d-2c811575f274",
   "metadata": {},
   "source": [
    "### Prepare a record for prediction: instance and parameters lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "68911df0-5bee-44fb-9bb8-5aa363ae1c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "# Make a list of columns to omit\n",
    "OMIT = [x for x in VAR_OMIT.split(',') if x != '']\n",
    "pred = bq.query(\n",
    "    query = f\"\"\"\n",
    "        SELECT * EXCEPT({','.join([VAR_TARGET] + OMIT)})\n",
    "        FROM {BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}\n",
    "        WHERE splits='TEST'\n",
    "        LIMIT {n}\n",
    "        \"\"\"\n",
    ").to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e2bae334-4223-4680-a2d0-d350f6a7ef1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35337</td>\n",
       "      <td>1.092844</td>\n",
       "      <td>-0.013230</td>\n",
       "      <td>1.359829</td>\n",
       "      <td>2.731537</td>\n",
       "      <td>-0.707357</td>\n",
       "      <td>0.873837</td>\n",
       "      <td>-0.796130</td>\n",
       "      <td>0.437707</td>\n",
       "      <td>0.396770</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.240428</td>\n",
       "      <td>0.037603</td>\n",
       "      <td>0.380026</td>\n",
       "      <td>-0.167647</td>\n",
       "      <td>0.027557</td>\n",
       "      <td>0.592115</td>\n",
       "      <td>0.219695</td>\n",
       "      <td>0.036970</td>\n",
       "      <td>0.010984</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60481</td>\n",
       "      <td>1.238973</td>\n",
       "      <td>0.035226</td>\n",
       "      <td>0.063003</td>\n",
       "      <td>0.641406</td>\n",
       "      <td>-0.260893</td>\n",
       "      <td>-0.580097</td>\n",
       "      <td>0.049938</td>\n",
       "      <td>-0.034733</td>\n",
       "      <td>0.405932</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.265080</td>\n",
       "      <td>-0.060003</td>\n",
       "      <td>-0.053585</td>\n",
       "      <td>-0.057718</td>\n",
       "      <td>0.104983</td>\n",
       "      <td>0.537987</td>\n",
       "      <td>0.589563</td>\n",
       "      <td>-0.046207</td>\n",
       "      <td>-0.006212</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>139587</td>\n",
       "      <td>1.870539</td>\n",
       "      <td>0.211079</td>\n",
       "      <td>0.224457</td>\n",
       "      <td>3.889486</td>\n",
       "      <td>-0.380177</td>\n",
       "      <td>0.249799</td>\n",
       "      <td>-0.577133</td>\n",
       "      <td>0.179189</td>\n",
       "      <td>-0.120462</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.374356</td>\n",
       "      <td>0.196006</td>\n",
       "      <td>0.656552</td>\n",
       "      <td>0.180776</td>\n",
       "      <td>-0.060226</td>\n",
       "      <td>-0.228979</td>\n",
       "      <td>0.080827</td>\n",
       "      <td>0.009868</td>\n",
       "      <td>-0.036997</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>162908</td>\n",
       "      <td>-3.368339</td>\n",
       "      <td>-1.980442</td>\n",
       "      <td>0.153645</td>\n",
       "      <td>-0.159795</td>\n",
       "      <td>3.847169</td>\n",
       "      <td>-3.516873</td>\n",
       "      <td>-1.209398</td>\n",
       "      <td>-0.292122</td>\n",
       "      <td>0.760543</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.923275</td>\n",
       "      <td>-0.545992</td>\n",
       "      <td>-0.252324</td>\n",
       "      <td>-1.171627</td>\n",
       "      <td>0.214333</td>\n",
       "      <td>-0.159652</td>\n",
       "      <td>-0.060883</td>\n",
       "      <td>1.294977</td>\n",
       "      <td>0.120503</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>165236</td>\n",
       "      <td>2.180149</td>\n",
       "      <td>0.218732</td>\n",
       "      <td>-2.637726</td>\n",
       "      <td>0.348776</td>\n",
       "      <td>1.063546</td>\n",
       "      <td>-1.249197</td>\n",
       "      <td>0.942021</td>\n",
       "      <td>-0.547652</td>\n",
       "      <td>-0.087823</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.250653</td>\n",
       "      <td>0.234502</td>\n",
       "      <td>0.825237</td>\n",
       "      <td>-0.176957</td>\n",
       "      <td>0.563779</td>\n",
       "      <td>0.730183</td>\n",
       "      <td>0.707494</td>\n",
       "      <td>-0.131066</td>\n",
       "      <td>-0.090428</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>62606</td>\n",
       "      <td>1.199408</td>\n",
       "      <td>0.352007</td>\n",
       "      <td>0.379645</td>\n",
       "      <td>1.372017</td>\n",
       "      <td>0.291347</td>\n",
       "      <td>0.524919</td>\n",
       "      <td>-0.117555</td>\n",
       "      <td>0.132907</td>\n",
       "      <td>-0.935169</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042979</td>\n",
       "      <td>-0.050291</td>\n",
       "      <td>-0.126609</td>\n",
       "      <td>-0.022218</td>\n",
       "      <td>-0.599026</td>\n",
       "      <td>0.258188</td>\n",
       "      <td>0.928721</td>\n",
       "      <td>-0.058988</td>\n",
       "      <td>-0.008856</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>90719</td>\n",
       "      <td>1.937447</td>\n",
       "      <td>0.337882</td>\n",
       "      <td>-0.000630</td>\n",
       "      <td>3.816486</td>\n",
       "      <td>0.276515</td>\n",
       "      <td>1.079842</td>\n",
       "      <td>-0.730626</td>\n",
       "      <td>0.197353</td>\n",
       "      <td>1.137566</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.315667</td>\n",
       "      <td>-0.038376</td>\n",
       "      <td>0.208914</td>\n",
       "      <td>0.160189</td>\n",
       "      <td>-0.015145</td>\n",
       "      <td>-0.162678</td>\n",
       "      <td>-0.000843</td>\n",
       "      <td>-0.018178</td>\n",
       "      <td>-0.039339</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>113350</td>\n",
       "      <td>1.891900</td>\n",
       "      <td>0.401086</td>\n",
       "      <td>-0.119983</td>\n",
       "      <td>4.047500</td>\n",
       "      <td>0.049952</td>\n",
       "      <td>0.192793</td>\n",
       "      <td>-0.108512</td>\n",
       "      <td>-0.040400</td>\n",
       "      <td>-0.390391</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.267639</td>\n",
       "      <td>0.094177</td>\n",
       "      <td>0.613712</td>\n",
       "      <td>0.070986</td>\n",
       "      <td>0.079543</td>\n",
       "      <td>0.135219</td>\n",
       "      <td>0.128961</td>\n",
       "      <td>0.003667</td>\n",
       "      <td>-0.045079</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>156499</td>\n",
       "      <td>0.060003</td>\n",
       "      <td>1.461355</td>\n",
       "      <td>0.378915</td>\n",
       "      <td>2.835455</td>\n",
       "      <td>1.626526</td>\n",
       "      <td>-0.164732</td>\n",
       "      <td>1.551858</td>\n",
       "      <td>-0.412927</td>\n",
       "      <td>-1.735264</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.175275</td>\n",
       "      <td>0.042293</td>\n",
       "      <td>0.277536</td>\n",
       "      <td>-0.123379</td>\n",
       "      <td>1.081552</td>\n",
       "      <td>-0.053079</td>\n",
       "      <td>-0.149809</td>\n",
       "      <td>-0.314438</td>\n",
       "      <td>-0.216539</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>73902</td>\n",
       "      <td>-1.859260</td>\n",
       "      <td>2.158799</td>\n",
       "      <td>1.085671</td>\n",
       "      <td>2.615483</td>\n",
       "      <td>0.246660</td>\n",
       "      <td>2.133925</td>\n",
       "      <td>-1.569015</td>\n",
       "      <td>-2.612353</td>\n",
       "      <td>-1.312509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.590142</td>\n",
       "      <td>-0.867178</td>\n",
       "      <td>-0.700479</td>\n",
       "      <td>0.231972</td>\n",
       "      <td>-1.374527</td>\n",
       "      <td>0.140285</td>\n",
       "      <td>0.128806</td>\n",
       "      <td>0.153606</td>\n",
       "      <td>0.092042</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows  30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0   35337  1.092844 -0.013230  1.359829  2.731537 -0.707357  0.873837   \n",
       "1   60481  1.238973  0.035226  0.063003  0.641406 -0.260893 -0.580097   \n",
       "2  139587  1.870539  0.211079  0.224457  3.889486 -0.380177  0.249799   \n",
       "3  162908 -3.368339 -1.980442  0.153645 -0.159795  3.847169 -3.516873   \n",
       "4  165236  2.180149  0.218732 -2.637726  0.348776  1.063546 -1.249197   \n",
       "5   62606  1.199408  0.352007  0.379645  1.372017  0.291347  0.524919   \n",
       "6   90719  1.937447  0.337882 -0.000630  3.816486  0.276515  1.079842   \n",
       "7  113350  1.891900  0.401086 -0.119983  4.047500  0.049952  0.192793   \n",
       "8  156499  0.060003  1.461355  0.378915  2.835455  1.626526 -0.164732   \n",
       "9   73902 -1.859260  2.158799  1.085671  2.615483  0.246660  2.133925   \n",
       "\n",
       "         V7        V8        V9  ...       V20       V21       V22       V23  \\\n",
       "0 -0.796130  0.437707  0.396770  ... -0.240428  0.037603  0.380026 -0.167647   \n",
       "1  0.049938 -0.034733  0.405932  ... -0.265080 -0.060003 -0.053585 -0.057718   \n",
       "2 -0.577133  0.179189 -0.120462  ... -0.374356  0.196006  0.656552  0.180776   \n",
       "3 -1.209398 -0.292122  0.760543  ... -0.923275 -0.545992 -0.252324 -1.171627   \n",
       "4  0.942021 -0.547652 -0.087823  ... -0.250653  0.234502  0.825237 -0.176957   \n",
       "5 -0.117555  0.132907 -0.935169  ... -0.042979 -0.050291 -0.126609 -0.022218   \n",
       "6 -0.730626  0.197353  1.137566  ... -0.315667 -0.038376  0.208914  0.160189   \n",
       "7 -0.108512 -0.040400 -0.390391  ... -0.267639  0.094177  0.613712  0.070986   \n",
       "8  1.551858 -0.412927 -1.735264  ... -0.175275  0.042293  0.277536 -0.123379   \n",
       "9 -1.569015 -2.612353 -1.312509  ...  0.590142 -0.867178 -0.700479  0.231972   \n",
       "\n",
       "        V24       V25       V26       V27       V28  Amount  \n",
       "0  0.027557  0.592115  0.219695  0.036970  0.010984     0.0  \n",
       "1  0.104983  0.537987  0.589563 -0.046207 -0.006212     0.0  \n",
       "2 -0.060226 -0.228979  0.080827  0.009868 -0.036997     0.0  \n",
       "3  0.214333 -0.159652 -0.060883  1.294977  0.120503     0.0  \n",
       "4  0.563779  0.730183  0.707494 -0.131066 -0.090428     0.0  \n",
       "5 -0.599026  0.258188  0.928721 -0.058988 -0.008856     0.0  \n",
       "6 -0.015145 -0.162678 -0.000843 -0.018178 -0.039339     0.0  \n",
       "7  0.079543  0.135219  0.128961  0.003667 -0.045079     0.0  \n",
       "8  1.081552 -0.053079 -0.149809 -0.314438 -0.216539     0.0  \n",
       "9 -1.374527  0.140285  0.128806  0.153606  0.092042     0.0  \n",
       "\n",
       "[10 rows x 30 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5640e67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "newobs = pred.to_dict(orient = 'records')\n",
    "#newobs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "da4637b9-2faf-4e15-b27e-0e6a934b11ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "newobs = [{k:[v] for k,v in newob.items()} for newob in newobs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ce631c5e-b200-43c8-9577-b77f957bb63f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Time': [35337],\n",
       " 'V1': [1.0928441854981998],\n",
       " 'V2': [-0.0132303486713432],\n",
       " 'V3': [1.35982868199426],\n",
       " 'V4': [2.7315370965921004],\n",
       " 'V5': [-0.707357349219652],\n",
       " 'V6': [0.8738370029866129],\n",
       " 'V7': [-0.7961301510622031],\n",
       " 'V8': [0.437706509544851],\n",
       " 'V9': [0.39676985012996396],\n",
       " 'V10': [0.587438102569443],\n",
       " 'V11': [-0.14979756231827498],\n",
       " 'V12': [0.29514781622888103],\n",
       " 'V13': [-1.30382621882143],\n",
       " 'V14': [-0.31782283120234495],\n",
       " 'V15': [-2.03673231037199],\n",
       " 'V16': [0.376090905274179],\n",
       " 'V17': [-0.30040350116459497],\n",
       " 'V18': [0.433799615590844],\n",
       " 'V19': [-0.145082264348681],\n",
       " 'V20': [-0.240427548108996],\n",
       " 'V21': [0.0376030733329398],\n",
       " 'V22': [0.38002620963091405],\n",
       " 'V23': [-0.16764742731151097],\n",
       " 'V24': [0.0275573495476881],\n",
       " 'V25': [0.59211469704354],\n",
       " 'V26': [0.219695164116351],\n",
       " 'V27': [0.0369695108704894],\n",
       " 'V28': [0.010984441006191],\n",
       " 'Amount': [0.0]}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newobs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24ba27e-d559-4287-9cdf-b3db3fac305c",
   "metadata": {},
   "source": [
    "### Get Predictions: Python Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dec05c59-dc93-4a69-90bf-5f3f96f4d006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(predictions=[[0.999759495, 0.000240550202]], deployed_model_id='2423682068408958976', metadata=None, model_version_id='18', model_resource_name='projects/1026793852137/locations/us-central1/models/model_05_05', explanations=None)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = endpoint.predict(instances = newobs[0:1])\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "06cb59fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(predictions=[[0.999759436, 0.000240550187], [0.999389887, 0.000610154064], [0.999763489, 0.000236547974], [0.999877691, 0.000122421377], [0.999873161, 0.000126962157], [0.999579489, 0.000420496828], [0.999929368, 7.053015e-05], [0.999938548, 6.13750744e-05], [0.999892116, 0.00010785809], [0.999943733, 5.62981877e-05]], deployed_model_id='2423682068408958976', metadata=None, model_version_id='18', model_resource_name='projects/1026793852137/locations/us-central1/models/model_05_05', explanations=None)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = endpoint.predict(instances = newobs)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3b22b4cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.999759436, 0.000240550187]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b64e3283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(prediction.predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b6a7f8-2150-4530-9238-c339ed69be00",
   "metadata": {},
   "source": [
    "### Get Predictions: REST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5f97f30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{DIR}/request.json','w') as file:\n",
    "    file.write(json.dumps({\"instances\": newobs[0:1]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "362dd5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"predictions\": [\n",
      "    [\n",
      "      0.999759495,\n",
      "      0.000240550202\n",
      "    ]\n",
      "  ],\n",
      "  \"deployedModelId\": \"2423682068408958976\",\n",
      "  \"model\": \"projects/1026793852137/locations/us-central1/models/model_05_05\",\n",
      "  \"modelDisplayName\": \"05_05\",\n",
      "  \"modelVersionId\": \"18\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!curl -X POST \\\n",
    "-H \"Authorization: Bearer \"$(gcloud auth application-default print-access-token) \\\n",
    "-H \"Content-Type: application/json; charset=utf-8\" \\\n",
    "-d @{DIR}/request.json \\\n",
    "https://{REGION}-aiplatform.googleapis.com/v1/{endpoint.resource_name}:predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04883335-b127-4ae3-b78a-4a6e43bf3386",
   "metadata": {},
   "source": [
    "### Get Predictions: gcloud (CLI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d1e56e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-prediction-aiplatform.googleapis.com/]\n",
      "[[0.999759495, 0.000240550202]]\n"
     ]
    }
   ],
   "source": [
    "!gcloud ai endpoints predict {endpoint.name.rsplit('/',1)[-1]} --region={REGION} --json-request={DIR}/request.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbcc8cb-2555-4406-a180-30828fd78b11",
   "metadata": {},
   "source": [
    "---\n",
    "## Pipeline: Continous Training & Serving\n",
    "\n",
    "Create a pipeline job on Vertex AI Pipelines that does the complete workflow above: setup, train, register model, rank model, bless model (compare to currently deployed model), update endpoint, test endpoint.\n",
    "\n",
    "First, read about pipelines [here](../MLOps.md#Pipelines)!\n",
    "\n",
    "This section builds a [Kubeflow Pipeline](https://www.kubeflow.org/docs/components/pipelines/v1/introduction/) and runs it on [Vertex AI Pipelines](https://cloud.google.com/vertex-ai/docs/pipelines/introduction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbabbbe-1610-491a-ad5c-849d28f168db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from google_cloud_pipeline_components.types import artifact_types\n",
    "from typing import NamedTuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cedb270-26fc-4f10-b4fb-370443858d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfp.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5208011f-9298-4310-bcc9-621e1c003727",
   "metadata": {},
   "source": [
    "### Store Training Code In GCS\n",
    "\n",
    "This workflow uses [aiplatform.CustomJob.from_local_script()](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.CustomJob#google_cloud_aiplatform_CustomJob_from_local_script) to create a [Vertex AI Training Custom Job](https://cloud.google.com/vertex-ai/docs/training/create-custom-job#create_custom_job-python_vertex_ai_sdk).  The key is the method expects the file to be local to the request.  When a Vertex AI Pipeline job runs, the component that is built below will execute this method.  Saving the file to a known GCS location means that the component can reference it as local by using the automatically created [GCS Storage FUSE](https://cloud.google.com/vertex-ai/docs/training/cloud-storage-file-system) mounted at the location `/gcs/<bucket-name>/path-to-file.ext`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d19131-fe8f-4d93-b6ff-6b0f4071ad28",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = gcs.lookup_bucket(GCS_BUCKET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe47391-1f95-4cbb-93ff-d90b3448f4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCRIPT_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774c9720-042f-41b6-9992-edc90edb38d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCRIPT_NAME = SCRIPT_PATH.split('/')[-1]\n",
    "SCRIPT_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f8b0fe-a07a-4579-a680-2456c36bb3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = bucket.blob(f'{SERIES}/{EXPERIMENT}/training/{SCRIPT_NAME}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebde69a3-7bfa-4173-948e-68430dbbfe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob.upload_from_filename(SCRIPT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fd36ca-181b-4893-80eb-1dc6db4641b5",
   "metadata": {},
   "source": [
    "### Component: experiment_setup\n",
    "\n",
    "The first component in the pipeline.  It makes sure the `experiment` and `series` exist and sets up a Tensorboard instance if needed.  It also create a `run_name` for this run of the `experiment` while also adding thes variables to the `CMDARGS` that are input to the training job.  It even gets a single instance from the test data to use for prediction test during the pipeline execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e723c7-5fab-4b56-b87e-1a1ce4325a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@kfp.dsl.component(\n",
    "    base_image = \"python:3.9\",\n",
    "    packages_to_install = [\"google-cloud-aiplatform\", \"google-cloud-pipeline-components\", \"google-cloud-bigquery\", \"pandas\", \"db-dtypes\"]\n",
    ")\n",
    "def experiment_setup(\n",
    "    project: str,\n",
    "    region: str,\n",
    "    series: str,\n",
    "    experiment: str,\n",
    "    experiment_name: str,\n",
    "    cmdargs: list,\n",
    "    bq_project: str,\n",
    "    bq_dataset: str,\n",
    "    bq_table: str,\n",
    "    var_target: str,\n",
    "    var_omit: str,\n",
    "    bq_source: kfp.dsl.Output[artifact_types.BQTable]\n",
    ") -> NamedTuple('outputs', [\n",
    "    ('cmdargs', list), \n",
    "    ('run_name', str), \n",
    "    ('tensorboard', str), \n",
    "    ('timestamp', str),\n",
    "    ('experiment_uri', str),\n",
    "    ('experiment_run_uri', str),\n",
    "    ('sample', dict)]):\n",
    "\n",
    "    # setup the output parameters\n",
    "    from collections import namedtuple\n",
    "    result = namedtuple('outputs', ['cmdargs', 'run_name', 'tensorboard', 'timestamp', 'experiment_uri', 'experiment_run_uri', 'sample'])\n",
    "    \n",
    "    # vertex client\n",
    "    from google.cloud import aiplatform\n",
    "    aiplatform.init(project = project, location = region)\n",
    "\n",
    "    # bigquery client\n",
    "    from google.cloud import bigquery\n",
    "    bq = bigquery.Client(project = project)\n",
    "    \n",
    "    # return/create TensorBoard instance for series\n",
    "    tb = aiplatform.Tensorboard.list(filter=f\"labels.series={series}\")\n",
    "    if tb:\n",
    "        tb = tb[0]\n",
    "    else: \n",
    "        tb = aiplatform.Tensorboard.create(display_name = series, labels = {'series' : f'{series}'})\n",
    "    \n",
    "    # initialize experiment - in case it is new\n",
    "    aiplatform.init(experiment = experiment_name, experiment_tensorboard = tb.resource_name)\n",
    "    \n",
    "    # Output Parameters: update parameters list\n",
    "    from datetime import datetime\n",
    "    TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    RUN_NAME = f'run-{TIMESTAMP}'\n",
    "    CMDARGS = cmdargs + [\n",
    "        \"--project_id=\" + project,\n",
    "        \"--region=\" + region,\n",
    "        \"--series=\" + series,\n",
    "        \"--experiment=\" + experiment,\n",
    "        \"--experiment_name=\" + experiment_name,\n",
    "        \"--run_name=\" + RUN_NAME,\n",
    "        \"--bq_project=\" + bq_project,\n",
    "        \"--bq_dataset=\" + bq_dataset,\n",
    "        \"--bq_table=\" + bq_table,\n",
    "        \"--var_target=\" + var_target,\n",
    "        \"--var_omit=\" + var_omit\n",
    "    ]\n",
    "    \n",
    "    # Output Parameter: get sample for prediction\n",
    "    OMIT = [x for x in var_omit.split(',') if x != '']\n",
    "    samples = bq.query(query = f\"\"\"\n",
    "        SELECT * EXCEPT({','.join([var_target] + OMIT)})\n",
    "        FROM `{bq_project}.{bq_dataset}.{bq_table}`\n",
    "        WHERE splits = 'TEST'\n",
    "        LIMIT 1\n",
    "    \"\"\").to_dataframe().to_dict(orient = 'records')\n",
    "    \n",
    "    # Output Artifact: BigQuery Table \n",
    "    bq_source.uri = f'https://www.googleapis.com/bigquery/v2/projects/{bq_project}/datasets/{bq_dataset}/tables/{bq_table}'\n",
    "    bq_source.metadata['projectId'] = bq_project\n",
    "    bq_source.metadata['datasetId'] = bq_dataset\n",
    "    bq_source.metadata['tableId'] = bq_table\n",
    "\n",
    "    # create links for the experiment and experiment run\n",
    "    exp_uri = f'https://console.cloud.google.com/vertex-ai/locations/{region}/experiments/{experiment_name}?project={project}'\n",
    "    exp_run_uri = f'https://console.cloud.google.com/vertex-ai/locations/{region}/experiments/{experiment_name}/runs/{experiment_name}-{RUN_NAME}?project={project}'\n",
    "\n",
    "    # return the output parameters\n",
    "    return result(CMDARGS, RUN_NAME, tb.resource_name, TIMESTAMP, exp_uri, exp_run_uri, samples[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e1fe02-b7ca-44af-9157-a61cf953fde4",
   "metadata": {},
   "source": [
    "### Component: train_from_local_script\n",
    "\n",
    "Receives the pipeline inputs as well as the runs setup information from the `experiment_setup` component defined above.  This component is used to launch the Vertex AI Custom training job and wait for its completion. It uses the local `/gcs` folder, a GCS Fuse mount, to pass the script as though it is local.  The fuse mount is an automatically created [GCS Storage FUSE](https://cloud.google.com/vertex-ai/docs/training/cloud-storage-file-system) mounted at the location `/gcs/<bucket-name>/path-to-file.ext`.\n",
    "\n",
    "This uses a special type of parameter `gcp_resource` that renders the job information in the console for review while training is running. [Reference](https://cloud.google.com/vertex-ai/docs/pipelines/build-own-components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36c9ab6-f7a4-4388-ad07-edfd8f63aca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@kfp.dsl.component(\n",
    "    base_image = \"python:3.9\",\n",
    "    packages_to_install = [\"google-cloud-aiplatform\", \"google-cloud-pipeline-components\"]\n",
    ")\n",
    "def train_from_local_script(\n",
    "    project: str,\n",
    "    region: str,\n",
    "    series: str,\n",
    "    experiment: str,\n",
    "    experiment_name: str,\n",
    "    run_name: str,\n",
    "    cmdargs: list,\n",
    "    script: str,\n",
    "    train_image: str,\n",
    "    requirements: list,\n",
    "    train_compute: str,\n",
    "    timestamp: str,\n",
    "    bucket: str,\n",
    "    service_account: str,\n",
    "    tensorboard: str,\n",
    "    job_resources: kfp.dsl.Output[kfp.dsl.Artifact]\n",
    ") -> NamedTuple('outputs', [('state', str), ('gcp_resources', str)]):\n",
    "    \n",
    "    # setup the output parameters\n",
    "    from collections import namedtuple\n",
    "    result = namedtuple('outputs', ['state', 'gcp_resources'])\n",
    "    \n",
    "    # vertex client\n",
    "    from google.cloud import aiplatform\n",
    "    aiplatform.init(project = project, location = region)\n",
    "    \n",
    "    # create job:\n",
    "    customJob = aiplatform.CustomJob.from_local_script(\n",
    "        display_name = f'{series}_{experiment}_{timestamp}',\n",
    "        script_path = f'/gcs/{bucket}/{series}/{experiment}/training/{script}',\n",
    "        container_uri = train_image,\n",
    "        args = cmdargs,\n",
    "        requirements = requirements,\n",
    "        replica_count = 1,\n",
    "        machine_type = train_compute,\n",
    "        accelerator_count = 0,\n",
    "        base_output_dir = f\"gs://{bucket}/{series}/{experiment}/models/{timestamp}\",\n",
    "        staging_bucket = f\"gs://{bucket}/{series}/{experiment}/models/{timestamp}\",\n",
    "        labels = {'series' : f'{series}', 'experiment' : f'{experiment}', 'experiment_name' : f'{experiment_name}', 'run_name' : f'{run_name}'}\n",
    "    )    \n",
    "\n",
    "    # run job:\n",
    "    customJob.run(\n",
    "        service_account = service_account,\n",
    "        tensorboard = tensorboard\n",
    "    )\n",
    "\n",
    "    # Output Artifact: job resources\n",
    "    job_resources.uri = f\"https://console.cloud.google.com/vertex-ai/locations/{region}/training/{customJob.resource_name.split('/')[-1]}/cpu\"\n",
    "    job_resources.metadata = dict(state = customJob.state.name, resource_name = customJob.resource_name, model = f\"gs://{bucket}/{series}/{experiment}/models/{timestamp}/model\")\n",
    "    \n",
    "    # Output Special: gcp_resource parameter for in concole monitoring of the job\n",
    "    # info: https://cloud.google.com/vertex-ai/docs/pipelines/build-own-components\n",
    "    # GCP Resource Proto: https://github.com/kubeflow/pipelines/tree/master/components/google-cloud/google_cloud_pipeline_components/proto\n",
    "    from google_cloud_pipeline_components.proto.gcp_resources_pb2 import GcpResources\n",
    "    from google.protobuf.json_format import MessageToJson\n",
    "    customJob_resources = GcpResources()\n",
    "    cr = customJob_resources.resources.add()\n",
    "    cr.resource_type = 'CustomJob'\n",
    "    # customJob URI like: https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.customJobs/create\n",
    "    cr.resource_uri = f'https://{region}-aiplatform.googleapis.com/v1/{customJob.resource_name}'\n",
    "    gcp_resources = MessageToJson(customJob_resources)\n",
    "    \n",
    "    return result(customJob.state.name, gcp_resources)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62095d6-72d9-4ca5-9804-81bf7ecefc4f",
   "metadata": {},
   "source": [
    "### Component: register_model\n",
    "\n",
    "Register the resulting model as a new version and update the experiment data with model and job information.\n",
    "\n",
    "Output Model Artifact:\n",
    "- use Vertex AI Model Artifact: https://google-cloud-pipeline-components.readthedocs.io/en/google-cloud-pipeline-components-2.0.0/api/artifact_types.html#\n",
    "    - GitHub Source: https://github.com/kubeflow/pipelines/blob/master/components/google-cloud/google_cloud_pipeline_components/types/artifact_types.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bada3689-d823-4588-b39a-e71fb24ba1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "@kfp.dsl.component(\n",
    "    base_image = \"python:3.9\",\n",
    "    packages_to_install = [\"google-cloud-aiplatform\", \"google-cloud-pipeline-components\"]\n",
    ")\n",
    "def register_model(\n",
    "    project: str,\n",
    "    region: str,\n",
    "    series: str,\n",
    "    experiment: str,\n",
    "    experiment_name: str,\n",
    "    run_name: str,\n",
    "    deploy_image: str,\n",
    "    job_resources: kfp.dsl.Input[kfp.dsl.Artifact],\n",
    "    tensorboard: str,\n",
    "    vertex_model: kfp.dsl.Output[artifact_types.VertexModel]\n",
    ") -> NamedTuple('outputs', [('version_id', str)]):\n",
    "    \n",
    "    # setup the output parameters\n",
    "    from collections import namedtuple\n",
    "    result = namedtuple('outputs', ['version_id'])\n",
    "    \n",
    "    # vertex client\n",
    "    from google.cloud import aiplatform\n",
    "    aiplatform.init(project = project, location = region)\n",
    "    \n",
    "    # Upload Model\n",
    "    modelmatch = aiplatform.Model.list(filter = f'display_name={series}_{experiment} AND labels.series={series} AND labels.experiment={experiment}')\n",
    "\n",
    "    upload_model = True\n",
    "    if modelmatch:\n",
    "        print(\"Model Already in Registry:\")\n",
    "        if run_name in modelmatch[0].version_aliases:\n",
    "            print(\"This version already loaded, no action taken.\")\n",
    "            upload_model = False\n",
    "            model = aiplatform.Model(model_name = modelmatch[0].resource_name)\n",
    "        else:\n",
    "            print('Loading model as new default version.')\n",
    "            parent_model = modelmatch[0].resource_name\n",
    "\n",
    "    else:\n",
    "        print('This is a new model, creating in model registry')\n",
    "        parent_model = ''\n",
    "\n",
    "    if upload_model:\n",
    "        model = aiplatform.Model.upload(\n",
    "            display_name = f'{series}_{experiment}',\n",
    "            model_id = f'model_{series}_{experiment}',\n",
    "            parent_model =  parent_model,\n",
    "            serving_container_image_uri = deploy_image,\n",
    "            artifact_uri = job_resources.metadata['model'], \n",
    "            is_default_version = True,\n",
    "            version_aliases = [run_name],\n",
    "            version_description = run_name,\n",
    "            labels = {'series' : f'{series}', 'experiment' : f'{experiment}', 'experiment_name' : f'{experiment_name}', 'run_name' : f'{run_name}'}        \n",
    "        )\n",
    "\n",
    "    #print(f'Review the model in the Vertex AI Model Registry:\\nhttps://console.cloud.google.com/vertex-ai/locations/{region}/models/{model.name}?project={project}')\n",
    "\n",
    "    customJob = aiplatform.CustomJob.get(resource_name = job_resources.metadata['resource_name'])\n",
    "    board_link = f\"https://{region}.tensorboard.googleusercontent.com/experiment/{tensorboard.replace('/', '+')}+experiments+{customJob.resource_name.split('/')[-1]}\"\n",
    "    \n",
    "    \n",
    "    expRun = aiplatform.ExperimentRun(run_name = run_name, experiment = experiment_name)\n",
    "    expRun.log_params({\n",
    "        'model.uri': model.uri,\n",
    "        'model.display_name': model.display_name,\n",
    "        'model.name': model.name,\n",
    "        'model.resource_name': model.resource_name,\n",
    "        'model.version_id': model.version_id,\n",
    "        'model.versioned_resource_name': model.versioned_resource_name,\n",
    "        'customJobs.display_name': customJob.display_name,\n",
    "        'customJobs.resource_name': customJob.resource_name,\n",
    "        'customJobs.link': job_resources.uri,\n",
    "        'customJobs.tensorboard': board_link\n",
    "    })\n",
    "\n",
    "    expRun.update_state(state = aiplatform.gapic.Execution.State.COMPLETE)\n",
    "\n",
    "    #print(f'Review The Experiment in the Console:\\nhttps://console.cloud.google.com/vertex-ai/locations/{region}/experiments/{experiment_name}?project={project}')\n",
    "    #print(f'Review The Experiment Run in the Console:\\nhttps://console.cloud.google.com/vertex-ai/locations/{region}/experiments/{experiment_name}/runs/{experiment_name}-{run_name}?project={project}')\n",
    "\n",
    "    # Output Artifact: Vertex Model (versioned)\n",
    "    #vertex_model.name = model.display_name\n",
    "    vertex_model.uri = f'https://{region}-aiplatform.googleapis.com/v1/{model.versioned_resource_name}'\n",
    "    vertex_model.metadata['model_resource_name'] = model.versioned_resource_name\n",
    "    \n",
    "    return result(model.version_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8424a02a-3bf8-4f29-86f9-59a985868128",
   "metadata": {},
   "source": [
    "## Component: endpoint_model\n",
    "\n",
    "Retrieve (or Create) the endpoint and get the currently deployed model receiving traffic.\n",
    "\n",
    "Ouput Artifacts for the endpoint and current model on endpoint:\n",
    "- use Vertex AI Model Artifact: https://google-cloud-pipeline-components.readthedocs.io/en/google-cloud-pipeline-components-2.0.0/api/artifact_types.html#\n",
    "    - GitHub Source: https://github.com/kubeflow/pipelines/blob/master/components/google-cloud/google_cloud_pipeline_components/types/artifact_types.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa89a0a-91e6-49b0-bd65-65ef78a5010e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@kfp.dsl.component(\n",
    "    base_image = \"python:3.9\",\n",
    "    packages_to_install = [\"google-cloud-aiplatform\", \"google-cloud-pipeline-components\", 'pandas']\n",
    ")\n",
    "def endpoint_model(\n",
    "    project: str,\n",
    "    region: str,\n",
    "    series: str,\n",
    "    vertex_endpoint: kfp.dsl.Output[artifact_types.VertexEndpoint],\n",
    "    vertex_model: kfp.dsl.Output[artifact_types.VertexModel]\n",
    "):\n",
    "    \n",
    "    # vertex client\n",
    "    from google.cloud import aiplatform\n",
    "    aiplatform.init(project = project, location = region)\n",
    "    \n",
    "    endpoints = aiplatform.Endpoint.list(filter = f\"labels.series={series} AND display_name={series}\")\n",
    "    if endpoints:\n",
    "        endpoint = endpoints[0]\n",
    "        print(f\"Endpoint Exists: {endpoints[0].resource_name}\")\n",
    "    else:\n",
    "        endpoint = aiplatform.Endpoint.create(\n",
    "            display_name = f\"{series}\",\n",
    "            labels = {'series' : f\"{series}\"}    \n",
    "        )\n",
    "        print(f\"Endpoint Created: {endpoint.resource_name}\")\n",
    "\n",
    "    # Output Artifact: Vertex Endpoint\n",
    "    vertex_endpoint.uri = f'https://{region}-aiplatform.googleapis.com/v1/{endpoint.resource_name}'\n",
    "    vertex_endpoint.metadata['endpoint_resource_name'] = endpoint.resource_name\n",
    "    \n",
    "    # Output Artifact: Vertex Model\n",
    "    for model in endpoint.list_models():\n",
    "        if endpoint.traffic_split[model.id] == 100:\n",
    "            vertex_model.uri = f'https://{region}-aiplatform.googleapis.com/v1/{model.model}@{model.model_version_id}'\n",
    "            vertex_model.metadata['model_resource_name'] = model.model+'@'+model.model_version_id\n",
    "    print(model.model_version_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f5ae14-fd77-42c5-8b8b-32aeb5b893c3",
   "metadata": {},
   "source": [
    "### Component: rank_model\n",
    "\n",
    "Use Vertex AI Experiments to retrieve information from all runs in this experiment and all experiments in this series.  Then rank models and versions.  Use the ranks to compare the newly trained model to the model currently on the endpoint.  Ouput the ranks table as a [Markdown Artifact](https://kubeflow-pipelines.readthedocs.io/en/latest/source/dsl.html#kfp.dsl.Markdown) that is reviewable in the console for the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597cbefc-b3cc-42eb-a615-afe52470b41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@kfp.dsl.component(\n",
    "    base_image = \"python:3.9\",\n",
    "    packages_to_install = [\"google-cloud-aiplatform\", \"google-cloud-pipeline-components\", 'pandas']\n",
    ")\n",
    "def rank_model(\n",
    "    project: str,\n",
    "    region: str,\n",
    "    series: str,\n",
    "    current_model: kfp.dsl.Input[artifact_types.VertexModel], \n",
    "    new_model: kfp.dsl.Input[artifact_types.VertexModel],\n",
    "    ranks_table: kfp.dsl.Output[kfp.dsl.Markdown]\n",
    ") -> NamedTuple('outputs', [('new_model_experiment_rank', float), ('new_model_series_rank', float), ('current_model_series_rank', float)]):\n",
    "    \n",
    "    # setup the output parameters\n",
    "    from collections import namedtuple\n",
    "    result = namedtuple('outputs', ['new_model_experiment_rank', 'new_model_series_rank', 'current_model_series_rank'])\n",
    "    \n",
    "    # vertex client\n",
    "    from google.cloud import aiplatform\n",
    "    aiplatform.init(project = project, location = region)\n",
    "\n",
    "    import pandas as pd\n",
    "    \n",
    "    # get models\n",
    "    current_model = aiplatform.Model(model_name = current_model.metadata['model_resource_name'])\n",
    "    new_model = aiplatform.Model(model_name = new_model.metadata['model_resource_name'])\n",
    "    \n",
    "    # list experiments in project\n",
    "    experiments = aiplatform.Experiment.list()\n",
    "    # filter to experiment is SERIES\n",
    "    experiments = [e for e in experiments if e.name.split('-')[0:2] == ['experiment', series]]\n",
    "    # combine runs from all experiment in SERIES into single dataframe\n",
    "    results = []\n",
    "    for experiment in experiments:\n",
    "            results.append(experiment.get_data_frame())\n",
    "            print(experiment.name)\n",
    "    results = pd.concat(results)\n",
    "    # define rank for models: within experiment and across entire series\n",
    "    def ranker(metric = 'metric.test_auprc'):\n",
    "        ranks = results[['experiment_name', 'run_name', 'param.model.display_name', 'param.model.version_id', metric]].copy().reset_index(drop = True)\n",
    "        ranks = ranks[ranks['param.model.display_name'].notnull()]\n",
    "        ranks['series_rank'] = ranks[metric].rank(method = 'dense', ascending = False)\n",
    "        ranks['experiment_rank'] = ranks.groupby('experiment_name')[metric].rank(method = 'dense', ascending = False)\n",
    "        return ranks.sort_values(by = ['series_rank', 'experiment_rank'])\n",
    "    ranks = ranker('metric.test_auprc') \n",
    "    # mark current model and new model:\n",
    "    ranks.loc[(ranks['param.model.display_name'] == current_model.display_name) & (ranks['param.model.version_id'] == current_model.version_id), 'Status'] = 'On Endpoint'\n",
    "    ranks.loc[(ranks['param.model.display_name'] == new_model.display_name) & (ranks['param.model.version_id'] == new_model.version_id), 'Status'] = 'New Model'\n",
    "    col = ranks.pop('Status')\n",
    "    ranks.insert(0, col.name, col)\n",
    "    # get value for current and new model:\n",
    "    current_rank = ranks.loc[(ranks['param.model.display_name'] == current_model.display_name) & (ranks['param.model.version_id'] == current_model.version_id)]\n",
    "    new_rank = ranks.loc[(ranks['param.model.display_name'] == new_model.display_name) & (ranks['param.model.version_id'] == new_model.version_id)]\n",
    "    \n",
    "    # output markdown artifact: the ranks table\n",
    "    with open(ranks_table.path, 'w') as f:\n",
    "        f.write(ranks.to_markdown(index = False))\n",
    "    \n",
    "    return result(new_rank['experiment_rank'].iloc[0], new_rank['series_rank'].iloc[0], current_rank['series_rank'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3482cb-6a97-4b1f-82b6-fe529fce00cb",
   "metadata": {},
   "source": [
    "### Component: deploy_model\n",
    "\n",
    "A component that deploys the new model to the endpoint and removes traffic from older models on the endpoint, and undeploys them.  Returns the status of the deployment and confirmed traffic percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026a8d26-4138-4dd0-bf9b-ff8060b16c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@kfp.dsl.component(\n",
    "    base_image = \"python:3.9\",\n",
    "    packages_to_install = [\"google-cloud-aiplatform\", \"google-cloud-pipeline-components\"]\n",
    ")\n",
    "def deploy_model(\n",
    "    project: str,\n",
    "    region: str,\n",
    "    deploy_compute: str,\n",
    "    vertex_endpoint: kfp.dsl.Input[artifact_types.VertexEndpoint], \n",
    "    vertex_model: kfp.dsl.Input[artifact_types.VertexModel]\n",
    ") -> NamedTuple('outputs', [('count_of_deployed', int), ('new_model_deployed', bool), ('traffic_new_model', int)]):\n",
    "\n",
    "    # setup the output parameters\n",
    "    from collections import namedtuple\n",
    "    result = namedtuple('outputs', ['count_of_deployed', 'new_model_deployed', 'traffic_new_model'])\n",
    "    \n",
    "    # vertex client\n",
    "    from google.cloud import aiplatform\n",
    "    aiplatform.init(project = project, location = region)\n",
    "    \n",
    "    endpoint = aiplatform.Endpoint(endpoint_name = vertex_endpoint.metadata['endpoint_resource_name'])\n",
    "    model = aiplatform.Model(model_name = vertex_model.metadata['model_resource_name'])\n",
    "    \n",
    "    # deploy the model to the endpoint\n",
    "    endpoint.deploy(\n",
    "        model = model,\n",
    "        deployed_model_display_name = model.display_name,\n",
    "        traffic_percentage = 100,\n",
    "        machine_type = deploy_compute,\n",
    "        min_replica_count = 1,\n",
    "        max_replica_count = 1\n",
    "    )\n",
    "\n",
    "    # remove models without traffic\n",
    "    deployed = False\n",
    "    traffic = 0\n",
    "    for deployed_model in endpoint.list_models():\n",
    "        if deployed_model.id not in endpoint.traffic_split:\n",
    "            endpoint.undeploy(deployed_model_id = deployed_model.id)\n",
    "        elif f'{deployed_model.model}@{deployed_model.model_version_id}' == vertex_model.metadata['model_resource_name']:\n",
    "            deployed = True\n",
    "            traffic = endpoint.traffic_split[deployed_model.id]\n",
    "\n",
    "    info = endpoint.to_dict()\n",
    "    \n",
    "    return result(\n",
    "        len(info['deployedModels']),\n",
    "        deployed,\n",
    "        traffic\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb883bef-83a9-47e6-88b7-2f77c47ab5bf",
   "metadata": {},
   "source": [
    "### Component: prediction_test\n",
    "\n",
    "A custom component to run a prediction request on the endpoint (input artifact) and return the result of the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364479e3-49dd-41a2-9583-2b7f34a6d1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@kfp.dsl.component(\n",
    "    base_image = \"python:3.9\",\n",
    "    packages_to_install = [\"google-cloud-aiplatform\", \"google-cloud-pipeline-components\"]\n",
    ")\n",
    "def prediction_test(\n",
    "    project: str,\n",
    "    region: str,\n",
    "    sample: dict,\n",
    "    vertex_endpoint: kfp.dsl.Input[artifact_types.VertexEndpoint]\n",
    ") -> NamedTuple('outputs', [('predictions', list), ('model_resource_name', str)]):\n",
    "\n",
    "    # setup the output parameters\n",
    "    from collections import namedtuple\n",
    "    result = namedtuple('outputs', ['predictions', 'model_resource_name'])\n",
    "\n",
    "    \n",
    "    # vertex client\n",
    "    from google.cloud import aiplatform\n",
    "    aiplatform.init(project = project, location = region) \n",
    "    \n",
    "    endpoint = aiplatform.Endpoint(endpoint_name = vertex_endpoint.metadata['endpoint_resource_name'])\n",
    "    \n",
    "    prediction = endpoint.predict(instances = [sample])\n",
    "    \n",
    "    return result(\n",
    "        predictions = prediction.predictions[0],\n",
    "        model_resource_name = prediction.model_resource_name + '@' + prediction.model_version_id\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2165b6f-4bbe-41a5-8670-d0d31c2ea8a8",
   "metadata": {},
   "source": [
    "### Pipeline\n",
    "\n",
    "Create the pipeline using [kfp.dsl.pipeline()](https://kubeflow-pipelines.readthedocs.io/en/latest/source/dsl.html#kfp.dsl.pipeline) using features like:\n",
    "- conditional execution for registering model and deploying the new model to the endpoint with [kfp.dsl.Condition](https://kubeflow-pipelines.readthedocs.io/en/latest/source/dsl.html#kfp.dsl.Condition)\n",
    "- naming components with `.set_display_name()`\n",
    "- controling caching of components with `.set_caching_options()`\n",
    "- set [compute resources for a components VM](https://cloud.google.com/vertex-ai/docs/pipelines/machine-types) with `.set_cpu_limit()`\n",
    "- force order of exectuion with `.after()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b7d36a-8a28-4fe6-b4c1-b83048faed15",
   "metadata": {},
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(\n",
    "    name = f'series-{SERIES}-{EXPERIMENT}-pipeline',\n",
    "    description = 'Full development pipeline.'\n",
    ")\n",
    "def retrain_pipeline(\n",
    "    project: str,\n",
    "    region: str,\n",
    "    series: str,\n",
    "    experiment: str,\n",
    "    experiment_name: str,\n",
    "    bq_project: str,\n",
    "    bq_dataset: str,\n",
    "    bq_table: str,\n",
    "    var_target: str,\n",
    "    var_omit: str,\n",
    "    cmdargs: list,\n",
    "    script: str,\n",
    "    train_image: str,\n",
    "    requirements: list,\n",
    "    train_compute: str,\n",
    "    deploy_image: str,\n",
    "    deploy_compute: str,\n",
    "    bucket: str,\n",
    "    service_account: str\n",
    "):\n",
    "\n",
    "    from google_cloud_pipeline_components.types import artifact_types\n",
    "    \n",
    "    # run setup\n",
    "    setup = experiment_setup(\n",
    "        project = project,\n",
    "        region = region,\n",
    "        series = series,\n",
    "        experiment = experiment,\n",
    "        experiment_name = experiment_name,\n",
    "        cmdargs = cmdargs,\n",
    "        bq_project = bq_project,\n",
    "        bq_dataset = bq_dataset,\n",
    "        bq_table = bq_table,\n",
    "        var_target = var_target,\n",
    "        var_omit = var_omit\n",
    "    ).set_display_name('Setup').set_cpu_limit('2').set_caching_options(True)\n",
    "    \n",
    "    # launch training job from component - using script stored in GCS\n",
    "    trainer = train_from_local_script(\n",
    "        project = project,\n",
    "        region = region,\n",
    "        series = series,\n",
    "        experiment = experiment,\n",
    "        experiment_name = experiment_name,\n",
    "        run_name = setup.outputs['run_name'],\n",
    "        cmdargs = setup.outputs['cmdargs'],\n",
    "        script = script,\n",
    "        train_image = train_image,\n",
    "        requirements = requirements,\n",
    "        train_compute = train_compute,\n",
    "        timestamp = setup.outputs['timestamp'],\n",
    "        bucket = bucket,\n",
    "        service_account = service_account,\n",
    "        tensorboard = setup.outputs['tensorboard']\n",
    "    ).set_display_name('Train With Script').set_cpu_limit('2').set_caching_options(True)\n",
    "    \n",
    "    \n",
    "    # check if train was sucessful\n",
    "    with kfp.dsl.If(\n",
    "        trainer.outputs['state'] == 'JOB_STATE_SUCCEEDED',\n",
    "        name = 'Check Training Completion'\n",
    "    ):\n",
    "    \n",
    "        endpoint_before = endpoint_model(\n",
    "            project = project,\n",
    "            region = region,\n",
    "            series = series\n",
    "        ).set_display_name('Endpoint: Before Update').set_cpu_limit('2').set_caching_options(False)\n",
    "        \n",
    "        model = register_model(\n",
    "            project = project,\n",
    "            region = region,\n",
    "            series = series,\n",
    "            experiment = experiment,\n",
    "            experiment_name = experiment_name,\n",
    "            run_name = setup.outputs['run_name'],\n",
    "            deploy_image = deploy_image,\n",
    "            job_resources = trainer.outputs['job_resources'],\n",
    "            tensorboard = setup.outputs['tensorboard']\n",
    "        ).set_display_name('Register Model').set_cpu_limit('2').set_caching_options(False)\n",
    "    \n",
    "        rank = rank_model(\n",
    "            project = project,\n",
    "            region = region,\n",
    "            series = series,\n",
    "            new_model = model.outputs['vertex_model'],\n",
    "            current_model = endpoint_before.outputs['vertex_model']\n",
    "        ).set_display_name('Rank Model').set_cpu_limit('2').set_caching_options(False)\n",
    "    \n",
    "        with kfp.dsl.If(\n",
    "            rank.outputs['new_model_series_rank'] < rank.outputs['current_model_series_rank'],\n",
    "            name = 'Bless New Model'\n",
    "        ):\n",
    "            \n",
    "            deploy = deploy_model(\n",
    "                project = project,\n",
    "                region = region,\n",
    "                deploy_compute = deploy_compute,\n",
    "                vertex_endpoint = endpoint_before.outputs['vertex_endpoint'],\n",
    "                vertex_model = model.outputs['vertex_model']\n",
    "            ).set_display_name('Deploy Model').set_cpu_limit('2').set_caching_options(False)\n",
    "            \n",
    "            endpoint_after = endpoint_model(\n",
    "                project = project,\n",
    "                region = region,\n",
    "                series = series\n",
    "            ).set_display_name('Endpoint: After Update').set_cpu_limit('2').set_caching_options(False).after(deploy)\n",
    "    \n",
    "            with kfp.dsl.If(\n",
    "                deploy.outputs['new_model_deployed'] == True,\n",
    "                name = 'Check The Model Deployment'\n",
    "            ):\n",
    "    \n",
    "                prediction = prediction_test(\n",
    "                    project = project,\n",
    "                    region = region,\n",
    "                    sample = setup.outputs['sample'],\n",
    "                    vertex_endpoint = endpoint_after.outputs['vertex_endpoint'],\n",
    "                ).set_display_name('Prediction').set_cpu_limit('2').set_caching_options(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22e5d0e-844c-4a73-b894-fc7dfd7aeb26",
   "metadata": {},
   "source": [
    "### Compile Pipeline\n",
    "\n",
    "Compile the pipeline using [kfp.compiler.Compiler()](https://kubeflow-pipelines.readthedocs.io/en/latest/source/compiler.html#kfp.compiler.Compiler).  Here the `json` format is used but alternatively the `yaml` format could be used for storing this as a [pipeline template in artifact registry](https://cloud.google.com/vertex-ai/docs/pipelines/create-pipeline-template)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9f1887-00c2-46f3-8ff7-fed03c336a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfp.compiler.Compiler().compile(\n",
    "    pipeline_func = retrain_pipeline,\n",
    "    package_path = f\"{DIR}/{EXPERIMENT}.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81eccc8-5bb0-4b0b-950e-474d67b15088",
   "metadata": {},
   "source": [
    "### Define Pipeline Job\n",
    "\n",
    "Setup the input parameters for the pipeline and create a pipeline job with the SDK [aiplatform.PipelineJob()](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.PipelineJob)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3c6903-3e6c-43ab-b3b1-675ae921a87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "REQUIREMENTS = ['tensorflow_io', f'google-cloud-aiplatform>={aiplatform.__version__}', 'db-dtypes', f\"protobuf>={importlib.metadata.version('protobuf')}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6937e307-fd73-4f8a-98c8-6c4a42859a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "CMDARGS = [\n",
    "    \"--epochs=\" + str(EPOCHS),\n",
    "    \"--batch_size=\" + str(BATCH_SIZE)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1f1d21-1e60-4b73-9de1-0ee39df0763c",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_values = {\n",
    "    \"project\": PROJECT_ID,\n",
    "    \"region\": REGION,\n",
    "    \"series\": SERIES,\n",
    "    \"experiment\": EXPERIMENT,\n",
    "    \"experiment_name\": EXPERIMENT_NAME,\n",
    "    \"bq_project\": BQ_PROJECT,\n",
    "    \"bq_dataset\": BQ_DATASET,\n",
    "    \"bq_table\": BQ_TABLE,\n",
    "    \"var_target\": VAR_TARGET,\n",
    "    \"var_omit\": VAR_OMIT,\n",
    "    \"cmdargs\": CMDARGS,\n",
    "    \"script\": SCRIPT_NAME,\n",
    "    \"train_image\": TRAIN_IMAGE,\n",
    "    \"requirements\": REQUIREMENTS,\n",
    "    \"train_compute\": TRAIN_COMPUTE,\n",
    "    \"deploy_image\": DEPLOY_IMAGE,\n",
    "    \"deploy_compute\": DEPLOY_COMPUTE,\n",
    "    \"bucket\": GCS_BUCKET,\n",
    "    \"service_account\": SERVICE_ACCOUNT\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996900fc-4c40-47fc-9e10-f29726689b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_job = aiplatform.PipelineJob(\n",
    "    display_name = f\"{SERIES}_{EXPERIMENT}\",\n",
    "    template_path = f\"{DIR}/{EXPERIMENT}.json\",\n",
    "    parameter_values = parameter_values,\n",
    "    pipeline_root = f\"{URI}/pipeline_root\",\n",
    "    enable_caching = None, # True (enabled), False (disable), None (defer to component level caching) \n",
    "    labels = {'series': SERIES, 'experiment': EXPERIMENT}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89f8cf2-5a92-40bd-83c4-be434a9ae384",
   "metadata": {},
   "source": [
    "### Submit Pipeline Job\n",
    "\n",
    "Submit the pipeline job for execution with [aiplatform.PipelineJob.sumit()](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.PipelineJob#google_cloud_aiplatform_PipelineJob_submit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c508ad-2c20-421e-ae5d-f62dfa7c8d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = pipeline_job.submit(\n",
    "    service_account = SERVICE_ACCOUNT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fdbc80-73c0-4882-9226-f7155efaa569",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The Dashboard can be viewed here:\\n{pipeline_job._dashboard_uri()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7407f63a-461c-4bfb-934d-b8515f56b784",
   "metadata": {},
   "source": [
    "### Wait On Pipeline Job\n",
    "\n",
    "For the execution to wait on the completion of the pipeline job with [aiplatform.PipelineJob.wait()](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.PipelineJob#google_cloud_aiplatform_PipelineJob_wait)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c28463-498a-43cb-9fb8-0a51f1744e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb70a21-953a-4f0c-86fb-a3573dcc543c",
   "metadata": {},
   "source": [
    "### Retrieve Pipeline Information\n",
    "\n",
    "Retrive the pipeline execution information for all runs of this pipeline (have the same name) using [aiplatform.get_pipeline_df()](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform#google_cloud_aiplatform_get_pipeline_df)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d34a358-cfa1-4416-94ab-fcd8d6b2c2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.get_pipeline_df(pipeline = f'series-{SERIES}-{EXPERIMENT}-pipeline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13087f03-4a41-43e2-9f7e-4973c87fa847",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tasks = {task.task_name: task for task in pipeline_job.task_details}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89400041-2996-4354-ac67-bdf7544ac2ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for task in tasks:\n",
    "  print(task, tasks[task].state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4bf05d-3867-4091-af46-e0fda1c41583",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tasks.get('rank-model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9994cec5-4fc7-46a5-99c0-9f64b0d60b97",
   "metadata": {},
   "source": [
    "---\n",
    "## Monitor Pipeline: In Console\n",
    "\n",
    "This is what the pipeline looks like in the Vertex AI Console:\n",
    "\n",
    "<p align=\"center\" width=\"90%\">\n",
    "    <img src=\"../architectures/notebooks/05/05a_pipeline.png\" width=\"75%\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510557be-84f2-4478-b7b5-87ba1b67f16f",
   "metadata": {},
   "source": [
    "## TODO\n",
    "- how to handle when endpoint does not have current model - new endpoint?\n",
    "- rework manual workflow ranks section to match the new component\n",
    "- rework experiments integration\n",
    "- add model evaluation to registry\n",
    "- save pipeline to artifact registry - show in Vertex AI Pipeline Templates\n",
    "- Schedule pipeline execution: from pipeline or artifact registry\n",
    "- include resource removal in notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294e9d5f-1540-482f-b969-c88c226caa98",
   "metadata": {},
   "source": [
    "---\n",
    "## Remove Resources\n",
    "see notebook \"99 - Cleanup\""
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m113"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
