{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6f5de2d",
   "metadata": {},
   "source": [
    "![tracker](https://us-central1-vertex-ai-mlops-369716.cloudfunctions.net/pixel-tracking?path=statmike%2Fvertex-ai-mlops%2F05+-+TensorFlow&file=05Tools+-+Automation.ipynb)\n",
    "<!--- header table --->\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/statmike/vertex-ai-mlops/blob/main/05%20-%20TensorFlow/05Tools%20-%20Automation.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\">\n",
    "      <br>Run in<br>Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https%3A%2F%2Fraw.githubusercontent.com%2Fstatmike%2Fvertex-ai-mlops%2Fmain%2F05%2520-%2520TensorFlow%2F05Tools%2520-%2520Automation.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\">\n",
    "      <br>Run in<br>Colab Enterprise\n",
    "    </a>\n",
    "  </td>      \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/statmike/vertex-ai-mlops/blob/main/05%20-%20TensorFlow/05Tools%20-%20Automation.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      <br>View on<br>GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/statmike/vertex-ai-mlops/main/05%20-%20TensorFlow/05Tools%20-%20Automation.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      <br>Open in<br>Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68182d96-0b09-4e58-ae38-915313f6317b",
   "metadata": {},
   "source": [
    "# 05Tools - Automation\n",
    "\n",
    "This notebook will show using a Python Function to trigger jobs with the SDK summarized above.  The function will be run in a Cloud Function.  Functions are triggered, in this case triggering will be done with a Cloud Pub/Sub Topic.  Message will be sent to the Pub/Sub topic manually and on a schedule by using Cloud Scheduler.\n",
    "\n",
    "<p align=\"center\" width=\"100%\">\n",
    "    <img src=\"../architectures/overview/automation.png\" width=\"100%\">\n",
    "</p>\n",
    "    \n",
    "This notebook will focus on some helpful GCP tools for automation. In Vertex AI, Training Jobs and Pipelines are triggered to run with the Vertex AI Client library:\n",
    "\n",
    "- [Python Cloud Client Libraries](https://cloud.google.com/python/docs/reference)\n",
    "    - [google-cloud-aiplatform](https://cloud.google.com/python/docs/reference/aiplatform/latest)\n",
    "        - [`aiplatform` package](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform)\n",
    "            - Training Jobs\n",
    "                - [`aiplatform.CustomJob.from_local_script()`](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.CustomJob#google_cloud_aiplatform_CustomJob_from_local_script)\n",
    "                    - 05a, Using a Python Script\n",
    "                - [`aiplatform.CustomJob()`](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.CustomJob#google_cloud_aiplatform_CustomJob)\n",
    "                    - with [worker_pool_specs](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform_v1.types.WorkerPoolSpec) using `python_package_spec`\n",
    "                    - 05b, Using a Python Source Distribution\n",
    "                - [`aiplatform.CustomJob()`](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.CustomJob#google_cloud_aiplatform_CustomJob)\n",
    "                    - with [worker_pool_specs](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform_v1.types.WorkerPoolSpec) using `container_spec`\n",
    "                    - 05c, Using a Custom Container\n",
    "                - [`aiplatform.CustomTrainingJob()`](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.CustomTrainingJob#google_cloud_aiplatform_CustomTrainingJob)\n",
    "                    - 05d, Using a Python Script\n",
    "                - [`aiplatform.CustomPythonPackageTrainingJob()`](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.CustomPythonPackageTrainingJob)\n",
    "                    - 05e, Using a Python Source Distribution\n",
    "                - [`aiplatform.CustomContainerTrainingJob()`](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.CustomContainerTrainingJob#google_cloud_aiplatform_CustomContainerTrainingJob)\n",
    "                    - 05f, Using a Custom Container\n",
    "                - Hyperparameter Tuning Job:\n",
    "                    - [`aiplatform.HyperparameterTuningJob()`](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.HyperparameterTuningJob#google_cloud_aiplatform_HyperparameterTuningJob)\n",
    "                    - In 05g, 05h, and 05i\n",
    "            - Pipelines\n",
    "                - [`aiplatform.PipelineJob`](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.PipelineJob)\n",
    "\n",
    "**Prerequisites:**\n",
    "- 05f\n",
    "\n",
    "**Resources:**\n",
    "- Documentation\n",
    "    - [Schedule pipeline exectuion with Cloud Scheduler](https://cloud.google.com/vertex-ai/docs/pipelines/schedule-cloud-scheduler#create_a_cloud_function_with_http_trigger)\n",
    "    - [Trigger a pipeline run with Pub/Sub](https://cloud.google.com/vertex-ai/docs/pipelines/trigger-pubsub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad75654-bfed-4207-b642-a7384b0c9d75",
   "metadata": {
    "id": "od_UkDpvRmgD",
    "tags": []
   },
   "source": [
    "---\n",
    "## Colab Setup\n",
    "\n",
    "To run this notebook in Colab click [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/statmike/vertex-ai-mlops/blob/main/05%20-%20TensorFlow/05Tools%20-%20Automation.ipynb) and run the cells in this section.  Otherwise, skip this section.\n",
    "\n",
    "This cell will authenticate to GCP (follow prompts in the popup)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "400f5efc-0b27-48ea-8e49-cce0d45d083c",
   "metadata": {
    "executionInfo": {
     "elapsed": 195,
     "status": "ok",
     "timestamp": 1683726184843,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "8UO9FnqyKBlF"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'statmike-mlops-349915' # replace with project ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "743e1391-ea24-4051-ba42-8417d420374b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68869,
     "status": "ok",
     "timestamp": 1683726253709,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "N98-KK7LRkjm",
    "outputId": "09ec5008-0def-4e1a-c349-c598ee752f78"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    !gcloud config set project {PROJECT_ID}\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2de878-922e-4a7a-a6d9-64babbdb1c11",
   "metadata": {},
   "source": [
    "---\n",
    "## Installs\n",
    "\n",
    "The list `packages` contains tuples of package import names and install names.  If the import name is not found then the install name is used to install quitely for the current user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7236b501-c5c5-4847-9842-15e01e12200c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tuples of (import name, install name, min_version)\n",
    "packages = [\n",
    "    ('google.cloud.aiplatform', 'google-cloud-aiplatform'),\n",
    "    ('google.cloud.pubsub', 'google-cloud-pubsub'),\n",
    "    ('google.cloud.functions', 'google-cloud-functions'),\n",
    "    ('google.cloud.scheduler', 'google-cloud-scheduler')\n",
    "]\n",
    "\n",
    "import importlib\n",
    "install = False\n",
    "for package in packages:\n",
    "    if not importlib.util.find_spec(package[0]):\n",
    "        print(f'installing package {package[1]}')\n",
    "        install = True\n",
    "        !pip install {package[1]} -U -q --user\n",
    "    elif len(package) == 3:\n",
    "        if importlib.metadata.version(package[0]) < package[2]:\n",
    "            print(f'updating package {package[1]}')\n",
    "            install = True\n",
    "            !pip install {package[1]} -U -q --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffe63db-ecbd-4b2c-a619-8470d7b718f9",
   "metadata": {},
   "source": [
    "## API Enablement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ab39e9a-cc8a-4665-930e-408951842c61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gcloud services enable pubsub.googleapis.com\n",
    "!gcloud services enable cloudfunctions.googleapis.com\n",
    "!gcloud services enable cloudscheduler.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785dde2d-9163-40b9-8705-aebde3c05d00",
   "metadata": {},
   "source": [
    "### Restart Kernel (If Installs Occured)\n",
    "\n",
    "After a kernel restart the code submission can start with the next cell after this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcb9ff53-f392-4c63-a7a2-06d30ef47e2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if install:\n",
    "    import IPython\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dab1250-c3f2-4993-abff-7b168ac12d3a",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d92af7-fb7d-48c7-85f3-68ddac43a229",
   "metadata": {},
   "source": [
    "inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06a4092d-c650-497f-9d17-9758fb52a0f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'statmike-mlops-349915'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f57aaa40-39aa-4a52-b6d9-c3c7fa7419f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "EXPERIMENT = 'automation'\n",
    "SERIES = '05'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbec30a9-37fc-4d5f-bf31-29ccd3aa7ec6",
   "metadata": {},
   "source": [
    "packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45f6221e-965f-413e-bc04-728d4f7bb521",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "from datetime import datetime\n",
    "from IPython.display import Markdown as md\n",
    "from google.cloud import pubsub_v1\n",
    "from google.cloud import functions_v1\n",
    "from google.cloud import scheduler_v1\n",
    "#from google.cloud\n",
    "#from google.cloud\n",
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "from google.protobuf import json_format\n",
    "from google.protobuf.struct_pb2 import Value\n",
    "from google.protobuf.duration_pb2 import Duration\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de80f037-c80d-4a93-a357-a7626a658db6",
   "metadata": {},
   "source": [
    "clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdef886a-3841-4124-a4ae-72a8977433ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gcs = storage.Client(project = PROJECT_ID)\n",
    "pubsub_pubclient = pubsub_v1.PublisherClient() \n",
    "functions_client = functions_v1.CloudFunctionsServiceClient()\n",
    "scheduler_client = scheduler_v1.CloudSchedulerClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3abf4be-ebdb-442e-ae48-09dd5f626e69",
   "metadata": {},
   "source": [
    "parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29c66ff7-dfd4-469e-b669-8386ecfced6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DIR = f\"temp/{EXPERIMENT}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "479db5db-1fd3-4f3c-96fe-67576c26a674",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1026793852137-compute@developer.gserviceaccount.com'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SERVICE_ACCOUNT = !gcloud config list --format='value(core.account)' \n",
    "SERVICE_ACCOUNT = SERVICE_ACCOUNT[0]\n",
    "SERVICE_ACCOUNT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b43610c-deb2-466d-88e7-31bb9d167a0b",
   "metadata": {},
   "source": [
    "List the service accounts current roles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9329f141-f9b9-4b38-b4dc-51b8d7b7b22d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROLE\n",
      "roles/bigquery.admin\n",
      "roles/owner\n",
      "roles/run.admin\n",
      "roles/secretmanager.secretAccessor\n",
      "roles/storage.objectAdmin\n"
     ]
    }
   ],
   "source": [
    "!gcloud projects get-iam-policy $PROJECT_ID --filter=\"bindings.members:$SERVICE_ACCOUNT\" --format='table(bindings.role)' --flatten=\"bindings[].members\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ecdea7-880c-4b8f-85b1-67577ec56e5e",
   "metadata": {},
   "source": [
    ">Note: If the resulting list is missing [roles/storage.objectAdmin](https://cloud.google.com/storage/docs/access-control/iam-roles) then [revisit the setup notebook](../00%20-%20Setup/00%20-%20Environment%20Setup.ipynb#permissions) and add this permission to the service account with the provided instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d74254-2a9b-4b81-a8d2-2fc9a1f9ebcf",
   "metadata": {},
   "source": [
    "environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "876379dc-dc1a-4dd2-87ac-1c9cc9c83afa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(DIR):\n",
    "    os.makedirs(DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115c4dc6-4e9a-47fa-92c7-8b64313c056c",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Pub/Sub\n",
    "\n",
    "The main concepts:\n",
    "- Topic - a feed of messages\n",
    "     - Publish - send a new message to a topic\n",
    "     - Subscription - receive messages that arrive on topic\n",
    "          - Push - the subscriber has new messages pushed to it\n",
    "          - Pull - the subscriber request new messages by pulling them\n",
    "          \n",
    "In this example, a topic will be set up for training the model in the local `EXPERIMENT`.  Publishing a new message to this topic will trigger a training run initiated by the Cloud Function (setup below).  The Cloud Funtion will have a push subscription to the topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cce2f700-99e2-4d62-af4f-ea8452900ae2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PUBSUB_TOPIC = f'train-{SERIES}-{EXPERIMENT}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31a45993-f31a-411e-8844-6f37f56d7184",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projects/statmike-mlops-349915/topics/train-05-automation\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    topic = pubsub_pubclient.get_topic(\n",
    "        topic = pubsub_pubclient.topic_path(PROJECT_ID, PUBSUB_TOPIC)\n",
    "    )\n",
    "    print(topic.name)\n",
    "except Exception:\n",
    "    topic = pubsub_pubclient.create_topic(\n",
    "        name = pubsub_pubclient.topic_path(PROJECT_ID, PUBSUB_TOPIC)\n",
    "    )\n",
    "    print(topic.name)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f81ede-fe92-4c8c-8980-85fefefbd6f3",
   "metadata": {},
   "source": [
    "---\n",
    "## Cloud Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cb5495-c2fa-4e47-ab47-9146c412b0eb",
   "metadata": {},
   "source": [
    "### Create Files for Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2881207e-272c-4487-81df-2ee3d49ff025",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(f'{DIR}/function'):\n",
    "    shutil.rmtree(f'{DIR}/function')\n",
    "os.makedirs(f'{DIR}/function')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "439f5cfc-744f-4734-ac62-f1fba50e5041",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing temp/automation/function/main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {DIR}/function/main.py\n",
    "\n",
    "# packages\n",
    "import base64\n",
    "import json\n",
    "from google.cloud import aiplatform\n",
    "from datetime import datetime\n",
    "\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "# function that runs the code from the 05f notebook with inputs\n",
    "def train(event, context):\n",
    "    #Triggered from a message on a Cloud Pub/Sub topic.\n",
    "    \n",
    "    # decode the data input from the event dictionary and convert to Python dictionary\n",
    "    function_input = json.loads(base64.b64decode(event['data']).decode('utf-8'))\n",
    "    print(function_input)\n",
    "    \n",
    "    # INPUTS\n",
    "    EPOCHS = function_input['EPOCHS']\n",
    "    BATCH_SIZE = function_input['BATCH_SIZE']\n",
    "    VAR_TARGET = function_input['VAR_TARGET']\n",
    "    VAR_OMIT = function_input['VAR_OMIT']\n",
    "    PROJECT_ID = function_input['PROJECT_ID']\n",
    "    BQ_PROJECT = function_input['BQ_PROJECT']\n",
    "    BQ_DATASET = function_input['BQ_DATASET']\n",
    "    BQ_TABLE = function_input['BQ_TABLE']\n",
    "    REGION = function_input['REGION']\n",
    "    EXPERIMENT = function_input['EXPERIMENT']\n",
    "    SERIES = function_input['SERIES']\n",
    "    EXPERIMENT_NAME = function_input['EXPERIMENT_NAME']\n",
    "    RUN_NAME = f'run-{TIMESTAMP}'\n",
    "    TRAIN_COMPUTE = function_input['TRAIN_COMPUTE']\n",
    "    DEPLOY_IMAGE = function_input['DEPLOY_IMAGE']\n",
    "    URI = function_input['URI']\n",
    "    REPOSITORY = function_input['REPOSITORY']\n",
    "    SERVICE_ACCOUNT = function_input['SERVICE_ACCOUNT']\n",
    "    \n",
    "    # clients\n",
    "    aiplatform.init(project = PROJECT_ID, location = REGION)\n",
    "    \n",
    "    # Get Vertex AI Experiment Tensorboard Instance Name\n",
    "    tb = aiplatform.Tensorboard.list(filter=f\"labels.series={SERIES}\")\n",
    "    if tb:\n",
    "        tb = tb[0]\n",
    "    else: \n",
    "        tb = aiplatform.Tensorboard.create(display_name = SERIES, labels = {'series' : f'{SERIES}'})\n",
    "    \n",
    "    # Setup Vertex AI Experiment\n",
    "    aiplatform.init(experiment = EXPERIMENT_NAME, experiment_tensorboard = tb.resource_name)\n",
    "    \n",
    "    # Setup Training Job\n",
    "    CMDARGS = [\n",
    "        \"--epochs=\" + str(EPOCHS),\n",
    "        \"--batch_size=\" + str(BATCH_SIZE),\n",
    "        \"--var_target=\" + VAR_TARGET,\n",
    "        \"--var_omit=\" + VAR_OMIT,\n",
    "        \"--project_id=\" + PROJECT_ID,\n",
    "        \"--bq_project=\" + BQ_PROJECT,\n",
    "        \"--bq_dataset=\" + BQ_DATASET,\n",
    "        \"--bq_table=\" + BQ_TABLE,\n",
    "        \"--region=\" + REGION,\n",
    "        \"--experiment=\" + EXPERIMENT,\n",
    "        \"--series=\" + SERIES,\n",
    "        \"--experiment_name=\" + EXPERIMENT_NAME,\n",
    "        \"--run_name=\" + RUN_NAME\n",
    "    ]\n",
    "\n",
    "    trainingJob = aiplatform.CustomContainerTrainingJob(\n",
    "        display_name = f'{SERIES}_{EXPERIMENT}_{TIMESTAMP}',\n",
    "        container_uri = f\"{REPOSITORY}/{EXPERIMENT}_trainer\",\n",
    "        model_serving_container_image_uri = DEPLOY_IMAGE,\n",
    "        staging_bucket = f\"{URI}/models/{TIMESTAMP}\",\n",
    "        labels = {'series' : f'{SERIES}', 'experiment' : f'{EXPERIMENT}', 'experiment_name' : f'{EXPERIMENT_NAME}', 'run_name' : f'{RUN_NAME}'}\n",
    "    ) \n",
    "    \n",
    "    # Run Training Job AND Upload The Model\n",
    "    modelmatch = aiplatform.Model.list(filter = f'display_name={SERIES}_{EXPERIMENT} AND labels.series={SERIES} AND labels.experiment={EXPERIMENT}')\n",
    "\n",
    "    upload_model = True\n",
    "    if modelmatch:\n",
    "        print(\"Model Already in Registry:\")\n",
    "        if RUN_NAME in modelmatch[0].version_aliases:\n",
    "            print(\"This version already loaded, no action taken.\")\n",
    "            upload_model = False\n",
    "            model = aiplatform.Model(model_name = modelmatch[0].resource_name)\n",
    "        else:\n",
    "            print('Loading model as new default version.')\n",
    "            parent_model = modelmatch[0].resource_name\n",
    "    else:\n",
    "        print('This is a new model, creating in model registry')\n",
    "        parent_model = ''\n",
    "\n",
    "    if upload_model:\n",
    "        model = trainingJob.run(\n",
    "            model_display_name = f'{SERIES}_{EXPERIMENT}',\n",
    "            model_labels = {'series' : f'{SERIES}', 'experiment' : f'{EXPERIMENT}', 'experiment_name' : f'{EXPERIMENT_NAME}', 'run_name' : f'{RUN_NAME}'},\n",
    "            model_id = f'model_{SERIES}_{EXPERIMENT}',\n",
    "            parent_model = parent_model,\n",
    "            is_default_version = True,\n",
    "            model_version_aliases = [RUN_NAME],\n",
    "            model_version_description = RUN_NAME,\n",
    "            base_output_dir = f\"{URI}/models/{TIMESTAMP}\",\n",
    "            service_account = SERVICE_ACCOUNT,\n",
    "            args = CMDARGS,\n",
    "            replica_count = 1,\n",
    "            machine_type = TRAIN_COMPUTE,\n",
    "            accelerator_count = 0,\n",
    "            tensorboard = tb.resource_name\n",
    "        )\n",
    "    \n",
    "    # THIS FUNCTION WILL TIMEOUT BEFORE IT CAN RUN THE FOLLOWING\n",
    "    # CONSIDER A SEPERATE FUNCTION THAT IS TRIGGERED BY A MODEL REGISTY UPDATE\n",
    "    \n",
    "    # Vertex AI Experiment Update and Review\n",
    "    expRun = aiplatform.ExperimentRun(run_name = RUN_NAME, experiment = EXPERIMENT_NAME)\n",
    "    expRun.log_params({\n",
    "        'model.uri': model.uri,\n",
    "        'model.display_name': model.display_name,\n",
    "        'model.name': model.name,\n",
    "        'model.resource_name': model.resource_name,\n",
    "        'model.version_id': model.version_id,\n",
    "        'model.versioned_resource_name': model.versioned_resource_name,\n",
    "        'customJobs.display_name': customJob.display_name,\n",
    "        'customJobs.resource_name': customJob.resource_name,\n",
    "        'customJobs.link': job_link,\n",
    "        'customJobs.tensorboard': board_link\n",
    "    })\n",
    "    expRun.update_state(state = aiplatform.gapic.Execution.State.COMPLETE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b4fae4c-1703-485a-af12-04e466d0cdc3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing temp/automation/function/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile {DIR}/function/requirements.txt\n",
    "pandas\n",
    "google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac6b1ed-383e-42d2-9daf-39e64e10aaeb",
   "metadata": {},
   "source": [
    "### Store Files in Cloud Storage\n",
    "\n",
    "Copy from local folder (`DIR/function`) to GCS at the path `SERIES/EXPERIMENT/function`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25a93ddf-adb9-4f9f-b6c0-4cc7faa9f822",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main.py  requirements.txt\n"
     ]
    }
   ],
   "source": [
    "!ls {DIR}/function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aae18409-9466-4884-a912-ed3324f3d311",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main.py\n",
      "requirements.txt\n"
     ]
    }
   ],
   "source": [
    "!cd {DIR}/function && tar czvf function.tar.gz main.py requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ef013f2-eb74-4648-b77e-064ac28b2cd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(f'{DIR}/function/function.zip', mode = 'w') as archive:\n",
    "    archive.write(f'{DIR}/function/main.py', 'main.py')\n",
    "    archive.write(f'{DIR}/function/requirements.txt', 'requirements.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5730588-87a2-469f-b94d-79840250b0e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function.tar.gz  function.zip  main.py\trequirements.txt\n"
     ]
    }
   ],
   "source": [
    "!ls {DIR}/function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5e325410-b2d3-4057-9776-d3967a940ed0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Name                                             Modified             Size\n",
      "main.py                                        2024-02-22 19:02:24         5206\n",
      "requirements.txt                               2024-02-22 19:02:40           31\n"
     ]
    }
   ],
   "source": [
    "with zipfile.ZipFile(f'{DIR}/function/function.zip', mode = 'r') as zip:\n",
    "    zip.printdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f6521b22-1ad1-4b40-9310-bc5530a31f04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bucket = gcs.lookup_bucket(PROJECT_ID)\n",
    "SOURCEPATH = f'{SERIES}/{EXPERIMENT}/function'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fedac056-7f51-45a1-99f3-f4505e8c1e72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "blob = bucket.blob(f'{SOURCEPATH}/function.zip')\n",
    "blob.upload_from_filename(f'{DIR}/function/function.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bb660c52-dabd-40ce-9b48-a428c62fb4bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Blob: statmike-mlops-349915, 05/automation/function/function.zip, 1708628600181344>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(bucket.list_blobs(prefix = f'{SOURCEPATH}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7c682d2e-5c6d-45da-9e5e-1e7de0bab73d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the bucket directly here:\n",
      "https://console.cloud.google.com/storage/browser/statmike-mlops-349915/05/automation/function;tab=objects&project=statmike-mlops-349915\n"
     ]
    }
   ],
   "source": [
    "print(f\"View the bucket directly here:\\nhttps://console.cloud.google.com/storage/browser/{PROJECT_ID}/{SOURCEPATH};tab=objects&project={PROJECT_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8e0bbd-1e03-4739-96c5-3eb1b717298b",
   "metadata": {},
   "source": [
    "### Create (or Update) Cloud Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5bfb0f31-688a-4534-a6f6-8346f28eb819",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "function_name = f'train-{SERIES}-{EXPERIMENT}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fa902f5b-2ff7-491f-9642-80092dcd2ee9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "functionDef = functions_v1.CloudFunction()\n",
    "functionDef.name = f'projects/{PROJECT_ID}/locations/{REGION}/functions/{function_name}'\n",
    "functionDef.source_archive_url = f\"gs://{PROJECT_ID}/{SOURCEPATH}/function.zip\"\n",
    "functionDef.event_trigger = functions_v1.EventTrigger()\n",
    "functionDef.event_trigger.event_type = 'providers/cloud.pubsub/eventTypes/topic.publish'\n",
    "functionDef.event_trigger.resource = topic.name\n",
    "functionDef.available_memory_mb = 512\n",
    "functionDef.runtime = 'python310'\n",
    "functionDef.entry_point = 'train'\n",
    "functionDef.timeout = Duration(seconds = 540)\n",
    "functionDef.service_account_email = SERVICE_ACCOUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "267febd4-66da-471d-a958-c6591e5ff3d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    function = functions_client.get_function(\n",
    "        name = f'projects/{PROJECT_ID}/locations/{REGION}/functions/{function_name}'\n",
    "    )\n",
    "    request = functions_v1.UpdateFunctionRequest(\n",
    "        function = functionDef\n",
    "    )\n",
    "    operation = functions_client.update_function(request = request)\n",
    "except Exception:\n",
    "    request = functions_v1.CreateFunctionRequest(\n",
    "        location = f\"projects/{PROJECT_ID}/locations/{REGION}\",\n",
    "        function = functionDef\n",
    "    )\n",
    "    operation = functions_client.create_function(request = request)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bb04b527-d252-456e-81c8-c1ff07188011",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"projects/statmike-mlops-349915/locations/us-central1/functions/train-05-automation\"\n",
      "source_archive_url: \"gs://statmike-mlops-349915/05/automation/function/function.zip\"\n",
      "event_trigger {\n",
      "  event_type: \"providers/cloud.pubsub/eventTypes/topic.publish\"\n",
      "  resource: \"projects/statmike-mlops-349915/topics/train-05-automation\"\n",
      "  service: \"pubsub.googleapis.com\"\n",
      "  failure_policy {\n",
      "  }\n",
      "}\n",
      "status: ACTIVE\n",
      "entry_point: \"train\"\n",
      "runtime: \"python310\"\n",
      "timeout {\n",
      "  seconds: 540\n",
      "}\n",
      "available_memory_mb: 512\n",
      "service_account_email: \"1026793852137-compute@developer.gserviceaccount.com\"\n",
      "update_time {\n",
      "  seconds: 1708632962\n",
      "  nanos: 381000000\n",
      "}\n",
      "version_id: 3\n",
      "max_instances: 3000\n",
      "ingress_settings: ALLOW_ALL\n",
      "build_id: \"48ae8761-0257-4d35-9426-375cfe3cb36e\"\n",
      "build_name: \"projects/1026793852137/locations/us-central1/builds/48ae8761-0257-4d35-9426-375cfe3cb36e\"\n",
      "docker_registry: ARTIFACT_REGISTRY\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = operation.result()\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5d43d6a9-054c-436b-afd4-ef9cb98175c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review the Cloud Function in the console here:\n",
      "https://console.cloud.google.com/functions/list?env=gen1&project=statmike-mlops-349915\n"
     ]
    }
   ],
   "source": [
    "print(f'Review the Cloud Function in the console here:\\nhttps://console.cloud.google.com/functions/list?env=gen1&project={PROJECT_ID}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a813ea94-22c4-4bd7-8eea-5929d6698459",
   "metadata": {},
   "source": [
    "---\n",
    "## Manual Run of Cloud Function\n",
    "\n",
    "Publish a message to the Pub/Sub topic that will cause the Cloud Function to initiate training.  The code below could be anywhere you want to trigger training!\n",
    "\n",
    "The function will receive the message as `event` in the format:\n",
    "```\n",
    "{\n",
    "    '@type': 'type.googleapis.com/google.pubsub.v1.PubsubMessage',\n",
    "    'attributes': {'key' : 'value', ...},\n",
    "    'data': <base64 encoded string>\n",
    "}\n",
    "```\n",
    "\n",
    "To handle the `event` and retrieve the inputs of the message three things need to happen:\n",
    "1. reference the 'data' value as `event['data']`\n",
    "2. decode the 'data' value with `base64.b64decode(<1>).decode('utf-8')`\n",
    "3. convert the decoded string into a Python dictionary with `json.loads(<2>)`\n",
    "\n",
    "This looks like:\n",
    "```\n",
    "funtion_inputs = json.loads(base64.b64decode(event['data']).decode('utf-8'))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6ebaef20-6e01-4eaa-83f7-cb2717121684",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = f'experiment-{SERIES}-05f-tf-classification-dnn'\n",
    "BUCKET = PROJECT_ID\n",
    "URI = f\"gs://{BUCKET}/{SERIES}/05f\"\n",
    "REPOSITORY = f\"{REGION}-docker.pkg.dev/{PROJECT_ID}/{PROJECT_ID}\"\n",
    "\n",
    "function_input = {\n",
    "    'EPOCHS': 10,\n",
    "    'BATCH_SIZE': 100,\n",
    "    'VAR_TARGET': 'Class',\n",
    "    'VAR_OMIT': 'transaction_id,splits',\n",
    "    'PROJECT_ID': PROJECT_ID,\n",
    "    'BQ_PROJECT': PROJECT_ID,\n",
    "    'BQ_DATASET': 'fraud',\n",
    "    'BQ_TABLE': 'fraud_prepped',\n",
    "    'REGION': REGION,\n",
    "    'EXPERIMENT': '05f',\n",
    "    'SERIES': SERIES,\n",
    "    'EXPERIMENT_NAME': EXPERIMENT_NAME,\n",
    "    'TRAIN_COMPUTE': 'n1-standard-4',\n",
    "    'DEPLOY_IMAGE': 'us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-12:latest',\n",
    "    'URI': URI,\n",
    "    'REPOSITORY': REPOSITORY,\n",
    "    'SERVICE_ACCOUNT': SERVICE_ACCOUNT\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c09e6854-2d33-48a9-9a0b-3ccb3af4ef86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "message = json.dumps(function_input)\n",
    "message = message.encode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "448b5eba-2581-4a39-8057-ab2741f4151a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "future = pubsub_pubclient.publish(topic.name, message, trigger = 'manual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "007bb1a8-d77d-492d-973f-5f2d2cbba0ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10535176148570661'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202f798b-045a-468b-810d-42009c3500f1",
   "metadata": {},
   "source": [
    "---\n",
    "## Scheduled Run with Cloud Scheduler\n",
    "\n",
    "Use Cloud Scheduler to publish a message to the topic at any defined interval which will cause the Cloud Function to initiate training.\n",
    "\n",
    "Resources:\n",
    "- List of Time zones - [TZ Database Names](https://en.wikipedia.org/wiki/List_of_tz_database_time_zones)\n",
    "- Job Frequency - [unix-cron format guide](https://man7.org/linux/man-pages/man5/crontab.5.html)\n",
    "    - minute hour day_of_month month day_of_week\n",
    "    - 0 23 * * tue = 11PM every Tuesday\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "53913426-a4e6-4202-b094-b290167814fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "schedule_name = f'train-{SERIES}-{EXPERIMENT}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ab05c8ae-cefb-4fd4-9b12-faeeb97f33a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"projects/statmike-mlops-349915/locations/us-central1/jobs/train-05-automation\"\n",
      "pubsub_target {\n",
      "  topic_name: \"projects/statmike-mlops-349915/topics/train-05-automation\"\n",
      "  data: \"{\\\"EPOCHS\\\": 10, \\\"BATCH_SIZE\\\": 100, \\\"VAR_TARGET\\\": \\\"Class\\\", \\\"VAR_OMIT\\\": \\\"transaction_id,splits\\\", \\\"PROJECT_ID\\\": \\\"statmike-mlops-349915\\\", \\\"BQ_PROJECT\\\": \\\"statmike-mlops-349915\\\", \\\"BQ_DATASET\\\": \\\"fraud\\\", \\\"BQ_TABLE\\\": \\\"fraud_prepped\\\", \\\"REGION\\\": \\\"us-central1\\\", \\\"EXPERIMENT\\\": \\\"05f\\\", \\\"SERIES\\\": \\\"05\\\", \\\"EXPERIMENT_NAME\\\": \\\"experiment-05-05f-tf-classification-dnn\\\", \\\"TRAIN_COMPUTE\\\": \\\"n1-standard-4\\\", \\\"DEPLOY_IMAGE\\\": \\\"us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-12:latest\\\", \\\"URI\\\": \\\"gs://statmike-mlops-349915/05/05f\\\", \\\"REPOSITORY\\\": \\\"us-central1-docker.pkg.dev/statmike-mlops-349915/statmike-mlops-349915\\\", \\\"SERVICE_ACCOUNT\\\": \\\"1026793852137-compute@developer.gserviceaccount.com\\\"}\"\n",
      "  attributes {\n",
      "    key: \"trigger\"\n",
      "    value: \"scheduled\"\n",
      "  }\n",
      "}\n",
      "schedule: \"0 23 * * tue\"\n",
      "time_zone: \"America/New_York\"\n",
      "user_update_time {\n",
      "  seconds: 1708633994\n",
      "}\n",
      "state: ENABLED\n",
      "schedule_time {\n",
      "  seconds: 1709092800\n",
      "  nanos: 257336000\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "job_config = scheduler_v1.Job(\n",
    "    name = f'projects/{PROJECT_ID}/locations/{REGION}/jobs/{schedule_name}',\n",
    "    pubsub_target = scheduler_v1.PubsubTarget(\n",
    "        topic_name = topic.name,\n",
    "        data = message,\n",
    "        attributes = {'trigger': 'scheduled'}\n",
    "    ),\n",
    "    schedule = '0 23 * * tue',\n",
    "    time_zone = 'America/New_York'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    schedule = scheduler_client.get_job(name = scheduler_client.job_path(PROJECT_ID, REGION, schedule_name))\n",
    "    request = scheduler_v1.UpdateJobRequest(\n",
    "        job = job_config\n",
    "    )\n",
    "    schedule = scheduler_client.update_job(request = request)\n",
    "except Exception:\n",
    "    request = scheduler_v1.CreateJobRequest(\n",
    "        parent = f'projects/{PROJECT_ID}/locations/{REGION}',\n",
    "        job = job_config\n",
    "    )\n",
    "    schedule = scheduler_client.create_job(request = request)\n",
    "\n",
    "print(schedule)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e2834e9a-f5f4-4508-86b0-07d61e8ed42e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review the Cloud Scheduler in the console here:\n",
      "https://console.cloud.google.com/cloudscheduler?&project=statmike-mlops-349915\n"
     ]
    }
   ],
   "source": [
    "print(f'Review the Cloud Scheduler in the console here:\\nhttps://console.cloud.google.com/cloudscheduler?&project={PROJECT_ID}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d62dd66-e178-4d3d-b81a-346bc26a8b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m115",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m115"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
