{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40eace5b",
   "metadata": {},
   "source": [
    "# 05h - Vertex AI > Training > Hyperparameter Tuning Jobs With Tensorboard HPARAMS\n",
    "\n",
    "**05 Series Overview**\n",
    "\n",
    ">**NOTE:** The notebooks in the `05 - TensorFlow` series demonstrate training, serving and operations for TensorFlow models and take advantage of [Vertex AI TensorBoard](https://cloud.google.com/vertex-ai/docs/experiments/tensorboard-overview) to track training across experiments.  Running these notebooks will create a Vertex AI TensorBoard instance which has a user-based montly pricing that is different than other services that charge by usage.  This cost is $300 per user - [Vertex AI Pricing](https://cloud.google.com/vertex-ai/pricing#tensorboard).\n",
    "\n",
    "Where a model gets trained is where it consumes computing resources.  With Vertex AI, you have choices for configuring the computing resources available at training.  This notebook is an example of an execution environment.  When it was set up there were choices for machine type and accelerators (GPUs).  \n",
    "\n",
    "In the [05 - Vertex AI Custom Model - TensorFlow - in Notebook](./05%20-%20Vertex%20AI%20Custom%20Model%20-%20TensorFlow%20-%20in%20Notebook.ipynb) notebook, the model training happened directly in the notebook.  The model was then imported to Vertex AI and deployed to an endpoint for online predictions. \n",
    "\n",
    "In this `05a-05i` series of demonstrations, the same model is trained using managed computing resources in Vertex AI Training as managed jobs.  These jobs will be demonstrated as:\n",
    "\n",
    "-  Custom Job that trains and saves (to GCS) a model from a python script (`05a`), python source distribution (`05b`), and custom container (`05c`)\n",
    "-  Training Pipeline that trains and registers a model from a python script (`05d`), python source distribution (`05e`), and custom container (`05f`)\n",
    "-  Hyperparameter Tuning Jobs from a python script (`05g`), python source distribution (`05h`), and custom container (`05i`)\n",
    "\n",
    "**This Notebook (`05h`): An extension of `05b` with Hyperparmeter Tuning - And Tensorboard HParams**\n",
    "\n",
    "This notebook trains the same Tensorflow Keras model from [05 - Vertex AI Custom Model - TensorFlow - in Notebook](./05%20-%20Vertex%20AI%20Custom%20Model%20-%20TensorFlow%20-%20in%20Notebook.ipynb) by first modifying and saving the training code to a Python script as shown in [05 - Vertex AI Custom Model - TensorFlow - Notebook to Script](./05%20-%20Vertex%20AI%20Custom%20Model%20-%20TensorFlow%20-%20Notebook%20to%20Script.ipynb). \n",
    "\n",
    "A Python source distribution is built containing the script.  For more guidance on this process visit the tip notebook [Python Packages](../Tips/Python%20Packages.ipynb).  The source distribution is then used as an input for a Vertex AI > Training > Custom Job that is also assigned compute resources and a [pre-built container for custom training](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers) for executing the training in a managed service.  While this example fits nicely in a single script, larger examples will benefit from the flexibility offered by source distributions and this notebook gives an example of making the shift.\n",
    "\n",
    "The Custom Job is then used as the input for a Vertex AI > Training > Hyperparameter Tuning Job.  This runs and manages the tuning loops for the number of trials in each loop, collects the metric(s) and manages the parameters with the selected search algorithm for parameter modification.\n",
    "\n",
    "This job is launched using the Vertex AI client library:\n",
    "- [Python Cloud Client Libraries](https://cloud.google.com/python/docs/reference)\n",
    "    - [google-cloud-aiplatform](https://cloud.google.com/python/docs/reference/aiplatform/latest)\n",
    "        - [`aiplatform` package](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform)\n",
    "            - Custom Job:\n",
    "                - [`aiplatform.CustomJob()`](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.CustomJob#google_cloud_aiplatform_CustomJob)\n",
    "                    - with [worker_pool_specs](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform_v1.types.WorkerPoolSpec) using `python_package_spec`\n",
    "            - Hyperparameter Tuning Job:\n",
    "                - [`aiplatform.HyperparameterTuningJob()`](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.HyperparameterTuningJob#google_cloud_aiplatform_HyperparameterTuningJob)\n",
    "\n",
    "**Vertex AI Training**\n",
    "\n",
    "In Vertex AI Training you can run your training code as a job where you specify the compute resources to use. For tips on preparing code, running training jobs, and workflows for building custom containers with software and training code combined please visit these [tips notebooks](../Tips/readme.md) in this repository:\n",
    "- [Python Packages](../Tips/Python%20Packages.ipynb)\n",
    "- [Python Custom Containers](../Tips/Python%20Custom%20Containers.ipynb)\n",
    "- [Python Training](../Tips/Python%20Training.ipynb)\n",
    "\n",
    "<p align=\"center\" width=\"100%\">\n",
    "    <img src=\"../architectures/overview/training.png\" width=\"45%\">\n",
    "    &nbsp; &nbsp; &nbsp; &nbsp;\n",
    "    <img src=\"../architectures/overview/training2.png\" width=\"45%\">\n",
    "</p>\n",
    "\n",
    "**Prerequisites:**\n",
    "-  [01 - BigQuery - Table Data Source](../01%20-%20Data%20Sources/01%20-%20BigQuery%20-%20Table%20Data%20Source.ipynb)\n",
    "-  Understanding:\n",
    "    -  Model overview in [05 - Vertex AI Custom Model - TensorFlow - in Notebook](./05%20-%20Vertex%20AI%20Custom%20Model%20-%20TensorFlow%20-%20in%20Notebook.ipynb)\n",
    "    -  Convert notebook code to Python Script in [05 - Vertex AI Custom Model - TensorFlow - Notebook to Script](./05%20-%20Vertex%20AI%20Custom%20Model%20-%20TensorFlow%20-%20Notebook%20to%20Script.ipynb)\n",
    "\n",
    "**Resources:**\n",
    "-  [BigQuery Tensorflow Reader](https://www.tensorflow.org/io/tutorials/bigquery)\n",
    "-  [Keras Sequential](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential)\n",
    "   -  [Keras API](https://www.tensorflow.org/api_docs/python/tf/keras)\n",
    "-  [Python Client For Google BigQuery](https://googleapis.dev/python/bigquery/latest/index.html)\n",
    "-  [Tensorflow Python Client](https://www.tensorflow.org/api_docs/python/tf)\n",
    "-  [Tensorflow I/O Python Client](https://www.tensorflow.org/io/api_docs/python/tfio/bigquery)\n",
    "-  [Python Client for Vertex AI](https://googleapis.dev/python/aiplatform/latest/aiplatform.html)\n",
    "-  [Create a Python source distribution](https://cloud.google.com/vertex-ai/docs/training/create-python-pre-built-container) for a Vertex AI custom training job\n",
    "-  Containers for training (Pre-Built)\n",
    "   -  [Overview](https://cloud.google.com/vertex-ai/docs/training/create-python-pre-built-container)\n",
    "   -  [List](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers)\n",
    "-  Vertex AI Hyperparameter Tuning\n",
    "   -  [Overview of Hyperparameter Tuning](https://cloud.google.com/vertex-ai/docs/training/hyperparameter-tuning-overview)\n",
    "   -  [Using Hyperparameter Tuning](https://cloud.google.com/vertex-ai/docs/training/using-hyperparameter-tuning)\n",
    "-  [Tensorboard HParams Dashboard](https://www.tensorflow.org/tensorboard/hyperparameter_tuning_with_hparams)\n",
    "\n",
    "\n",
    "**Conceptual Flow & Workflow**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img alt=\"Conceptual Flow\" src=\"../architectures/slides/05h_arch.png\" width=\"45%\">\n",
    "&nbsp; &nbsp; &nbsp; &nbsp;\n",
    "  <img alt=\"Workflow\" src=\"../architectures/slides/05h_console.png\" width=\"45%\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e6a74f",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46013789-c290-4543-a3b8-f0ad38350c18",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Package Installs (if needed)\n",
    "\n",
    "The cells below check to see if the required Python libraries are installed.  If any are not it will print a message to do the install with the associated pip command to use.  These installs must be completed before continuing this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd34e1ad-c9d0-496f-941d-09fcc9fdec0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import build\n",
    "except ImportError:\n",
    "    print('You need to pip install build')\n",
    "    !pip install build -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12d7006-6ebd-4679-86c8-cf9b76f8d43b",
   "metadata": {},
   "source": [
    "### Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c6bc3a",
   "metadata": {},
   "source": [
    "inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aacef9d1-90ec-4d61-a500-daeb2cb31d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'statmike-mlops-349915'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbf17164",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "EXPERIMENT = '05h'\n",
    "SERIES = '05'\n",
    "\n",
    "# source data\n",
    "BQ_PROJECT = PROJECT_ID\n",
    "BQ_DATASET = 'fraud'\n",
    "BQ_TABLE = 'fraud_prepped'\n",
    "\n",
    "# Resources\n",
    "TRAIN_IMAGE = 'us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-7:latest'\n",
    "DEPLOY_IMAGE ='us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-7:latest'\n",
    "TRAIN_COMPUTE = 'n1-standard-4'\n",
    "DEPLOY_COMPUTE = 'n1-standard-4'\n",
    "\n",
    "# Model Training\n",
    "VAR_TARGET = 'Class'\n",
    "VAR_OMIT = 'transaction_id' # add more variables to the string with space delimiters\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490f950e",
   "metadata": {},
   "source": [
    "packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e9a79e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "from datetime import datetime\n",
    "import pkg_resources\n",
    "from IPython.display import Markdown as md\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "from google.protobuf import json_format\n",
    "from google.protobuf.struct_pb2 import Value\n",
    "import json\n",
    "import os, shutil\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0de49a4",
   "metadata": {},
   "source": [
    "clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d98a75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
    "gcs = storage.Client()\n",
    "bq = bigquery.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fcf6e6",
   "metadata": {},
   "source": [
    "parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcb21c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "BUCKET = PROJECT_ID\n",
    "URI = f\"gs://{BUCKET}/{SERIES}/{EXPERIMENT}\"\n",
    "DIR = f\"temp/{EXPERIMENT}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "22822892-69b2-4430-819f-d352c1a4b01a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1026793852137-compute@developer.gserviceaccount.com'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SERVICE_ACCOUNT = !gcloud config list --format='value(core.account)' \n",
    "SERVICE_ACCOUNT = SERVICE_ACCOUNT[0]\n",
    "SERVICE_ACCOUNT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29c2ca0-90c7-4e90-a2ff-c4eb81458303",
   "metadata": {},
   "source": [
    "List the service accounts current roles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "cdcab0b8-8462-4596-841f-ccbad3f79c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROLE\n",
      "roles/bigquery.admin\n",
      "roles/owner\n",
      "roles/run.admin\n",
      "roles/storage.objectAdmin\n"
     ]
    }
   ],
   "source": [
    "!gcloud projects get-iam-policy $PROJECT_ID --filter=\"bindings.members:$SERVICE_ACCOUNT\" --format='table(bindings.role)' --flatten=\"bindings[].members\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b118e70b-5807-4a55-875c-dd601e3d6d22",
   "metadata": {},
   "source": [
    ">Note: If the resulting list is missing [roles/storage.objectAdmin](https://cloud.google.com/storage/docs/access-control/iam-roles) then [revisit the setup notebook](../00%20-%20Setup/00%20-%20Environment%20Setup.ipynb#permissions) and add this permission to the service account with the provided instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feec6ffb",
   "metadata": {},
   "source": [
    "environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e66c810",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf {DIR}\n",
    "!mkdir -p {DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd61a106-da1a-424c-8c4b-fb442c6a95d9",
   "metadata": {},
   "source": [
    "Experiment Tracking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f0d96c2-4e2c-48c5-91b0-cb228be73f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAMEWORK = 'tf'\n",
    "TASK = 'classification'\n",
    "MODEL_TYPE = 'dnn'\n",
    "EXPERIMENT_NAME = f'experiment-{SERIES}-{EXPERIMENT}-{FRAMEWORK}-{TASK}-{MODEL_TYPE}'\n",
    "RUN_NAME = f'run-{TIMESTAMP}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7127c117-0631-49f6-adf5-2efe7b69c880",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Get Vertex AI Experiments Tensorboard Instance Name\n",
    "[Vertex AI Experiments](https://cloud.google.com/vertex-ai/docs/experiments/tensorboard-overview) has managed [Tensorboard](https://www.tensorflow.org/tensorboard) instances that you can track Tensorboard Experiments (a training run or hyperparameter tuning sweep).  \n",
    "\n",
    "The training job will show up as an experiment for the Tensorboard instance and have the same name as the training job ID.\n",
    "\n",
    "This code checks to see if a Tensorboard Instance has been created in the project, retrieves it if so, creates it otherwise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "106cfd64-55d1-4e89-ba15-758652d06ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = aiplatform.Tensorboard.list(filter=f\"labels.series={SERIES}\")\n",
    "if tb:\n",
    "    tb = tb[0]\n",
    "else: \n",
    "    tb = aiplatform.Tensorboard.create(display_name = SERIES, labels = {'series' : f'{SERIES}'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d45cfd18-c7b9-4075-8f13-6c315bd36111",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/1026793852137/locations/us-central1/tensorboards/7179142426307592192'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb.resource_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723d5f27-d596-4ba7-b3bd-be449da7d04c",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup Vertex AI Experiments\n",
    "\n",
    "The code in this section initializes the experiment and starts a run that represents this notebook.  Throughout the notebook sections for model training and evaluation information will be logged to the experiment using:\n",
    "- [.log_params](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform#google_cloud_aiplatform_log_params)\n",
    "- [.log_metrics](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform#google_cloud_aiplatform_log_metrics)\n",
    "- [.log_time_series_metrics](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform#google_cloud_aiplatform_log_time_series_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70055c94-b7b9-4527-be1e-c2d9ee3d6f7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aiplatform.init(experiment = EXPERIMENT_NAME, experiment_tensorboard = tb.resource_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8af61ff",
   "metadata": {},
   "source": [
    "---\n",
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3adef09-ff0e-411b-892d-edea69d0f1ff",
   "metadata": {},
   "source": [
    "### Python File for Training\n",
    "\n",
    "This notebook trains the same Tensorflow Keras model from [05 - Vertex AI Custom Model - TensorFlow - in Notebook](./05%20-%20Vertex%20AI%20Custom%20Model%20-%20TensorFlow%20-%20in%20Notebook.ipynb) by first modifying and saving the training code to a python script as shown in [05 - Vertex AI Custom Model - TensorFlow - Notebook to Hyperparameter Tuning Script.ipynb](./05%20-%20Vertex%20AI%20Custom%20Model%20-%20TensorFlow%20-%20Notebook%20to%20Hyperparameter%20Tuning%20Script.ipynb) which stores the script in [`./code/hp_train.py`](./code/hp_train.py).\n",
    "\n",
    "**Review the script:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b59ef69-fb65-4f4a-ad00-d0ea4e1572d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "\n",
       "\n",
       "# package import\n",
       "from tensorflow.python.framework import dtypes\n",
       "from tensorflow_io.bigquery import BigQueryClient\n",
       "import tensorflow as tf\n",
       "from google.cloud import bigquery\n",
       "from google.cloud import aiplatform\n",
       "import argparse\n",
       "import os\n",
       "import sys\n",
       "import hypertune\n",
       "from tensorboard.plugins.hparams import api as hp\n",
       "\n",
       "# import argument to local variables\n",
       "parser = argparse.ArgumentParser()\n",
       "# the passed param, dest: a name for the param, default: if absent fetch this param from the OS, type: type to convert to, help: description of argument\n",
       "parser.add_argument('--epochs', dest = 'epochs', default = 10, type = int, help = 'Number of Epochs')\n",
       "parser.add_argument('--batch_size', dest = 'batch_size', default = 32, type = int, help = 'Batch Size')\n",
       "parser.add_argument('--var_target', dest = 'var_target', type=str)\n",
       "parser.add_argument('--var_omit', dest = 'var_omit', type=str, nargs='*')\n",
       "parser.add_argument('--project_id', dest = 'project_id', type=str)\n",
       "parser.add_argument('--bq_project', dest = 'bq_project', type=str)\n",
       "parser.add_argument('--bq_dataset', dest = 'bq_dataset', type=str)\n",
       "parser.add_argument('--bq_table', dest = 'bq_table', type=str)\n",
       "parser.add_argument('--region', dest = 'region', type=str)\n",
       "parser.add_argument('--experiment', dest = 'experiment', type=str)\n",
       "parser.add_argument('--series', dest = 'series', type=str)\n",
       "parser.add_argument('--experiment_name', dest = 'experiment_name', type=str)\n",
       "parser.add_argument('--run_name', dest = 'run_name', type=str)\n",
       "# hyperparameters\n",
       "parser.add_argument('--lr', dest='learning_rate', required=True, type=float, help='Learning Rate')\n",
       "parser.add_argument('--m', dest='momentum', required=True, type=float, help='Momentum')\n",
       "args = parser.parse_args()\n",
       "\n",
       "# setup tensorboard hparams\n",
       "HP_LEARNING_RATE = hp.HParam('learning_rate', hp.RealInterval(0.0, 1.0))\n",
       "HP_MOMENTUM = hp.HParam('momentum', hp.RealInterval(0.0,1.0))\n",
       "hparams = {\n",
       "    HP_LEARNING_RATE: args.learning_rate,\n",
       "    HP_MOMENTUM: args.momentum\n",
       "}\n",
       "\n",
       "# clients\n",
       "bq = bigquery.Client(project = args.project_id)\n",
       "aiplatform.init(project = args.project_id, location = args.region)\n",
       "hpt = hypertune.HyperTune()\n",
       "args.run_name = f'{args.run_name}-{hpt.trial_id}'\n",
       "\n",
       "# Vertex AI Experiment\n",
       "expRun = aiplatform.ExperimentRun.create(run_name = args.run_name, experiment = args.experiment_name)\n",
       "expRun.log_params({'experiment': args.experiment, 'series': args.series, 'project_id': args.project_id})\n",
       "expRun.log_params({'hyperparameter.learning_rate': args.learning_rate, 'hyperparameter.momentum': args.momentum})\n",
       "\n",
       "# get schema from bigquery source\n",
       "query = f\"SELECT * FROM {args.bq_project}.{args.bq_dataset}.INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '{args.bq_table}'\"\n",
       "schema = bq.query(query).to_dataframe()\n",
       "\n",
       "# get number of classes from bigquery source\n",
       "nclasses = bq.query(query = f'SELECT DISTINCT {args.var_target} FROM {args.bq_project}.{args.bq_dataset}.{args.bq_table} WHERE {args.var_target} is not null').to_dataframe()\n",
       "nclasses = nclasses.shape[0]\n",
       "expRun.log_params({'data_source': f'bq://{args.bq_project}.{args.bq_dataset}.{args.bq_table}', 'nclasses': nclasses, 'var_split': 'splits', 'var_target': args.var_target})\n",
       "\n",
       "# Make a list of columns to omit\n",
       "OMIT = args.var_omit + ['splits']\n",
       "\n",
       "# use schema to prepare a list of columns to read from BigQuery\n",
       "selected_fields = schema[~schema.column_name.isin(OMIT)].column_name.tolist()\n",
       "\n",
       "# all the columns in this data source are either float64 or int64\n",
       "output_types = [dtypes.float64 if x=='FLOAT64' else dtypes.int64 for x in schema[~schema.column_name.isin(OMIT)].data_type.tolist()]\n",
       "\n",
       "# remap input data to Tensorflow inputs of features and target\n",
       "def transTable(row_dict):\n",
       "    target = row_dict.pop(args.var_target)\n",
       "    target = tf.one_hot(tf.cast(target, tf.int64), nclasses)\n",
       "    target = tf.cast(target, tf.float32)\n",
       "    return(row_dict, target)\n",
       "\n",
       "# function to setup a bigquery reader with Tensorflow I/O\n",
       "def bq_reader(split):\n",
       "    reader = BigQueryClient()\n",
       "\n",
       "    training = reader.read_session(\n",
       "        parent = f\"projects/{args.project_id}\",\n",
       "        project_id = args.bq_project,\n",
       "        table_id = args.bq_table,\n",
       "        dataset_id = args.bq_dataset,\n",
       "        selected_fields = selected_fields,\n",
       "        output_types = output_types,\n",
       "        row_restriction = f\"splits='{split}'\",\n",
       "        requested_streams = 3\n",
       "    )\n",
       "    \n",
       "    return training\n",
       "\n",
       "# setup feed for train, validate and test\n",
       "train = bq_reader('TRAIN').parallel_read_rows().prefetch(1).map(transTable).shuffle(args.batch_size*10).batch(args.batch_size)\n",
       "validate = bq_reader('VALIDATE').parallel_read_rows().prefetch(1).map(transTable).batch(args.batch_size)\n",
       "test = bq_reader('TEST').parallel_read_rows().prefetch(1).map(transTable).batch(args.batch_size)\n",
       "expRun.log_params({'training.batch_size': args.batch_size, 'training.shuffle': 10*args.batch_size, 'training.prefetch': 1})\n",
       "\n",
       "# Logistic Regression\n",
       "\n",
       "# model input definitions\n",
       "feature_columns = {header: tf.feature_column.numeric_column(header) for header in selected_fields if header != args.var_target}\n",
       "feature_layer_inputs = {header: tf.keras.layers.Input(shape = (1,), name = header) for header in selected_fields if header != args.var_target}\n",
       "\n",
       "# feature columns to a Dense Feature Layer\n",
       "feature_layer_outputs = tf.keras.layers.DenseFeatures(feature_columns.values(), name = 'feature_layer')(feature_layer_inputs)\n",
       "\n",
       "# batch normalization then Dense with softmax activation to nclasses\n",
       "layers = tf.keras.layers.BatchNormalization(name = 'batch_normalization_layer')(feature_layer_outputs)\n",
       "layers = tf.keras.layers.Dense(64, activation = 'relu', name = 'hidden_layer')(layers)\n",
       "layers = tf.keras.layers.Dense(32, activation = 'relu', name = 'embedding_layer')(layers)\n",
       "layers = tf.keras.layers.Dense(nclasses, activation = tf.nn.softmax, name = 'prediction_layer')(layers)\n",
       "\n",
       "# the model\n",
       "model = tf.keras.Model(\n",
       "    inputs = feature_layer_inputs,\n",
       "    outputs = layers,\n",
       "    name = args.experiment\n",
       ")\n",
       "opt = tf.keras.optimizers.SGD(learning_rate = args.learning_rate, momentum = args.momentum) #SGD or Adam\n",
       "loss = tf.keras.losses.CategoricalCrossentropy()\n",
       "model.compile(\n",
       "    optimizer = opt,\n",
       "    loss = loss,\n",
       "    metrics = ['accuracy', tf.keras.metrics.AUC(curve='PR', name = 'auprc')]\n",
       ")\n",
       "\n",
       "# setup tensorboard logs and train\n",
       "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=os.environ['AIP_TENSORBOARD_LOG_DIR'], histogram_freq=1)\n",
       "hparams_callback = hp.KerasCallback(os.environ['AIP_TENSORBOARD_LOG_DIR'] + 'train/', hparams, trial_id = args.run_name)\n",
       "history = model.fit(train, epochs = args.epochs, callbacks = [tensorboard_callback, hparams_callback], validation_data = validate)\n",
       "expRun.log_params({'epochs': history.params['epochs']})\n",
       "for e in range(0, history.params['epochs']):\n",
       "    expRun.log_time_series_metrics(\n",
       "        {\n",
       "            'train_loss': history.history['loss'][e],\n",
       "            'train_accuracy': history.history['accuracy'][e],\n",
       "            'train_auprc': history.history['auprc'][e],\n",
       "            'val_loss': history.history['val_loss'][e],\n",
       "            'val_accuracy': history.history['val_accuracy'][e],\n",
       "            'val_auprc': history.history['val_auprc'][e]\n",
       "        }\n",
       "    )\n",
       "\n",
       "# test evaluations:\n",
       "loss, accuracy, auprc = model.evaluate(test)\n",
       "expRun.log_metrics({'test_loss': loss, 'test_accuracy': accuracy, 'test_auprc': auprc})\n",
       "\n",
       "# val evaluations:\n",
       "loss, accuracy, auprc = model.evaluate(validate)\n",
       "expRun.log_metrics({'val_loss': loss, 'val_accuracy': accuracy, 'val_auprc': auprc})\n",
       "# report hypertune info back to Vertex AI Training > Hyperparamter Tuning Job\n",
       "hpt.report_hyperparameter_tuning_metric(\n",
       "    hyperparameter_metric_tag = 'auprc',\n",
       "    metric_value = history.history['auprc'][-1])\n",
       "\n",
       "# training evaluations:\n",
       "loss, accuracy, auprc = model.evaluate(train)\n",
       "expRun.log_metrics({'train_loss': loss, 'train_accuracy': accuracy, 'train_auprc': auprc})\n",
       "\n",
       "# output the model save files\n",
       "model.save(os.getenv(\"AIP_MODEL_DIR\"))\n",
       "expRun.log_params({'model.save': os.getenv(\"AIP_MODEL_DIR\")})\n",
       "expRun.end_run()\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCRIPT_PATH = './code/hp_train.py'\n",
    "\n",
    "with open(SCRIPT_PATH, 'r') as file:\n",
    "    data = file.read()\n",
    "md(f\"```python\\n\\n{data}\\n```\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e4ad7a-7f27-487a-983b-bcda24177a3b",
   "metadata": {},
   "source": [
    "### Construct Python Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1db8322e-b654-4788-9fe9-69f44e976486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'temp/05h'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a1fe610-d832-4aa1-88c8-f36a31de5024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e78ea2-c7c2-4f93-bb9b-7c92660390dd",
   "metadata": {},
   "source": [
    "#### Create the folder structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b69fb3f7-45f3-4df0-ad5d-853a930ddc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(DIR + f'/{EXPERIMENT}_trainer/src/{EXPERIMENT}_trainer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e73669e3-76aa-4213-9ce9-fc85531c51a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp/05h\n",
      "temp/05h/05h_trainer\n",
      "temp/05h/05h_trainer/src\n",
      "temp/05h/05h_trainer/src/05h_trainer\n"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk(DIR):\n",
    "    print(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7206e38d-1370-43e6-bde0-1cb653767545",
   "metadata": {},
   "source": [
    "#### Add files to directory\n",
    "Copy the `./code/train.py` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9081c6cf-1140-47af-9448-01ce0fb076b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.copyfile(SCRIPT_PATH, f'{DIR}/{EXPERIMENT}_trainer/src/{EXPERIMENT}_trainer/train.py')\n",
    "with open(f'{DIR}/{EXPERIMENT}_trainer/src/{EXPERIMENT}_trainer/__init__.py', 'w') as file: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e925ec81-f329-46c3-99dd-e2bcc84e67d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{DIR}/{EXPERIMENT}_trainer/pyproject.toml', 'w') as file:\n",
    "    file.write(f\"\"\"[build-system]\n",
    "requires = [\"setuptools\"]\n",
    "build-backend = \"setuptools.build_meta\"\n",
    "\n",
    "[project]\n",
    "name = '{EXPERIMENT}_trainer'\n",
    "version = '0.1'\n",
    "dependencies = ['tensorflow_io', 'google-cloud-aiplatform>={aiplatform.__version__}', 'protobuf=={pkg_resources.get_distribution('protobuf').version}']\n",
    "description = 'Training Package'\n",
    "authors = [{{name = 'statmike'}}]\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f35ce29-325c-4a05-8e04-b65c9918eb41",
   "metadata": {},
   "source": [
    "list directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f0dc96a-71d7-468a-9776-2127b5c2fb2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp/05h/05h_trainer/pyproject.toml\n",
      "temp/05h/05h_trainer/src/05h_trainer/__init__.py\n",
      "temp/05h/05h_trainer/src/05h_trainer/train.py\n"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk(DIR):\n",
    "    for f in files:\n",
    "        print(os.path.join(root, f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d802a10-459a-40a0-9943-04d0e1bb8595",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Build the Python distribution archives:\n",
    "\n",
    "The build process creates both a `.tar.gz` source distribution and a `.whl` built distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "208a4571-06d9-4113-afee-01686cd08e83",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m* Creating virtualenv isolated environment...\u001b[0m\n",
      "\u001b[1m* Installing packages in isolated environment... (setuptools)\u001b[0m\n",
      "\u001b[1m* Getting dependencies for sdist...\u001b[0m\n",
      "running egg_info\n",
      "creating src/05h_trainer.egg-info\n",
      "writing src/05h_trainer.egg-info/PKG-INFO\n",
      "writing dependency_links to src/05h_trainer.egg-info/dependency_links.txt\n",
      "writing requirements to src/05h_trainer.egg-info/requires.txt\n",
      "writing top-level names to src/05h_trainer.egg-info/top_level.txt\n",
      "writing manifest file 'src/05h_trainer.egg-info/SOURCES.txt'\n",
      "reading manifest file 'src/05h_trainer.egg-info/SOURCES.txt'\n",
      "writing manifest file 'src/05h_trainer.egg-info/SOURCES.txt'\n",
      "\u001b[1m* Building sdist...\u001b[0m\n",
      "running sdist\n",
      "running egg_info\n",
      "writing src/05h_trainer.egg-info/PKG-INFO\n",
      "writing dependency_links to src/05h_trainer.egg-info/dependency_links.txt\n",
      "writing requirements to src/05h_trainer.egg-info/requires.txt\n",
      "writing top-level names to src/05h_trainer.egg-info/top_level.txt\n",
      "reading manifest file 'src/05h_trainer.egg-info/SOURCES.txt'\n",
      "writing manifest file 'src/05h_trainer.egg-info/SOURCES.txt'\n",
      "warning: sdist: standard file not found: should have one of README, README.rst, README.txt, README.md\n",
      "\n",
      "running check\n",
      "creating 05h_trainer-0.1\n",
      "creating 05h_trainer-0.1/src\n",
      "creating 05h_trainer-0.1/src/05h_trainer\n",
      "creating 05h_trainer-0.1/src/05h_trainer.egg-info\n",
      "copying files to 05h_trainer-0.1...\n",
      "copying pyproject.toml -> 05h_trainer-0.1\n",
      "copying src/05h_trainer/__init__.py -> 05h_trainer-0.1/src/05h_trainer\n",
      "copying src/05h_trainer/train.py -> 05h_trainer-0.1/src/05h_trainer\n",
      "copying src/05h_trainer.egg-info/PKG-INFO -> 05h_trainer-0.1/src/05h_trainer.egg-info\n",
      "copying src/05h_trainer.egg-info/SOURCES.txt -> 05h_trainer-0.1/src/05h_trainer.egg-info\n",
      "copying src/05h_trainer.egg-info/dependency_links.txt -> 05h_trainer-0.1/src/05h_trainer.egg-info\n",
      "copying src/05h_trainer.egg-info/requires.txt -> 05h_trainer-0.1/src/05h_trainer.egg-info\n",
      "copying src/05h_trainer.egg-info/top_level.txt -> 05h_trainer-0.1/src/05h_trainer.egg-info\n",
      "Writing 05h_trainer-0.1/setup.cfg\n",
      "Creating tar archive\n",
      "removing '05h_trainer-0.1' (and everything under it)\n",
      "\u001b[1m* Building wheel from sdist\u001b[0m\n",
      "\u001b[1m* Creating virtualenv isolated environment...\u001b[0m\n",
      "\u001b[1m* Installing packages in isolated environment... (setuptools)\u001b[0m\n",
      "\u001b[1m* Getting dependencies for wheel...\u001b[0m\n",
      "running egg_info\n",
      "writing src/05h_trainer.egg-info/PKG-INFO\n",
      "writing dependency_links to src/05h_trainer.egg-info/dependency_links.txt\n",
      "writing requirements to src/05h_trainer.egg-info/requires.txt\n",
      "writing top-level names to src/05h_trainer.egg-info/top_level.txt\n",
      "reading manifest file 'src/05h_trainer.egg-info/SOURCES.txt'\n",
      "writing manifest file 'src/05h_trainer.egg-info/SOURCES.txt'\n",
      "\u001b[1m* Installing packages in isolated environment... (wheel)\u001b[0m\n",
      "\u001b[1m* Building wheel...\u001b[0m\n",
      "running bdist_wheel\n",
      "running build\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib\n",
      "creating build/lib/05h_trainer\n",
      "copying src/05h_trainer/train.py -> build/lib/05h_trainer\n",
      "copying src/05h_trainer/__init__.py -> build/lib/05h_trainer\n",
      "running egg_info\n",
      "writing src/05h_trainer.egg-info/PKG-INFO\n",
      "writing dependency_links to src/05h_trainer.egg-info/dependency_links.txt\n",
      "writing requirements to src/05h_trainer.egg-info/requires.txt\n",
      "writing top-level names to src/05h_trainer.egg-info/top_level.txt\n",
      "reading manifest file 'src/05h_trainer.egg-info/SOURCES.txt'\n",
      "writing manifest file 'src/05h_trainer.egg-info/SOURCES.txt'\n",
      "installing to build/bdist.linux-x86_64/wheel\n",
      "running install\n",
      "running install_lib\n",
      "creating build/bdist.linux-x86_64\n",
      "creating build/bdist.linux-x86_64/wheel\n",
      "creating build/bdist.linux-x86_64/wheel/05h_trainer\n",
      "copying build/lib/05h_trainer/train.py -> build/bdist.linux-x86_64/wheel/05h_trainer\n",
      "copying build/lib/05h_trainer/__init__.py -> build/bdist.linux-x86_64/wheel/05h_trainer\n",
      "running install_egg_info\n",
      "Copying src/05h_trainer.egg-info to build/bdist.linux-x86_64/wheel/05h_trainer-0.1-py3.7.egg-info\n",
      "running install_scripts\n",
      "creating build/bdist.linux-x86_64/wheel/05h_trainer-0.1.dist-info/WHEEL\n",
      "creating '/home/jupyter/vertex-ai-mlops/05 - TensorFlow/temp/05h/05h_trainer/dist/tmpq7x84jgk/05h_trainer-0.1-py3-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
      "adding '05h_trainer/__init__.py'\n",
      "adding '05h_trainer/train.py'\n",
      "adding '05h_trainer-0.1.dist-info/METADATA'\n",
      "adding '05h_trainer-0.1.dist-info/WHEEL'\n",
      "adding '05h_trainer-0.1.dist-info/top_level.txt'\n",
      "adding '05h_trainer-0.1.dist-info/RECORD'\n",
      "removing build/bdist.linux-x86_64/wheel\n",
      "\u001b[1m\u001b[92mSuccessfully built \u001b[4m05h_trainer-0.1.tar.gz\u001b[0m\u001b[1m\u001b[92m and \u001b[4m05h_trainer-0.1-py3-none-any.whl\u001b[0m\u001b[1m\u001b[92m\u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!cd ./{DIR}/{EXPERIMENT}_trainer && python -m build"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f27d91-b7b2-4b76-9332-59f0265978fd",
   "metadata": {},
   "source": [
    "list directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57b490b5-9fe6-4682-b474-b6e967ed5567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp/05h/05h_trainer/pyproject.toml\n",
      "temp/05h/05h_trainer/src/05h_trainer/__init__.py\n",
      "temp/05h/05h_trainer/src/05h_trainer/train.py\n",
      "temp/05h/05h_trainer/src/05h_trainer.egg-info/top_level.txt\n",
      "temp/05h/05h_trainer/src/05h_trainer.egg-info/SOURCES.txt\n",
      "temp/05h/05h_trainer/src/05h_trainer.egg-info/requires.txt\n",
      "temp/05h/05h_trainer/src/05h_trainer.egg-info/dependency_links.txt\n",
      "temp/05h/05h_trainer/src/05h_trainer.egg-info/PKG-INFO\n",
      "temp/05h/05h_trainer/dist/05h_trainer-0.1-py3-none-any.whl\n",
      "temp/05h/05h_trainer/dist/05h_trainer-0.1.tar.gz\n"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk(DIR):\n",
    "    for f in files:\n",
    "        print(os.path.join(root, f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342829d1-81ed-43af-89c8-fb9bf26e948c",
   "metadata": {},
   "source": [
    "#### Copy to GCS\n",
    "\n",
    "Here the folder structure for DIR will be copied to the GCS Bucket used across this project.  This section uses skills that are discussed in more detail in the [Python Client for GCS](../Tips/Python%20Client%20for%20GCS.ipynb) notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea4fa47-15c4-4372-8ad4-54540b083f5c",
   "metadata": {},
   "source": [
    "List buckets in project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c85dde48-64f3-404b-aea8-afe82ee61179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Bucket: cloud-ai-platform-a68e7f3a-fac8-47f6-9f92-fff95c09cdb8>,\n",
       " <Bucket: statmike-mlops-349915>,\n",
       " <Bucket: statmike-mlops-349915-vertex-pipelines-us-central1>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(gcs.list_buckets())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56aa71c8-a3da-4e44-9e31-c4a86b32f951",
   "metadata": {},
   "source": [
    "Get the bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5da58857-96e5-4e00-801e-e85a5aa33e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = gcs.lookup_bucket(PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e1829d-9aed-4fa4-afa1-0ebd9183198a",
   "metadata": {},
   "source": [
    "list files to upload:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35baec25-73cf-42e2-b52c-f3d9c8e5b7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/05h_trainer/pyproject.toml\n",
      "/05h_trainer/src/05h_trainer/__init__.py\n",
      "/05h_trainer/src/05h_trainer/train.py\n",
      "/05h_trainer/src/05h_trainer.egg-info/top_level.txt\n",
      "/05h_trainer/src/05h_trainer.egg-info/SOURCES.txt\n",
      "/05h_trainer/src/05h_trainer.egg-info/requires.txt\n",
      "/05h_trainer/src/05h_trainer.egg-info/dependency_links.txt\n",
      "/05h_trainer/src/05h_trainer.egg-info/PKG-INFO\n",
      "/05h_trainer/dist/05h_trainer-0.1-py3-none-any.whl\n",
      "/05h_trainer/dist/05h_trainer-0.1.tar.gz\n"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk(DIR):\n",
    "    for f in files:\n",
    "        print(os.path.join(root, f)[len(DIR):])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325c6e4c-d479-4138-af87-270673e499d0",
   "metadata": {},
   "source": [
    "list of desired bucket object URIs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "876fb6b5-1a99-4caf-adba-1b581a93ed20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/05h/trainer/05h_trainer/pyproject.toml\n",
      "05/05h/trainer/05h_trainer/src/05h_trainer/__init__.py\n",
      "05/05h/trainer/05h_trainer/src/05h_trainer/train.py\n",
      "05/05h/trainer/05h_trainer/src/05h_trainer.egg-info/top_level.txt\n",
      "05/05h/trainer/05h_trainer/src/05h_trainer.egg-info/SOURCES.txt\n",
      "05/05h/trainer/05h_trainer/src/05h_trainer.egg-info/requires.txt\n",
      "05/05h/trainer/05h_trainer/src/05h_trainer.egg-info/dependency_links.txt\n",
      "05/05h/trainer/05h_trainer/src/05h_trainer.egg-info/PKG-INFO\n",
      "05/05h/trainer/05h_trainer/dist/05h_trainer-0.1-py3-none-any.whl\n",
      "05/05h/trainer/05h_trainer/dist/05h_trainer-0.1.tar.gz\n"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk(DIR):\n",
    "    for f in files:\n",
    "        filepath = os.path.join(root, f)\n",
    "        gcspath = f'{SERIES}/{EXPERIMENT}/trainer/{filepath[len(DIR)+1:]}'\n",
    "        print(gcspath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d8e8c0-bb3d-4950-9717-3639d51770c3",
   "metadata": {},
   "source": [
    "upload files as objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "66a349c7-e241-4375-851a-4819ee20d7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk(DIR):\n",
    "    for f in files:\n",
    "        filepath = os.path.join(root, f)\n",
    "        gcspath = f'{SERIES}/{EXPERIMENT}/trainer/{filepath[len(DIR)+1:]}'\n",
    "        blob = bucket.blob(gcspath)\n",
    "        blob.upload_from_filename(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b6c4dd7-ee00-40ee-9f00-d2c4ef30b962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the bucket directly here:\n",
      "https://console.cloud.google.com/storage/browser/statmike-mlops-349915/05/05h;tab=objects&project=statmike-mlops-349915\n"
     ]
    }
   ],
   "source": [
    "print(f\"View the bucket directly here:\\nhttps://console.cloud.google.com/storage/browser/{PROJECT_ID}/{SERIES}/{EXPERIMENT};tab=objects&project={PROJECT_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32cd994-ad9a-4b73-86ab-1ebb635c8d9d",
   "metadata": {},
   "source": [
    "list files in bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a8d4a87-9489-49d4-a90b-13b8002854f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/05h/trainer/05h_trainer/dist/05h_trainer-0.1-py3-none-any.whl\n",
      "05/05h/trainer/05h_trainer/dist/05h_trainer-0.1.tar.gz\n",
      "05/05h/trainer/05h_trainer/pyproject.toml\n",
      "05/05h/trainer/05h_trainer/src/05h_trainer.egg-info/PKG-INFO\n",
      "05/05h/trainer/05h_trainer/src/05h_trainer.egg-info/SOURCES.txt\n",
      "05/05h/trainer/05h_trainer/src/05h_trainer.egg-info/dependency_links.txt\n",
      "05/05h/trainer/05h_trainer/src/05h_trainer.egg-info/requires.txt\n",
      "05/05h/trainer/05h_trainer/src/05h_trainer.egg-info/top_level.txt\n",
      "05/05h/trainer/05h_trainer/src/05h_trainer/__init__.py\n",
      "05/05h/trainer/05h_trainer/src/05h_trainer/train.py\n"
     ]
    }
   ],
   "source": [
    "for blob in list(bucket.list_blobs(prefix = f'{SERIES}/{EXPERIMENT}/trainer/')):\n",
    "    print(blob.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a86adbe-1a35-4971-92f3-19ae5a5e0999",
   "metadata": {},
   "source": [
    "get a list of source distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "08321796-9baf-4bbb-99aa-f0ca04b5c121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://statmike-mlops-349915/05/05h/trainer/05h_trainer/dist/05h_trainer-0.1.tar.gz']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SOURCES = [f'gs://{PROJECT_ID}/{blob.name}' for blob in list(bucket.list_blobs(prefix = f'{SERIES}/{EXPERIMENT}/trainer/')) if blob.name[-7:] == '.tar.gz']\n",
    "SOURCES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0a15de",
   "metadata": {},
   "source": [
    "### Setup Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "da3c29e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "CMDARGS = [\n",
    "    \"--epochs=\" + str(EPOCHS),\n",
    "    \"--batch_size=\" + str(BATCH_SIZE),\n",
    "    \"--var_target=\" + VAR_TARGET,\n",
    "    \"--var_omit=\" + VAR_OMIT,\n",
    "    \"--project_id=\" + PROJECT_ID,\n",
    "    \"--bq_project=\" + BQ_PROJECT,\n",
    "    \"--bq_dataset=\" + BQ_DATASET,\n",
    "    \"--bq_table=\" + BQ_TABLE,\n",
    "    \"--region=\" + REGION,\n",
    "    \"--experiment=\" + EXPERIMENT,\n",
    "    \"--series=\" + SERIES,\n",
    "    \"--experiment_name=\" + EXPERIMENT_NAME,\n",
    "    \"--run_name=\" + RUN_NAME\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f3853000",
   "metadata": {},
   "outputs": [],
   "source": [
    "MACHINE_SPEC = {\n",
    "    \"machine_type\": TRAIN_COMPUTE,\n",
    "    \"accelerator_count\": 0\n",
    "}\n",
    "\n",
    "WORKER_POOL_SPEC = [\n",
    "    {\n",
    "        \"replica_count\": 1,\n",
    "        \"machine_spec\": MACHINE_SPEC,\n",
    "        \"python_package_spec\": {\n",
    "            \"executor_image_uri\": TRAIN_IMAGE,\n",
    "            \"package_uris\": SOURCES,\n",
    "            \"python_module\": f\"{EXPERIMENT}_trainer.train\",\n",
    "            \"args\": CMDARGS\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8ced17c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "customJob = aiplatform.CustomJob(\n",
    "    display_name = f'{SERIES}_{EXPERIMENT}_{TIMESTAMP}',\n",
    "    worker_pool_specs = WORKER_POOL_SPEC,\n",
    "    base_output_dir = f\"{URI}/models/{TIMESTAMP}\",\n",
    "    staging_bucket = f\"{URI}/models/{TIMESTAMP}\",\n",
    "    labels = {'series' : f'{SERIES}', 'experiment' : f'{EXPERIMENT}', 'experiment_name' : f'{EXPERIMENT_NAME}', 'run_name' : f'{RUN_NAME}'}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af7ee7c",
   "metadata": {},
   "source": [
    "### Setup Hyperparameter Tuning Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "47250ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRIC_SPEC = {\n",
    "    \"auprc\": \"minimize\"\n",
    "}\n",
    "\n",
    "PARAMETER_SPEC = {\n",
    "    \"lr\": aiplatform.hyperparameter_tuning.DoubleParameterSpec(min=0.001, max=0.1, scale=\"log\"),\n",
    "    \"m\": aiplatform.hyperparameter_tuning.DoubleParameterSpec(min=1e-7, max=0.9, scale=\"linear\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e848550c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuningJob = aiplatform.HyperparameterTuningJob(\n",
    "    display_name = f'{SERIES}_{EXPERIMENT}_{TIMESTAMP}',\n",
    "    custom_job = customJob,\n",
    "    metric_spec = METRIC_SPEC,\n",
    "    parameter_spec = PARAMETER_SPEC,\n",
    "    max_trial_count = 20,\n",
    "    parallel_trial_count = 5,\n",
    "    search_algorithm = None,\n",
    "    labels = {'series' : f'{SERIES}', 'experiment' : f'{EXPERIMENT}', 'experiment_name' : f'{EXPERIMENT_NAME}', 'run_name' : f'{RUN_NAME}'}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3e25f1",
   "metadata": {},
   "source": [
    "### Run Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1ae1b9f8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating HyperparameterTuningJob\n",
      "HyperparameterTuningJob created. Resource name: projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384\n",
      "To use this HyperparameterTuningJob in another session:\n",
      "hpt_job = aiplatform.HyperparameterTuningJob.get('projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384')\n",
      "View HyperparameterTuningJob:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/6299929772906512384?project=1026793852137\n",
      "View Tensorboard:\n",
      "https://us-central1.tensorboard.googleusercontent.com/experiment/projects+1026793852137+locations+us-central1+tensorboards+7179142426307592192+experiments+6299929772906512384\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384 current state:\n",
      "JobState.JOB_STATE_SUCCEEDED\n",
      "HyperparameterTuningJob run completed. Resource name: projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384\n"
     ]
    }
   ],
   "source": [
    "tuningJob.run(\n",
    "    service_account = SERVICE_ACCOUNT,\n",
    "    tensorboard = tb.resource_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "25fdc0eb-77d9-4760-896d-53b1c018dbdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('projects/1026793852137/locations/us-central1/hyperparameterTuningJobs/6299929772906512384',\n",
       " '05_05h_20220927230247')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuningJob.resource_name, tuningJob.display_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea33e4fb-c199-4e1e-8011-8d74005f115e",
   "metadata": {},
   "source": [
    "Create hyperlinks to job and tensorboard here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a2895cc0-88f2-46bc-ba91-0851e5ce0426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review the Job here:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/6299929772906512384?project=statmike-mlops-349915\n",
      "Review the TensorBoard From the Job here:\n",
      "https://us-central1.tensorboard.googleusercontent.com/experiment/projects+1026793852137+locations+us-central1+tensorboards+7179142426307592192+experiments+6299929772906512384\n",
      "Review the TensorBoard From the Job here (direct link to HPARAMS dashboard):\n",
      "https://us-central1.tensorboard.googleusercontent.com/experiment/projects+1026793852137+locations+us-central1+tensorboards+7179142426307592192+experiments+6299929772906512384/#hparams\n"
     ]
    }
   ],
   "source": [
    "job_link = f\"https://console.cloud.google.com/ai/platform/locations/{REGION}/training/{tuningJob.resource_name.split('/')[-1]}?project={PROJECT_ID}\"\n",
    "board_link = f\"https://{REGION}.tensorboard.googleusercontent.com/experiment/{tb.resource_name.replace('/', '+')}+experiments+{tuningJob.resource_name.split('/')[-1]}\"\n",
    "\n",
    "print(f'Review the Job here:\\n{job_link}')\n",
    "print(f'Review the TensorBoard From the Job here:\\n{board_link}')\n",
    "print(f'Review the TensorBoard From the Job here (direct link to HPARAMS dashboard):\\n{board_link}/#hparams')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94928f1a-ae23-44e9-ac02-eb1604b68b4f",
   "metadata": {},
   "source": [
    "### Get Best Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "faed179a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9996923208236694,\n",
       " 0.9997443556785583,\n",
       " 0.9995754361152649,\n",
       " 0.9997208118438721,\n",
       " 0.9997908473014832,\n",
       " 0.9998709559440613,\n",
       " 0.9995505213737488,\n",
       " 0.9997617602348328,\n",
       " 0.9997098445892334,\n",
       " 0.9995516538619995,\n",
       " 0.9996912479400635,\n",
       " 0.999485433101654,\n",
       " 0.9997152090072632,\n",
       " 0.9995219707489014,\n",
       " 0.9995567798614502,\n",
       " 0.9994285106658936,\n",
       " 0.9994895458221436,\n",
       " 0.9995731711387634,\n",
       " 0.9992923736572266,\n",
       " 0.9994504451751709]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if trial.state.name == 'SUCCEEDED'\n",
    "auprc = [trial.final_measurement.metrics[0].value if trial.state.name == 'SUCCEEDED' else 1 for trial in tuningJob.trials]\n",
    "auprc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5e699294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id: \"6\"\n",
       "state: SUCCEEDED\n",
       "parameters {\n",
       "  parameter_id: \"lr\"\n",
       "  value {\n",
       "    number_value: 0.1\n",
       "  }\n",
       "}\n",
       "parameters {\n",
       "  parameter_id: \"m\"\n",
       "  value {\n",
       "    number_value: 0.9\n",
       "  }\n",
       "}\n",
       "final_measurement {\n",
       "  step_count: 1\n",
       "  metrics {\n",
       "    metric_id: \"auprc\"\n",
       "    value: 0.9998709559440613\n",
       "  }\n",
       "}\n",
       "start_time {\n",
       "  seconds: 1664320725\n",
       "  nanos: 31146253\n",
       "}\n",
       "end_time {\n",
       "  seconds: 1664321400\n",
       "}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = tuningJob.trials[auprc.index(max(auprc))]\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "471aa31a-122f-4147-aa4c-9776c12fa443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best.id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c476d6",
   "metadata": {},
   "source": [
    "---\n",
    "## Serving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ced262",
   "metadata": {},
   "source": [
    "### Upload The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2876b6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a new model, creating in model registry\n",
      "Creating Model\n",
      "Create Model backing LRO: projects/1026793852137/locations/us-central1/models/model_05_05h/operations/2025558047681675264\n",
      "Model created. Resource name: projects/1026793852137/locations/us-central1/models/8565947646328438784@1\n",
      "To use this Model in another session:\n",
      "model = aiplatform.Model('projects/1026793852137/locations/us-central1/models/8565947646328438784@1')\n"
     ]
    }
   ],
   "source": [
    "modelmatch = aiplatform.Model.list(filter = f'display_name={SERIES}_{EXPERIMENT} AND labels.series={SERIES} AND labels.experiment={EXPERIMENT}')\n",
    "if modelmatch:\n",
    "    print(\"Model Already in Registry:\")\n",
    "    if f'{RUN_NAME}-{best.id}' in modelmatch[0].version_aliases:\n",
    "        print(\"This version already loaded, no action taken.\")\n",
    "        model = aiplatform.Model(model_name = modelmatch[0].resource_name)\n",
    "    else:\n",
    "        print('Loading model as new default version.')\n",
    "        model = aiplatform.Model.upload(\n",
    "            display_name = f'{SERIES}_{EXPERIMENT}',\n",
    "            model_id = f'model_{SERIES}_{EXPERIMENT}',\n",
    "            parent_model =  modelmatch[0].resource_name,\n",
    "            serving_container_image_uri = DEPLOY_IMAGE,\n",
    "            artifact_uri = f\"{URI}/models/{TIMESTAMP}/{best.id}/model\",\n",
    "            is_default_version = True,\n",
    "            version_aliases = [f'{RUN_NAME}-{best.id}'],\n",
    "            version_description = f'{RUN_NAME}-{best.id}',\n",
    "            labels = {'series' : f'{SERIES}', 'experiment' : f'{EXPERIMENT}', 'experiment_name' : f'{EXPERIMENT_NAME}', 'run_name' : f'{RUN_NAME}-{best.id}'}        \n",
    "        )\n",
    "else:\n",
    "    print('This is a new model, creating in model registry')\n",
    "    model = aiplatform.Model.upload(\n",
    "        display_name = f'{SERIES}_{EXPERIMENT}',\n",
    "        model_id = f'model_{SERIES}_{EXPERIMENT}',\n",
    "        serving_container_image_uri = DEPLOY_IMAGE,\n",
    "        artifact_uri = f\"{URI}/models/{TIMESTAMP}/{best.id}/model\",\n",
    "        is_default_version = True,\n",
    "        version_aliases = [f'{RUN_NAME}-{best.id}'],\n",
    "        version_description = f'{RUN_NAME}-{best.id}',\n",
    "        labels = {'series' : f'{SERIES}', 'experiment' : f'{EXPERIMENT}', 'experiment_name' : f'{EXPERIMENT_NAME}', 'run_name' : f'{RUN_NAME}-{best.id}'}\n",
    "    )   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f77765-da9c-45e9-808e-3aba03b92ef0",
   "metadata": {},
   "source": [
    ">**Note** on Version Aliases:\n",
    ">Expectation is a name starting with `a-z` that can include `[a-zA-Z0-9-]`\n",
    ">\n",
    ">**Retrieve a Model Resource**\n",
    ">[aiplatform.Model()](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.Model)\n",
    ">```Python\n",
    "model = aiplatform.Model(model_name = f'model_{SERIES}_{EXPERIMENT}') # retrieves default version\n",
    "model = aiplatform.Model(model_name = f'model_{SERIES}_{EXPERIMENT}@time-{TIMESTAMP}') # retrieves specific version\n",
    "model = aiplatform.Model(model_name = f'model_{SERIES}_{EXPERIMENT}', version = f'time-{TIMESTAMP}') # retrieves specific version\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f957662d-ca4d-490e-9fb6-cba11892ca92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review the model in the Vertex AI Model Registry:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/models/8565947646328438784?project=statmike-mlops-349915\n"
     ]
    }
   ],
   "source": [
    "print(f'Review the model in the Vertex AI Model Registry:\\nhttps://console.cloud.google.com/vertex-ai/locations/{REGION}/models/{model.name}?project={PROJECT_ID}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c4b3bf-31f1-4f16-84f3-d653b59e5b9a",
   "metadata": {},
   "source": [
    "### Vertex AI Experiment Update and Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "39a85b24-9bcb-4d11-8818-f3e4f9a89f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "expRun = aiplatform.ExperimentRun(run_name = f'{RUN_NAME}-{best.id}', experiment = EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "80dbe229-564d-49fb-bbb2-280bfa07fa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "expRun.log_params({\n",
    "    'model.uri': model.uri,\n",
    "    'model.display_name': model.display_name,\n",
    "    'model.name': model.name,\n",
    "    'model.resource_name': model.resource_name,\n",
    "    'model.version_id': model.version_id,\n",
    "    'model.versioned_resource_name': model.versioned_resource_name,\n",
    "    'hyperparameterTuningJobs.display_name': tuningJob.display_name,\n",
    "    'hyperparameterTuning.resource_name': tuningJob.resource_name,\n",
    "    'hyperparameterTuning.link': job_link,\n",
    "    'hyperparameterTuning.tensorboard': board_link\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ff3b40-e898-4c02-841f-7887c77f355f",
   "metadata": {},
   "source": [
    "Complete the experiment run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e3a1dcfe-1b4a-434d-85e9-acd9e5e557be",
   "metadata": {},
   "outputs": [],
   "source": [
    "expRun.update_state(state = aiplatform.gapic.Execution.State.COMPLETE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81c8f21-220e-41f0-9962-e29a37ab5d01",
   "metadata": {},
   "source": [
    "Need to add the `hyperparameterTuning` job information to each run of the experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "23da03c9-0b38-41c8-b1e3-1d35ab7943fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for trial in tuningJob.trials:\n",
    "    expRun = aiplatform.ExperimentRun(run_name = f'{RUN_NAME}-{trial.id}', experiment = EXPERIMENT_NAME)\n",
    "    expRun.log_params({\n",
    "        'hyperparameterTuningJobs.display_name': tuningJob.display_name,\n",
    "        'hyperparameterTuning.resource_name': tuningJob.resource_name,\n",
    "        'hyperparameterTuning.link': job_link,\n",
    "        'hyperparameterTuning.tensorboard': board_link\n",
    "    })\n",
    "    expRun.update_state(state = aiplatform.gapic.Execution.State.COMPLETE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbe75dc-2050-4e03-bf56-7ffe22bcec05",
   "metadata": {},
   "source": [
    "Retrieve the experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "57b4e1d3-9836-4aac-9286-c0a07d4ccdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = aiplatform.Experiment(experiment_name = EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "65d603e1-b034-4469-a245-de9ab1334d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>run_name</th>\n",
       "      <th>run_type</th>\n",
       "      <th>state</th>\n",
       "      <th>param.epochs</th>\n",
       "      <th>param.hyperparameterTuningJobs.display_name</th>\n",
       "      <th>param.nclasses</th>\n",
       "      <th>param.series</th>\n",
       "      <th>param.hyperparameter.momentum</th>\n",
       "      <th>param.data_source</th>\n",
       "      <th>...</th>\n",
       "      <th>metric.test_loss</th>\n",
       "      <th>metric.train_auprc</th>\n",
       "      <th>metric.test_accuracy</th>\n",
       "      <th>metric.train_accuracy</th>\n",
       "      <th>time_series_metric.train_auprc</th>\n",
       "      <th>time_series_metric.val_loss</th>\n",
       "      <th>time_series_metric.train_accuracy</th>\n",
       "      <th>time_series_metric.val_accuracy</th>\n",
       "      <th>time_series_metric.val_auprc</th>\n",
       "      <th>time_series_metric.train_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220927230247-20</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05_05h_20220927230247</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>1.240522e-01</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006515</td>\n",
       "      <td>0.999290</td>\n",
       "      <td>0.999228</td>\n",
       "      <td>0.999189</td>\n",
       "      <td>0.999450</td>\n",
       "      <td>0.008677</td>\n",
       "      <td>0.999097</td>\n",
       "      <td>0.999044</td>\n",
       "      <td>0.999228</td>\n",
       "      <td>0.006356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220927230247-19</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05_05h_20220927230247</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>1.224430e-01</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.999042</td>\n",
       "      <td>0.998351</td>\n",
       "      <td>0.998259</td>\n",
       "      <td>0.999292</td>\n",
       "      <td>0.012379</td>\n",
       "      <td>0.998259</td>\n",
       "      <td>0.998301</td>\n",
       "      <td>0.998758</td>\n",
       "      <td>0.010039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220927230247-18</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05_05h_20220927230247</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>1.354129e-01</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006881</td>\n",
       "      <td>0.999394</td>\n",
       "      <td>0.998912</td>\n",
       "      <td>0.999044</td>\n",
       "      <td>0.999573</td>\n",
       "      <td>0.007880</td>\n",
       "      <td>0.998939</td>\n",
       "      <td>0.998973</td>\n",
       "      <td>0.999339</td>\n",
       "      <td>0.006136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220927230247-17</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05_05h_20220927230247</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>1.390266e-01</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007137</td>\n",
       "      <td>0.999316</td>\n",
       "      <td>0.999158</td>\n",
       "      <td>0.999075</td>\n",
       "      <td>0.999490</td>\n",
       "      <td>0.008760</td>\n",
       "      <td>0.998991</td>\n",
       "      <td>0.999079</td>\n",
       "      <td>0.999321</td>\n",
       "      <td>0.006555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220927230247-16</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05_05h_20220927230247</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>2.838257e-01</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007155</td>\n",
       "      <td>0.999388</td>\n",
       "      <td>0.998877</td>\n",
       "      <td>0.998711</td>\n",
       "      <td>0.999429</td>\n",
       "      <td>0.008970</td>\n",
       "      <td>0.998514</td>\n",
       "      <td>0.998619</td>\n",
       "      <td>0.999278</td>\n",
       "      <td>0.007733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220927230247-15</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05_05h_20220927230247</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005846</td>\n",
       "      <td>0.999373</td>\n",
       "      <td>0.999298</td>\n",
       "      <td>0.999285</td>\n",
       "      <td>0.999557</td>\n",
       "      <td>0.007877</td>\n",
       "      <td>0.999220</td>\n",
       "      <td>0.999150</td>\n",
       "      <td>0.999318</td>\n",
       "      <td>0.005249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220927230247-14</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05_05h_20220927230247</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006120</td>\n",
       "      <td>0.999488</td>\n",
       "      <td>0.999298</td>\n",
       "      <td>0.999211</td>\n",
       "      <td>0.999522</td>\n",
       "      <td>0.007489</td>\n",
       "      <td>0.999110</td>\n",
       "      <td>0.999044</td>\n",
       "      <td>0.999431</td>\n",
       "      <td>0.005137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220927230247-13</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05_05h_20220927230247</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>9.000000e-01</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003327</td>\n",
       "      <td>0.999622</td>\n",
       "      <td>0.999404</td>\n",
       "      <td>0.999434</td>\n",
       "      <td>0.999715</td>\n",
       "      <td>0.005259</td>\n",
       "      <td>0.999382</td>\n",
       "      <td>0.999256</td>\n",
       "      <td>0.999670</td>\n",
       "      <td>0.003139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220927230247-12</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05_05h_20220927230247</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007461</td>\n",
       "      <td>0.999313</td>\n",
       "      <td>0.999228</td>\n",
       "      <td>0.999198</td>\n",
       "      <td>0.999485</td>\n",
       "      <td>0.008619</td>\n",
       "      <td>0.999084</td>\n",
       "      <td>0.999079</td>\n",
       "      <td>0.999254</td>\n",
       "      <td>0.006364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220927230247-11</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05_05h_20220927230247</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>8.837002e-01</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003612</td>\n",
       "      <td>0.999570</td>\n",
       "      <td>0.999333</td>\n",
       "      <td>0.999395</td>\n",
       "      <td>0.999691</td>\n",
       "      <td>0.005326</td>\n",
       "      <td>0.999355</td>\n",
       "      <td>0.999186</td>\n",
       "      <td>0.999623</td>\n",
       "      <td>0.003534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220927230247-10</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05_05h_20220927230247</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>0.999390</td>\n",
       "      <td>0.999263</td>\n",
       "      <td>0.999316</td>\n",
       "      <td>0.999552</td>\n",
       "      <td>0.006427</td>\n",
       "      <td>0.999277</td>\n",
       "      <td>0.999150</td>\n",
       "      <td>0.999390</td>\n",
       "      <td>0.004449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220927230247-9</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05_05h_20220927230247</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>3.877480e-01</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003709</td>\n",
       "      <td>0.999588</td>\n",
       "      <td>0.999439</td>\n",
       "      <td>0.999430</td>\n",
       "      <td>0.999710</td>\n",
       "      <td>0.004577</td>\n",
       "      <td>0.999373</td>\n",
       "      <td>0.999292</td>\n",
       "      <td>0.999531</td>\n",
       "      <td>0.003186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220927230247-8</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05_05h_20220927230247</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>7.432967e-01</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003481</td>\n",
       "      <td>0.999594</td>\n",
       "      <td>0.999439</td>\n",
       "      <td>0.999439</td>\n",
       "      <td>0.999762</td>\n",
       "      <td>0.004992</td>\n",
       "      <td>0.999491</td>\n",
       "      <td>0.999292</td>\n",
       "      <td>0.999623</td>\n",
       "      <td>0.002713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220927230247-7</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05_05h_20220927230247</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>5.237038e-01</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005485</td>\n",
       "      <td>0.999417</td>\n",
       "      <td>0.999368</td>\n",
       "      <td>0.999334</td>\n",
       "      <td>0.999551</td>\n",
       "      <td>0.006124</td>\n",
       "      <td>0.999272</td>\n",
       "      <td>0.999256</td>\n",
       "      <td>0.999383</td>\n",
       "      <td>0.004822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220927230247-5</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05_05h_20220927230247</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>7.019653e-01</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003395</td>\n",
       "      <td>0.999663</td>\n",
       "      <td>0.999439</td>\n",
       "      <td>0.999456</td>\n",
       "      <td>0.999791</td>\n",
       "      <td>0.004299</td>\n",
       "      <td>0.999456</td>\n",
       "      <td>0.999363</td>\n",
       "      <td>0.999670</td>\n",
       "      <td>0.002468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220927230247-4</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05_05h_20220927230247</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>1.840781e-03</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003421</td>\n",
       "      <td>0.999674</td>\n",
       "      <td>0.999368</td>\n",
       "      <td>0.999399</td>\n",
       "      <td>0.999721</td>\n",
       "      <td>0.005154</td>\n",
       "      <td>0.999408</td>\n",
       "      <td>0.999186</td>\n",
       "      <td>0.999624</td>\n",
       "      <td>0.003269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220927230247-3</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05_05h_20220927230247</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>2.357123e-01</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004609</td>\n",
       "      <td>0.999415</td>\n",
       "      <td>0.999404</td>\n",
       "      <td>0.999382</td>\n",
       "      <td>0.999575</td>\n",
       "      <td>0.006370</td>\n",
       "      <td>0.999277</td>\n",
       "      <td>0.999221</td>\n",
       "      <td>0.999345</td>\n",
       "      <td>0.004172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220927230247-2</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05_05h_20220927230247</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>2.522877e-01</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003160</td>\n",
       "      <td>0.999623</td>\n",
       "      <td>0.999474</td>\n",
       "      <td>0.999417</td>\n",
       "      <td>0.999744</td>\n",
       "      <td>0.004041</td>\n",
       "      <td>0.999439</td>\n",
       "      <td>0.999292</td>\n",
       "      <td>0.999624</td>\n",
       "      <td>0.002788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220927230247-1</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05_05h_20220927230247</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>4.500001e-01</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003402</td>\n",
       "      <td>0.999588</td>\n",
       "      <td>0.999404</td>\n",
       "      <td>0.999412</td>\n",
       "      <td>0.999692</td>\n",
       "      <td>0.004070</td>\n",
       "      <td>0.999408</td>\n",
       "      <td>0.999292</td>\n",
       "      <td>0.999625</td>\n",
       "      <td>0.003120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220927230247-6</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05_05h_20220927230247</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>9.000000e-01</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003266</td>\n",
       "      <td>0.999846</td>\n",
       "      <td>0.999404</td>\n",
       "      <td>0.999439</td>\n",
       "      <td>0.999871</td>\n",
       "      <td>0.005112</td>\n",
       "      <td>0.999452</td>\n",
       "      <td>0.999221</td>\n",
       "      <td>0.999761</td>\n",
       "      <td>0.002193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220827031936-20</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05h_fraud_20220827031936</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>9.000000e-01</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003233</td>\n",
       "      <td>0.999657</td>\n",
       "      <td>0.999404</td>\n",
       "      <td>0.999439</td>\n",
       "      <td>0.999739</td>\n",
       "      <td>0.004431</td>\n",
       "      <td>0.999408</td>\n",
       "      <td>0.999292</td>\n",
       "      <td>0.999670</td>\n",
       "      <td>0.002760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220827031936-19</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05h_fraud_20220827031936</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>6.569114e-01</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003153</td>\n",
       "      <td>0.999754</td>\n",
       "      <td>0.999404</td>\n",
       "      <td>0.999430</td>\n",
       "      <td>0.999826</td>\n",
       "      <td>0.004535</td>\n",
       "      <td>0.999509</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>0.999669</td>\n",
       "      <td>0.002230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220827031936-18</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05h_fraud_20220827031936</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>6.111249e-01</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005762</td>\n",
       "      <td>0.999383</td>\n",
       "      <td>0.999298</td>\n",
       "      <td>0.999277</td>\n",
       "      <td>0.999531</td>\n",
       "      <td>0.006980</td>\n",
       "      <td>0.999198</td>\n",
       "      <td>0.999150</td>\n",
       "      <td>0.999342</td>\n",
       "      <td>0.005036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220827031936-17</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05h_fraud_20220827031936</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>1.803773e-01</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007108</td>\n",
       "      <td>0.999518</td>\n",
       "      <td>0.998807</td>\n",
       "      <td>0.998698</td>\n",
       "      <td>0.999585</td>\n",
       "      <td>0.007662</td>\n",
       "      <td>0.998557</td>\n",
       "      <td>0.998548</td>\n",
       "      <td>0.999422</td>\n",
       "      <td>0.006858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220827031936-16</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05h_fraud_20220827031936</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>1.707894e-01</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007804</td>\n",
       "      <td>0.999449</td>\n",
       "      <td>0.999018</td>\n",
       "      <td>0.998899</td>\n",
       "      <td>0.999509</td>\n",
       "      <td>0.008622</td>\n",
       "      <td>0.998829</td>\n",
       "      <td>0.998867</td>\n",
       "      <td>0.999369</td>\n",
       "      <td>0.006982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220827031936-15</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05h_fraud_20220827031936</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>1.937884e-01</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003381</td>\n",
       "      <td>0.999634</td>\n",
       "      <td>0.999439</td>\n",
       "      <td>0.999443</td>\n",
       "      <td>0.999739</td>\n",
       "      <td>0.004625</td>\n",
       "      <td>0.999456</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>0.999716</td>\n",
       "      <td>0.002810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220827031936-14</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05h_fraud_20220827031936</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>9.000000e-01</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003118</td>\n",
       "      <td>0.999714</td>\n",
       "      <td>0.999439</td>\n",
       "      <td>0.999439</td>\n",
       "      <td>0.999779</td>\n",
       "      <td>0.004204</td>\n",
       "      <td>0.999404</td>\n",
       "      <td>0.999256</td>\n",
       "      <td>0.999670</td>\n",
       "      <td>0.002622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220827031936-12</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05h_fraud_20220827031936</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>9.000000e-01</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003451</td>\n",
       "      <td>0.999646</td>\n",
       "      <td>0.999404</td>\n",
       "      <td>0.999430</td>\n",
       "      <td>0.999732</td>\n",
       "      <td>0.005162</td>\n",
       "      <td>0.999373</td>\n",
       "      <td>0.999292</td>\n",
       "      <td>0.999578</td>\n",
       "      <td>0.003215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220827031936-11</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05h_fraud_20220827031936</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003501</td>\n",
       "      <td>0.999640</td>\n",
       "      <td>0.999404</td>\n",
       "      <td>0.999452</td>\n",
       "      <td>0.999745</td>\n",
       "      <td>0.004662</td>\n",
       "      <td>0.999513</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>0.999578</td>\n",
       "      <td>0.002562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220827031936-10</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05h_fraud_20220827031936</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>1.896781e-01</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004830</td>\n",
       "      <td>0.999442</td>\n",
       "      <td>0.999333</td>\n",
       "      <td>0.999373</td>\n",
       "      <td>0.999595</td>\n",
       "      <td>0.006202</td>\n",
       "      <td>0.999347</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>0.999430</td>\n",
       "      <td>0.004296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220827031936-9</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05h_fraud_20220827031936</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>2.270920e-01</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003978</td>\n",
       "      <td>0.999478</td>\n",
       "      <td>0.999404</td>\n",
       "      <td>0.999377</td>\n",
       "      <td>0.999580</td>\n",
       "      <td>0.007162</td>\n",
       "      <td>0.999325</td>\n",
       "      <td>0.999256</td>\n",
       "      <td>0.999391</td>\n",
       "      <td>0.004096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220827031936-8</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05h_fraud_20220827031936</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>3.222550e-01</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006893</td>\n",
       "      <td>0.999320</td>\n",
       "      <td>0.999193</td>\n",
       "      <td>0.999136</td>\n",
       "      <td>0.999499</td>\n",
       "      <td>0.007717</td>\n",
       "      <td>0.999040</td>\n",
       "      <td>0.999079</td>\n",
       "      <td>0.999390</td>\n",
       "      <td>0.005978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220827031936-7</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05h_fraud_20220827031936</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004877</td>\n",
       "      <td>0.999420</td>\n",
       "      <td>0.999404</td>\n",
       "      <td>0.999342</td>\n",
       "      <td>0.999634</td>\n",
       "      <td>0.006030</td>\n",
       "      <td>0.999303</td>\n",
       "      <td>0.999150</td>\n",
       "      <td>0.999392</td>\n",
       "      <td>0.004040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220827031936-6</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05h_fraud_20220827031936</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007768</td>\n",
       "      <td>0.999377</td>\n",
       "      <td>0.999088</td>\n",
       "      <td>0.999062</td>\n",
       "      <td>0.999460</td>\n",
       "      <td>0.008247</td>\n",
       "      <td>0.998952</td>\n",
       "      <td>0.999009</td>\n",
       "      <td>0.999267</td>\n",
       "      <td>0.007007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220827031936-5</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05h_fraud_20220827031936</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>2.116719e-01</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004306</td>\n",
       "      <td>0.999454</td>\n",
       "      <td>0.999404</td>\n",
       "      <td>0.999373</td>\n",
       "      <td>0.999604</td>\n",
       "      <td>0.005888</td>\n",
       "      <td>0.999307</td>\n",
       "      <td>0.999256</td>\n",
       "      <td>0.999391</td>\n",
       "      <td>0.004020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220827031936-4</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05h_fraud_20220827031936</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>4.146275e-01</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003268</td>\n",
       "      <td>0.999708</td>\n",
       "      <td>0.999439</td>\n",
       "      <td>0.999456</td>\n",
       "      <td>0.999831</td>\n",
       "      <td>0.004621</td>\n",
       "      <td>0.999509</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>0.999670</td>\n",
       "      <td>0.002357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220827031936-3</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05h_fraud_20220827031936</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>6.549223e-01</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003653</td>\n",
       "      <td>0.999608</td>\n",
       "      <td>0.999333</td>\n",
       "      <td>0.999443</td>\n",
       "      <td>0.999708</td>\n",
       "      <td>0.005493</td>\n",
       "      <td>0.999377</td>\n",
       "      <td>0.999256</td>\n",
       "      <td>0.999620</td>\n",
       "      <td>0.003072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220827031936-2</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05h_fraud_20220827031936</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>6.477870e-01</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003828</td>\n",
       "      <td>0.999651</td>\n",
       "      <td>0.999404</td>\n",
       "      <td>0.999443</td>\n",
       "      <td>0.999767</td>\n",
       "      <td>0.005060</td>\n",
       "      <td>0.999496</td>\n",
       "      <td>0.999292</td>\n",
       "      <td>0.999577</td>\n",
       "      <td>0.002563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220827031936-1</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05h_fraud_20220827031936</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>4.500001e-01</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003513</td>\n",
       "      <td>0.999525</td>\n",
       "      <td>0.999439</td>\n",
       "      <td>0.999456</td>\n",
       "      <td>0.999704</td>\n",
       "      <td>0.004945</td>\n",
       "      <td>0.999426</td>\n",
       "      <td>0.999398</td>\n",
       "      <td>0.999624</td>\n",
       "      <td>0.003037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220827031936-13</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05h_fraud_20220827031936</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>9.000000e-01</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.999791</td>\n",
       "      <td>0.999439</td>\n",
       "      <td>0.999452</td>\n",
       "      <td>0.999871</td>\n",
       "      <td>0.005052</td>\n",
       "      <td>0.999391</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>0.999577</td>\n",
       "      <td>0.002173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220826194057-20</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05h_fraud_20220826194057</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>8.780123e-01</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003183</td>\n",
       "      <td>0.999685</td>\n",
       "      <td>0.999404</td>\n",
       "      <td>0.999465</td>\n",
       "      <td>0.999762</td>\n",
       "      <td>0.004673</td>\n",
       "      <td>0.999408</td>\n",
       "      <td>0.999256</td>\n",
       "      <td>0.999670</td>\n",
       "      <td>0.002607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220826194057-19</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05h_fraud_20220826194057</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>2.412312e-01</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003099</td>\n",
       "      <td>0.999657</td>\n",
       "      <td>0.999439</td>\n",
       "      <td>0.999421</td>\n",
       "      <td>0.999733</td>\n",
       "      <td>0.004579</td>\n",
       "      <td>0.999448</td>\n",
       "      <td>0.999398</td>\n",
       "      <td>0.999671</td>\n",
       "      <td>0.002799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220826194057-18</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05h_fraud_20220826194057</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>9.000000e-01</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003715</td>\n",
       "      <td>0.999574</td>\n",
       "      <td>0.999404</td>\n",
       "      <td>0.999395</td>\n",
       "      <td>0.999651</td>\n",
       "      <td>0.005530</td>\n",
       "      <td>0.999386</td>\n",
       "      <td>0.999221</td>\n",
       "      <td>0.999622</td>\n",
       "      <td>0.003518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220826194057-17</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05h_fraud_20220826194057</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>1.756494e-01</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006488</td>\n",
       "      <td>0.999266</td>\n",
       "      <td>0.999228</td>\n",
       "      <td>0.999167</td>\n",
       "      <td>0.999428</td>\n",
       "      <td>0.007790</td>\n",
       "      <td>0.999079</td>\n",
       "      <td>0.999186</td>\n",
       "      <td>0.999286</td>\n",
       "      <td>0.006471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220826194057-16</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05h_fraud_20220826194057</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>9.508024e-02</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006703</td>\n",
       "      <td>0.999364</td>\n",
       "      <td>0.999018</td>\n",
       "      <td>0.999141</td>\n",
       "      <td>0.999495</td>\n",
       "      <td>0.007971</td>\n",
       "      <td>0.999092</td>\n",
       "      <td>0.999009</td>\n",
       "      <td>0.999284</td>\n",
       "      <td>0.006196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220826194057-15</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05h_fraud_20220826194057</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>1.615301e-01</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006821</td>\n",
       "      <td>0.999426</td>\n",
       "      <td>0.999123</td>\n",
       "      <td>0.999092</td>\n",
       "      <td>0.999467</td>\n",
       "      <td>0.008237</td>\n",
       "      <td>0.998970</td>\n",
       "      <td>0.999115</td>\n",
       "      <td>0.999346</td>\n",
       "      <td>0.006818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220826194057-14</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05h_fraud_20220826194057</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>1.399267e-01</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006261</td>\n",
       "      <td>0.999402</td>\n",
       "      <td>0.999228</td>\n",
       "      <td>0.999233</td>\n",
       "      <td>0.999553</td>\n",
       "      <td>0.006734</td>\n",
       "      <td>0.999180</td>\n",
       "      <td>0.999115</td>\n",
       "      <td>0.999440</td>\n",
       "      <td>0.005723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220826194057-13</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05h_fraud_20220826194057</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>5.251923e-01</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006536</td>\n",
       "      <td>0.999416</td>\n",
       "      <td>0.999298</td>\n",
       "      <td>0.999255</td>\n",
       "      <td>0.999501</td>\n",
       "      <td>0.007077</td>\n",
       "      <td>0.999136</td>\n",
       "      <td>0.999292</td>\n",
       "      <td>0.999369</td>\n",
       "      <td>0.005540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220826194057-12</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05h_fraud_20220826194057</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>4.245512e-02</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007228</td>\n",
       "      <td>0.999310</td>\n",
       "      <td>0.998983</td>\n",
       "      <td>0.999031</td>\n",
       "      <td>0.999445</td>\n",
       "      <td>0.008708</td>\n",
       "      <td>0.998939</td>\n",
       "      <td>0.998902</td>\n",
       "      <td>0.999282</td>\n",
       "      <td>0.006839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220826194057-11</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05h_fraud_20220826194057</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003452</td>\n",
       "      <td>0.999646</td>\n",
       "      <td>0.999404</td>\n",
       "      <td>0.999474</td>\n",
       "      <td>0.999802</td>\n",
       "      <td>0.004416</td>\n",
       "      <td>0.999535</td>\n",
       "      <td>0.999363</td>\n",
       "      <td>0.999670</td>\n",
       "      <td>0.002359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220826194057-10</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05h_fraud_20220826194057</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003235</td>\n",
       "      <td>0.999649</td>\n",
       "      <td>0.999368</td>\n",
       "      <td>0.999408</td>\n",
       "      <td>0.999697</td>\n",
       "      <td>0.005194</td>\n",
       "      <td>0.999395</td>\n",
       "      <td>0.999256</td>\n",
       "      <td>0.999668</td>\n",
       "      <td>0.003177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220826194057-9</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05h_fraud_20220826194057</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>2.004127e-01</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008172</td>\n",
       "      <td>0.999395</td>\n",
       "      <td>0.998912</td>\n",
       "      <td>0.998895</td>\n",
       "      <td>0.999439</td>\n",
       "      <td>0.007738</td>\n",
       "      <td>0.998750</td>\n",
       "      <td>0.998761</td>\n",
       "      <td>0.999275</td>\n",
       "      <td>0.007443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220826194057-8</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05h_fraud_20220826194057</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>7.559923e-01</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003470</td>\n",
       "      <td>0.999627</td>\n",
       "      <td>0.999368</td>\n",
       "      <td>0.999426</td>\n",
       "      <td>0.999715</td>\n",
       "      <td>0.005299</td>\n",
       "      <td>0.999364</td>\n",
       "      <td>0.999292</td>\n",
       "      <td>0.999669</td>\n",
       "      <td>0.003140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220826194057-7</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05h_fraud_20220826194057</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>2.181226e-01</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005467</td>\n",
       "      <td>0.999386</td>\n",
       "      <td>0.999193</td>\n",
       "      <td>0.999263</td>\n",
       "      <td>0.999542</td>\n",
       "      <td>0.006516</td>\n",
       "      <td>0.999246</td>\n",
       "      <td>0.999079</td>\n",
       "      <td>0.999339</td>\n",
       "      <td>0.004555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220826194057-6</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05h_fraud_20220826194057</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008315</td>\n",
       "      <td>0.999286</td>\n",
       "      <td>0.999123</td>\n",
       "      <td>0.999097</td>\n",
       "      <td>0.999450</td>\n",
       "      <td>0.008842</td>\n",
       "      <td>0.999031</td>\n",
       "      <td>0.998938</td>\n",
       "      <td>0.999315</td>\n",
       "      <td>0.006761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220826194057-5</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05h_fraud_20220826194057</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>3.947495e-01</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.999645</td>\n",
       "      <td>0.999404</td>\n",
       "      <td>0.999452</td>\n",
       "      <td>0.999791</td>\n",
       "      <td>0.004653</td>\n",
       "      <td>0.999526</td>\n",
       "      <td>0.999363</td>\n",
       "      <td>0.999624</td>\n",
       "      <td>0.002310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220826194057-4</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05h_fraud_20220826194057</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>2.162283e-01</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004816</td>\n",
       "      <td>0.999350</td>\n",
       "      <td>0.999333</td>\n",
       "      <td>0.999342</td>\n",
       "      <td>0.999568</td>\n",
       "      <td>0.006951</td>\n",
       "      <td>0.999307</td>\n",
       "      <td>0.999256</td>\n",
       "      <td>0.999344</td>\n",
       "      <td>0.004180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220826194057-2</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05h_fraud_20220826194057</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>6.462329e-01</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>0.999634</td>\n",
       "      <td>0.999439</td>\n",
       "      <td>0.999452</td>\n",
       "      <td>0.999773</td>\n",
       "      <td>0.004512</td>\n",
       "      <td>0.999483</td>\n",
       "      <td>0.999292</td>\n",
       "      <td>0.999531</td>\n",
       "      <td>0.002588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220826194057-1</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05h_fraud_20220826194057</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>4.500001e-01</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003539</td>\n",
       "      <td>0.999582</td>\n",
       "      <td>0.999404</td>\n",
       "      <td>0.999448</td>\n",
       "      <td>0.999710</td>\n",
       "      <td>0.004185</td>\n",
       "      <td>0.999465</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>0.999624</td>\n",
       "      <td>0.002893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220826194057-3</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05h_fraud_20220826194057</td>\n",
       "      <td>2.0</td>\n",
       "      <td>05</td>\n",
       "      <td>8.617184e-01</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003172</td>\n",
       "      <td>0.999773</td>\n",
       "      <td>0.999404</td>\n",
       "      <td>0.999448</td>\n",
       "      <td>0.999843</td>\n",
       "      <td>0.004350</td>\n",
       "      <td>0.999461</td>\n",
       "      <td>0.999292</td>\n",
       "      <td>0.999624</td>\n",
       "      <td>0.002209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60 rows  43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            experiment_name               run_name  \\\n",
       "0   experiment-05-05h-tf-classification-dnn  run-20220927230247-20   \n",
       "1   experiment-05-05h-tf-classification-dnn  run-20220927230247-19   \n",
       "2   experiment-05-05h-tf-classification-dnn  run-20220927230247-18   \n",
       "3   experiment-05-05h-tf-classification-dnn  run-20220927230247-17   \n",
       "4   experiment-05-05h-tf-classification-dnn  run-20220927230247-16   \n",
       "5   experiment-05-05h-tf-classification-dnn  run-20220927230247-15   \n",
       "6   experiment-05-05h-tf-classification-dnn  run-20220927230247-14   \n",
       "7   experiment-05-05h-tf-classification-dnn  run-20220927230247-13   \n",
       "8   experiment-05-05h-tf-classification-dnn  run-20220927230247-12   \n",
       "9   experiment-05-05h-tf-classification-dnn  run-20220927230247-11   \n",
       "10  experiment-05-05h-tf-classification-dnn  run-20220927230247-10   \n",
       "11  experiment-05-05h-tf-classification-dnn   run-20220927230247-9   \n",
       "12  experiment-05-05h-tf-classification-dnn   run-20220927230247-8   \n",
       "13  experiment-05-05h-tf-classification-dnn   run-20220927230247-7   \n",
       "14  experiment-05-05h-tf-classification-dnn   run-20220927230247-5   \n",
       "15  experiment-05-05h-tf-classification-dnn   run-20220927230247-4   \n",
       "16  experiment-05-05h-tf-classification-dnn   run-20220927230247-3   \n",
       "17  experiment-05-05h-tf-classification-dnn   run-20220927230247-2   \n",
       "18  experiment-05-05h-tf-classification-dnn   run-20220927230247-1   \n",
       "19  experiment-05-05h-tf-classification-dnn   run-20220927230247-6   \n",
       "20  experiment-05-05h-tf-classification-dnn  run-20220827031936-20   \n",
       "21  experiment-05-05h-tf-classification-dnn  run-20220827031936-19   \n",
       "22  experiment-05-05h-tf-classification-dnn  run-20220827031936-18   \n",
       "23  experiment-05-05h-tf-classification-dnn  run-20220827031936-17   \n",
       "24  experiment-05-05h-tf-classification-dnn  run-20220827031936-16   \n",
       "25  experiment-05-05h-tf-classification-dnn  run-20220827031936-15   \n",
       "26  experiment-05-05h-tf-classification-dnn  run-20220827031936-14   \n",
       "27  experiment-05-05h-tf-classification-dnn  run-20220827031936-12   \n",
       "28  experiment-05-05h-tf-classification-dnn  run-20220827031936-11   \n",
       "29  experiment-05-05h-tf-classification-dnn  run-20220827031936-10   \n",
       "30  experiment-05-05h-tf-classification-dnn   run-20220827031936-9   \n",
       "31  experiment-05-05h-tf-classification-dnn   run-20220827031936-8   \n",
       "32  experiment-05-05h-tf-classification-dnn   run-20220827031936-7   \n",
       "33  experiment-05-05h-tf-classification-dnn   run-20220827031936-6   \n",
       "34  experiment-05-05h-tf-classification-dnn   run-20220827031936-5   \n",
       "35  experiment-05-05h-tf-classification-dnn   run-20220827031936-4   \n",
       "36  experiment-05-05h-tf-classification-dnn   run-20220827031936-3   \n",
       "37  experiment-05-05h-tf-classification-dnn   run-20220827031936-2   \n",
       "38  experiment-05-05h-tf-classification-dnn   run-20220827031936-1   \n",
       "39  experiment-05-05h-tf-classification-dnn  run-20220827031936-13   \n",
       "40  experiment-05-05h-tf-classification-dnn  run-20220826194057-20   \n",
       "41  experiment-05-05h-tf-classification-dnn  run-20220826194057-19   \n",
       "42  experiment-05-05h-tf-classification-dnn  run-20220826194057-18   \n",
       "43  experiment-05-05h-tf-classification-dnn  run-20220826194057-17   \n",
       "44  experiment-05-05h-tf-classification-dnn  run-20220826194057-16   \n",
       "45  experiment-05-05h-tf-classification-dnn  run-20220826194057-15   \n",
       "46  experiment-05-05h-tf-classification-dnn  run-20220826194057-14   \n",
       "47  experiment-05-05h-tf-classification-dnn  run-20220826194057-13   \n",
       "48  experiment-05-05h-tf-classification-dnn  run-20220826194057-12   \n",
       "49  experiment-05-05h-tf-classification-dnn  run-20220826194057-11   \n",
       "50  experiment-05-05h-tf-classification-dnn  run-20220826194057-10   \n",
       "51  experiment-05-05h-tf-classification-dnn   run-20220826194057-9   \n",
       "52  experiment-05-05h-tf-classification-dnn   run-20220826194057-8   \n",
       "53  experiment-05-05h-tf-classification-dnn   run-20220826194057-7   \n",
       "54  experiment-05-05h-tf-classification-dnn   run-20220826194057-6   \n",
       "55  experiment-05-05h-tf-classification-dnn   run-20220826194057-5   \n",
       "56  experiment-05-05h-tf-classification-dnn   run-20220826194057-4   \n",
       "57  experiment-05-05h-tf-classification-dnn   run-20220826194057-2   \n",
       "58  experiment-05-05h-tf-classification-dnn   run-20220826194057-1   \n",
       "59  experiment-05-05h-tf-classification-dnn   run-20220826194057-3   \n",
       "\n",
       "                run_type     state  param.epochs  \\\n",
       "0   system.ExperimentRun  COMPLETE          10.0   \n",
       "1   system.ExperimentRun  COMPLETE          10.0   \n",
       "2   system.ExperimentRun  COMPLETE          10.0   \n",
       "3   system.ExperimentRun  COMPLETE          10.0   \n",
       "4   system.ExperimentRun  COMPLETE          10.0   \n",
       "5   system.ExperimentRun  COMPLETE          10.0   \n",
       "6   system.ExperimentRun  COMPLETE          10.0   \n",
       "7   system.ExperimentRun  COMPLETE          10.0   \n",
       "8   system.ExperimentRun  COMPLETE          10.0   \n",
       "9   system.ExperimentRun  COMPLETE          10.0   \n",
       "10  system.ExperimentRun  COMPLETE          10.0   \n",
       "11  system.ExperimentRun  COMPLETE          10.0   \n",
       "12  system.ExperimentRun  COMPLETE          10.0   \n",
       "13  system.ExperimentRun  COMPLETE          10.0   \n",
       "14  system.ExperimentRun  COMPLETE          10.0   \n",
       "15  system.ExperimentRun  COMPLETE          10.0   \n",
       "16  system.ExperimentRun  COMPLETE          10.0   \n",
       "17  system.ExperimentRun  COMPLETE          10.0   \n",
       "18  system.ExperimentRun  COMPLETE          10.0   \n",
       "19  system.ExperimentRun  COMPLETE          10.0   \n",
       "20  system.ExperimentRun  COMPLETE          10.0   \n",
       "21  system.ExperimentRun  COMPLETE          10.0   \n",
       "22  system.ExperimentRun  COMPLETE          10.0   \n",
       "23  system.ExperimentRun  COMPLETE          10.0   \n",
       "24  system.ExperimentRun  COMPLETE          10.0   \n",
       "25  system.ExperimentRun  COMPLETE          10.0   \n",
       "26  system.ExperimentRun  COMPLETE          10.0   \n",
       "27  system.ExperimentRun  COMPLETE          10.0   \n",
       "28  system.ExperimentRun  COMPLETE          10.0   \n",
       "29  system.ExperimentRun  COMPLETE          10.0   \n",
       "30  system.ExperimentRun  COMPLETE          10.0   \n",
       "31  system.ExperimentRun  COMPLETE          10.0   \n",
       "32  system.ExperimentRun  COMPLETE          10.0   \n",
       "33  system.ExperimentRun  COMPLETE          10.0   \n",
       "34  system.ExperimentRun  COMPLETE          10.0   \n",
       "35  system.ExperimentRun  COMPLETE          10.0   \n",
       "36  system.ExperimentRun  COMPLETE          10.0   \n",
       "37  system.ExperimentRun  COMPLETE          10.0   \n",
       "38  system.ExperimentRun  COMPLETE          10.0   \n",
       "39  system.ExperimentRun  COMPLETE          10.0   \n",
       "40  system.ExperimentRun  COMPLETE          10.0   \n",
       "41  system.ExperimentRun  COMPLETE          10.0   \n",
       "42  system.ExperimentRun  COMPLETE          10.0   \n",
       "43  system.ExperimentRun  COMPLETE          10.0   \n",
       "44  system.ExperimentRun  COMPLETE          10.0   \n",
       "45  system.ExperimentRun  COMPLETE          10.0   \n",
       "46  system.ExperimentRun  COMPLETE          10.0   \n",
       "47  system.ExperimentRun  COMPLETE          10.0   \n",
       "48  system.ExperimentRun  COMPLETE          10.0   \n",
       "49  system.ExperimentRun  COMPLETE          10.0   \n",
       "50  system.ExperimentRun  COMPLETE          10.0   \n",
       "51  system.ExperimentRun  COMPLETE          10.0   \n",
       "52  system.ExperimentRun  COMPLETE          10.0   \n",
       "53  system.ExperimentRun  COMPLETE          10.0   \n",
       "54  system.ExperimentRun  COMPLETE          10.0   \n",
       "55  system.ExperimentRun  COMPLETE          10.0   \n",
       "56  system.ExperimentRun  COMPLETE          10.0   \n",
       "57  system.ExperimentRun  COMPLETE          10.0   \n",
       "58  system.ExperimentRun  COMPLETE          10.0   \n",
       "59  system.ExperimentRun  COMPLETE          10.0   \n",
       "\n",
       "   param.hyperparameterTuningJobs.display_name  param.nclasses param.series  \\\n",
       "0                        05_05h_20220927230247             2.0           05   \n",
       "1                        05_05h_20220927230247             2.0           05   \n",
       "2                        05_05h_20220927230247             2.0           05   \n",
       "3                        05_05h_20220927230247             2.0           05   \n",
       "4                        05_05h_20220927230247             2.0           05   \n",
       "5                        05_05h_20220927230247             2.0           05   \n",
       "6                        05_05h_20220927230247             2.0           05   \n",
       "7                        05_05h_20220927230247             2.0           05   \n",
       "8                        05_05h_20220927230247             2.0           05   \n",
       "9                        05_05h_20220927230247             2.0           05   \n",
       "10                       05_05h_20220927230247             2.0           05   \n",
       "11                       05_05h_20220927230247             2.0           05   \n",
       "12                       05_05h_20220927230247             2.0           05   \n",
       "13                       05_05h_20220927230247             2.0           05   \n",
       "14                       05_05h_20220927230247             2.0           05   \n",
       "15                       05_05h_20220927230247             2.0           05   \n",
       "16                       05_05h_20220927230247             2.0           05   \n",
       "17                       05_05h_20220927230247             2.0           05   \n",
       "18                       05_05h_20220927230247             2.0           05   \n",
       "19                       05_05h_20220927230247             2.0           05   \n",
       "20                    05h_fraud_20220827031936             2.0           05   \n",
       "21                    05h_fraud_20220827031936             2.0           05   \n",
       "22                    05h_fraud_20220827031936             2.0           05   \n",
       "23                    05h_fraud_20220827031936             2.0           05   \n",
       "24                    05h_fraud_20220827031936             2.0           05   \n",
       "25                    05h_fraud_20220827031936             2.0           05   \n",
       "26                    05h_fraud_20220827031936             2.0           05   \n",
       "27                    05h_fraud_20220827031936             2.0           05   \n",
       "28                    05h_fraud_20220827031936             2.0           05   \n",
       "29                    05h_fraud_20220827031936             2.0           05   \n",
       "30                    05h_fraud_20220827031936             2.0           05   \n",
       "31                    05h_fraud_20220827031936             2.0           05   \n",
       "32                    05h_fraud_20220827031936             2.0           05   \n",
       "33                    05h_fraud_20220827031936             2.0           05   \n",
       "34                    05h_fraud_20220827031936             2.0           05   \n",
       "35                    05h_fraud_20220827031936             2.0           05   \n",
       "36                    05h_fraud_20220827031936             2.0           05   \n",
       "37                    05h_fraud_20220827031936             2.0           05   \n",
       "38                    05h_fraud_20220827031936             2.0           05   \n",
       "39                    05h_fraud_20220827031936             2.0           05   \n",
       "40                    05h_fraud_20220826194057             2.0           05   \n",
       "41                    05h_fraud_20220826194057             2.0           05   \n",
       "42                    05h_fraud_20220826194057             2.0           05   \n",
       "43                    05h_fraud_20220826194057             2.0           05   \n",
       "44                    05h_fraud_20220826194057             2.0           05   \n",
       "45                    05h_fraud_20220826194057             2.0           05   \n",
       "46                    05h_fraud_20220826194057             2.0           05   \n",
       "47                    05h_fraud_20220826194057             2.0           05   \n",
       "48                    05h_fraud_20220826194057             2.0           05   \n",
       "49                    05h_fraud_20220826194057             2.0           05   \n",
       "50                    05h_fraud_20220826194057             2.0           05   \n",
       "51                    05h_fraud_20220826194057             2.0           05   \n",
       "52                    05h_fraud_20220826194057             2.0           05   \n",
       "53                    05h_fraud_20220826194057             2.0           05   \n",
       "54                    05h_fraud_20220826194057             2.0           05   \n",
       "55                    05h_fraud_20220826194057             2.0           05   \n",
       "56                    05h_fraud_20220826194057             2.0           05   \n",
       "57                    05h_fraud_20220826194057             2.0           05   \n",
       "58                    05h_fraud_20220826194057             2.0           05   \n",
       "59                    05h_fraud_20220826194057             2.0           05   \n",
       "\n",
       "    param.hyperparameter.momentum  \\\n",
       "0                    1.240522e-01   \n",
       "1                    1.224430e-01   \n",
       "2                    1.354129e-01   \n",
       "3                    1.390266e-01   \n",
       "4                    2.838257e-01   \n",
       "5                    1.000000e-07   \n",
       "6                    1.000000e-07   \n",
       "7                    9.000000e-01   \n",
       "8                    1.000000e-07   \n",
       "9                    8.837002e-01   \n",
       "10                   1.000000e-07   \n",
       "11                   3.877480e-01   \n",
       "12                   7.432967e-01   \n",
       "13                   5.237038e-01   \n",
       "14                   7.019653e-01   \n",
       "15                   1.840781e-03   \n",
       "16                   2.357123e-01   \n",
       "17                   2.522877e-01   \n",
       "18                   4.500001e-01   \n",
       "19                   9.000000e-01   \n",
       "20                   9.000000e-01   \n",
       "21                   6.569114e-01   \n",
       "22                   6.111249e-01   \n",
       "23                   1.803773e-01   \n",
       "24                   1.707894e-01   \n",
       "25                   1.937884e-01   \n",
       "26                   9.000000e-01   \n",
       "27                   9.000000e-01   \n",
       "28                   1.000000e-07   \n",
       "29                   1.896781e-01   \n",
       "30                   2.270920e-01   \n",
       "31                   3.222550e-01   \n",
       "32                   1.000000e-07   \n",
       "33                   1.000000e-07   \n",
       "34                   2.116719e-01   \n",
       "35                   4.146275e-01   \n",
       "36                   6.549223e-01   \n",
       "37                   6.477870e-01   \n",
       "38                   4.500001e-01   \n",
       "39                   9.000000e-01   \n",
       "40                   8.780123e-01   \n",
       "41                   2.412312e-01   \n",
       "42                   9.000000e-01   \n",
       "43                   1.756494e-01   \n",
       "44                   9.508024e-02   \n",
       "45                   1.615301e-01   \n",
       "46                   1.399267e-01   \n",
       "47                   5.251923e-01   \n",
       "48                   4.245512e-02   \n",
       "49                   1.000000e-07   \n",
       "50                   1.000000e-07   \n",
       "51                   2.004127e-01   \n",
       "52                   7.559923e-01   \n",
       "53                   2.181226e-01   \n",
       "54                   1.000000e-07   \n",
       "55                   3.947495e-01   \n",
       "56                   2.162283e-01   \n",
       "57                   6.462329e-01   \n",
       "58                   4.500001e-01   \n",
       "59                   8.617184e-01   \n",
       "\n",
       "                                 param.data_source  ... metric.test_loss  \\\n",
       "0   bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.006515   \n",
       "1   bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.010101   \n",
       "2   bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.006881   \n",
       "3   bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.007137   \n",
       "4   bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.007155   \n",
       "5   bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.005846   \n",
       "6   bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.006120   \n",
       "7   bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.003327   \n",
       "8   bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.007461   \n",
       "9   bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.003612   \n",
       "10  bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.005168   \n",
       "11  bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.003709   \n",
       "12  bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.003481   \n",
       "13  bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.005485   \n",
       "14  bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.003395   \n",
       "15  bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.003421   \n",
       "16  bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.004609   \n",
       "17  bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.003160   \n",
       "18  bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.003402   \n",
       "19  bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.003266   \n",
       "20  bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.003233   \n",
       "21  bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.003153   \n",
       "22  bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.005762   \n",
       "23  bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.007108   \n",
       "24  bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.007804   \n",
       "25  bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.003381   \n",
       "26  bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.003118   \n",
       "27  bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.003451   \n",
       "28  bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.003501   \n",
       "29  bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.004830   \n",
       "30  bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.003978   \n",
       "31  bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.006893   \n",
       "32  bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.004877   \n",
       "33  bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.007768   \n",
       "34  bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.004306   \n",
       "35  bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.003268   \n",
       "36  bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.003653   \n",
       "37  bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.003828   \n",
       "38  bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.003513   \n",
       "39  bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.003784   \n",
       "40  bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.003183   \n",
       "41  bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.003099   \n",
       "42  bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.003715   \n",
       "43  bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.006488   \n",
       "44  bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.006703   \n",
       "45  bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.006821   \n",
       "46  bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.006261   \n",
       "47  bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.006536   \n",
       "48  bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.007228   \n",
       "49  bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.003452   \n",
       "50  bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.003235   \n",
       "51  bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.008172   \n",
       "52  bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.003470   \n",
       "53  bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.005467   \n",
       "54  bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.008315   \n",
       "55  bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.003448   \n",
       "56  bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.004816   \n",
       "57  bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.003532   \n",
       "58  bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.003539   \n",
       "59  bq://statmike-mlops-349915.fraud.fraud_prepped  ...         0.003172   \n",
       "\n",
       "   metric.train_auprc  metric.test_accuracy  metric.train_accuracy  \\\n",
       "0            0.999290              0.999228               0.999189   \n",
       "1            0.999042              0.998351               0.998259   \n",
       "2            0.999394              0.998912               0.999044   \n",
       "3            0.999316              0.999158               0.999075   \n",
       "4            0.999388              0.998877               0.998711   \n",
       "5            0.999373              0.999298               0.999285   \n",
       "6            0.999488              0.999298               0.999211   \n",
       "7            0.999622              0.999404               0.999434   \n",
       "8            0.999313              0.999228               0.999198   \n",
       "9            0.999570              0.999333               0.999395   \n",
       "10           0.999390              0.999263               0.999316   \n",
       "11           0.999588              0.999439               0.999430   \n",
       "12           0.999594              0.999439               0.999439   \n",
       "13           0.999417              0.999368               0.999334   \n",
       "14           0.999663              0.999439               0.999456   \n",
       "15           0.999674              0.999368               0.999399   \n",
       "16           0.999415              0.999404               0.999382   \n",
       "17           0.999623              0.999474               0.999417   \n",
       "18           0.999588              0.999404               0.999412   \n",
       "19           0.999846              0.999404               0.999439   \n",
       "20           0.999657              0.999404               0.999439   \n",
       "21           0.999754              0.999404               0.999430   \n",
       "22           0.999383              0.999298               0.999277   \n",
       "23           0.999518              0.998807               0.998698   \n",
       "24           0.999449              0.999018               0.998899   \n",
       "25           0.999634              0.999439               0.999443   \n",
       "26           0.999714              0.999439               0.999439   \n",
       "27           0.999646              0.999404               0.999430   \n",
       "28           0.999640              0.999404               0.999452   \n",
       "29           0.999442              0.999333               0.999373   \n",
       "30           0.999478              0.999404               0.999377   \n",
       "31           0.999320              0.999193               0.999136   \n",
       "32           0.999420              0.999404               0.999342   \n",
       "33           0.999377              0.999088               0.999062   \n",
       "34           0.999454              0.999404               0.999373   \n",
       "35           0.999708              0.999439               0.999456   \n",
       "36           0.999608              0.999333               0.999443   \n",
       "37           0.999651              0.999404               0.999443   \n",
       "38           0.999525              0.999439               0.999456   \n",
       "39           0.999791              0.999439               0.999452   \n",
       "40           0.999685              0.999404               0.999465   \n",
       "41           0.999657              0.999439               0.999421   \n",
       "42           0.999574              0.999404               0.999395   \n",
       "43           0.999266              0.999228               0.999167   \n",
       "44           0.999364              0.999018               0.999141   \n",
       "45           0.999426              0.999123               0.999092   \n",
       "46           0.999402              0.999228               0.999233   \n",
       "47           0.999416              0.999298               0.999255   \n",
       "48           0.999310              0.998983               0.999031   \n",
       "49           0.999646              0.999404               0.999474   \n",
       "50           0.999649              0.999368               0.999408   \n",
       "51           0.999395              0.998912               0.998895   \n",
       "52           0.999627              0.999368               0.999426   \n",
       "53           0.999386              0.999193               0.999263   \n",
       "54           0.999286              0.999123               0.999097   \n",
       "55           0.999645              0.999404               0.999452   \n",
       "56           0.999350              0.999333               0.999342   \n",
       "57           0.999634              0.999439               0.999452   \n",
       "58           0.999582              0.999404               0.999448   \n",
       "59           0.999773              0.999404               0.999448   \n",
       "\n",
       "    time_series_metric.train_auprc time_series_metric.val_loss  \\\n",
       "0                         0.999450                    0.008677   \n",
       "1                         0.999292                    0.012379   \n",
       "2                         0.999573                    0.007880   \n",
       "3                         0.999490                    0.008760   \n",
       "4                         0.999429                    0.008970   \n",
       "5                         0.999557                    0.007877   \n",
       "6                         0.999522                    0.007489   \n",
       "7                         0.999715                    0.005259   \n",
       "8                         0.999485                    0.008619   \n",
       "9                         0.999691                    0.005326   \n",
       "10                        0.999552                    0.006427   \n",
       "11                        0.999710                    0.004577   \n",
       "12                        0.999762                    0.004992   \n",
       "13                        0.999551                    0.006124   \n",
       "14                        0.999791                    0.004299   \n",
       "15                        0.999721                    0.005154   \n",
       "16                        0.999575                    0.006370   \n",
       "17                        0.999744                    0.004041   \n",
       "18                        0.999692                    0.004070   \n",
       "19                        0.999871                    0.005112   \n",
       "20                        0.999739                    0.004431   \n",
       "21                        0.999826                    0.004535   \n",
       "22                        0.999531                    0.006980   \n",
       "23                        0.999585                    0.007662   \n",
       "24                        0.999509                    0.008622   \n",
       "25                        0.999739                    0.004625   \n",
       "26                        0.999779                    0.004204   \n",
       "27                        0.999732                    0.005162   \n",
       "28                        0.999745                    0.004662   \n",
       "29                        0.999595                    0.006202   \n",
       "30                        0.999580                    0.007162   \n",
       "31                        0.999499                    0.007717   \n",
       "32                        0.999634                    0.006030   \n",
       "33                        0.999460                    0.008247   \n",
       "34                        0.999604                    0.005888   \n",
       "35                        0.999831                    0.004621   \n",
       "36                        0.999708                    0.005493   \n",
       "37                        0.999767                    0.005060   \n",
       "38                        0.999704                    0.004945   \n",
       "39                        0.999871                    0.005052   \n",
       "40                        0.999762                    0.004673   \n",
       "41                        0.999733                    0.004579   \n",
       "42                        0.999651                    0.005530   \n",
       "43                        0.999428                    0.007790   \n",
       "44                        0.999495                    0.007971   \n",
       "45                        0.999467                    0.008237   \n",
       "46                        0.999553                    0.006734   \n",
       "47                        0.999501                    0.007077   \n",
       "48                        0.999445                    0.008708   \n",
       "49                        0.999802                    0.004416   \n",
       "50                        0.999697                    0.005194   \n",
       "51                        0.999439                    0.007738   \n",
       "52                        0.999715                    0.005299   \n",
       "53                        0.999542                    0.006516   \n",
       "54                        0.999450                    0.008842   \n",
       "55                        0.999791                    0.004653   \n",
       "56                        0.999568                    0.006951   \n",
       "57                        0.999773                    0.004512   \n",
       "58                        0.999710                    0.004185   \n",
       "59                        0.999843                    0.004350   \n",
       "\n",
       "   time_series_metric.train_accuracy time_series_metric.val_accuracy  \\\n",
       "0                           0.999097                        0.999044   \n",
       "1                           0.998259                        0.998301   \n",
       "2                           0.998939                        0.998973   \n",
       "3                           0.998991                        0.999079   \n",
       "4                           0.998514                        0.998619   \n",
       "5                           0.999220                        0.999150   \n",
       "6                           0.999110                        0.999044   \n",
       "7                           0.999382                        0.999256   \n",
       "8                           0.999084                        0.999079   \n",
       "9                           0.999355                        0.999186   \n",
       "10                          0.999277                        0.999150   \n",
       "11                          0.999373                        0.999292   \n",
       "12                          0.999491                        0.999292   \n",
       "13                          0.999272                        0.999256   \n",
       "14                          0.999456                        0.999363   \n",
       "15                          0.999408                        0.999186   \n",
       "16                          0.999277                        0.999221   \n",
       "17                          0.999439                        0.999292   \n",
       "18                          0.999408                        0.999292   \n",
       "19                          0.999452                        0.999221   \n",
       "20                          0.999408                        0.999292   \n",
       "21                          0.999509                        0.999327   \n",
       "22                          0.999198                        0.999150   \n",
       "23                          0.998557                        0.998548   \n",
       "24                          0.998829                        0.998867   \n",
       "25                          0.999456                        0.999327   \n",
       "26                          0.999404                        0.999256   \n",
       "27                          0.999373                        0.999292   \n",
       "28                          0.999513                        0.999327   \n",
       "29                          0.999347                        0.999327   \n",
       "30                          0.999325                        0.999256   \n",
       "31                          0.999040                        0.999079   \n",
       "32                          0.999303                        0.999150   \n",
       "33                          0.998952                        0.999009   \n",
       "34                          0.999307                        0.999256   \n",
       "35                          0.999509                        0.999327   \n",
       "36                          0.999377                        0.999256   \n",
       "37                          0.999496                        0.999292   \n",
       "38                          0.999426                        0.999398   \n",
       "39                          0.999391                        0.999327   \n",
       "40                          0.999408                        0.999256   \n",
       "41                          0.999448                        0.999398   \n",
       "42                          0.999386                        0.999221   \n",
       "43                          0.999079                        0.999186   \n",
       "44                          0.999092                        0.999009   \n",
       "45                          0.998970                        0.999115   \n",
       "46                          0.999180                        0.999115   \n",
       "47                          0.999136                        0.999292   \n",
       "48                          0.998939                        0.998902   \n",
       "49                          0.999535                        0.999363   \n",
       "50                          0.999395                        0.999256   \n",
       "51                          0.998750                        0.998761   \n",
       "52                          0.999364                        0.999292   \n",
       "53                          0.999246                        0.999079   \n",
       "54                          0.999031                        0.998938   \n",
       "55                          0.999526                        0.999363   \n",
       "56                          0.999307                        0.999256   \n",
       "57                          0.999483                        0.999292   \n",
       "58                          0.999465                        0.999327   \n",
       "59                          0.999461                        0.999292   \n",
       "\n",
       "   time_series_metric.val_auprc time_series_metric.train_loss  \n",
       "0                      0.999228                      0.006356  \n",
       "1                      0.998758                      0.010039  \n",
       "2                      0.999339                      0.006136  \n",
       "3                      0.999321                      0.006555  \n",
       "4                      0.999278                      0.007733  \n",
       "5                      0.999318                      0.005249  \n",
       "6                      0.999431                      0.005137  \n",
       "7                      0.999670                      0.003139  \n",
       "8                      0.999254                      0.006364  \n",
       "9                      0.999623                      0.003534  \n",
       "10                     0.999390                      0.004449  \n",
       "11                     0.999531                      0.003186  \n",
       "12                     0.999623                      0.002713  \n",
       "13                     0.999383                      0.004822  \n",
       "14                     0.999670                      0.002468  \n",
       "15                     0.999624                      0.003269  \n",
       "16                     0.999345                      0.004172  \n",
       "17                     0.999624                      0.002788  \n",
       "18                     0.999625                      0.003120  \n",
       "19                     0.999761                      0.002193  \n",
       "20                     0.999670                      0.002760  \n",
       "21                     0.999669                      0.002230  \n",
       "22                     0.999342                      0.005036  \n",
       "23                     0.999422                      0.006858  \n",
       "24                     0.999369                      0.006982  \n",
       "25                     0.999716                      0.002810  \n",
       "26                     0.999670                      0.002622  \n",
       "27                     0.999578                      0.003215  \n",
       "28                     0.999578                      0.002562  \n",
       "29                     0.999430                      0.004296  \n",
       "30                     0.999391                      0.004096  \n",
       "31                     0.999390                      0.005978  \n",
       "32                     0.999392                      0.004040  \n",
       "33                     0.999267                      0.007007  \n",
       "34                     0.999391                      0.004020  \n",
       "35                     0.999670                      0.002357  \n",
       "36                     0.999620                      0.003072  \n",
       "37                     0.999577                      0.002563  \n",
       "38                     0.999624                      0.003037  \n",
       "39                     0.999577                      0.002173  \n",
       "40                     0.999670                      0.002607  \n",
       "41                     0.999671                      0.002799  \n",
       "42                     0.999622                      0.003518  \n",
       "43                     0.999286                      0.006471  \n",
       "44                     0.999284                      0.006196  \n",
       "45                     0.999346                      0.006818  \n",
       "46                     0.999440                      0.005723  \n",
       "47                     0.999369                      0.005540  \n",
       "48                     0.999282                      0.006839  \n",
       "49                     0.999670                      0.002359  \n",
       "50                     0.999668                      0.003177  \n",
       "51                     0.999275                      0.007443  \n",
       "52                     0.999669                      0.003140  \n",
       "53                     0.999339                      0.004555  \n",
       "54                     0.999315                      0.006761  \n",
       "55                     0.999624                      0.002310  \n",
       "56                     0.999344                      0.004180  \n",
       "57                     0.999531                      0.002588  \n",
       "58                     0.999624                      0.002893  \n",
       "59                     0.999624                      0.002209  \n",
       "\n",
       "[60 rows x 43 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.get_data_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca6741a-b8b3-4b61-a243-10ab3fa64e48",
   "metadata": {},
   "source": [
    "Review the Experiments TensorBoard to compare runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3ce18389-8484-4d5d-a30e-c4841eb52e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Experiment TensorBoard Link:\n",
      "https://us-central1.tensorboard.googleusercontent.com/experiment/projects+1026793852137+locations+us-central1+tensorboards+7179142426307592192+experiments+experiment-05-05h-tf-classification-dnn\n"
     ]
    }
   ],
   "source": [
    "print(f\"The Experiment TensorBoard Link:\\nhttps://{REGION}.tensorboard.googleusercontent.com/experiment/{tb.resource_name.replace('/', '+')}+experiments+{exp.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77d7258-57df-41b7-b904-7daa2216ceeb",
   "metadata": {},
   "source": [
    "### Compare This Run Using Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba305010-3630-446a-9466-a293fa7a69bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "Get a list of all experiments in this project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bb42949a-a4ab-4ef0-b163-ce89d2b58c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = aiplatform.Experiment.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46873d5-19c2-465e-84c4-ae6071b75dc4",
   "metadata": {},
   "source": [
    "Remove experiments not in the SERIES:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d9fd9424-3b50-4921-868e-e08eb6e2c033",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [e for e in experiments if e.name.split('-')[0:2] == ['experiment', SERIES]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091a7519-489f-4ae3-9f74-b42bbca5fe23",
   "metadata": {},
   "source": [
    "Combine the runs from all experiments in SERIES into a single dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "eb7352f4-d50a-43c1-a342-a15ba06b1ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment-05-05i-tf-classification-dnn\n",
      "experiment-05-05h-tf-classification-dnn\n",
      "experiment-05-05g-tf-classification-dnn\n",
      "experiment-05-05f-tf-classification-dnn\n",
      "experiment-05-05e-tf-classification-dnn\n",
      "experiment-05-05d-tf-classification-dnn\n",
      "experiment-05-05c-tf-classification-dnn\n",
      "experiment-05-05b-tf-classification-dnn\n",
      "experiment-05-05a-tf-classification-dnn\n",
      "experiment-05-05-tf-classification-dnn\n"
     ]
    }
   ],
   "source": [
    "import time # temporary to force sleep between requests\n",
    "results = []\n",
    "for experiment in experiments:\n",
    "        results.append(experiment.get_data_frame())\n",
    "        print(experiment.name)\n",
    "        time.sleep(60)\n",
    "results = pd.concat(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9b5c44-a020-49b1-8eab-ecf4cb88b6b4",
   "metadata": {},
   "source": [
    "Create ranks for models within experiment and across the entire SERIES:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7cd876a4-7984-4687-b42b-c829952c2ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>run_name</th>\n",
       "      <th>param.model.display_name</th>\n",
       "      <th>param.model.version_id</th>\n",
       "      <th>metric.test_auprc</th>\n",
       "      <th>series_rank</th>\n",
       "      <th>experiment_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>experiment-05-05-tf-classification-dnn</td>\n",
       "      <td>run-20220825143943</td>\n",
       "      <td>05_fraud</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999398</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>experiment-05-05-tf-classification-dnn</td>\n",
       "      <td>run-20220825161109</td>\n",
       "      <td>05_fraud</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999397</td>\n",
       "      <td>33.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>experiment-05-05-tf-classification-dnn</td>\n",
       "      <td>run-20220825175329</td>\n",
       "      <td>05_fraud</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999344</td>\n",
       "      <td>36.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>experiment-05-05-tf-classification-dnn</td>\n",
       "      <td>run-20220827023100</td>\n",
       "      <td>05_fraud</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999394</td>\n",
       "      <td>35.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>experiment-05-05-tf-classification-dnn</td>\n",
       "      <td>run-20220926162349</td>\n",
       "      <td>05_05</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999533</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>experiment-05-05-tf-classification-dnn</td>\n",
       "      <td>run-20220927110007</td>\n",
       "      <td>05_05</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999445</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>experiment-05-05-tf-classification-dnn</td>\n",
       "      <td>run-20220927184222</td>\n",
       "      <td>05_05</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999397</td>\n",
       "      <td>34.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>experiment-05-05a-tf-classification-dnn</td>\n",
       "      <td>run-20220826104731</td>\n",
       "      <td>05a_fraud</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999627</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>experiment-05-05a-tf-classification-dnn</td>\n",
       "      <td>run-20220827023541</td>\n",
       "      <td>05a_fraud</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999581</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>experiment-05-05a-tf-classification-dnn</td>\n",
       "      <td>run-20220926133308</td>\n",
       "      <td>05_05a</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999625</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>experiment-05-05a-tf-classification-dnn</td>\n",
       "      <td>run-20220927105742</td>\n",
       "      <td>05_05a</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999673</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>experiment-05-05b-tf-classification-dnn</td>\n",
       "      <td>run-20220826114523</td>\n",
       "      <td>05b_fraud</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999582</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>experiment-05-05b-tf-classification-dnn</td>\n",
       "      <td>run-20220827023620</td>\n",
       "      <td>05b_fraud</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999628</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>experiment-05-05b-tf-classification-dnn</td>\n",
       "      <td>run-20220926182813</td>\n",
       "      <td>05_05b</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999536</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>experiment-05-05b-tf-classification-dnn</td>\n",
       "      <td>run-20220927105812</td>\n",
       "      <td>05_05b</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999626</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>experiment-05-05c-tf-classification-dnn</td>\n",
       "      <td>run-20220826163231</td>\n",
       "      <td>05c_fraud</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999674</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>experiment-05-05c-tf-classification-dnn</td>\n",
       "      <td>run-20220827023625</td>\n",
       "      <td>05c_fraud</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999673</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>experiment-05-05c-tf-classification-dnn</td>\n",
       "      <td>run-20220927094428</td>\n",
       "      <td>05_05c</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999629</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>experiment-05-05d-tf-classification-dnn</td>\n",
       "      <td>run-20220826170803</td>\n",
       "      <td>05d_fraud</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999579</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>experiment-05-05d-tf-classification-dnn</td>\n",
       "      <td>run-20220827025723</td>\n",
       "      <td>05d_fraud</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999672</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>experiment-05-05d-tf-classification-dnn</td>\n",
       "      <td>run-20220927154304</td>\n",
       "      <td>05_05d</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999716</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>experiment-05-05e-tf-classification-dnn</td>\n",
       "      <td>run-20220826174636</td>\n",
       "      <td>05e_fraud</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999581</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>experiment-05-05e-tf-classification-dnn</td>\n",
       "      <td>run-20220827025727</td>\n",
       "      <td>05e_fraud</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999628</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>experiment-05-05e-tf-classification-dnn</td>\n",
       "      <td>run-20220927181116</td>\n",
       "      <td>05_05e</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999625</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>experiment-05-05f-tf-classification-dnn</td>\n",
       "      <td>run-20220826182653</td>\n",
       "      <td>05f_fraud</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999672</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>experiment-05-05f-tf-classification-dnn</td>\n",
       "      <td>run-20220827025732</td>\n",
       "      <td>05f_fraud</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999626</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>experiment-05-05f-tf-classification-dnn</td>\n",
       "      <td>run-20220927190441</td>\n",
       "      <td>05_05f</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999537</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>experiment-05-05g-tf-classification-dnn</td>\n",
       "      <td>run-20220826184958-7</td>\n",
       "      <td>05g_fraud</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999671</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>experiment-05-05g-tf-classification-dnn</td>\n",
       "      <td>run-20220827031931-6</td>\n",
       "      <td>05g_fraud</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999720</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>experiment-05-05g-tf-classification-dnn</td>\n",
       "      <td>run-20220927230209-10</td>\n",
       "      <td>05_05g</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999720</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220826194057-3</td>\n",
       "      <td>05h_fraud</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999721</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220827031936-13</td>\n",
       "      <td>05h_fraud</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999628</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220927230247-6</td>\n",
       "      <td>05_05h</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999765</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>experiment-05-05i-tf-classification-dnn</td>\n",
       "      <td>run-20220826194138-7</td>\n",
       "      <td>05i_fraud</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>experiment-05-05i-tf-classification-dnn</td>\n",
       "      <td>run-20220827031941-5</td>\n",
       "      <td>05i_fraud</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>experiment-05-05i-tf-classification-dnn</td>\n",
       "      <td>run-20220927230444-13</td>\n",
       "      <td>05_05i</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999764</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             experiment_name               run_name  \\\n",
       "172   experiment-05-05-tf-classification-dnn     run-20220825143943   \n",
       "171   experiment-05-05-tf-classification-dnn     run-20220825161109   \n",
       "170   experiment-05-05-tf-classification-dnn     run-20220825175329   \n",
       "169   experiment-05-05-tf-classification-dnn     run-20220827023100   \n",
       "168   experiment-05-05-tf-classification-dnn     run-20220926162349   \n",
       "167   experiment-05-05-tf-classification-dnn     run-20220927110007   \n",
       "166   experiment-05-05-tf-classification-dnn     run-20220927184222   \n",
       "165  experiment-05-05a-tf-classification-dnn     run-20220826104731   \n",
       "164  experiment-05-05a-tf-classification-dnn     run-20220827023541   \n",
       "161  experiment-05-05a-tf-classification-dnn     run-20220926133308   \n",
       "160  experiment-05-05a-tf-classification-dnn     run-20220927105742   \n",
       "159  experiment-05-05b-tf-classification-dnn     run-20220826114523   \n",
       "158  experiment-05-05b-tf-classification-dnn     run-20220827023620   \n",
       "157  experiment-05-05b-tf-classification-dnn     run-20220926182813   \n",
       "156  experiment-05-05b-tf-classification-dnn     run-20220927105812   \n",
       "155  experiment-05-05c-tf-classification-dnn     run-20220826163231   \n",
       "154  experiment-05-05c-tf-classification-dnn     run-20220827023625   \n",
       "153  experiment-05-05c-tf-classification-dnn     run-20220927094428   \n",
       "152  experiment-05-05d-tf-classification-dnn     run-20220826170803   \n",
       "151  experiment-05-05d-tf-classification-dnn     run-20220827025723   \n",
       "150  experiment-05-05d-tf-classification-dnn     run-20220927154304   \n",
       "149  experiment-05-05e-tf-classification-dnn     run-20220826174636   \n",
       "148  experiment-05-05e-tf-classification-dnn     run-20220827025727   \n",
       "147  experiment-05-05e-tf-classification-dnn     run-20220927181116   \n",
       "146  experiment-05-05f-tf-classification-dnn     run-20220826182653   \n",
       "145  experiment-05-05f-tf-classification-dnn     run-20220827025732   \n",
       "144  experiment-05-05f-tf-classification-dnn     run-20220927190441   \n",
       "143  experiment-05-05g-tf-classification-dnn   run-20220826184958-7   \n",
       "133  experiment-05-05g-tf-classification-dnn   run-20220827031931-6   \n",
       "123  experiment-05-05g-tf-classification-dnn  run-20220927230209-10   \n",
       "113  experiment-05-05h-tf-classification-dnn   run-20220826194057-3   \n",
       "93   experiment-05-05h-tf-classification-dnn  run-20220827031936-13   \n",
       "73   experiment-05-05h-tf-classification-dnn   run-20220927230247-6   \n",
       "53   experiment-05-05i-tf-classification-dnn   run-20220826194138-7   \n",
       "35   experiment-05-05i-tf-classification-dnn   run-20220827031941-5   \n",
       "17   experiment-05-05i-tf-classification-dnn  run-20220927230444-13   \n",
       "\n",
       "    param.model.display_name param.model.version_id  metric.test_auprc  \\\n",
       "172                 05_fraud                      1           0.999398   \n",
       "171                 05_fraud                      2           0.999397   \n",
       "170                 05_fraud                      3           0.999344   \n",
       "169                 05_fraud                      4           0.999394   \n",
       "168                    05_05                      1           0.999533   \n",
       "167                    05_05                      2           0.999445   \n",
       "166                    05_05                      3           0.999397   \n",
       "165                05a_fraud                      1           0.999627   \n",
       "164                05a_fraud                      2           0.999581   \n",
       "161                   05_05a                      1           0.999625   \n",
       "160                   05_05a                      2           0.999673   \n",
       "159                05b_fraud                      1           0.999582   \n",
       "158                05b_fraud                      2           0.999628   \n",
       "157                   05_05b                      1           0.999536   \n",
       "156                   05_05b                      2           0.999626   \n",
       "155                05c_fraud                      1           0.999674   \n",
       "154                05c_fraud                      2           0.999673   \n",
       "153                   05_05c                      1           0.999629   \n",
       "152                05d_fraud                      1           0.999579   \n",
       "151                05d_fraud                      2           0.999672   \n",
       "150                   05_05d                      1           0.999716   \n",
       "149                05e_fraud                      1           0.999581   \n",
       "148                05e_fraud                      2           0.999628   \n",
       "147                   05_05e                      1           0.999625   \n",
       "146                05f_fraud                      1           0.999672   \n",
       "145                05f_fraud                      2           0.999626   \n",
       "144                   05_05f                      1           0.999537   \n",
       "143                05g_fraud                      1           0.999671   \n",
       "133                05g_fraud                      2           0.999720   \n",
       "123                   05_05g                      1           0.999720   \n",
       "113                05h_fraud                      1           0.999721   \n",
       "93                 05h_fraud                      2           0.999628   \n",
       "73                    05_05h                      1           0.999765   \n",
       "53                 05i_fraud                      1           0.999812   \n",
       "35                 05i_fraud                      2           0.999812   \n",
       "17                    05_05i                      1           0.999764   \n",
       "\n",
       "     series_rank  experiment_rank  \n",
       "172         32.0              3.0  \n",
       "171         33.0              4.0  \n",
       "170         36.0              7.0  \n",
       "169         35.0              6.0  \n",
       "168         30.0              1.0  \n",
       "167         31.0              2.0  \n",
       "166         34.0              5.0  \n",
       "165         19.0              2.0  \n",
       "164         26.0              4.0  \n",
       "161         23.0              3.0  \n",
       "160         10.0              1.0  \n",
       "159         24.0              3.0  \n",
       "158         17.0              1.0  \n",
       "157         29.0              4.0  \n",
       "156         20.0              2.0  \n",
       "155          9.0              1.0  \n",
       "154         11.0              2.0  \n",
       "153         15.0              3.0  \n",
       "152         27.0              3.0  \n",
       "151         12.0              2.0  \n",
       "150          8.0              1.0  \n",
       "149         25.0              3.0  \n",
       "148         18.0              1.0  \n",
       "147         22.0              2.0  \n",
       "146         13.0              1.0  \n",
       "145         21.0              2.0  \n",
       "144         28.0              3.0  \n",
       "143         14.0              3.0  \n",
       "133          6.0              1.0  \n",
       "123          7.0              2.0  \n",
       "113          5.0              2.0  \n",
       "93          16.0              3.0  \n",
       "73           3.0              1.0  \n",
       "53           2.0              2.0  \n",
       "35           1.0              1.0  \n",
       "17           4.0              3.0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ranker(metric = 'metric.test_auprc'):\n",
    "    ranks = results[['experiment_name', 'run_name', 'param.model.display_name', 'param.model.version_id', metric]].copy().reset_index(drop = True)\n",
    "    ranks = ranks[~ranks['param.model.display_name'].isnull()]\n",
    "    ranks['series_rank'] = ranks[metric].rank(method = 'dense', ascending = False)\n",
    "    ranks['experiment_rank'] = ranks.groupby('experiment_name')[metric].rank(method = 'dense', ascending = False)\n",
    "    return ranks.sort_values(by = ['experiment_name', 'run_name'])\n",
    "    \n",
    "ranks = ranker('metric.test_auprc')\n",
    "ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dae6903c-1986-47f8-b1e7-f05777ca6fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>run_name</th>\n",
       "      <th>param.model.display_name</th>\n",
       "      <th>param.model.version_id</th>\n",
       "      <th>metric.test_auprc</th>\n",
       "      <th>series_rank</th>\n",
       "      <th>experiment_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>experiment-05-05h-tf-classification-dnn</td>\n",
       "      <td>run-20220927230247-6</td>\n",
       "      <td>05_05h</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999765</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            experiment_name              run_name  \\\n",
       "73  experiment-05-05h-tf-classification-dnn  run-20220927230247-6   \n",
       "\n",
       "   param.model.display_name param.model.version_id  metric.test_auprc  \\\n",
       "73                   05_05h                      1           0.999765   \n",
       "\n",
       "    series_rank  experiment_rank  \n",
       "73          3.0              1.0  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_rank = ranks.loc[(ranks['param.model.display_name'] == model.display_name) & (ranks['param.model.version_id'] == model.version_id)]\n",
    "current_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1e45ccb7-8f93-4c12-9b7d-666fd8fa238c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current model is ranked 1.0 within this experiment and 3.0 across this series.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The current model is ranked {current_rank['experiment_rank'].iloc[0]} within this experiment and {current_rank['series_rank'].iloc[0]} across this series.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fdc4e2-de10-48a8-9c76-0ce544f7f761",
   "metadata": {},
   "source": [
    "### Create/Retrieve The Endpoint For This Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2cc28d98-b525-4385-9b95-489bf574f967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Exists: projects/1026793852137/locations/us-central1/endpoints/1961322035766362112\n",
      "Review the Endpoint in the Console:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/endpoints/1961322035766362112?project=statmike-mlops-349915\n"
     ]
    }
   ],
   "source": [
    "endpoints = aiplatform.Endpoint.list(filter = f\"labels.series={SERIES}\")\n",
    "if endpoints:\n",
    "    endpoint = endpoints[0]\n",
    "    print(f\"Endpoint Exists: {endpoints[0].resource_name}\")\n",
    "else:\n",
    "    endpoint = aiplatform.Endpoint.create(\n",
    "        display_name = f\"{SERIES}\",\n",
    "        labels = {'series' : f\"{SERIES}\"}    \n",
    "    )\n",
    "    print(f\"Endpoint Created: {endpoint.resource_name}\")\n",
    "    \n",
    "print(f'Review the Endpoint in the Console:\\nhttps://console.cloud.google.com/vertex-ai/locations/{REGION}/endpoints/{endpoint.name}?project={PROJECT_ID}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0a538bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'05'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint.display_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0a0029bd-9744-4449-91f0-56ef7ca5e535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'397112813627113472': 100}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint.traffic_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "85d06eba-82dc-4d50-8405-800d756e3584",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployed_models = endpoint.list_models()\n",
    "#deployed_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f00c0a-7b78-4469-b205-65a936fab64f",
   "metadata": {},
   "source": [
    "### Should This Model Be Deployed?\n",
    "Is it better than the model already deployed on the endpoint?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5db9b246-2b03-4313-b620-5fc8029280b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current model is ranked better (3.0) than a currently deployed model (7.0).\n"
     ]
    }
   ],
   "source": [
    "deploy = False\n",
    "if deployed_models:\n",
    "    for deployed_model in deployed_models:\n",
    "        deployed_rank = ranks.loc[(ranks['param.model.display_name'] == deployed_model.display_name) & (ranks['param.model.version_id'] == deployed_model.model_version_id)]['series_rank'].iloc[0]\n",
    "        model_rank = current_rank['series_rank'].iloc[0]\n",
    "        if deployed_model.display_name == model.display_name and deployed_model.model_version_id == model.version_id:\n",
    "            print(f'The current model/version is already deployed.')\n",
    "            break\n",
    "        elif model_rank <= deployed_rank:\n",
    "            deploy = True\n",
    "            print(f'The current model is ranked better ({model_rank}) than a currently deployed model ({deployed_rank}).')\n",
    "            break\n",
    "    if deploy == False: print(f'The current model is ranked worse ({model_rank}) than a currently deployed model ({deployed_rank})')\n",
    "else: \n",
    "    deploy = True\n",
    "    print('No models currently deployed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afafd7c-3abd-4caf-bffa-322282519bdc",
   "metadata": {},
   "source": [
    "### Deploy Model To Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2aa50205-0f93-423e-a622-4659f81e8674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying model with 100% of traffic...\n",
      "Deploying Model projects/1026793852137/locations/us-central1/models/8565947646328438784 to Endpoint : projects/1026793852137/locations/us-central1/endpoints/1961322035766362112\n",
      "Deploy Endpoint model backing LRO: projects/1026793852137/locations/us-central1/endpoints/1961322035766362112/operations/6095263998452695040\n",
      "Endpoint model deployed. Resource name: projects/1026793852137/locations/us-central1/endpoints/1961322035766362112\n"
     ]
    }
   ],
   "source": [
    "if deploy:\n",
    "    print(f'Deploying model with 100% of traffic...')\n",
    "    endpoint.deploy(\n",
    "        model = model,\n",
    "        deployed_model_display_name = model.display_name,\n",
    "        traffic_percentage = 100,\n",
    "        machine_type = DEPLOY_COMPUTE,\n",
    "        min_replica_count = 1,\n",
    "        max_replica_count = 1\n",
    "    )\n",
    "else: print(f'Not deploying - current model is worse ({model_rank}) than the currently deployed model ({deployed_rank})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2e60be-6174-46cf-a34f-c95a2ca47b2a",
   "metadata": {},
   "source": [
    "### Remove Deployed Models without Traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6945f51a-0c06-4760-bbfe-f2b9d1e7d38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undeploying Endpoint model: projects/1026793852137/locations/us-central1/endpoints/1961322035766362112\n",
      "Undeploy Endpoint model backing LRO: projects/1026793852137/locations/us-central1/endpoints/1961322035766362112/operations/519807659768020992\n",
      "Endpoint model undeployed. Resource name: projects/1026793852137/locations/us-central1/endpoints/1961322035766362112\n",
      "Undeploying 05_05g with version 1 because it has no traffic.\n",
      "Model 05_05h with version 1 has traffic = 100\n"
     ]
    }
   ],
   "source": [
    "for deployed_model in endpoint.list_models():\n",
    "    if deployed_model.id in endpoint.traffic_split:\n",
    "        print(f\"Model {deployed_model.display_name} with version {deployed_model.model_version_id} has traffic = {endpoint.traffic_split[deployed_model.id]}\")\n",
    "    else:\n",
    "        endpoint.undeploy(deployed_model_id = deployed_model.id)\n",
    "        print(f\"Undeploying {deployed_model.display_name} with version {deployed_model.model_version_id} because it has no traffic.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d90c6900-de81-4fcd-af0b-ba6b3925724d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2853826410357719040': 100}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint.traffic_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "14cbf4a3-9e32-4158-a9ee-0cfca92e8574",
   "metadata": {},
   "outputs": [],
   "source": [
    "#endpoint.list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a63e92-bae2-40ab-999f-07351e4bc739",
   "metadata": {},
   "source": [
    "---\n",
    "## Prediction\n",
    "\n",
    "See many more details on requesting predictions in the [05Tools - Prediction](./05Tools%20-%20Prediction.ipynb) notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd68eb51-e773-4936-9465-19fcbf081ba1",
   "metadata": {},
   "source": [
    "### Prepare a record for prediction: instance and parameters lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c2588145",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = bq.query(query = f\"SELECT * FROM {BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE} WHERE splits='TEST' LIMIT 10\").to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8dff5477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>splits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35337</td>\n",
       "      <td>1.092844</td>\n",
       "      <td>-0.013230</td>\n",
       "      <td>1.359829</td>\n",
       "      <td>2.731537</td>\n",
       "      <td>-0.707357</td>\n",
       "      <td>0.873837</td>\n",
       "      <td>-0.796130</td>\n",
       "      <td>0.437707</td>\n",
       "      <td>0.396770</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.167647</td>\n",
       "      <td>0.027557</td>\n",
       "      <td>0.592115</td>\n",
       "      <td>0.219695</td>\n",
       "      <td>0.036970</td>\n",
       "      <td>0.010984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>a1b10547-d270-48c0-b902-7a0f735dadc7</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60481</td>\n",
       "      <td>1.238973</td>\n",
       "      <td>0.035226</td>\n",
       "      <td>0.063003</td>\n",
       "      <td>0.641406</td>\n",
       "      <td>-0.260893</td>\n",
       "      <td>-0.580097</td>\n",
       "      <td>0.049938</td>\n",
       "      <td>-0.034733</td>\n",
       "      <td>0.405932</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057718</td>\n",
       "      <td>0.104983</td>\n",
       "      <td>0.537987</td>\n",
       "      <td>0.589563</td>\n",
       "      <td>-0.046207</td>\n",
       "      <td>-0.006212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>814c62c8-ade4-47d5-bf83-313b0aafdee5</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>139587</td>\n",
       "      <td>1.870539</td>\n",
       "      <td>0.211079</td>\n",
       "      <td>0.224457</td>\n",
       "      <td>3.889486</td>\n",
       "      <td>-0.380177</td>\n",
       "      <td>0.249799</td>\n",
       "      <td>-0.577133</td>\n",
       "      <td>0.179189</td>\n",
       "      <td>-0.120462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180776</td>\n",
       "      <td>-0.060226</td>\n",
       "      <td>-0.228979</td>\n",
       "      <td>0.080827</td>\n",
       "      <td>0.009868</td>\n",
       "      <td>-0.036997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>d08a1bfa-85c5-4f1b-9537-1c5a93e6afd0</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>162908</td>\n",
       "      <td>-3.368339</td>\n",
       "      <td>-1.980442</td>\n",
       "      <td>0.153645</td>\n",
       "      <td>-0.159795</td>\n",
       "      <td>3.847169</td>\n",
       "      <td>-3.516873</td>\n",
       "      <td>-1.209398</td>\n",
       "      <td>-0.292122</td>\n",
       "      <td>0.760543</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.171627</td>\n",
       "      <td>0.214333</td>\n",
       "      <td>-0.159652</td>\n",
       "      <td>-0.060883</td>\n",
       "      <td>1.294977</td>\n",
       "      <td>0.120503</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>802f3307-8e5a-4475-b795-5d5d8d7d0120</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows  33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0   35337  1.092844 -0.013230  1.359829  2.731537 -0.707357  0.873837   \n",
       "1   60481  1.238973  0.035226  0.063003  0.641406 -0.260893 -0.580097   \n",
       "2  139587  1.870539  0.211079  0.224457  3.889486 -0.380177  0.249799   \n",
       "3  162908 -3.368339 -1.980442  0.153645 -0.159795  3.847169 -3.516873   \n",
       "\n",
       "         V7        V8        V9  ...       V23       V24       V25       V26  \\\n",
       "0 -0.796130  0.437707  0.396770  ... -0.167647  0.027557  0.592115  0.219695   \n",
       "1  0.049938 -0.034733  0.405932  ... -0.057718  0.104983  0.537987  0.589563   \n",
       "2 -0.577133  0.179189 -0.120462  ...  0.180776 -0.060226 -0.228979  0.080827   \n",
       "3 -1.209398 -0.292122  0.760543  ... -1.171627  0.214333 -0.159652 -0.060883   \n",
       "\n",
       "        V27       V28  Amount  Class                        transaction_id  \\\n",
       "0  0.036970  0.010984     0.0      0  a1b10547-d270-48c0-b902-7a0f735dadc7   \n",
       "1 -0.046207 -0.006212     0.0      0  814c62c8-ade4-47d5-bf83-313b0aafdee5   \n",
       "2  0.009868 -0.036997     0.0      0  d08a1bfa-85c5-4f1b-9537-1c5a93e6afd0   \n",
       "3  1.294977  0.120503     0.0      0  802f3307-8e5a-4475-b795-5d5d8d7d0120   \n",
       "\n",
       "   splits  \n",
       "0    TEST  \n",
       "1    TEST  \n",
       "2    TEST  \n",
       "3    TEST  \n",
       "\n",
       "[4 rows x 33 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "13bacbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "newob = pred[pred.columns[~pred.columns.isin(VAR_OMIT.split()+[VAR_TARGET, 'splits'])]].to_dict(orient='records')[0]\n",
    "#newob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9d8b6579",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instances = [json_format.ParseDict(newob, Value())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1adb8f-c055-4e55-a9ae-dcb1febcb647",
   "metadata": {},
   "source": [
    "### Get Predictions: Python Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e452b19e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(predictions=[[0.999359429, 0.000640570885]], deployed_model_id='2853826410357719040', model_version_id='1', model_resource_name='projects/1026793852137/locations/us-central1/models/model_05_05h', explanations=None)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = endpoint.predict(instances=instances)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7dc3e2af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.999359429, 0.000640570885]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8f6fbf8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(prediction.predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ef4c60",
   "metadata": {},
   "source": [
    "### Get Predictions: REST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "396dde09",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{DIR}/request.json','w') as file:\n",
    "    file.write(json.dumps({\"instances\": [newob]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "25685907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"predictions\": [\n",
      "    [\n",
      "      0.999359429,\n",
      "      0.000640570885\n",
      "    ]\n",
      "  ],\n",
      "  \"deployedModelId\": \"2853826410357719040\",\n",
      "  \"model\": \"projects/1026793852137/locations/us-central1/models/model_05_05h\",\n",
      "  \"modelDisplayName\": \"05_05h\",\n",
      "  \"modelVersionId\": \"1\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!curl -X POST \\\n",
    "-H \"Authorization: Bearer \"$(gcloud auth application-default print-access-token) \\\n",
    "-H \"Content-Type: application/json; charset=utf-8\" \\\n",
    "-d @{DIR}/request.json \\\n",
    "https://{REGION}-aiplatform.googleapis.com/v1/{endpoint.resource_name}:predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf26f85",
   "metadata": {},
   "source": [
    "### Get Predictions: gcloud (CLI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3ad30d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-prediction-aiplatform.googleapis.com/]\n",
      "[[0.999359429, 0.000640570885]]\n"
     ]
    }
   ],
   "source": [
    "!gcloud beta ai endpoints predict {endpoint.name.rsplit('/',1)[-1]} --region={REGION} --json-request={DIR}/request.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b803a30",
   "metadata": {},
   "source": [
    "---\n",
    "## Remove Resources\n",
    "see notebook \"99 - Cleanup\""
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-3.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m94"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
