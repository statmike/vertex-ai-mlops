{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3338167d-26e6-4c56-9aaa-b7657935fd8b",
   "metadata": {},
   "source": [
    "![ga4](https://www.google-analytics.com/collect?v=2&tid=G-6VDTYWLKX6&cid=1&en=page_view&sid=1&dl=statmike%2Fvertex-ai-mlops%2F05+-+TensorFlow&dt=05Tools+-+Prediction+-+NVIDIA+Triton.ipynb)\n",
    "\n",
    "# 05Tools - Prediction - NVIDIA Triton\n",
    "\n",
    "Throughout the `05` Series of notebooks (05, 05a, ..., 05i) each run of the notebooks results in a new model version for the model created by the notebook.  What if you wanted to host all models and version created by this series on a single endpoint to compare predictions throughout the model training lifecycle?  This workflow uses the feature of NVIDIA Triton Inference Server to accomplish this.\n",
    "\n",
    "This workflow uses a Vertex AI Endpoint with NVIDIA Triton Inference Server to serve predictions - [details](https://cloud.google.com/vertex-ai/docs/predictions/using-nvidia-triton).  This is an open-source inference serving solution from NVIDIA that has many benefits:\n",
    "- Many frameworks: TensorFlow, PyTorch, TensorRT, ONNX, OpenVINO, FIL (XGBoost, LightGBM, Scikit-Learn).\n",
    "- Concurrent Models: multiple models, multiple version of same model\n",
    "- CPU and/or GPU\n",
    "- Ensembles that chain multiple models together, including Python backend for pre and post processing\n",
    "- Dynamic batching to combine incoming requests into batches\n",
    "- Optimization setting for batching rules, rate limiting, prioritization and even response caching\n",
    "\n",
    "\n",
    "Workflow:\n",
    "- Create Triton Server Model Repository: \n",
    "    - Source of Models in Vertex AI Model Registry\n",
    "    - Destination is Vertex AI Model Registry Entry for NVIDIA Triton Inference Server Model Repository\n",
    "- Vertex AI Endpoint: create endpoint and deploy NVIDIA Triton Inference Server Model Repository From Vertex AI Model Registry\n",
    "- Predictions\n",
    "    - From default model and version\n",
    "    - From specific models latest version\n",
    "    - From all models latest version\n",
    "    - From all models and all versions\n",
    "    \n",
    "Resources:\n",
    "- Vertex AI Model Registry\n",
    "- GCS\n",
    "- Vetex AI Endpoints\n",
    "- Artifact Registry\n",
    "\n",
    "Prerequisites:\n",
    "- Multiple of [05, 05a-05i] will create multiple models in the SERIES\n",
    "    - including multiple runs will also create multiple versions of the models\n",
    "\n",
    "References:\n",
    "- [Vertex AI Prediction Endpoints With NVIDIA Triton](https://cloud.google.com/vertex-ai/docs/predictions/using-nvidia-triton)\n",
    "- [NVIDIA Triton Server Ensemble Models (with DALI for preprocessing images)](https://developer.nvidia.com/blog/accelerating-inference-with-triton-inference-server-and-dali/)\n",
    "- [Triton Tutorials](https://github.com/triton-inference-server/tutorials/blob/main/README.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bcaac8-7d1a-4577-96df-cb6cc5b401ae",
   "metadata": {},
   "source": [
    "---\n",
    "## Installs and API Enablement\n",
    "\n",
    "The clients packages may need installing in this environment.  Also, the API for Artifact Registry needs to be enabled (if not already enabled)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88186f6-e672-4d0b-b232-219193a8e312",
   "metadata": {},
   "source": [
    "### Installs (If Needed)\n",
    "The list `packages` contains tuples of package import names and install names.  If the import name is not found then the install name is used to install quitely for the current user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dc16a5f-b922-48f4-8738-e5a20dfbafac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuples of (import name, install name)\n",
    "packages = [\n",
    "    ('google.cloud.artifactregistry_v1', 'google-cloud-artifact-registry')\n",
    "]\n",
    "\n",
    "import importlib\n",
    "install = False\n",
    "for package in packages:\n",
    "    if not importlib.util.find_spec(package[0]):\n",
    "        print(f'installing package {package[1]}')\n",
    "        install = True\n",
    "        !pip install {package[1]} -U -q --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46609c95-8816-4ca6-8be8-b7f27fff403a",
   "metadata": {},
   "source": [
    "### Restart Kernel (If Installs Occured)\n",
    "\n",
    "After a kernel restart the code submission can start with the next cell after this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "334837d7-f67b-45ad-822b-ddd0f542350e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if install:\n",
    "    import IPython\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5209d2b5-03f1-4fbe-8a50-6b8631237783",
   "metadata": {},
   "source": [
    "### API Enablement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76a52cc6-0746-4d2b-9226-cf5be17cb251",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud services enable artifactregistry.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43abb516-d82b-48e7-bee3-f477c136bc13",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba42dbc4-9a65-4025-b9bb-6c36481c118a",
   "metadata": {},
   "source": [
    "inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d87d88d0-67bd-47aa-93e3-1e282c1cc021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'statmike-mlops-349915'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "704d0ea3-f588-41e9-a58f-49ed56c5fe2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "EXPERIMENT = 'triton'\n",
    "SERIES = '05'\n",
    "\n",
    "# source data\n",
    "BQ_PROJECT = PROJECT_ID\n",
    "BQ_DATASET = 'fraud'\n",
    "BQ_TABLE = 'fraud_prepped'\n",
    "\n",
    "# Resources\n",
    "DEPLOY_COMPUTE = 'n1-standard-4'\n",
    "\n",
    "# Model Training\n",
    "VAR_TARGET = 'Class'\n",
    "VAR_OMIT = 'transaction_id' # add more variables to the string with space delimiters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e80c26-f8e4-45cd-9de3-4dfbe6dc5de6",
   "metadata": {},
   "source": [
    "packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8954c99e-1e41-4699-b551-ee27c896c4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import artifactregistry_v1\n",
    "from google.cloud import storage\n",
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "import multiprocessing\n",
    "from google.api import httpbody_pb2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266960d7-e925-4fad-a4d1-fba7e3da4260",
   "metadata": {},
   "source": [
    "clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c07af4f-5b60-4bf1-adc5-44af7b87fe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project = PROJECT_ID, location = REGION)\n",
    "bq = bigquery.Client(project = PROJECT_ID)\n",
    "gcs = storage.Client(project = PROJECT_ID)\n",
    "ar_client = artifactregistry_v1.ArtifactRegistryClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c110fbe-299b-4018-b9bc-fa5d5e55c2bb",
   "metadata": {},
   "source": [
    "parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2586197-6e5e-49f2-bb72-24e7bcae6c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = PROJECT_ID\n",
    "DIR = f\"temp/{EXPERIMENT}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33b66c7-5e5d-455f-b1e1-0b69d262eb4a",
   "metadata": {},
   "source": [
    "environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "905ee649-162c-410a-aef5-c2024cf36bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf {DIR}\n",
    "!mkdir -p {DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6b3f78-dbdd-4fe4-b6f9-257a82c5da92",
   "metadata": {},
   "source": [
    "---\n",
    "## Retrieve Records For Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7ef60a7-4962-4236-a245-ad4f33028ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "samples = bq.query(\n",
    "    query = f\"\"\"\n",
    "        SELECT * EXCEPT({VAR_TARGET}, {VAR_OMIT}, splits)\n",
    "        FROM {BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}\n",
    "        WHERE splits='TEST'\n",
    "        AND {VAR_TARGET} = 1\n",
    "        LIMIT {n}\"\"\"\n",
    ").to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a3096e7-a2a2-40c1-b7f3-b3e8d068acdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85285</td>\n",
       "      <td>-7.030308</td>\n",
       "      <td>3.421991</td>\n",
       "      <td>-9.525072</td>\n",
       "      <td>5.270891</td>\n",
       "      <td>-4.024630</td>\n",
       "      <td>-2.865682</td>\n",
       "      <td>-6.989195</td>\n",
       "      <td>3.791551</td>\n",
       "      <td>-4.622730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.545698</td>\n",
       "      <td>1.103398</td>\n",
       "      <td>-0.541855</td>\n",
       "      <td>0.036943</td>\n",
       "      <td>-0.355519</td>\n",
       "      <td>0.353634</td>\n",
       "      <td>1.042458</td>\n",
       "      <td>1.359516</td>\n",
       "      <td>-0.272188</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56887</td>\n",
       "      <td>-0.075483</td>\n",
       "      <td>1.812355</td>\n",
       "      <td>-2.566981</td>\n",
       "      <td>4.127549</td>\n",
       "      <td>-1.628532</td>\n",
       "      <td>-0.805895</td>\n",
       "      <td>-3.390135</td>\n",
       "      <td>1.019353</td>\n",
       "      <td>-2.451251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.338598</td>\n",
       "      <td>0.794372</td>\n",
       "      <td>0.270471</td>\n",
       "      <td>-0.143624</td>\n",
       "      <td>0.013566</td>\n",
       "      <td>0.634203</td>\n",
       "      <td>0.213693</td>\n",
       "      <td>0.773625</td>\n",
       "      <td>0.387434</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43369</td>\n",
       "      <td>-3.365319</td>\n",
       "      <td>2.426503</td>\n",
       "      <td>-3.752227</td>\n",
       "      <td>0.276017</td>\n",
       "      <td>-2.305870</td>\n",
       "      <td>-1.961578</td>\n",
       "      <td>-3.029283</td>\n",
       "      <td>-1.674462</td>\n",
       "      <td>0.183961</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036837</td>\n",
       "      <td>2.070008</td>\n",
       "      <td>-0.512626</td>\n",
       "      <td>-0.248502</td>\n",
       "      <td>0.126550</td>\n",
       "      <td>0.104166</td>\n",
       "      <td>-1.055997</td>\n",
       "      <td>-1.200165</td>\n",
       "      <td>-1.012066</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>143354</td>\n",
       "      <td>1.118331</td>\n",
       "      <td>2.074439</td>\n",
       "      <td>-3.837518</td>\n",
       "      <td>5.448060</td>\n",
       "      <td>0.071816</td>\n",
       "      <td>-1.020509</td>\n",
       "      <td>-1.808574</td>\n",
       "      <td>0.521744</td>\n",
       "      <td>-2.032638</td>\n",
       "      <td>...</td>\n",
       "      <td>0.163513</td>\n",
       "      <td>0.289861</td>\n",
       "      <td>-0.172718</td>\n",
       "      <td>-0.021910</td>\n",
       "      <td>-0.376560</td>\n",
       "      <td>0.192817</td>\n",
       "      <td>0.114107</td>\n",
       "      <td>0.500996</td>\n",
       "      <td>0.259533</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0   85285 -7.030308  3.421991 -9.525072  5.270891 -4.024630 -2.865682   \n",
       "1   56887 -0.075483  1.812355 -2.566981  4.127549 -1.628532 -0.805895   \n",
       "2   43369 -3.365319  2.426503 -3.752227  0.276017 -2.305870 -1.961578   \n",
       "3  143354  1.118331  2.074439 -3.837518  5.448060  0.071816 -1.020509   \n",
       "\n",
       "         V7        V8        V9  ...       V20       V21       V22       V23  \\\n",
       "0 -6.989195  3.791551 -4.622730  ...  0.545698  1.103398 -0.541855  0.036943   \n",
       "1 -3.390135  1.019353 -2.451251  ...  0.338598  0.794372  0.270471 -0.143624   \n",
       "2 -3.029283 -1.674462  0.183961  ... -0.036837  2.070008 -0.512626 -0.248502   \n",
       "3 -1.808574  0.521744 -2.032638  ...  0.163513  0.289861 -0.172718 -0.021910   \n",
       "\n",
       "        V24       V25       V26       V27       V28  Amount  \n",
       "0 -0.355519  0.353634  1.042458  1.359516 -0.272188     0.0  \n",
       "1  0.013566  0.634203  0.213693  0.773625  0.387434     5.0  \n",
       "2  0.126550  0.104166 -1.055997 -1.200165 -1.012066    88.0  \n",
       "3 -0.376560  0.192817  0.114107  0.500996  0.259533     1.0  \n",
       "\n",
       "[4 rows x 30 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0815aa-74ae-41ca-93be-79565fcf238d",
   "metadata": {},
   "source": [
    "Remove columns not included as features in the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4ef58a8-03ff-4592-b703-15c85d16c1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "newobs = samples.to_dict(orient='records')\n",
    "#newobs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "349640c3-53d5-490b-90f1-ae6056aa913f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "774ea125-6f92-4a6f-b7f1-9a729f1028ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Time': 85285,\n",
       " 'V1': -7.03030814445441,\n",
       " 'V2': 3.4219909046755297,\n",
       " 'V3': -9.52507177254752,\n",
       " 'V4': 5.27089100906596,\n",
       " 'V5': -4.02463027558805,\n",
       " 'V6': -2.86568161775739,\n",
       " 'V7': -6.989194734394459,\n",
       " 'V8': 3.7915509375591294,\n",
       " 'V9': -4.62273033596451,\n",
       " 'V10': -8.40966487562735,\n",
       " 'V11': 6.30904400603177,\n",
       " 'V12': -8.57676143258937,\n",
       " 'V13': 0.24674671692986203,\n",
       " 'V14': -11.534046018150802,\n",
       " 'V15': -0.36426513875870004,\n",
       " 'V16': -5.45249465771382,\n",
       " 'V17': -11.8875700201872,\n",
       " 'V18': -3.5635848100701097,\n",
       " 'V19': 0.8760187681566278,\n",
       " 'V20': 0.545698040621445,\n",
       " 'V21': 1.10339774484256,\n",
       " 'V22': -0.541854751589521,\n",
       " 'V23': 0.0369432219896495,\n",
       " 'V24': -0.355519004066217,\n",
       " 'V25': 0.35363438209700004,\n",
       " 'V26': 1.04245799282131,\n",
       " 'V27': 1.35951563156376,\n",
       " 'V28': -0.272188101257294,\n",
       " 'Amount': 0.0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newobs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ce0628-e979-42db-b27b-04a0d5a6951e",
   "metadata": {},
   "source": [
    "Re-format an instance for prediction with Triton Inference Server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3f7d15a-179b-4f31-ba7a-8bc930d11fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = dict(\n",
    "    inputs = [\n",
    "        dict(\n",
    "            name = key, \n",
    "            data = [newobs[0][key]], \n",
    "            datatype = 'FP32', \n",
    "            shape = [1,1]\n",
    "        ) for key in newobs[0]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a869ed08-c716-4d89-8db4-1a6168914fac",
   "metadata": {},
   "source": [
    "---\n",
    "## Copy Container For Serving\n",
    "Actually, with Vertex AI Prediction Endpoints, we mainly need to satisfy the requirement that the serving container be in Artifact Registry (or GCR).  The process below selects an NVIDIA Triton container, pulls it to the local environment, tags it with the desired name, the pushes it to artifact registry.  Note that no dockerfile was created or run to alter the container here.\n",
    "\n",
    "- Containers: https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tritonserver\n",
    "- Release Notes: https://docs.nvidia.com/deeplearning/triton-inference-server/release-notes/overview.html#overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b2562c8-441d-4249-9bdc-bb3d64093824",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('nvcr.io/nvidia/tritonserver:23.03-py3',\n",
       " 'us-central1-docker.pkg.dev/statmike-mlops-349915/statmike-mlops-349915/05_triton:23.03')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRITON_IMAGE = \"nvcr.io/nvidia/tritonserver:23.03-py3\"\n",
    "\n",
    "REPOSITORY = f\"{REGION}-docker.pkg.dev/{PROJECT_ID}/{PROJECT_ID}\"\n",
    "\n",
    "AR_IMAGE = f\"{REPOSITORY}/{SERIES}_{EXPERIMENT}:{TRITON_IMAGE.split(':')[-1].split('-')[0]}\"\n",
    "\n",
    "TRITON_IMAGE, AR_IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "6d26300f-1a27-438e-9aa6-9c5ff983f491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.03-py3: Pulling from nvidia/tritonserver\n",
      "Digest: sha256:10579fb31cb7388501649f610f9fc7cf3f78367c626f33d038a33deda3e0961a\n",
      "Status: Image is up to date for nvcr.io/nvidia/tritonserver:23.03-py3\n",
      "nvcr.io/nvidia/tritonserver:23.03-py3\n"
     ]
    }
   ],
   "source": [
    "!docker pull $TRITON_IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "1b51b55e-73e3-45c1-bdc7-7fe4e182ffe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker tag $TRITON_IMAGE $AR_IMAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfaa618-3086-40f1-8407-c4526f9e1d28",
   "metadata": {},
   "source": [
    "### Create Docker Image Repository\n",
    "\n",
    "Create an Artifact Registry Repository to hold Docker Images created by this notebook. First, check to see if it is already created by a previous run and retrieve it if it has. Otherwise, create!\n",
    "\n",
    "Name the repository the same name as the `PROJECT_ID`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51439a76-97c4-4210-94b5-5b2e75dc0d69",
   "metadata": {},
   "source": [
    "First, configure `gcloud` as the credential helper for Google Cloud Docker registries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "206ead9a-5ba4-46cd-9f43-88ba5311509d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mWARNING:\u001b[0m Your config file at [/home/jupyter/.docker/config.json] contains these credential helper entries:\n",
      "\n",
      "{\n",
      "  \"credHelpers\": {\n",
      "    \"gcr.io\": \"gcloud\",\n",
      "    \"us.gcr.io\": \"gcloud\",\n",
      "    \"eu.gcr.io\": \"gcloud\",\n",
      "    \"asia.gcr.io\": \"gcloud\",\n",
      "    \"staging-k8s.gcr.io\": \"gcloud\",\n",
      "    \"marketplace.gcr.io\": \"gcloud\",\n",
      "    \"us-central1-docker.pkg.dev\": \"gcloud\"\n",
      "  }\n",
      "}\n",
      "Adding credentials for: us-central1-docker.pkg.dev\n",
      "gcloud credential helpers already registered correctly.\n"
     ]
    }
   ],
   "source": [
    "!gcloud auth configure-docker $REGION-docker.pkg.dev --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "c03f4997-6cfb-45c5-8407-b317a09172b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved existing repo: projects/statmike-mlops-349915/locations/us-central1/repositories/statmike-mlops-349915\n"
     ]
    }
   ],
   "source": [
    "docker_repo = None\n",
    "for repo in ar_client.list_repositories(parent = f'projects/{PROJECT_ID}/locations/{REGION}'):\n",
    "    if f'{PROJECT_ID}' == repo.name.split('/')[-1]:\n",
    "        docker_repo = repo\n",
    "        print(f'Retrieved existing repo: {docker_repo.name}')\n",
    "\n",
    "if not docker_repo:\n",
    "    operation = ar_client.create_repository(\n",
    "        request = artifactregistry_v1.CreateRepositoryRequest(\n",
    "            parent = f'projects/{PROJECT_ID}/locations/{REGION}',\n",
    "            repository_id = f'{PROJECT_ID}',\n",
    "            repository = artifactregistry_v1.Repository(\n",
    "                description = f'A repository for the {SERIES} series that holds docker images.',\n",
    "                name = f'{PROJECT_ID}',\n",
    "                format_ = artifactregistry_v1.Repository.Format.DOCKER,\n",
    "                labels = {'series': SERIES}\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    print('Creating Repository ...')\n",
    "    docker_repo = operation.result()\n",
    "    print(f'Completed creating repo: {docker_repo.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "b0156334-1558-48c4-8f48-2264bc6f1b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('projects/statmike-mlops-349915/locations/us-central1/repositories/statmike-mlops-349915',\n",
       " 'DOCKER')"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docker_repo.name, docker_repo.format_.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "5161c0ff-231a-420d-bf7d-7e84af4b47e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'us-central1-docker.pkg.dev/statmike-mlops-349915/statmike-mlops-349915'"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REPOSITORY = f\"{REGION}-docker.pkg.dev/{PROJECT_ID}/{docker_repo.name.split('/')[-1]}\"\n",
    "REPOSITORY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744dcfe5-217e-4ed5-8093-c77a53d02244",
   "metadata": {},
   "source": [
    "### Push Image to Artifact Registry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "1283e6e1-e6f7-4733-b0b7-c67fd93483a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The push refers to repository [us-central1-docker.pkg.dev/statmike-mlops-349915/statmike-mlops-349915/05_triton]\n",
      "\n",
      "\u001b[1B8d03f49e: Preparing \n",
      "\u001b[1B1c796ff9: Preparing \n",
      "\u001b[1Bf74e4989: Preparing \n",
      "\u001b[1B1545fba7: Preparing \n",
      "\u001b[1Be14e5b31: Preparing \n",
      "\u001b[1B287202c9: Preparing \n",
      "\u001b[1B4ab46b10: Preparing \n",
      "\u001b[1B1a84df07: Preparing \n",
      "\u001b[1Badf23a62: Preparing \n",
      "\u001b[1B2b52dc10: Preparing \n",
      "\u001b[1Bbf18a086: Preparing \n",
      "\u001b[1B5fc56587: Preparing \n",
      "\u001b[1B474188a6: Preparing \n",
      "\u001b[1Bdb6c3896: Preparing \n",
      "\u001b[1Bb7fd341b: Preparing \n",
      "\u001b[1B232d1291: Preparing \n",
      "\u001b[1B3a4224a1: Preparing \n",
      "\u001b[1Bc02687ba: Preparing \n",
      "\u001b[1Be352f364: Preparing \n",
      "\u001b[1B7d3bab63: Preparing \n",
      "\u001b[1Baaf8cc7e: Preparing \n",
      "\u001b[1B6de4f64c: Preparing \n",
      "\u001b[1Bb45bef95: Preparing \n",
      "\u001b[1Bb8cad89e: Layer already exists \u001b[18A\u001b[2K\u001b[15A\u001b[2K\u001b[12A\u001b[2K\u001b[6A\u001b[2K\u001b[3A\u001b[2K23.03: digest: sha256:b784e0da2d9d1f894366d16be90784e95866e29767b1164e661034964470b5b6 size: 5365\n"
     ]
    }
   ],
   "source": [
    "!docker push $AR_IMAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b25e367-6c9b-41a4-9722-1f5a2f5f0253",
   "metadata": {},
   "source": [
    "---\n",
    "## Create A Triton Server Model Repository\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d5d44b-5b9b-44a6-88c7-161cb0fec735",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "### List Models\n",
    "This series, `05`, has a multiple workflows that create models that each predict the `Class` of transactions from a fraud dataset. This section will list all models in the series as well as all versions of each model.\n",
    "- [aiplatform.Model.list()](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.Model#google_cloud_aiplatform_Model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eff52f49-cccd-4dce-b6ba-51110ec68026",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = aiplatform.Model.list(filter = f'labels.series={SERIES}')\n",
    "# filter it further to just the notebooks in the series 05, 05a-05i\n",
    "models = [model for model in models if model.display_name.startswith('05_0')]\n",
    "models.sort(key = lambda x: x.display_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "baf9eebc-fff6-46b4-8cfe-7f4585e0625e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05_05\n",
      "05_05a\n",
      "05_05b\n",
      "05_05c\n",
      "05_05d\n",
      "05_05e\n",
      "05_05f\n",
      "05_05g\n",
      "05_05h\n",
      "05_05i\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(model.display_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cce00c1e-7bbd-4e15-a85b-2a59b5ba6b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.models.Model object at 0x7f9b90707160> \n",
       "resource name: projects/1026793852137/locations/us-central1/models/model_05_05"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bf490b-ebf8-4ada-a99b-02e278c400d1",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "### List Model Versions\n",
    "Each model in the series has 1 or more versions.  List each version.\n",
    "- [aiplatform.Model.versioning_registry](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.Model#google_cloud_aiplatform_Model_versioning_registry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f97e953-ebf7-4578-99f3-ad8ff0a59063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting versions for projects/1026793852137/locations/us-central1/models/model_05_05\n",
      "05_05 ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13']\n",
      "Getting versions for projects/1026793852137/locations/us-central1/models/model_05_05a\n",
      "05_05a ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16']\n",
      "Getting versions for projects/1026793852137/locations/us-central1/models/model_05_05b\n",
      "05_05b ['1', '2', '3', '4']\n",
      "Getting versions for projects/1026793852137/locations/us-central1/models/model_05_05c\n",
      "05_05c ['1', '2', '3']\n",
      "Getting versions for projects/1026793852137/locations/us-central1/models/model_05_05d\n",
      "05_05d ['1', '2', '3']\n",
      "Getting versions for projects/1026793852137/locations/us-central1/models/model_05_05e\n",
      "05_05e ['1', '2', '3']\n",
      "Getting versions for projects/1026793852137/locations/us-central1/models/model_05_05f\n",
      "05_05f ['1', '2', '3', '4', '5', '6', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53']\n",
      "Getting versions for projects/1026793852137/locations/us-central1/models/model_05_05g\n",
      "05_05g ['1', '2', '3']\n",
      "Getting versions for projects/1026793852137/locations/us-central1/models/model_05_05h\n",
      "05_05h ['1', '2', '3']\n",
      "Getting versions for projects/1026793852137/locations/us-central1/models/model_05_05i\n",
      "05_05i ['1', '2', '3', '4']\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    versions = [version.version_id for version in model.versioning_registry.list_versions()]\n",
    "    print(model.display_name, versions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "833ad525-0165-4a98-a55a-0681c5c18f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting versions for projects/1026793852137/locations/us-central1/models/model_05_05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VersionInfo(version_id='1', version_create_time=DatetimeWithNanoseconds(2022, 9, 26, 16, 36, 47, 373777, tzinfo=datetime.timezone.utc), version_update_time=DatetimeWithNanoseconds(2022, 9, 27, 12, 2, 12, 192630, tzinfo=datetime.timezone.utc), model_display_name='05_05', model_resource_name='projects/1026793852137/locations/us-central1/models/model_05_05', version_aliases=['run-20220926162349'], version_description='run-20220926162349')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[0].versioning_registry.list_versions()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e25d8e6-7dee-4620-a5ae-f2d6128d9bea",
   "metadata": {},
   "source": [
    "---\n",
    "### Links To Model Version Artifacts\n",
    "\n",
    "Each model version has a `uri` parameter that is a gcs bucket path for the models saved files.  Create a list of tuples with \n",
    "```\n",
    "[(model, [(version.version_id, model.uri), ...]), ...]\n",
    "```\n",
    "\n",
    "[aiplatform.Model.uri](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.Model#google_cloud_aiplatform_Model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8d06f9a-078c-46d4-becf-a5e3b888abf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting versions for projects/1026793852137/locations/us-central1/models/model_05_05\n",
      "Getting versions for projects/1026793852137/locations/us-central1/models/model_05_05a\n",
      "Getting versions for projects/1026793852137/locations/us-central1/models/model_05_05b\n",
      "Getting versions for projects/1026793852137/locations/us-central1/models/model_05_05c\n",
      "Getting versions for projects/1026793852137/locations/us-central1/models/model_05_05d\n",
      "Getting versions for projects/1026793852137/locations/us-central1/models/model_05_05e\n",
      "Getting versions for projects/1026793852137/locations/us-central1/models/model_05_05f\n",
      "Getting versions for projects/1026793852137/locations/us-central1/models/model_05_05g\n",
      "Getting versions for projects/1026793852137/locations/us-central1/models/model_05_05h\n",
      "Getting versions for projects/1026793852137/locations/us-central1/models/model_05_05i\n"
     ]
    }
   ],
   "source": [
    "models_artifacts = [\n",
    "    (\n",
    "        model,\n",
    "        [\n",
    "            (\n",
    "                version.version_id,\n",
    "                aiplatform.Model(model_name = f'{model.resource_name}@{version.version_id}').uri\n",
    "            ) for version in model.versioning_registry.list_versions()\n",
    "        ]\n",
    "    ) for model in models\n",
    "]    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55e4eab-c607-4495-8005-00966b3bc0e3",
   "metadata": {},
   "source": [
    "It's possible that artifacts for a model may have been removed.  To prevent trying to copy model versions to the Triton Server model repository that are empty do a check of the artifact URI and remove any that are missing/empty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31bb4c26-71de-4de1-9fbc-b5ae5fe8ae73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model model_05_05 version 1 is Missing Artifacts\n",
      "Model model_05_05a version 1 is Missing Artifacts\n",
      "Model model_05_05b version 1 is Missing Artifacts\n",
      "Removing Model@Versions With Missing Artifacts:\n",
      "Removing:  ('1', 'gs://statmike-mlops-349915/05/05b/20220926182813/model')\n",
      "Removing:  ('1', 'gs://statmike-mlops-349915/05/05a/20220926133308/model')\n",
      "Removing:  ('1', 'gs://statmike-mlops-349915/05/05/20220926162349/model')\n"
     ]
    }
   ],
   "source": [
    "bucket = gcs.lookup_bucket(BUCKET)\n",
    "\n",
    "# find versions with missing artifacts:\n",
    "missing = []\n",
    "for m, model in enumerate(models_artifacts):\n",
    "    for v, version in enumerate(model[1]):\n",
    "        blob_list = bucket.list_blobs(max_results = 1, prefix = version[1].split(f'gs://{BUCKET}/')[-1])\n",
    "        if sum(1 for _ in blob_list) == 0:\n",
    "            print(f'Model {model[0].name} version {version[0]} is Missing Artifacts')\n",
    "            missing.append((m,v))\n",
    "# remove versions with missing artifacts:\n",
    "if len(missing) > 0:\n",
    "    print('Removing Model@Versions With Missing Artifacts:')\n",
    "    for r in reversed(missing): # remove in reverse order because using indexes\n",
    "        print('Removing: ', models_artifacts[r[0]][1][r[1]])\n",
    "        models_artifacts[r[0]][1].pop(r[1])\n",
    "# find models with no remaining versions:\n",
    "missing = []\n",
    "for m, model in enumerate(models_artifacts):\n",
    "    if len(model[1]) == 0:\n",
    "        print(f'Model {model[0].display_name} has no remaining versions')\n",
    "        missing.append()\n",
    "# remove models with no remaining versions:\n",
    "if len(missing) > 0:\n",
    "    for r in reversed(missing):\n",
    "        print(f'Removing Model {models_artifacts[m][0].display_name}')\n",
    "        models_artifacts.pop(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d434cd6e-789a-4b8a-87c0-727a58b8d2d6",
   "metadata": {},
   "source": [
    "---\n",
    "### Create NVIDIA Triton Model Registry\n",
    "\n",
    "NVIDIA Triton Sever uses a specific folder structure for its model registry.  Naming of files and folders, their order, and contents is specific to the type of model being served as well.  Check the guidelines for [Model Registry](https://github.com/triton-inference-server/server/blob/main/docs/user_guide/model_repository.md) here.\n",
    "\n",
    "The model registry also includes configuration files in the form of `config.pbtxt`.  The contents of these files are model type and model specific.  Check the guidlines for [Model Configuration](https://github.com/triton-inference-server/server/blob/main/docs/user_guide/model_configuration.md) here.  Some model types can automatically detect configurations.  This workflow is using TensorFlow models which are automatically configured when the `config.pbtxt` files are missing - see [Auto-Generated Model Configuration](https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/user_guide/model_configuration.html#auto-generated-model-configuration).\n",
    "\n",
    "```\n",
    "    <model-repository-path>/\n",
    "        <model-name>/\n",
    "            [config.pbtxt]\n",
    "            [<output-labels-file> ...]\n",
    "            <version>/\n",
    "                <model-definition-file>\n",
    "            <version>/\n",
    "                <model-definition-file>\n",
    "            ...\n",
    "        <model-name>/\n",
    "            [config.pbtxt]\n",
    "            [<output-labels-file> ...]\n",
    "            <version>/\n",
    "                <model-definition-file>\n",
    "            <version>/\n",
    "                <model-definition-file>\n",
    "            ...\n",
    "        ...\n",
    "```\n",
    "\n",
    "**Model Loading And Versions**\n",
    "\n",
    "When Triton Inference Server starts up it has a control mode. The default is `--model-control-mode=none` which tries to load all models in the registry. [Reference](https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/user_guide/model_management.html#model-control-mode-none)\n",
    "\n",
    "This sounds like the perfect solution but it has a limit, it loads the model version specified in the config file for the model - see [Model Configuration Version Policy](https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/user_guide/model_configuration.html#version-policy).  Remember from the second paragraph of this section that we are taking advantage of automatic configuration so what happens by default?  Well, the default version policy is `version_policy: { latest: { num_versions: 1}}` which is just that lastest version of the model.  To override this we need to provide a config file with the desired version policy that loads all versions: `version_policy: { all: {}}`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49b7daed-78d5-470c-98dd-ab95ff07f75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = 'version_policy: { all: {}}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df2cd594-d678-4598-97b5-c191834d5a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = gcs.lookup_bucket(BUCKET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6fabab83-baac-44f1-b2ce-9f3e9e382baf",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://statmike-mlops-349915/05/05/models/20220927110007/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05/models/20220927110007/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05/models/20220927110007/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05/models/20220927184222/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05/models/20220927184222/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05/models/20220927184222/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05/models/20221023210622/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05/models/20221023210622/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05/models/20221023210622/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05/models/20230209212046/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05/models/20230209212046/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05/models/20230209212046/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05/models/20230210115433/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05/models/20230210115433/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05/models/20230210115433/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05/models/20230308225745/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05/models/20230308225745/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05/models/20230308225745/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05/models/20230324103811/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05/models/20230324103811/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05/models/20230324103811/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05/models/20230324104933/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05/models/20230324104933/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05/models/20230324104933/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05/models/20230325135459/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05/models/20230325135459/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05/models/20230325135459/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05/models/20230325220538/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05/models/20230325220538/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05/models/20230325220538/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05/models/20230327111418/model/fingerprint.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05/models/20230327111418/model/keras_metadata.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05/models/20230327111418/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05/models/20230327111418/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05/models/20230327111418/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05/models/20230327115749/model/keras_metadata.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05/models/20230327115749/model/fingerprint.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05/models/20230327115749/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05/models/20230327115749/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05/models/20230327115749/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20220927105742/model/keras_metadata.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20220927105742/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20220927105742/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20220927105742/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20221024120130/model/keras_metadata.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20221024120130/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20221024120130/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20221024120130/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20221109171913/model/keras_metadata.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20221109171913/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20221109171913/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20221109171913/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20230210122632/model/keras_metadata.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20230210122632/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20230210122632/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20230210122632/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20230210132930/model/keras_metadata.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20230210132930/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20230210132930/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20230210132930/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20230214162254/model/keras_metadata.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20230214162254/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20230214162254/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20230214162254/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20230925162315/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20230925162315/model/keras_metadata.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20230925162315/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20230925162315/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20230929134956/model/keras_metadata.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20230929134956/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20230929134956/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20230929134956/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20230930133138/model/keras_metadata.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20230930133138/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20230930133138/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20230930133138/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20231001235637/model/keras_metadata.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20231001235637/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20231001235637/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20231001235637/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20231002102623/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20231002102623/model/keras_metadata.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20231002102623/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20231002102623/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20231002112215/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20231002112215/model/keras_metadata.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20231002112215/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20231002112215/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20231002164113/model/keras_metadata.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20231002164113/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20231002164113/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20231002164113/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20231003161407/model/keras_metadata.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20231003161407/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20231003161407/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20231003161407/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20231003202509/model/keras_metadata.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20231003202509/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20231003202509/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05a/models/20231003202509/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05b/models/20220927105812/model/keras_metadata.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05b/models/20220927105812/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05b/models/20220927105812/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05b/models/20220927105812/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05b/models/20221024121343/model/keras_metadata.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05b/models/20221024121343/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05b/models/20221024121343/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05b/models/20221024121343/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05b/models/20230210130602/model/keras_metadata.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05b/models/20230210130602/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05b/models/20230210130602/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05b/models/20230210130602/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05c/models/20220927094738/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05c/models/20220927094738/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05c/models/20220927094738/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05c/models/20221024121349/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05c/models/20221024121349/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05c/models/20221024121349/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05c/models/20230210130701/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05c/models/20230210130701/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05c/models/20230210130701/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05d/models/20220927154304/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05d/models/20220927154304/model/keras_metadata.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05d/models/20220927154304/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05d/models/20220927154304/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05d/models/20221024130031/model/keras_metadata.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05d/models/20221024130031/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05d/models/20221024130031/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05d/models/20221024130031/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05d/models/20230211141913/model/keras_metadata.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05d/models/20230211141913/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05d/models/20230211141913/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05d/models/20230211141913/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05e/models/20220927181116/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05e/models/20220927181116/model/keras_metadata.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05e/models/20220927181116/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05e/models/20220927181116/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05e/models/20221024130058/model/keras_metadata.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05e/models/20221024130058/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05e/models/20221024130058/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05e/models/20221024130058/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05e/models/20230211141838/model/keras_metadata.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05e/models/20230211141838/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05e/models/20230211141838/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05e/models/20230211141838/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20220927190441/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20220927190441/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20220927190441/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20221024130131/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20221024130131/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20221024130131/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20221101224649/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20221101224649/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20221101224649/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20221102030007/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20221102030007/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20221102030007/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20221109040010/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20221109040010/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20221109040010/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20221116040015/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20221116040015/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20221116040015/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20221130040015/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20221130040015/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20221130040015/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20221207040014/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20221207040014/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20221207040014/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20221214040012/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20221214040012/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20221214040012/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20221221040013/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20221221040013/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20221221040013/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20221228040012/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20221228040012/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20221228040012/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230104040014/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230104040014/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230104040014/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230111040013/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230111040013/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230111040013/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230118040014/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230118040014/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230118040014/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230125040014/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230125040014/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230125040014/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230201040010/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230201040010/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230201040010/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230208040015/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230208040015/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230208040015/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230211141850/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230211141850/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230211141850/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230215040013/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230215040013/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230215040013/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230222040011/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230222040011/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230222040011/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230301040012/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230301040012/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230301040012/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230308040011/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230308040011/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230308040011/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230315030020/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230315030020/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230315030020/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230322030013/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230322030013/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230322030013/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230329030016/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230329030016/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230329030016/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230405030018/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230405030018/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230405030018/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230412030016/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230412030016/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230412030016/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230419030012/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230419030012/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230419030012/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230426030015/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230426030015/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230426030015/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230503030020/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230503030020/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230503030020/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230510030044/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230510030044/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230510030044/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230517030015/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230517030015/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230517030015/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230524030020/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230524030020/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230524030020/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230531030020/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230531030020/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230531030020/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230607030016/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230607030016/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230607030016/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230614030019/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230614030019/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230614030019/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230621030039/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230621030039/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230621030039/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230628030037/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230628030037/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230628030037/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230705030024/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230705030024/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230705030024/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230712030023/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230712030023/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230712030023/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230719030015/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230719030015/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230719030015/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230726030013/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230726030013/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230726030013/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230802030014/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230802030014/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230802030014/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230809030015/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230809030015/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230809030015/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230816030014/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230816030014/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230816030014/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230823030013/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230823030013/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230823030013/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230830030013/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230830030013/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230830030013/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230906030012/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230906030012/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230906030012/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230913030011/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230913030011/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230913030011/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230920030018/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230920030018/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230920030018/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230927030015/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230927030015/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20230927030015/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20231004030017/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20231004030017/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05f/models/20231004030017/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05g/models/20220927230209/10/model/keras_metadata.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05g/models/20220927230209/10/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05g/models/20220927230209/10/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05g/models/20220927230209/10/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05g/models/20221024135352/4/model/keras_metadata.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05g/models/20221024135352/4/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05g/models/20221024135352/4/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05g/models/20221024135352/4/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05g/models/20230211145013/5/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05g/models/20230211145013/5/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05g/models/20230211145013/5/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05g/models/20230211145013/5/model/keras_metadata.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05h/models/20220927230247/6/model/keras_metadata.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05h/models/20220927230247/6/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05h/models/20220927230247/6/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05h/models/20220927230247/6/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05h/models/20221024135432/17/model/keras_metadata.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05h/models/20221024135432/17/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05h/models/20221024135432/17/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05h/models/20221024135432/17/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05h/models/20230211221917/3/model/keras_metadata.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05h/models/20230211221917/3/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05h/models/20230211221917/3/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05h/models/20230211221917/3/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05i/models/20220928000517/13/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05i/models/20220928000517/13/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05i/models/20220928000517/13/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05i/models/20221024135445/11/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05i/models/20221024135445/11/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05i/models/20221024135445/11/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05i/models/20230203134418/3/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05i/models/20230203134418/3/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05i/models/20230203134418/3/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05i/models/20230211221928/11/model/variables/variables.index...\n",
      "Copying gs://statmike-mlops-349915/05/05i/models/20230211221928/11/model/saved_model.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05i/models/20230211221928/11/model/variables/variables.data-00000-of-00001...\n",
      "/ [3/6 files][519.8 KiB/519.8 KiB]  99% Done                                    \r"
     ]
    }
   ],
   "source": [
    "for model in models_artifacts:\n",
    "    blob = bucket.blob(f'{SERIES}/{EXPERIMENT}/model_repo/{model[0].display_name}/config.pbtxt')\n",
    "    blob.upload_from_string(config)\n",
    "    for version in model[1]:\n",
    "        !gsutil -m cp -r {version[1]} gs://{BUCKET}/{SERIES}/{EXPERIMENT}/model_repo/{model[0].display_name}/{version[0]}/model.savedmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dd05e8-936a-491d-95ff-18e01d19cb31",
   "metadata": {},
   "source": [
    "---\n",
    "## Run Container Locally (Optional)\n",
    "\n",
    "This section is optional but helpful if troubleshooting a deployment prior to deploying on Vertex AI Endpoints.  There are a few extra steps taken here to make the container run in a separate process so that the notebook does not get tied up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffae1c49-440a-432f-a14e-a624ac09a663",
   "metadata": {},
   "source": [
    "### Run the serving image locally\n",
    "\n",
    "The container is going to be run with commands in this notebook.  In order to run the serving while not tying up further exectutions in this notebook, a subprocess will be launched using `multiprocessing`. To learn more about multiprocessing and running tasks from Python in parallel visit the tips notebook [Python Multiprocessing](../Tips/Python%20Multiprocessing.ipynb). Alternatively, the `-d` option could be used to run the container in detached mode but it is not used here because reviewing the logging of the server is very helpful within the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68850649-e342-4e84-9ae0-43f9b1f76199",
   "metadata": {},
   "source": [
    "First, build the syntax of the `docker run` command.  Note that `-e AIP_MODE = True` is used, which allows the model repository to be set directly from a GCS URI rather than using a `-v local/dir:server/dir` mount.  This could be done but the the `gscfuse` above would need the `-o allow_other` option which is not recommended due to security risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6fea27ef-d16a-4033-a8ba-e2fb84c0af1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker run -t -p 8000:8000 -p 8001:8001 -p 8002:8002 --rm -e AIP_MODE=True --name=local_triton_server us-central1-docker.pkg.dev/statmike-mlops-349915/statmike-mlops-349915/05_triton:23.03 --model-repository gs://statmike-mlops-349915/05/triton/model_repo\n"
     ]
    }
   ],
   "source": [
    "command = f'''docker run -t -p 8000:8000 -p 8001:8001 -p 8002:8002 --rm \\\n",
    "-e AIP_MODE=True \\\n",
    "--name=local_triton_server \\\n",
    "{AR_IMAGE} \\\n",
    "--model-repository gs://{BUCKET}/{SERIES}/{EXPERIMENT}/model_repo'''\n",
    "\n",
    "#command += ' --log-verbose=1'\n",
    "\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c030d196-599d-4d65-8d8a-a9086deed62e",
   "metadata": {},
   "source": [
    "Run the command in a subprocess at the local folder of this notebook - use multiprocess.Process():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a6de61d1-2cb0-467d-b89f-9598a06d0f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/vertex-ai-mlops/05 - TensorFlow\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ce4ace-73ec-4473-aac1-62ee9ac3f547",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def docker_runner():\n",
    "    !{command}\n",
    "\n",
    "def main():\n",
    "    p = multiprocessing.Process(target=docker_runner)\n",
    "    p.start()\n",
    "    return p\n",
    "    \n",
    "p = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bfaea4-1389-4f79-889a-c264f73b9dcb",
   "metadata": {},
   "source": [
    "### Check The Server Health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01d52ae-7cb7-4e5c-8347-bd61bfa0d129",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -v localhost:8000/v2/health/ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572da9c8-1c97-4a6b-ba3b-53852b85ac56",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -s -o /dev/null -w \"%{http_code}\" http://localhost:8000/v2/health/ready"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb7bafb-ca25-49f0-9874-83127a84cc3c",
   "metadata": {},
   "source": [
    "### Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "id": "ae1daf72-2dc4-4973-b6ca-5f6d2f382c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<google.cloud.aiplatform.models.Model object at 0x7f9f784fb7f0> \n",
       " resource name: projects/1026793852137/locations/us-central1/models/model_05_05,\n",
       " [('2', 'gs://statmike-mlops-349915/05/05/models/20220927110007/model'),\n",
       "  ('3', 'gs://statmike-mlops-349915/05/05/models/20220927184222/model'),\n",
       "  ('4', 'gs://statmike-mlops-349915/05/05/models/20221023210622/model'),\n",
       "  ('5', 'gs://statmike-mlops-349915/05/05/models/20230209212046/model'),\n",
       "  ('6', 'gs://statmike-mlops-349915/05/05/models/20230210115433/model'),\n",
       "  ('7', 'gs://statmike-mlops-349915/05/05/models/20230308225745/model'),\n",
       "  ('8', 'gs://statmike-mlops-349915/05/05/models/20230324103811/model'),\n",
       "  ('9', 'gs://statmike-mlops-349915/05/05/models/20230324104933/model'),\n",
       "  ('10', 'gs://statmike-mlops-349915/05/05/models/20230325135459/model'),\n",
       "  ('11', 'gs://statmike-mlops-349915/05/05/models/20230325220538/model'),\n",
       "  ('12', 'gs://statmike-mlops-349915/05/05/models/20230327111418/model'),\n",
       "  ('13', 'gs://statmike-mlops-349915/05/05/models/20230327115749/model')])"
      ]
     },
     "execution_count": 652,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_artifacts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "id": "ff8b4083-e67f-4d86-9b1b-cc5090e969ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(\n",
    "    f'http://localhost:8000/v2/models/{models_artifacts[0][0].display_name}/versions/{models_artifacts[0][1][-1][0]}/infer',\n",
    "    data = json.dumps(instances),\n",
    "    headers = {\"content-type\": \"application/json; charset=utf-8\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "id": "11e7450f-ab7e-45f2-ad37-d1b92941c0be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': '05_05',\n",
       " 'model_version': '13',\n",
       " 'outputs': [{'name': 'logistic',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [1.6803035407519928e-07, 0.9999998807907104]}]}"
      ]
     },
     "execution_count": 654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = json.loads(response.text)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "id": "a971774e-c8f6-4eb6-8b96-254ce6e9ed51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 655,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class = np.argmax(result['outputs'][0]['data'])\n",
    "predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "id": "93eb1f0d-3389-410d-9ae7-52f7486495f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999998807907104"
      ]
     },
     "execution_count": 656,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class_proba = result['outputs'][0]['data'][predicted_class]\n",
    "predicted_class_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d6ce31-025c-4b4e-a561-883fb390cc1f",
   "metadata": {},
   "source": [
    "### Stop The Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2708b6a8-42ee-4096-aa77-178883c4e6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.is_alive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "id": "9db61324-a7e7-4ba1-82e9-f3a855b735f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local_triton_server\n"
     ]
    }
   ],
   "source": [
    "# if needed, run this to stop the server\n",
    "!docker stop local_triton_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "id": "8cdeaf76-ef58-4f07-ae8e-42549d26d314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 751,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.is_alive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "id": "083c4ab4-8fa0-4a3a-a19c-8fbd11a95be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
     ]
    }
   ],
   "source": [
    "!docker ps -f \"name=local_triton_server\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc64443-ad0e-442c-b71b-1c193fe83bd5",
   "metadata": {},
   "source": [
    "---\n",
    "## Vertex AI Model Registry Entry For Triton Model Repository\n",
    "\n",
    "The NVIDIA Triton server model registry created above needs to be registred as a model in the Vertex AI Model Registry.  While the Triton server model registry could represent multiple models, versions of models, and ensembles, it represents a single model entity in the Vertex AI Model Registry."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3f58eb-459b-4e76-b413-11bb7d6bc470",
   "metadata": {},
   "source": [
    "### Container Arguments For Vertex AI\n",
    "\n",
    "The TRITON Server has a series of command line arguments that include Vertex AI specific setting.  \n",
    "\n",
    "> Search the page at the following link to find \"VERTEX_AI\":\n",
    "> [TRITON Server Command Line Parser](https://github.com/triton-inference-server/server/blob/main/src/command_line_parser.cc)\n",
    "\n",
    "This notebook loads multiple models to TRITON server which may result in an error like the following on deployment to the endpoint:\n",
    "\n",
    "> `\"E0822 01:17:50.086439 1 main.cc:278] failed to start Vertex AI service: Invalid argument - Expect the model repository contains only a single model if default model is not specified\"`\n",
    "\n",
    "Multiple models can be used for inference but Vertex AI needs to know which is the default for when a model is not specified.  This is done using the `vertex-ai-default-model` flag.  See the prediction section for how to make prediction with the default model, and how to specify a specific model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a55b0f75-af6e-4325-947b-2804d332fa3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['--vertex-ai-default-model=05_05']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serving_container_args = [\n",
    "    f\"--vertex-ai-default-model={models_artifacts[0][0].display_name}\"\n",
    "]\n",
    "serving_container_args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e11148d-b554-440e-8aae-ec8ad07df64c",
   "metadata": {},
   "source": [
    "### Register In Vertex AI Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6084ebbe-e2df-4d4f-bd44-305baccc23db",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b94afa13-cbc0-4877-a10e-505d56df64c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_NAME = f'run-{TIMESTAMP}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15a16a3-1a98-4809-8231-79fd0835bccf",
   "metadata": {},
   "source": [
    "Check for existing version of the model in the model registry do one of the following:\n",
    "- Register as new model\n",
    "- Register as new version of existing model\n",
    "- Detect already registered model version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8b71993e-2e13-4aaa-93ab-906b28e5fda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Already in Registry:\n",
      "Loading model as new default version.\n",
      "Creating Model\n",
      "Create Model backing LRO: projects/1026793852137/locations/us-central1/models/model_05_triton/operations/6538786510693466112\n",
      "Model created. Resource name: projects/1026793852137/locations/us-central1/models/model_05_triton@20\n",
      "To use this Model in another session:\n",
      "model = aiplatform.Model('projects/1026793852137/locations/us-central1/models/model_05_triton@20')\n"
     ]
    }
   ],
   "source": [
    "modelmatch = aiplatform.Model.list(filter = f'display_name={SERIES}_{EXPERIMENT} AND labels.series={SERIES} AND labels.experiment={EXPERIMENT}')\n",
    "\n",
    "upload_model = True\n",
    "if modelmatch:\n",
    "    print(\"Model Already in Registry:\")\n",
    "    if RUN_NAME in modelmatch[0].version_aliases:\n",
    "        print(\"This version already loaded, no action taken.\")\n",
    "        upload_model = False\n",
    "        vertex_model = aiplatform.Model(model_name = modelmatch[0].resource_name)\n",
    "    else:\n",
    "        print('Loading model as new default version.')\n",
    "        parent_model = modelmatch[0].resource_name\n",
    "\n",
    "else:\n",
    "    print('This is a new model, creating in model registry')\n",
    "    parent_model = ''\n",
    "\n",
    "if upload_model:\n",
    "    vertex_model = aiplatform.Model.upload(\n",
    "        display_name = f'{SERIES}_{EXPERIMENT}',\n",
    "        model_id = f'model_{SERIES}_{EXPERIMENT}',\n",
    "        parent_model =  parent_model,\n",
    "        serving_container_image_uri = AR_IMAGE,\n",
    "        serving_container_args = serving_container_args,\n",
    "        artifact_uri = f\"gs://{BUCKET}/{SERIES}/{EXPERIMENT}/model_repo\",\n",
    "        is_default_version = True,\n",
    "        version_aliases = [RUN_NAME],\n",
    "        version_description = RUN_NAME,\n",
    "        labels = {'series' : f'{SERIES}', 'experiment' : f'{EXPERIMENT}'}        \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cb2722a5-23b2-481f-a392-f47dca50dc80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model_05_triton'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vertex_model.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4eaeae72-03dc-435b-b3f7-4ad7ca105d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vertex_model.version_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b8a4402a-957d-4716-850c-222c75e04ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review the model in the Vertex AI Model Registry:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/models/model_05_triton?project=statmike-mlops-349915\n"
     ]
    }
   ],
   "source": [
    "print(f'Review the model in the Vertex AI Model Registry:\\nhttps://console.cloud.google.com/vertex-ai/locations/{REGION}/models/{vertex_model.name}?project={PROJECT_ID}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27badb06-ccf3-4508-85bd-a99c2e662957",
   "metadata": {},
   "source": [
    "---\n",
    "## Vertex AI Prediction Endpoint\n",
    "\n",
    "Create a prediction endpoint and deploy the model (version) from the Vertex AI model registry."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d70e8c-5758-436a-a227-f904b0749876",
   "metadata": {},
   "source": [
    "Create or detect existing endpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "51028888-e3d6-456b-b42d-f3a58d5a98cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Exists: projects/1026793852137/locations/us-central1/endpoints/8971471723908038656\n",
      "Review the Endpoint in the Console:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/endpoints/8971471723908038656?project=statmike-mlops-349915\n"
     ]
    }
   ],
   "source": [
    "endpoints = aiplatform.Endpoint.list(filter = f\"labels.series={SERIES} AND labels.experiment={EXPERIMENT}\")\n",
    "if endpoints:\n",
    "    endpoint = endpoints[0]\n",
    "    print(f\"Endpoint Exists: {endpoints[0].resource_name}\")\n",
    "else:\n",
    "    endpoint = aiplatform.Endpoint.create(\n",
    "        display_name = f\"{SERIES}_{EXPERIMENT}\",\n",
    "        labels = {'series' : f\"{SERIES}\", 'experiment': f\"{EXPERIMENT}\"}    \n",
    "    )\n",
    "    print(f\"Endpoint Created: {endpoint.resource_name}\")\n",
    "    \n",
    "print(f'Review the Endpoint in the Console:\\nhttps://console.cloud.google.com/vertex-ai/locations/{REGION}/endpoints/{endpoint.name}?project={PROJECT_ID}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "03d5c74a-06ea-46ba-9f0b-27504c3a523f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'05_triton'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint.display_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9d9c8274-d443-4464-8211-0090d3704fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'4993465042893537280': 100}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint.traffic_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e434d55e-5790-4f47-9563-b7ebe66d3d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('05_triton', '17')]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployed_models = endpoint.list_models()\n",
    "[(d.display_name, d.model_version_id) for d in deployed_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f37d7372-690f-4a15-862a-66ab7a9e150e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1026793852137-compute@developer.gserviceaccount.com'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SERVICE_ACCOUNT = !gcloud config list --format='value(core.account)' \n",
    "SERVICE_ACCOUNT = SERVICE_ACCOUNT[0]\n",
    "SERVICE_ACCOUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "feeb3e2d-6367-4c96-a4f4-4af365b29cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROLE\n",
      "roles/bigquery.admin\n",
      "roles/owner\n",
      "roles/run.admin\n",
      "roles/storage.objectAdmin\n"
     ]
    }
   ],
   "source": [
    "!gcloud projects get-iam-policy $PROJECT_ID --filter=\"bindings.members:$SERVICE_ACCOUNT\" --format='table(bindings.role)' --flatten=\"bindings[].members\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942e03a6-5a1a-4db9-adc9-7c48dd5d17fb",
   "metadata": {},
   "source": [
    "### Deploy The Model To The Endpoint\n",
    "\n",
    "Note that the Vertex AI Model Registry has the information needed for the deployment:\n",
    "- URI of the serving container in Artifact Registry\n",
    "- URI of the model registry files in GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "20a9100d-b6d1-489c-a42c-51ec597fab27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying model with 100% of traffic...\n",
      "Deploying Model projects/1026793852137/locations/us-central1/models/model_05_triton to Endpoint : projects/1026793852137/locations/us-central1/endpoints/8971471723908038656\n",
      "Deploy Endpoint model backing LRO: projects/1026793852137/locations/us-central1/endpoints/8971471723908038656/operations/8472387659300339712\n",
      "Endpoint model deployed. Resource name: projects/1026793852137/locations/us-central1/endpoints/8971471723908038656\n"
     ]
    }
   ],
   "source": [
    "if (vertex_model.display_name, vertex_model.version_id) not in [(d.display_name, d.model_version_id) for d in endpoint.list_models()]:\n",
    "    print(f'Deploying model with 100% of traffic...')\n",
    "    endpoint.deploy(\n",
    "        model = vertex_model,\n",
    "        deployed_model_display_name = vertex_model.display_name,\n",
    "        traffic_percentage = 100,\n",
    "        machine_type = 'n1-highmem-4',\n",
    "        min_replica_count = 1,\n",
    "        max_replica_count = 1,\n",
    "        #accelerator_type = 'NVIDIA_TESLA_T4',\n",
    "        accelerator_count = 0,\n",
    "        #service_account = SERVICE_ACCOUNT\n",
    "    )\n",
    "else:\n",
    "    print(f'Not deploying because model = {vertex_model.display_name} with version {vertex_model.version_id} is already on endpoint = {endpoint.display_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb82eeac-05e7-4b50-89ed-9cd6c888ce20",
   "metadata": {},
   "source": [
    "**NOTE On Memory Errors In Triton Container Logs**\n",
    "\n",
    "The model may fail to deploy.  In reviewing the logs an error related to shared memory in the environment like the one below may occur:\n",
    "\n",
    "> `E0824 10:49:33.972408 1 model_lifecycle.cc:597] failed to load 'postprocess' version 1: Internal: Unable to initialize shared memory key 'triton_python_backend_shm_region_4' to requested size (67108864 bytes). If you are running Triton inside docker, use '--shm-size' flag to control the shared memory region size. Each Python backend model instance requires at least 64MBs of shared memory. Error: No space left on device`\n",
    "\n",
    "With Vertex AI Endpoints you cannot provide a value for `--shm-size`.  If you contact support you can request the project to have an override for this error that changes the default shared memory size the a larger percentage of the nodes memory.  This does not necessarily mean chosing a different or larger node size configuration, rather, just allocating more of its memory to shared memory for the Triton Server processes to utilize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "056cefc6-01bd-4fc8-9b6a-0e42d2bb84e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'4993465042893537280': 100}"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint.traffic_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce8435f-4218-4493-b187-9a6a87af45cb",
   "metadata": {},
   "source": [
    "#### Remove Deployed Models Without Traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "aaed7a68-5618-416d-b314-2d4180a79214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undeploying Endpoint model: projects/1026793852137/locations/us-central1/endpoints/8971471723908038656\n",
      "Undeploy Endpoint model backing LRO: projects/1026793852137/locations/us-central1/endpoints/8971471723908038656/operations/503831068621668352\n",
      "Endpoint model undeployed. Resource name: projects/1026793852137/locations/us-central1/endpoints/8971471723908038656\n",
      "Undeploying 05_triton with version 9 because it has no traffic.\n",
      "Model 05_triton with version 17 has traffic = 100\n"
     ]
    }
   ],
   "source": [
    "for deployed_model in endpoint.list_models():\n",
    "    if deployed_model.id in endpoint.traffic_split:\n",
    "        print(f\"Model {deployed_model.display_name} with version {deployed_model.model_version_id} has traffic = {endpoint.traffic_split[deployed_model.id]}\")\n",
    "    else:\n",
    "        endpoint.undeploy(deployed_model_id = deployed_model.id)\n",
    "        print(f\"Undeploying {deployed_model.display_name} with version {deployed_model.model_version_id} because it has no traffic.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3bd242-a691-4d17-a228-cf69780cd918",
   "metadata": {},
   "source": [
    "---\n",
    "## Prediction\n",
    "\n",
    "Use prediction instances created before in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5c5a2e-24e1-47b1-b2ca-d1af11b90c54",
   "metadata": {},
   "source": [
    "### Client For Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6f5b1819-d826-4e21-84f2-d36c9d0c6ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_options = {\"api_endpoint\": f\"{REGION}-aiplatform.googleapis.com\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8f3ae474-3c70-46ea-9b09-abda0ae7dd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = aiplatform.gapic.PredictionServiceClient(client_options = client_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a30ad3da-7f8f-4eb3-b94b-923e626cbe9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/1026793852137/locations/us-central1/endpoints/8971471723908038656'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint.resource_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94aea0e4-54b2-4394-8bb6-de58b214625d",
   "metadata": {},
   "source": [
    "### Make A Prediction Request: default model/version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "790ae8c8-1b43-40f8-8f7d-5b60c37394d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "http_body = httpbody_pb2.HttpBody(\n",
    "    data = json.dumps(instances).encode(\"utf-8\"),\n",
    "    content_type = \"application/json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3370a9f2-6c57-4714-b465-e2bc2aec911c",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = aiplatform.gapic.RawPredictRequest(\n",
    "    endpoint = endpoint.resource_name,\n",
    "    http_body = http_body\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d606b29f-c896-4fcd-9183-d3a3a2aa9723",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = predictor.raw_predict(request = request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "72d78872-990b-4897-876e-ecd770cac477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "content_type: \"application/json\"\n",
       "data: \"{\\\"model_name\\\":\\\"05_05\\\",\\\"model_version\\\":\\\"13\\\",\\\"outputs\\\":[{\\\"name\\\":\\\"logistic\\\",\\\"datatype\\\":\\\"FP32\\\",\\\"shape\\\":[1,2],\\\"data\\\":[1.6803035407519929e-7,0.9999998807907105]}]}\""
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b9aabe80-6d25-4581-8a29-8677df20ed3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': '05_05',\n",
       " 'model_version': '13',\n",
       " 'outputs': [{'name': 'logistic',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [1.6803035407519928e-07, 0.9999998807907104]}]}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = json.loads(response.data)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8de33d2c-38b7-4bb5-8ddb-2e8f9e66b5b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class = np.argmax(result['outputs'][0]['data'])\n",
    "predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "eb444285-3983-4ecd-9a64-993ddd119d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999998807907104"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class_proba = result['outputs'][0]['data'][predicted_class]\n",
    "predicted_class_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e101a3b-3894-4b40-8037-6fe4271adcbf",
   "metadata": {},
   "source": [
    "### Make A Prediction Request: specific model / latest version\n",
    "\n",
    "To make a request of a specific model and version, other than the default, the header value for `X-Vertex-Ai-Triton-Redirect` can be set to a model path on the Triton Inference Server.  To make this header modification the requests is made using the Python `requests` library where custom headers can be specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f825f80d-2560-41fd-a986-e6659ad58c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<google.cloud.aiplatform.models.Model object at 0x7f9b90707160> \n",
       " resource name: projects/1026793852137/locations/us-central1/models/model_05_05,\n",
       " [('2', 'gs://statmike-mlops-349915/05/05/models/20220927110007/model'),\n",
       "  ('3', 'gs://statmike-mlops-349915/05/05/models/20220927184222/model'),\n",
       "  ('4', 'gs://statmike-mlops-349915/05/05/models/20221023210622/model'),\n",
       "  ('5', 'gs://statmike-mlops-349915/05/05/models/20230209212046/model'),\n",
       "  ('6', 'gs://statmike-mlops-349915/05/05/models/20230210115433/model'),\n",
       "  ('7', 'gs://statmike-mlops-349915/05/05/models/20230308225745/model'),\n",
       "  ('8', 'gs://statmike-mlops-349915/05/05/models/20230324103811/model'),\n",
       "  ('9', 'gs://statmike-mlops-349915/05/05/models/20230324104933/model'),\n",
       "  ('10', 'gs://statmike-mlops-349915/05/05/models/20230325135459/model'),\n",
       "  ('11', 'gs://statmike-mlops-349915/05/05/models/20230325220538/model'),\n",
       "  ('12', 'gs://statmike-mlops-349915/05/05/models/20230327111418/model'),\n",
       "  ('13', 'gs://statmike-mlops-349915/05/05/models/20230327115749/model')])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_artifacts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "524860c1-1c6d-4261-a5bf-eddcfd54567d",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = !gcloud auth application-default print-access-token\n",
    "headers = {\n",
    "    \"content-type\": \"application/json; charset=utf-8\",\n",
    "    \"X-Vertex-Ai-Triton-Redirect\": f\"v2/models/{models_artifacts[0][0].display_name}/versions/{models_artifacts[0][1][-1][0]}/infer\",\n",
    "    \"Authorization\": f'Bearer {token[0]}'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "963bd08d-e2e6-4a4d-b6fd-21bfb9f9ea09",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(\n",
    "    f'https://{REGION}-aiplatform.googleapis.com/v1/{endpoint.resource_name}:rawPredict',\n",
    "    data = json.dumps(instances),\n",
    "    headers = headers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "65d9d407-b91e-418f-b1c2-180a901b513f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': '05_05',\n",
       " 'model_version': '13',\n",
       " 'outputs': [{'name': 'logistic',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [1.6803035407519928e-07, 0.9999998807907104]}]}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = json.loads(response.text)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3dba1206-745b-4465-9acc-683e4136a0ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class = np.argmax(result['outputs'][0]['data'])\n",
    "predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ad11529a-d818-4c5b-965c-8e72bbd5cefd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999998807907104"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class_proba = result['outputs'][0]['data'][predicted_class]\n",
    "predicted_class_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c923615-1453-480f-938b-8b66453a8593",
   "metadata": {},
   "source": [
    "### Make A Prediction Request: all models / latest version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2ede897a-067f-48b8-a8a2-7d639e664971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('05_05@13', 1, 0.9999998807907104),\n",
       " ('05_05a@16', 1, 0.9999985694885254),\n",
       " ('05_05b@4', 1, 1.0),\n",
       " ('05_05c@3', 1, 0.9999970197677612),\n",
       " ('05_05d@3', 1, 1.0),\n",
       " ('05_05e@3', 1, 0.9999979734420776),\n",
       " ('05_05f@53', 1, 1.0),\n",
       " ('05_05g@3', 1, 1.0),\n",
       " ('05_05h@3', 1, 0.9987230896949768),\n",
       " ('05_05i@4', 1, 1.0)]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for model in models_artifacts:\n",
    "    token = !gcloud auth application-default print-access-token\n",
    "    headers = {\n",
    "        \"content-type\": \"application/json; charset=utf-8\",\n",
    "        \"X-Vertex-Ai-Triton-Redirect\": f\"v2/models/{model[0].display_name}/versions/{model[1][-1][0]}/infer\",\n",
    "        \"Authorization\": f'Bearer {token[0]}'\n",
    "    }\n",
    "    response = requests.post(\n",
    "        f'https://{REGION}-aiplatform.googleapis.com/v1/{endpoint.resource_name}:rawPredict',\n",
    "        data = json.dumps(instances),\n",
    "        headers = headers\n",
    "    )\n",
    "    result = json.loads(response.text)\n",
    "    predicted_class = np.argmax(result['outputs'][0]['data'])\n",
    "    results.append(\n",
    "        (\n",
    "            f\"{result['model_name']}@{result['model_version']}\",\n",
    "            predicted_class,\n",
    "            result['outputs'][0]['data'][predicted_class]\n",
    "        )\n",
    "    )\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1d07f5-2a0f-4889-bcff-e7079b4b27f4",
   "metadata": {},
   "source": [
    "### Make A Prediction Request: all models / all versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8d26ea5e-93c5-4448-ad4f-790879ddcaca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<google.cloud.aiplatform.models.Model object at 0x7f9b90707160> \n",
       " resource name: projects/1026793852137/locations/us-central1/models/model_05_05,\n",
       " [('2', 'gs://statmike-mlops-349915/05/05/models/20220927110007/model'),\n",
       "  ('3', 'gs://statmike-mlops-349915/05/05/models/20220927184222/model'),\n",
       "  ('4', 'gs://statmike-mlops-349915/05/05/models/20221023210622/model'),\n",
       "  ('5', 'gs://statmike-mlops-349915/05/05/models/20230209212046/model'),\n",
       "  ('6', 'gs://statmike-mlops-349915/05/05/models/20230210115433/model'),\n",
       "  ('7', 'gs://statmike-mlops-349915/05/05/models/20230308225745/model'),\n",
       "  ('8', 'gs://statmike-mlops-349915/05/05/models/20230324103811/model'),\n",
       "  ('9', 'gs://statmike-mlops-349915/05/05/models/20230324104933/model'),\n",
       "  ('10', 'gs://statmike-mlops-349915/05/05/models/20230325135459/model'),\n",
       "  ('11', 'gs://statmike-mlops-349915/05/05/models/20230325220538/model'),\n",
       "  ('12', 'gs://statmike-mlops-349915/05/05/models/20230327111418/model'),\n",
       "  ('13', 'gs://statmike-mlops-349915/05/05/models/20230327115749/model')])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_artifacts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e2468c4c-f740-4893-a95d-75283cf669e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'05_05@2': (1, 0.9997386336326599, 'prediction_layer'),\n",
       " '05_05@3': (1, 0.9996007084846497, 'prediction_layer'),\n",
       " '05_05@4': (1, 0.9997250437736511, 'logistic'),\n",
       " '05_05@5': (1, 0.9999992847442627, 'logistic'),\n",
       " '05_05@6': (1, 1.0, 'logistic'),\n",
       " '05_05@7': (1, 1.0, 'logistic'),\n",
       " '05_05@8': (1, 0.9999997615814209, 'logistic'),\n",
       " '05_05@9': (1, 0.9999983310699463, 'logistic'),\n",
       " '05_05@10': (1, 0.9999998807907104, 'logistic'),\n",
       " '05_05@11': (1, 0.9999986886978149, 'logistic'),\n",
       " '05_05@12': (1, 1.0, 'logistic'),\n",
       " '05_05@13': (1, 0.9999998807907104, 'logistic'),\n",
       " '05_05a@2': (1, 0.9989877343177795, 'prediction_layer'),\n",
       " '05_05a@3': (1, 0.9999998807907104, 'logistic'),\n",
       " '05_05a@4': (1, 0.9999881982803345, 'logistic'),\n",
       " '05_05a@5': (1, 0.9999998807907104, 'logistic'),\n",
       " '05_05a@6': (1, 0.9999980926513672, 'logistic'),\n",
       " '05_05a@7': (1, 0.9999998807907104, 'logistic'),\n",
       " '05_05a@8': (1, 0.9999998807907104, 'logistic'),\n",
       " '05_05a@9': (1, 0.9999971389770508, 'logistic'),\n",
       " '05_05a@10': (1, 1.0, 'logistic'),\n",
       " '05_05a@11': (1, 1.0, 'logistic'),\n",
       " '05_05a@12': (1, 0.9999991655349731, 'logistic'),\n",
       " '05_05a@13': (1, 1.0, 'logistic'),\n",
       " '05_05a@14': (1, 1.0, 'logistic'),\n",
       " '05_05a@15': (1, 0.9999988079071045, 'logistic'),\n",
       " '05_05a@16': (1, 0.9999985694885254, 'logistic'),\n",
       " '05_05b@2': (1, 0.9929108023643494, 'prediction_layer'),\n",
       " '05_05b@3': (1, 0.9999990463256836, 'logistic'),\n",
       " '05_05b@4': (1, 1.0, 'logistic'),\n",
       " '05_05c@1': (1, 0.9999518394470215, 'prediction_layer'),\n",
       " '05_05c@2': (1, 0.9999997615814209, 'logistic'),\n",
       " '05_05c@3': (1, 0.9999970197677612, 'logistic'),\n",
       " '05_05d@1': (1, 0.992363452911377, 'prediction_layer'),\n",
       " '05_05d@2': (1, 1.0, 'logistic'),\n",
       " '05_05d@3': (1, 1.0, 'logistic'),\n",
       " '05_05e@1': (1, 0.9999854564666748, 'prediction_layer'),\n",
       " '05_05e@2': (1, 0.9999994039535522, 'logistic'),\n",
       " '05_05e@3': (1, 0.9999979734420776, 'logistic'),\n",
       " '05_05f@1': (1, 0.9998890161514282, 'prediction_layer'),\n",
       " '05_05f@2': (1, 1.0, 'logistic'),\n",
       " '05_05f@3': (1, 0.9999978542327881, 'logistic'),\n",
       " '05_05f@4': (1, 0.9999995231628418, 'logistic'),\n",
       " '05_05f@5': (1, 1.0, 'logistic'),\n",
       " '05_05f@6': (1, 1.0, 'logistic'),\n",
       " '05_05f@8': (1, 1.0, 'logistic'),\n",
       " '05_05f@9': (1, 1.0, 'logistic'),\n",
       " '05_05f@10': (1, 0.9999841451644897, 'logistic'),\n",
       " '05_05f@11': (1, 1.0, 'logistic'),\n",
       " '05_05f@12': (1, 0.9999991655349731, 'logistic'),\n",
       " '05_05f@13': (1, 0.999998927116394, 'logistic'),\n",
       " '05_05f@14': (1, 0.9999953508377075, 'logistic'),\n",
       " '05_05f@15': (1, 1.0, 'logistic'),\n",
       " '05_05f@16': (1, 0.9999997615814209, 'logistic'),\n",
       " '05_05f@17': (1, 0.9999996423721313, 'logistic'),\n",
       " '05_05f@18': (1, 0.9999998807907104, 'logistic'),\n",
       " '05_05f@19': (1, 0.9999997615814209, 'logistic'),\n",
       " '05_05f@20': (1, 0.9999997615814209, 'logistic'),\n",
       " '05_05f@21': (1, 1.0, 'logistic'),\n",
       " '05_05f@22': (1, 1.0, 'logistic'),\n",
       " '05_05f@23': (1, 0.9999997615814209, 'logistic'),\n",
       " '05_05f@24': (1, 0.9999996423721313, 'logistic'),\n",
       " '05_05f@25': (1, 1.0, 'logistic'),\n",
       " '05_05f@26': (1, 0.9999995231628418, 'logistic'),\n",
       " '05_05f@27': (1, 1.0, 'logistic'),\n",
       " '05_05f@28': (1, 0.9999971389770508, 'logistic'),\n",
       " '05_05f@29': (1, 0.9999998807907104, 'logistic'),\n",
       " '05_05f@30': (1, 0.9999960660934448, 'logistic'),\n",
       " '05_05f@31': (1, 0.9999998807907104, 'logistic'),\n",
       " '05_05f@32': (1, 0.9999988079071045, 'logistic'),\n",
       " '05_05f@33': (1, 1.0, 'logistic'),\n",
       " '05_05f@34': (1, 1.0, 'logistic'),\n",
       " '05_05f@35': (1, 1.0, 'logistic'),\n",
       " '05_05f@36': (1, 0.9999990463256836, 'logistic'),\n",
       " '05_05f@37': (1, 0.9999912977218628, 'logistic'),\n",
       " '05_05f@38': (1, 0.9999998807907104, 'logistic'),\n",
       " '05_05f@39': (1, 0.9999911785125732, 'logistic'),\n",
       " '05_05f@40': (1, 0.9999889135360718, 'logistic'),\n",
       " '05_05f@41': (1, 0.9999979734420776, 'logistic'),\n",
       " '05_05f@42': (1, 0.9999995231628418, 'logistic'),\n",
       " '05_05f@43': (1, 0.9999964237213135, 'logistic'),\n",
       " '05_05f@44': (1, 1.0, 'logistic'),\n",
       " '05_05f@45': (1, 0.9999994039535522, 'logistic'),\n",
       " '05_05f@46': (1, 0.9999998807907104, 'logistic'),\n",
       " '05_05f@47': (1, 0.9999996423721313, 'logistic'),\n",
       " '05_05f@48': (1, 0.9999963045120239, 'logistic'),\n",
       " '05_05f@49': (1, 0.9999967813491821, 'logistic'),\n",
       " '05_05f@50': (1, 0.9999997615814209, 'logistic'),\n",
       " '05_05f@51': (1, 1.0, 'logistic'),\n",
       " '05_05f@52': (1, 0.9999998807907104, 'logistic'),\n",
       " '05_05f@53': (1, 1.0, 'logistic'),\n",
       " '05_05g@1': (1, 0.9999880790710449, 'prediction_layer'),\n",
       " '05_05g@2': (1, 1.0, 'logistic'),\n",
       " '05_05g@3': (1, 1.0, 'logistic'),\n",
       " '05_05h@1': (1, 0.9998008608818054, 'prediction_layer'),\n",
       " '05_05h@2': (1, 1.0, 'logistic'),\n",
       " '05_05h@3': (1, 0.9987230896949768, 'logistic'),\n",
       " '05_05i@1': (1, 0.9999951124191284, 'prediction_layer'),\n",
       " '05_05i@2': (1, 1.0, 'logistic'),\n",
       " '05_05i@3': (1, 0.9999959468841553, 'logistic'),\n",
       " '05_05i@4': (1, 1.0, 'logistic')}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = {}\n",
    "for model in models_artifacts:\n",
    "    for version in model[1]:\n",
    "        token = !gcloud auth application-default print-access-token\n",
    "        headers = {\n",
    "            \"content-type\": \"application/json; charset=utf-8\",\n",
    "            \"X-Vertex-Ai-Triton-Redirect\": f\"v2/models/{model[0].display_name}/versions/{version[0]}/infer\",\n",
    "            \"Authorization\": f'Bearer {token[0]}'\n",
    "        }\n",
    "        response = requests.post(\n",
    "            f'https://{REGION}-aiplatform.googleapis.com/v1/{endpoint.resource_name}:rawPredict',\n",
    "            data = json.dumps(instances),\n",
    "            headers = headers\n",
    "        )\n",
    "        result = json.loads(response.text)\n",
    "        if 'error' in result.keys():\n",
    "            results[f\"{model[0].display_name}@{version[0]}\"] = (\n",
    "                        'Missing',\n",
    "                        'Missing',\n",
    "                        'Missing'\n",
    "                    )\n",
    "        else:\n",
    "            predicted_class = np.argmax(result['outputs'][0]['data'])\n",
    "            results[f\"{result['model_name']}@{result['model_version']}\"] = (\n",
    "                        predicted_class,\n",
    "                        result['outputs'][0]['data'][predicted_class],\n",
    "                        result['outputs'][0]['name']\n",
    "                    )\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4cf39c-5470-40c1-82b3-1df7253a8bd6",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Ensemble: Pipeline Instances To All Models And Versions\n",
    "\n",
    "Triton Server has a model abstraction that can be specified with `platform: ensemble` in a `config.pbtxt` file.  This can be added to a model repository like any other model:\n",
    "\n",
    "```\n",
    "    <model-repository-path>/\n",
    "        <model-name>/\n",
    "            [config.pbtxt]\n",
    "            [<output-labels-file> ...]\n",
    "            <version>/\n",
    "                <model-definition-file>\n",
    "            <version>/\n",
    "                <model-definition-file>\n",
    "            ...\n",
    "        <model-name>/\n",
    "            [config.pbtxt]\n",
    "            [<output-labels-file> ...]\n",
    "            <version>/\n",
    "                <model-definition-file>\n",
    "            <version>/\n",
    "                <model-definition-file>\n",
    "        <ensemble-name>/\n",
    "            [config.pbtxt]\n",
    "            <version>/\n",
    "                empty\n",
    "            ...\n",
    "        ...\n",
    "```\n",
    "\n",
    "The ensemble model specification is primarily made up of `ensemble_scheduling` which is a series of steps that map inputs > outputs > inputs.  The steps are made up of key:value pairs that map the steps name for a variable or output to the name it should have within the ensemble.  While the names can be the same, it is also helpful to create unique naming in circumstances where naming can collide.\n",
    "\n",
    "Reference [Ensemble Models](https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/user_guide/architecture.html?highlight=ensemble#ensemble-models)\n",
    "\n",
    "\n",
    "**NOTE FOR THIS WORKFLOW**\n",
    "\n",
    "There are many models with many versions and each has a set of 30 features.  This would be a very tedious ensemble to code so instead, the use of strings and Python below build the ensembles `config.pbtxt` dynamically using the model repository information collected above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a87ebe8-c441-46a7-8aaf-b8865f2f3a4a",
   "metadata": {},
   "source": [
    "### Create The Header:\n",
    "\n",
    "Start the `config.pbtxt` construction with a string representing the header:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fc658f1e-1b33-40cd-ba67-71b101eb2602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"ensemble_all\"\n",
      "platform: \"ensemble\"\n",
      "max_batch_size: 4\n"
     ]
    }
   ],
   "source": [
    "ensemble_all = f\"\"\"name: \"ensemble_all\"\n",
    "platform: \"ensemble\"\n",
    "max_batch_size: 4\"\"\"\n",
    "\n",
    "print(ensemble_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1abcb6-8cf4-44fd-97cd-6c0e726007a8",
   "metadata": {},
   "source": [
    "### Note For Models and Versions\n",
    "\n",
    "The results create above show a prediction for each model and version.  The output also incude the name of the output, a layer from the TensorFlow model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b165a584-b5ca-4cfc-a352-a3d2068ed5b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logistic', 'prediction_layer'}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([results[r][2] for r in results])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d7e968-67f7-4ebf-b780-d22829a676fb",
   "metadata": {},
   "source": [
    "During development of the model, the output layer name changed.  This creates an issue because model configuration in NVIDIA Triton Inference Sever is done once at the model level.  In this workflow we are using the automatic configuration where it build the `config.pbtxt` file during startup.  This build uses the latest version of the model and set the output name accordingly.  This makes it difficult to incorporate earlier version of the model with different output names.  Either the model would need to be updated (which could break other systems using the model) or within Triton Severs Model Repository these would need to be represented by separate models.  In this case the change was made early on and the ensemble will build for only the versions with the latest output name: `logistic`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04afcf2-523d-405e-b76f-903e07c56981",
   "metadata": {},
   "source": [
    "### Add The Ensembles Inputs:\n",
    "\n",
    "Add the `input` specification for the ensemble using the feature names:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fe90bb-0cc3-418d-ad71-7037d6a837b6",
   "metadata": {},
   "source": [
    "List of input feature names to use for constructing the ensemble.  For this model all the input features have the same shape `[1, 1]` and data type `FP32`.  \n",
    "\n",
    "Note: This could be automated by loading a model and retriving its serving signature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c72f5cd4-7806-4a8f-ada8-55a4f7c4e971",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b6645ef9-53a8-46ff-8170-d90f43cdd079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"ensemble_all\"\n",
      "platform: \"ensemble\"\n",
      "max_batch_size: 4\n",
      "input [\n",
      "    {\n",
      "        name: \"Time\"\n",
      "        data_type: TYPE_FP32\n",
      "        dims: [ 1 ]\n",
      "    }, \n",
      "\n",
      "\n",
      "<2223 characters hidden>\n",
      "\n",
      "\n",
      " e: \"V28\"\n",
      "        data_type: TYPE_FP32\n",
      "        dims: [ 1 ]\n",
      "    },\n",
      "    {\n",
      "        name: \"Amount\"\n",
      "        data_type: TYPE_FP32\n",
      "        dims: [ 1 ]\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "ensemble_all += \"\\ninput [\"\n",
    "\n",
    "for n, name in enumerate(feature_names):\n",
    "    if ensemble_all.endswith('}'):\n",
    "        ensemble_all += \",\"\n",
    "    ensemble_all += f\"\"\"\n",
    "    {{\n",
    "        name: \"{name}\"\n",
    "        data_type: TYPE_FP32\n",
    "        dims: [ 1 ]\n",
    "    }}\"\"\"\n",
    "\n",
    "ensemble_all += \"\\n]\"\n",
    "        \n",
    "print(ensemble_all[0:150], f'\\n\\n\\n<{len(ensemble_all)-300} characters hidden>\\n\\n\\n', ensemble_all[-150:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e8acaa-3bc6-458a-98c1-bce644489a96",
   "metadata": {},
   "source": [
    "### Add The Ensembles Outputs:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a30b9c2-07df-4403-ba11-3bc3115f3a28",
   "metadata": {},
   "source": [
    "Add the `output` specification for the ensemble using the model names and versions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1fc1d052-fe29-453b-8b6c-e90b714eaac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"ensemble_all\"\n",
      "platform: \"ensemble\"\n",
      "max_batch_size: 4\n",
      "input [\n",
      "    {\n",
      "        name: \"Time\"\n",
      "        data_type: TYPE_FP32\n",
      "        dims: [ 1 ]\n",
      "    }, \n",
      "\n",
      "\n",
      "<13348 characters hidden>\n",
      "\n",
      "\n",
      "     dims: [ 2 ]\n",
      "        },\n",
      "        {\n",
      "            name: \"predictions_for_05_05i@4\"\n",
      "            data_type: TYPE_FP32\n",
      "            dims: [ 2 ]\n",
      "        }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "ensemble_all += \"\\noutput [\"\n",
    "\n",
    "for m, model in enumerate(results.keys()):\n",
    "    if results[model][2] == 'logistic':\n",
    "        if ensemble_all.endswith(\"}\"):\n",
    "            ensemble_all += \",\"\n",
    "        ensemble_all += f\"\"\"\n",
    "        {{\n",
    "            name: \"predictions_for_{model}\"\n",
    "            data_type: TYPE_FP32\n",
    "            dims: [ 2 ]\n",
    "        }}\"\"\"\n",
    "\n",
    "ensemble_all += \"\\n]\"\n",
    "        \n",
    "print(ensemble_all[0:150], f'\\n\\n\\n<{len(ensemble_all)-300} characters hidden>\\n\\n\\n', ensemble_all[-150:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3d3ee1-2aa9-44c0-833e-a53e91ada4f2",
   "metadata": {},
   "source": [
    "### Add The Ensemble Scheduling:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17d6b7d-ffa9-4685-a01d-3588daadf782",
   "metadata": {},
   "source": [
    "Build the `ensemble_scheduling` specification.  This is very large due to the number of models and input parameters.  Also, the output layer of each model has a variation in naming due to changes in the 05 series over time.  The `results` above include the output name and is used here to map the output of each model to the overall ensemble output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "81700865-b128-4af4-b04c-facae2a62fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ensemble_scheduling {\n",
      "    step [\n",
      "        {\n",
      "            model_name: \"05_05\"\n",
      "            model_version: 4\n",
      "            input_map {\n",
      "                key: \"Time\"\n",
      "                value: \"Time\"\n",
      "            }\n",
      "            input_map {\n",
      "                key: \"V1\"\n",
      "                value: \"V1\"\n",
      "            }\n",
      "        \n",
      "\n",
      "\n",
      "<270790 characters hidden>\n",
      "\n",
      "\n",
      "         key: \"V28\"\n",
      "                value: \"V28\"\n",
      "            }\n",
      "            input_map {\n",
      "                key: \"Amount\"\n",
      "                value: \"Amount\"\n",
      "            }\n",
      "            output_map {\n",
      "                key: \"logistic\"\n",
      "                value: \"predictions_for_05_05i@4\"\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# start the ensemble scheduling section:\n",
    "ensemble_scheduling = \"\"\"\n",
    "ensemble_scheduling {\n",
    "    step [\"\"\"\n",
    "\n",
    "# Build The input_map for all models:\n",
    "for n, name in enumerate(feature_names):\n",
    "    if n == 0:\n",
    "        input_map = \"\"\n",
    "    #else:\n",
    "    #    input_map += \",\"\n",
    "    input_map += f\"\"\"\n",
    "            input_map {{\n",
    "                key: \"{name}\"\n",
    "                value: \"{name}\"\n",
    "            }}\"\"\"\n",
    "\n",
    "# construct the ensemble scheduling:\n",
    "for m, model in enumerate(results.keys()):\n",
    "    if results[model][2] == 'logistic':\n",
    "        if ensemble_scheduling.endswith(\"}\"):\n",
    "            ensemble_scheduling += \",\"\n",
    "        ensemble_scheduling += f\"\"\"\n",
    "        {{\n",
    "            model_name: \"{model.split('@')[0]}\"\n",
    "            model_version: {model.split('@')[-1]}{input_map}\n",
    "            output_map {{\n",
    "                key: \"{results[model][2]}\"\n",
    "                value: \"predictions_for_{model}\"\n",
    "            }}\n",
    "        }}\"\"\"\n",
    "\n",
    "# finish the ensemble scheuling section:\n",
    "ensemble_scheduling += \"\"\"\n",
    "    ]\n",
    "}\"\"\"\n",
    "        \n",
    "print(ensemble_scheduling[0:300], f'\\n\\n\\n<{len(ensemble_scheduling)-600} characters hidden>\\n\\n\\n', ensemble_scheduling[-300:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b02fda-c0bd-48a7-a311-2eb562fe138b",
   "metadata": {},
   "source": [
    "Add the `ensemble_scheduling` specification to the overall ensemble specification in `ensemble_all`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b2ed364a-7ceb-44d2-adab-7427a4c9a1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_all = ensemble_all + ensemble_scheduling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4644e1-a4e4-4022-afb9-b88fb75b74da",
   "metadata": {},
   "source": [
    "### Add Then Ensemble To The Triton Server Model Repository:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe7f2ee-b82e-4ae0-847c-450272916bbd",
   "metadata": {},
   "source": [
    "Add the ensemble model to the model repository in GCS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1f5aeb42-a37c-4dd4-8db1-d4e069de9138",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = gcs.lookup_bucket(BUCKET)\n",
    "blob = bucket.blob(f'{SERIES}/{EXPERIMENT}/model_repo/ensemble_all/config.pbtxt')\n",
    "blob.upload_from_string(ensemble_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b0fc7c-6d7f-41c1-b859-d3934de5f04d",
   "metadata": {},
   "source": [
    "Review the `config.pbtxt` in the browser with the following link:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5970ee43-d9ab-4587-9889-151f630003e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://storage.cloud.google.com/statmike-mlops-349915/05/triton/model_repo/ensemble_all/config.pbtxt\n"
     ]
    }
   ],
   "source": [
    "print(f'https://storage.cloud.google.com/{BUCKET}/{SERIES}/{EXPERIMENT}/model_repo/ensemble_all/config.pbtxt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93bafd2-1ba4-4a7d-be43-9cdefe64480b",
   "metadata": {},
   "source": [
    "**NOTES ON TRITON MODEL REPOSITORY FOR ENSEMBLE**\n",
    "\n",
    "All models in the TRITON model repository need version folders. But what about ensemble models? While nothing is required in the version folder, it still seems to be required. Since the souce of the model repository is a GCS URI registered in Vertex AI Model Registry, and object storage does not have the concept of \"folders\", you find this error:\n",
    "\n",
    ">E0822 00:28:44.857235 1 model_repository_manager.cc:546] failed to load model 'ensemble_all': at least one version must be available under the version policy of model 'ensemble_all'\n",
    "\n",
    "To solve this, the following cells create an empty text file named `empty.txt` and copy it to the `/1/empty.txt` location of the ensemble model in the model registry folder of GCS.\n",
    "\n",
    "Check out [this related GitHub issue](https://github.com/triton-inference-server/server/issues/3623) for confirmation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "908cdfaf-6529-445e-9875-5c4b261483b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = bucket.blob(f'{SERIES}/{EXPERIMENT}/model_repo/ensemble_all/1/empty.txt')\n",
    "blob.upload_from_string('# just an empty file to help force the creation of a version folder: /1/empty.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40914ee7-c8a4-456e-aa03-02a4e1ad1ae4",
   "metadata": {},
   "source": [
    "### Register In Vertex AI Model Registry As A New Version\n",
    "\n",
    "Upload as a new version to the model above!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5277f47e-b047-4b4e-9244-aa14022f4a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "28dffea9-775d-4401-8aa8-119db958dab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_NAME = f'run-{TIMESTAMP}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc947e30-0ad6-4abf-bc59-e79e91432210",
   "metadata": {},
   "source": [
    "Check for existing version of the model in the model registry do one of the following:\n",
    "- Register as new model\n",
    "- Register as new version of existing model\n",
    "- Detect already registered model version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6d4a0833-f23e-4c35-a825-88258f319db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Already in Registry:\n",
      "Loading model as new default version.\n",
      "Creating Model\n",
      "Create Model backing LRO: projects/1026793852137/locations/us-central1/models/model_05_triton/operations/1864032505296846848\n",
      "Model created. Resource name: projects/1026793852137/locations/us-central1/models/model_05_triton@22\n",
      "To use this Model in another session:\n",
      "model = aiplatform.Model('projects/1026793852137/locations/us-central1/models/model_05_triton@22')\n"
     ]
    }
   ],
   "source": [
    "modelmatch = aiplatform.Model.list(filter = f'display_name={SERIES}_{EXPERIMENT} AND labels.series={SERIES} AND labels.experiment={EXPERIMENT}')\n",
    "\n",
    "upload_model = True\n",
    "if modelmatch:\n",
    "    print(\"Model Already in Registry:\")\n",
    "    if RUN_NAME in modelmatch[0].version_aliases:\n",
    "        print(\"This version already loaded, no action taken.\")\n",
    "        upload_model = False\n",
    "        vertex_model = aiplatform.Model(model_name = modelmatch[0].resource_name)\n",
    "    else:\n",
    "        print('Loading model as new default version.')\n",
    "        parent_model = modelmatch[0].resource_name\n",
    "\n",
    "else:\n",
    "    print('This is a new model, creating in model registry')\n",
    "    parent_model = ''\n",
    "\n",
    "if upload_model:\n",
    "    vertex_model = aiplatform.Model.upload(\n",
    "        display_name = f'{SERIES}_{EXPERIMENT}',\n",
    "        model_id = f'model_{SERIES}_{EXPERIMENT}',\n",
    "        parent_model =  parent_model,\n",
    "        serving_container_image_uri = AR_IMAGE,\n",
    "        serving_container_args = serving_container_args + ['--log-verbose=1'],\n",
    "        artifact_uri = f\"gs://{BUCKET}/{SERIES}/{EXPERIMENT}/model_repo\",\n",
    "        is_default_version = True,\n",
    "        version_aliases = [RUN_NAME],\n",
    "        version_description = RUN_NAME,\n",
    "        labels = {'series' : f'{SERIES}', 'experiment' : f'{EXPERIMENT}'}        \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a4615a4c-1f78-4cc9-8a88-c1df8e69bf22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model_05_triton'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vertex_model.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d77430a9-8100-40b3-8fb9-df2761f9e3ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'22'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vertex_model.version_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c9ee66be-30cf-43e5-a09d-60464cabdab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review the model in the Vertex AI Model Registry:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/models/model_05_triton?project=statmike-mlops-349915\n"
     ]
    }
   ],
   "source": [
    "print(f'Review the model in the Vertex AI Model Registry:\\nhttps://console.cloud.google.com/vertex-ai/locations/{REGION}/models/{vertex_model.name}?project={PROJECT_ID}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c70e21-7673-44a9-b8d6-7ec868b82c60",
   "metadata": {},
   "source": [
    "### Re-Deploy The Model To The Endpoint\n",
    "\n",
    "Note that the Vertex AI Model Registry has the information needed for the deployment:\n",
    "- URI of the serving container in Artifact Registry\n",
    "- URI of the model registry files in GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3f32c14a-857f-4833-8835-b1126e3461be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying model with 100% of traffic...\n",
      "Deploying Model projects/1026793852137/locations/us-central1/models/model_05_triton to Endpoint : projects/1026793852137/locations/us-central1/endpoints/8971471723908038656\n",
      "Deploy Endpoint model backing LRO: projects/1026793852137/locations/us-central1/endpoints/8971471723908038656/operations/3766803347860881408\n",
      "Endpoint model deployed. Resource name: projects/1026793852137/locations/us-central1/endpoints/8971471723908038656\n"
     ]
    }
   ],
   "source": [
    "if (vertex_model.display_name, vertex_model.version_id) not in [(d.display_name, d.model_version_id) for d in endpoint.list_models()]:\n",
    "    print(f'Deploying model with 100% of traffic...')\n",
    "    endpoint.deploy(\n",
    "        model = vertex_model,\n",
    "        deployed_model_display_name = vertex_model.display_name,\n",
    "        traffic_percentage = 100,\n",
    "        machine_type = 'n1-highmem-4',\n",
    "        min_replica_count = 1,\n",
    "        max_replica_count = 1,\n",
    "        #accelerator_type = 'NVIDIA_TESLA_T4',\n",
    "        accelerator_count = 0,\n",
    "        #service_account = SERVICE_ACCOUNT\n",
    "    )\n",
    "else:\n",
    "    print(f'Not deploying because model = {vertex_model.display_name} with version {vertex_model.version_id} is already on endpoint = {endpoint.display_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ff02d5a5-81a6-4020-a6c7-e7d526c49488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2275824142752153600': 100}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint.traffic_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cd7feb-4d61-42ad-9217-73d4719f9b93",
   "metadata": {},
   "source": [
    "#### Remove Deployed Models Without Traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4c0bb51d-7d04-48fb-84c5-18682a276250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 05_triton with version 22 has traffic = 100\n",
      "Undeploying Endpoint model: projects/1026793852137/locations/us-central1/endpoints/8971471723908038656\n",
      "Undeploy Endpoint model backing LRO: projects/1026793852137/locations/us-central1/endpoints/8971471723908038656/operations/2120737684056965120\n",
      "Endpoint model undeployed. Resource name: projects/1026793852137/locations/us-central1/endpoints/8971471723908038656\n",
      "Undeploying 05_triton with version 17 because it has no traffic.\n"
     ]
    }
   ],
   "source": [
    "for deployed_model in endpoint.list_models():\n",
    "    if deployed_model.id in endpoint.traffic_split:\n",
    "        print(f\"Model {deployed_model.display_name} with version {deployed_model.model_version_id} has traffic = {endpoint.traffic_split[deployed_model.id]}\")\n",
    "    else:\n",
    "        endpoint.undeploy(deployed_model_id = deployed_model.id)\n",
    "        print(f\"Undeploying {deployed_model.display_name} with version {deployed_model.model_version_id} because it has no traffic.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424a82d1-46a2-40aa-a535-68d541e5aa12",
   "metadata": {},
   "source": [
    "### Make A Prediction Request: Directly To Ensemble\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2120ac3c-5c15-4d2e-b952-db5daacb642f",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = !gcloud auth application-default print-access-token\n",
    "headers = {\n",
    "    \"content-type\": \"application/json; charset=utf-8\",\n",
    "    \"X-Vertex-Ai-Triton-Redirect\": f\"v2/models/ensemble_all/versions/1/infer\",\n",
    "    \"Authorization\": f'Bearer {token[0]}'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7ec72c30-a7b9-43ce-bf99-80d257a99dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(\n",
    "    f'https://{REGION}-aiplatform.googleapis.com/v1/{endpoint.resource_name}:rawPredict',\n",
    "    data = json.dumps(instances),\n",
    "    headers = headers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "bbad5974-790c-4fd2-a5cc-da9e96bd6a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'ensemble_all',\n",
       " 'model_version': '1',\n",
       " 'parameters': {'sequence_id': 0,\n",
       "  'sequence_start': False,\n",
       "  'sequence_end': False},\n",
       " 'outputs': [{'name': 'predictions_for_05_05i@4',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [5.811791492504881e-09, 1.0]},\n",
       "  {'name': 'predictions_for_05_05i@3',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [4.06037861466757e-06, 0.9999959468841553]},\n",
       "  {'name': 'predictions_for_05_05h@2',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [2.745789551283906e-08, 1.0]},\n",
       "  {'name': 'predictions_for_05_05g@3',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [1.0706844300045759e-08, 1.0]},\n",
       "  {'name': 'predictions_for_05_05f@53',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [9.6332977150837e-09, 1.0]},\n",
       "  {'name': 'predictions_for_05_05f@51',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [2.901783258124624e-10, 1.0]},\n",
       "  {'name': 'predictions_for_05_05h@3',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [0.0012768624583259225, 0.9987230896949768]},\n",
       "  {'name': 'predictions_for_05_05f@50',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [2.399341951786482e-07, 0.9999997615814209]},\n",
       "  {'name': 'predictions_for_05_05f@43',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [3.5185805700166384e-06, 0.9999964237213135]},\n",
       "  {'name': 'predictions_for_05_05f@40',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [1.112913105316693e-05, 0.9999889135360718]},\n",
       "  {'name': 'predictions_for_05_05f@37',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [8.750166671234183e-06, 0.9999912977218628]},\n",
       "  {'name': 'predictions_for_05_05f@36',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [9.51542972416064e-07, 0.9999990463256836]},\n",
       "  {'name': 'predictions_for_05_05f@35',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [1.775860702935006e-08, 1.0]},\n",
       "  {'name': 'predictions_for_05_05f@33',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [4.573918133132793e-08, 1.0]},\n",
       "  {'name': 'predictions_for_05_05f@32',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [1.1466735259091365e-06, 0.9999988079071045]},\n",
       "  {'name': 'predictions_for_05_05f@48',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [3.7124293612578185e-06, 0.9999963045120239]},\n",
       "  {'name': 'predictions_for_05_05f@30',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [3.9188776099763345e-06, 0.9999960660934448]},\n",
       "  {'name': 'predictions_for_05_05f@44',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [2.664240916772087e-08, 1.0]},\n",
       "  {'name': 'predictions_for_05_05a@16',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [1.4537241668222123e-06, 0.9999985694885254]},\n",
       "  {'name': 'predictions_for_05_05f@12',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [8.613544650870608e-07, 0.9999991655349731]},\n",
       "  {'name': 'predictions_for_05_05c@2',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [2.329068848894167e-07, 0.9999997615814209]},\n",
       "  {'name': 'predictions_for_05_05a@13',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [2.951645683424431e-08, 1.0]},\n",
       "  {'name': 'predictions_for_05_05f@47',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [3.013521165939892e-07, 0.9999996423721313]},\n",
       "  {'name': 'predictions_for_05_05a@14',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [3.2905511204717186e-08, 1.0]},\n",
       "  {'name': 'predictions_for_05_05f@18',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [6.696022580854333e-08, 0.9999998807907104]},\n",
       "  {'name': 'predictions_for_05_05b@4',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [3.0997771460761214e-08, 1.0]},\n",
       "  {'name': 'predictions_for_05_05a@15',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [1.232152499142103e-06, 0.9999988079071045]},\n",
       "  {'name': 'predictions_for_05_05f@41',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [2.055836603176431e-06, 0.9999979734420776]},\n",
       "  {'name': 'predictions_for_05_05a@8',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [8.965618292222644e-08, 0.9999998807907104]},\n",
       "  {'name': 'predictions_for_05_05f@38',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [9.919266119595704e-08, 0.9999998807907104]},\n",
       "  {'name': 'predictions_for_05_05@4',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [0.00027496935217641294, 0.9997250437736511]},\n",
       "  {'name': 'predictions_for_05_05@5',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [7.41387054858933e-07, 0.9999992847442627]},\n",
       "  {'name': 'predictions_for_05_05@7',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [4.8198103286267724e-08, 1.0]},\n",
       "  {'name': 'predictions_for_05_05a@6',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [1.9414549115026603e-06, 0.9999980926513672]},\n",
       "  {'name': 'predictions_for_05_05@10',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [1.5425715105266136e-07, 0.9999998807907104]},\n",
       "  {'name': 'predictions_for_05_05f@34',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [2.1925481874518482e-08, 1.0]},\n",
       "  {'name': 'predictions_for_05_05@11',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [1.264448087567871e-06, 0.9999986886978149]},\n",
       "  {'name': 'predictions_for_05_05f@13',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [1.1157206927236984e-06, 0.999998927116394]},\n",
       "  {'name': 'predictions_for_05_05a@3',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [1.7580636324510124e-07, 0.9999998807907104]},\n",
       "  {'name': 'predictions_for_05_05f@31',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [9.18858376053322e-08, 0.9999998807907104]},\n",
       "  {'name': 'predictions_for_05_05@6',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [1.0316722587333516e-08, 1.0]},\n",
       "  {'name': 'predictions_for_05_05f@10',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [1.5909849025774747e-05, 0.9999841451644897]},\n",
       "  {'name': 'predictions_for_05_05f@22',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [2.6661522767312817e-08, 1.0]},\n",
       "  {'name': 'predictions_for_05_05f@16',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [2.1774705771804292e-07, 0.9999997615814209]},\n",
       "  {'name': 'predictions_for_05_05c@3',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [2.9516904760384932e-06, 0.9999970197677612]},\n",
       "  {'name': 'predictions_for_05_05a@7',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [1.1230486762769942e-07, 0.9999998807907104]},\n",
       "  {'name': 'predictions_for_05_05f@19',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [2.1217012147189962e-07, 0.9999997615814209]},\n",
       "  {'name': 'predictions_for_05_05a@11',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [5.53159189564667e-08, 1.0]},\n",
       "  {'name': 'predictions_for_05_05@9',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [1.6301239611493656e-06, 0.9999983310699463]},\n",
       "  {'name': 'predictions_for_05_05b@3',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [9.872406963040703e-07, 0.9999990463256836]},\n",
       "  {'name': 'predictions_for_05_05f@45',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [6.257649829422007e-07, 0.9999994039535522]},\n",
       "  {'name': 'predictions_for_05_05f@39',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [8.771086868364364e-06, 0.9999911785125732]},\n",
       "  {'name': 'predictions_for_05_05e@3',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [2.0731920358230127e-06, 0.9999979734420776]},\n",
       "  {'name': 'predictions_for_05_05f@52',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [1.7712507371925312e-07, 0.9999998807907104]},\n",
       "  {'name': 'predictions_for_05_05a@12',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [8.220026757044252e-07, 0.9999991655349731]},\n",
       "  {'name': 'predictions_for_05_05f@2',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [1.76138907903578e-08, 1.0]},\n",
       "  {'name': 'predictions_for_05_05f@46',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [6.296632903968202e-08, 0.9999998807907104]},\n",
       "  {'name': 'predictions_for_05_05d@3',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [2.5223851451983137e-08, 1.0]},\n",
       "  {'name': 'predictions_for_05_05@12',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [3.807899773278223e-08, 1.0]},\n",
       "  {'name': 'predictions_for_05_05d@2',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [4.787157337204917e-08, 1.0]},\n",
       "  {'name': 'predictions_for_05_05@13',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [1.6803035407519928e-07, 0.9999998807907104]},\n",
       "  {'name': 'predictions_for_05_05g@2',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [1.7446410538468626e-08, 1.0]},\n",
       "  {'name': 'predictions_for_05_05a@9',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [2.886247784772422e-06, 0.9999971389770508]},\n",
       "  {'name': 'predictions_for_05_05@8',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [2.872277491405839e-07, 0.9999997615814209]},\n",
       "  {'name': 'predictions_for_05_05f@21',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [3.4036129470393917e-09, 1.0]},\n",
       "  {'name': 'predictions_for_05_05a@4',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [1.1811715012299828e-05, 0.9999881982803345]},\n",
       "  {'name': 'predictions_for_05_05a@5',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [6.46701181494791e-08, 0.9999998807907104]},\n",
       "  {'name': 'predictions_for_05_05f@20',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [2.0674156075983774e-07, 0.9999997615814209]},\n",
       "  {'name': 'predictions_for_05_05f@8',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [3.4206529164748645e-08, 1.0]},\n",
       "  {'name': 'predictions_for_05_05e@2',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [6.195059540914372e-07, 0.9999994039535522]},\n",
       "  {'name': 'predictions_for_05_05f@3',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [2.1414123239082983e-06, 0.9999978542327881]},\n",
       "  {'name': 'predictions_for_05_05f@11',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [3.083648891788471e-08, 1.0]},\n",
       "  {'name': 'predictions_for_05_05f@15',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [3.2545093286984184e-09, 1.0]},\n",
       "  {'name': 'predictions_for_05_05f@24',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [3.086735773649707e-07, 0.9999996423721313]},\n",
       "  {'name': 'predictions_for_05_05f@4',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [4.987031729797309e-07, 0.9999995231628418]},\n",
       "  {'name': 'predictions_for_05_05f@49',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [3.2284749522659695e-06, 0.9999967813491821]},\n",
       "  {'name': 'predictions_for_05_05f@5',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [1.0716568965563056e-08, 1.0]},\n",
       "  {'name': 'predictions_for_05_05f@6',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [9.031143832771704e-09, 1.0]},\n",
       "  {'name': 'predictions_for_05_05f@9',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [3.6490252597332073e-08, 1.0]},\n",
       "  {'name': 'predictions_for_05_05f@27',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [3.267560444442097e-08, 1.0]},\n",
       "  {'name': 'predictions_for_05_05a@10',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [3.381665436563708e-08, 1.0]},\n",
       "  {'name': 'predictions_for_05_05f@14',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [4.692959009844344e-06, 0.9999953508377075]},\n",
       "  {'name': 'predictions_for_05_05f@23',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [1.969748950614303e-07, 0.9999997615814209]},\n",
       "  {'name': 'predictions_for_05_05f@25',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [7.510194244275681e-09, 1.0]},\n",
       "  {'name': 'predictions_for_05_05f@26',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [4.5170881435296906e-07, 0.9999995231628418]},\n",
       "  {'name': 'predictions_for_05_05i@2',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [3.270858783821495e-08, 1.0]},\n",
       "  {'name': 'predictions_for_05_05f@42',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [4.4030761614521907e-07, 0.9999995231628418]},\n",
       "  {'name': 'predictions_for_05_05f@17',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [3.535849941727065e-07, 0.9999996423721313]},\n",
       "  {'name': 'predictions_for_05_05f@28',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [2.852113311746507e-06, 0.9999971389770508]},\n",
       "  {'name': 'predictions_for_05_05f@29',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [1, 2],\n",
       "   'data': [1.7646617322952807e-07, 0.9999998807907104]}]}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = json.loads(response.text)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9dcc67d3-4cdf-4566-b044-88912bd3d4ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('predictions_for_05_05i@4', 1, 1.0),\n",
       " ('predictions_for_05_05i@3', 1, 0.9999959468841553),\n",
       " ('predictions_for_05_05h@2', 1, 1.0),\n",
       " ('predictions_for_05_05g@3', 1, 1.0),\n",
       " ('predictions_for_05_05f@53', 1, 1.0),\n",
       " ('predictions_for_05_05f@51', 1, 1.0),\n",
       " ('predictions_for_05_05h@3', 1, 0.9987230896949768),\n",
       " ('predictions_for_05_05f@50', 1, 0.9999997615814209),\n",
       " ('predictions_for_05_05f@43', 1, 0.9999964237213135),\n",
       " ('predictions_for_05_05f@40', 1, 0.9999889135360718),\n",
       " ('predictions_for_05_05f@37', 1, 0.9999912977218628),\n",
       " ('predictions_for_05_05f@36', 1, 0.9999990463256836),\n",
       " ('predictions_for_05_05f@35', 1, 1.0),\n",
       " ('predictions_for_05_05f@33', 1, 1.0),\n",
       " ('predictions_for_05_05f@32', 1, 0.9999988079071045),\n",
       " ('predictions_for_05_05f@48', 1, 0.9999963045120239),\n",
       " ('predictions_for_05_05f@30', 1, 0.9999960660934448),\n",
       " ('predictions_for_05_05f@44', 1, 1.0),\n",
       " ('predictions_for_05_05a@16', 1, 0.9999985694885254),\n",
       " ('predictions_for_05_05f@12', 1, 0.9999991655349731),\n",
       " ('predictions_for_05_05c@2', 1, 0.9999997615814209),\n",
       " ('predictions_for_05_05a@13', 1, 1.0),\n",
       " ('predictions_for_05_05f@47', 1, 0.9999996423721313),\n",
       " ('predictions_for_05_05a@14', 1, 1.0),\n",
       " ('predictions_for_05_05f@18', 1, 0.9999998807907104),\n",
       " ('predictions_for_05_05b@4', 1, 1.0),\n",
       " ('predictions_for_05_05a@15', 1, 0.9999988079071045),\n",
       " ('predictions_for_05_05f@41', 1, 0.9999979734420776),\n",
       " ('predictions_for_05_05a@8', 1, 0.9999998807907104),\n",
       " ('predictions_for_05_05f@38', 1, 0.9999998807907104),\n",
       " ('predictions_for_05_05@4', 1, 0.9997250437736511),\n",
       " ('predictions_for_05_05@5', 1, 0.9999992847442627),\n",
       " ('predictions_for_05_05@7', 1, 1.0),\n",
       " ('predictions_for_05_05a@6', 1, 0.9999980926513672),\n",
       " ('predictions_for_05_05@10', 1, 0.9999998807907104),\n",
       " ('predictions_for_05_05f@34', 1, 1.0),\n",
       " ('predictions_for_05_05@11', 1, 0.9999986886978149),\n",
       " ('predictions_for_05_05f@13', 1, 0.999998927116394),\n",
       " ('predictions_for_05_05a@3', 1, 0.9999998807907104),\n",
       " ('predictions_for_05_05f@31', 1, 0.9999998807907104),\n",
       " ('predictions_for_05_05@6', 1, 1.0),\n",
       " ('predictions_for_05_05f@10', 1, 0.9999841451644897),\n",
       " ('predictions_for_05_05f@22', 1, 1.0),\n",
       " ('predictions_for_05_05f@16', 1, 0.9999997615814209),\n",
       " ('predictions_for_05_05c@3', 1, 0.9999970197677612),\n",
       " ('predictions_for_05_05a@7', 1, 0.9999998807907104),\n",
       " ('predictions_for_05_05f@19', 1, 0.9999997615814209),\n",
       " ('predictions_for_05_05a@11', 1, 1.0),\n",
       " ('predictions_for_05_05@9', 1, 0.9999983310699463),\n",
       " ('predictions_for_05_05b@3', 1, 0.9999990463256836),\n",
       " ('predictions_for_05_05f@45', 1, 0.9999994039535522),\n",
       " ('predictions_for_05_05f@39', 1, 0.9999911785125732),\n",
       " ('predictions_for_05_05e@3', 1, 0.9999979734420776),\n",
       " ('predictions_for_05_05f@52', 1, 0.9999998807907104),\n",
       " ('predictions_for_05_05a@12', 1, 0.9999991655349731),\n",
       " ('predictions_for_05_05f@2', 1, 1.0),\n",
       " ('predictions_for_05_05f@46', 1, 0.9999998807907104),\n",
       " ('predictions_for_05_05d@3', 1, 1.0),\n",
       " ('predictions_for_05_05@12', 1, 1.0),\n",
       " ('predictions_for_05_05d@2', 1, 1.0),\n",
       " ('predictions_for_05_05@13', 1, 0.9999998807907104),\n",
       " ('predictions_for_05_05g@2', 1, 1.0),\n",
       " ('predictions_for_05_05a@9', 1, 0.9999971389770508),\n",
       " ('predictions_for_05_05@8', 1, 0.9999997615814209),\n",
       " ('predictions_for_05_05f@21', 1, 1.0),\n",
       " ('predictions_for_05_05a@4', 1, 0.9999881982803345),\n",
       " ('predictions_for_05_05a@5', 1, 0.9999998807907104),\n",
       " ('predictions_for_05_05f@20', 1, 0.9999997615814209),\n",
       " ('predictions_for_05_05f@8', 1, 1.0),\n",
       " ('predictions_for_05_05e@2', 1, 0.9999994039535522),\n",
       " ('predictions_for_05_05f@3', 1, 0.9999978542327881),\n",
       " ('predictions_for_05_05f@11', 1, 1.0),\n",
       " ('predictions_for_05_05f@15', 1, 1.0),\n",
       " ('predictions_for_05_05f@24', 1, 0.9999996423721313),\n",
       " ('predictions_for_05_05f@4', 1, 0.9999995231628418),\n",
       " ('predictions_for_05_05f@49', 1, 0.9999967813491821),\n",
       " ('predictions_for_05_05f@5', 1, 1.0),\n",
       " ('predictions_for_05_05f@6', 1, 1.0),\n",
       " ('predictions_for_05_05f@9', 1, 1.0),\n",
       " ('predictions_for_05_05f@27', 1, 1.0),\n",
       " ('predictions_for_05_05a@10', 1, 1.0),\n",
       " ('predictions_for_05_05f@14', 1, 0.9999953508377075),\n",
       " ('predictions_for_05_05f@23', 1, 0.9999997615814209),\n",
       " ('predictions_for_05_05f@25', 1, 1.0),\n",
       " ('predictions_for_05_05f@26', 1, 0.9999995231628418),\n",
       " ('predictions_for_05_05i@2', 1, 1.0),\n",
       " ('predictions_for_05_05f@42', 1, 0.9999995231628418),\n",
       " ('predictions_for_05_05f@17', 1, 0.9999996423721313),\n",
       " ('predictions_for_05_05f@28', 1, 0.9999971389770508),\n",
       " ('predictions_for_05_05f@29', 1, 0.9999998807907104)]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(r['name'], np.argmax(r['data']), r['data'][np.argmax(r['data'])]) for r in result['outputs']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65abfc56-775f-4297-86b7-33a6c97ac432",
   "metadata": {},
   "source": [
    "---\n",
    "## Remove Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "ccf99dbd-1f7d-485c-9b8c-17c6d7b972af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#endpoint.delete(force = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "163600ad-8d71-4abb-aa48-d595bb347434",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vertex_model.delete()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-12.m110",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-12:m110"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
