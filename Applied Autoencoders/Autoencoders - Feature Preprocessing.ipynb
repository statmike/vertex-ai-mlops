{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d783fb5f",
   "metadata": {},
   "source": [
    "![tracker](https://us-central1-vertex-ai-mlops-369716.cloudfunctions.net/pixel-tracking?path=statmike%2Fvertex-ai-mlops%2FApplied+Autoencoders&file=Autoencoders+-+Feature+Preprocessing.ipynb)\n",
    "<!--- header table --->\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/statmike/vertex-ai-mlops/blob/main/Applied%20Autoencoders/Autoencoders%20-%20Feature%20Preprocessing.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\">\n",
    "      <br>Run in<br>Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https%3A%2F%2Fraw.githubusercontent.com%2Fstatmike%2Fvertex-ai-mlops%2Fmain%2FApplied%2520Autoencoders%2FAutoencoders%2520-%2520Feature%2520Preprocessing.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\">\n",
    "      <br>Run in<br>Colab Enterprise\n",
    "    </a>\n",
    "  </td>      \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/statmike/vertex-ai-mlops/blob/main/Applied%20Autoencoders/Autoencoders%20-%20Feature%20Preprocessing.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      <br>View on<br>GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/statmike/vertex-ai-mlops/main/Applied%20Autoencoders/Autoencoders%20-%20Feature%20Preprocessing.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      <br>Open in<br>Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561b0c10-b8ec-4138-9ddb-8c6944288d32",
   "metadata": {},
   "source": [
    "# Autoencoders - Feature Preprocessing\n",
    "\n",
    "How and where to do feature preprocessing: at the source, during input, within the model, or all of the above!\n",
    "\n",
    "This workflow build upon the basic concepts of prerprocessing used in [Autoencoders - Data To Training](./Autoencoders%20-%20Data%20To%20Training.ipynb). Here feature preprocessing is examined across the various step the data takes to get from source to training.\n",
    "\n",
    "---\n",
    "Part of the [series **Applied Autoencoders Series**](https://github.com/statmike/vertex-ai-mlops/blob/main/Applied%20Autoencoders/readme.md)\n",
    "\n",
    "A series of workflows focused on training and using autoencoders.  The series starts from the foundation of reading data efficiently and incrementally introduces concepts.\n",
    "\n",
    "---\n",
    "\n",
    "**Prerequisites**\n",
    "\n",
    "[01 - BigQuery - Table Data Source](../../01%20-%20Data%20Sources/01%20-%20BigQuery%20-%20Table%20Data%20Source.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f03877-fd86-41e2-909a-78a397229e2f",
   "metadata": {},
   "source": [
    "---\n",
    "## Colab Setup\n",
    "\n",
    "To run this notebook in Colab click [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/statmike/vertex-ai-mlops/blob/main/Applied%20Autoencoders/Autoencoders%20-%20Feature%20Preprocessing.ipynb) and run the cells in this section.  Otherwise, skip this section.\n",
    "\n",
    "This cell will authenticate to GCP (follow prompts in the popup)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a714e08b-46e0-4311-8087-7036e4232296",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'statmike-mlops-349915' # replace with project ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dab79b80-9b5c-4ebb-ada0-15d7226b28b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    !gcloud config set project {PROJECT_ID}\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba38cd5-2950-40ca-983a-70d1061cdc6d",
   "metadata": {},
   "source": [
    "---\n",
    "## Installs\n",
    "\n",
    "The list `packages` contains tuples of package import names and install names.  If the import name is not found then the install name is used to install quitely for the current user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "365f76ef-bf97-46c4-b625-0c9df7e50cd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tuples of (import name, install name)\n",
    "packages = [\n",
    "    ('google.cloud.bigquery', 'google-cloud-bigquery'),\n",
    "    ('google.cloud.bigquery_storage', 'google-cloud-bigquery-storage'),\n",
    "    ('bigframes', 'bigframes'),\n",
    "    ('pandas_gbq', 'pandas-gbq'),\n",
    "    ('tensorflow', 'tensorflow', '2.10'),\n",
    "    ('tensorflow_io', '--no-deps tensorflow-io'),\n",
    "    ('graphviz', 'graphviz'),\n",
    "    ('pydot', 'pydot')\n",
    "]\n",
    "\n",
    "import importlib\n",
    "install = False\n",
    "for package in packages:\n",
    "    if not importlib.util.find_spec(package[0]):\n",
    "        print(f'installing package {package[1]}')\n",
    "        install = True\n",
    "        !pip install {package[1]} -U -q --user\n",
    "    elif len(package) == 3:\n",
    "        if importlib.metadata.version(package[0]) < package[2]:\n",
    "            print(f'updating package {package[1]}')\n",
    "            install = True\n",
    "            !pip install {package[1]} -U -q --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3bb724b-c175-4412-967b-30312e5a8b53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!sudo apt-get -qq install graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6982013-6350-4c26-96b6-f1602abfb907",
   "metadata": {},
   "source": [
    "### Restart Kernel (If Installs Occured)\n",
    "\n",
    "After a kernel restart the code submission can start with the next cell after this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c552423-a52d-430f-94bf-75bc903a963c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if install:\n",
    "    import IPython\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282fa008-4057-4ef1-a249-1bb05229be49",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e9571b-5d0f-4136-bba6-09150d2152f9",
   "metadata": {},
   "source": [
    "inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3c2cc21-f7f8-42d2-8c37-cda0d3eae8b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'statmike-mlops-349915'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b264ff2-a8e8-48f5-91d3-12105c8086d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "EXPERIMENT = 'preprocess'\n",
    "SERIES = 'applied-autoencoders'\n",
    "\n",
    "# source data\n",
    "BQ_PROJECT = PROJECT_ID\n",
    "BQ_DATASET = 'fraud'\n",
    "BQ_TABLE = 'fraud_prepped'\n",
    "\n",
    "# specify a GCS Bucket\n",
    "GCS_BUCKET = PROJECT_ID\n",
    "\n",
    "# Model Training\n",
    "VAR_TARGET = 'Class'\n",
    "VAR_OMIT = 'transaction_id,splits' # add more variables to the string with comma delimiters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178fd0f2-b2e9-409d-8b3e-0338b69b42f0",
   "metadata": {},
   "source": [
    "packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c773b5a5-2d27-46e4-bcaa-dac230bcdb1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import bigquery_storage\n",
    "import bigframes.pandas as bpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import concurrent.futures\n",
    "\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow_io.bigquery import BigQueryClient\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00879a22-0565-4d61-99c5-8b0d7b46f38d",
   "metadata": {},
   "source": [
    "clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b992757-7128-48cb-b5e8-e7b83f074749",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bq = bigquery.Client(project = PROJECT_ID)\n",
    "bqstorage = bigquery_storage.BigQueryReadClient()\n",
    "bpd.options.bigquery.project = PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d79f2c-9d22-422d-833b-68d26e9467fb",
   "metadata": {},
   "source": [
    "---\n",
    "## Review Data\n",
    "\n",
    "The data source here was prepared in [01 - BigQuery - Table Data Source](../01%20-%20Data%20Sources/01%20-%20BigQuery%20-%20Table%20Data%20Source.ipynb).  In this notebook we will use prepared BigQuery table as input for TensorFlow.\n",
    "\n",
    "This is a table of 284,807 credit card transactions classified as fradulant or normal in the column `Class`.  In order protect confidentiality, the original features have been transformed using [principle component analysis (PCA)](https://en.wikipedia.org/wiki/Principal_component_analysis) into 28 features named `V1, V2, ... V28` (float).  Two descriptive features are provided without transformation by PCA:\n",
    "- `Time` (integer) is the seconds elapsed between the transaction and the earliest transaction in the table\n",
    "- `Amount` (float) is the value of the transaction\n",
    "\n",
    "The data preparation included added splits for machine learning with a column named `splits` with 80% for training (`TRAIN`), 10% for validation (`VALIDATE`) and 10% for testing (`TEST`).  Additionally, a unique identifier was added to each transaction, `transaction_id`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c1eebc-6614-48ff-9820-c1325edc1e91",
   "metadata": {},
   "source": [
    "Review the number of records for each level of the data splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05f5cd08-86c8-40e1-ba4a-683480464eab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    SELECT splits, count(*) as n\n",
      "    FROM `statmike-mlops-349915.fraud.fraud_prepped`\n",
      "    GROUP BY splits\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "    SELECT splits, count(*) as n\n",
    "    FROM `{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}`\n",
    "    GROUP BY splits\n",
    "\"\"\"\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd0e45f7-271e-40cf-bbe4-c762261dc5cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>splits</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST</td>\n",
       "      <td>28502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>228061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VALIDATE</td>\n",
       "      <td>28244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     splits       n\n",
       "0      TEST   28502\n",
       "1     TRAIN  228061\n",
       "2  VALIDATE   28244"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bq.query(query = query).to_dataframe()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m113"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
