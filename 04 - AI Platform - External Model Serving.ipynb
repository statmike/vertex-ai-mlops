{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "coated-revelation",
   "metadata": {},
   "source": [
    "# AI Platform - External Model Serving\n",
    "\n",
    "This notebook uses an AI Platform Notebook to train a TensorFlow model (locally) with the data in BigQuery table `<PROJECT_ID>.digits.digits_prepped`.  This model is then saved and AI Platform clients are used to upload the model and deploy it to an endpoint for online predictions.\n",
    "\n",
    "**Prerequisites**\n",
    "- `00 - Initial Setup`\n",
    "- `01 - BigQuery - Data`\n",
    "\n",
    "**Overview**\n",
    "\n",
    "<img src=\"architectures/statmike-mlops-04.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-parcel",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fallen-faculty",
   "metadata": {},
   "source": [
    "Prepare TensorFlow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "vital-bride",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow._api.v2.experimental' has no attribute 'register_filesystem_plugin'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-493257f76a93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbigquery\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBigQueryClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbigquery\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBigQueryReadSession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_io/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\"\"\"tensorflow_io\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv0\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# pylint: disable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVERSION\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_io/core/python/api/v0/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# tensorflow_io.core.python.ops is implicitly imported (along with file system)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIODataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio_tensor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIOTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_io/core/python/ops/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0mcore_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLazyLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"core_ops\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"libtensorflow_io.so\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0mplugin_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"libtensorflow_io_plugins.so\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;31m# Note: load libtensorflow_io.so imperatively in case of statically linking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_io/core/python/ops/__init__.py\u001b[0m in \u001b[0;36m_load_library\u001b[0;34m(filename, lib)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_io/core/python/ops/__init__.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mload_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRTLD_GLOBAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mlib\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"fs\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mload_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_filesystem_plugin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mload_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_file_system_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow._api.v2.experimental' has no attribute 'register_filesystem_plugin'"
     ]
    }
   ],
   "source": [
    "from tensorflow_io.bigquery import BigQueryClient\n",
    "from tensorflow_io.bigquery import BigQueryReadSession\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "presidential-bacon",
   "metadata": {},
   "source": [
    "Setup Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alike-secretary",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID='statmike-mlops'\n",
    "REGION='us-central1'\n",
    "\n",
    "BQDATASET_ID='digits'\n",
    "BQTABLE_ID='digits_prepped'\n",
    "\n",
    "MODEL_DIR='gs://{}/digits/keras'.format(PROJECT_ID)\n",
    "PARENT = \"projects/\" + PROJECT_ID + \"/locations/\" + REGION\n",
    "\n",
    "BATCH_SIZE = 30\n",
    "\n",
    "MODEL_NAME='MODEL_KERAS-DIGITS'\n",
    "ENDPOINT_NAME='ENDPOINT_KERAS-DIGITS'\n",
    "params = {\"MODEL_DIR\":MODEL_DIR}\n",
    "DEPLOY_IMAGE='us-docker.pkg.dev/cloud-aiplatform/prediction/tf2-cpu.2-2:latest'\n",
    "DEPLOY_COMPUTE='n1-standard-4'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utility-detail",
   "metadata": {},
   "source": [
    "Setup AI Platform Python Clients\n",
    "- https://googleapis.dev/python/aiplatform/latest/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "temporal-memorabilia",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "API_ENDPOINT = \"{}-aiplatform.googleapis.com\".format(REGION)\n",
    "client_options = {\"api_endpoint\": API_ENDPOINT}\n",
    "clients = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emerging-contamination",
   "metadata": {},
   "source": [
    "---\n",
    "## Prepare Data Connection\n",
    "\n",
    "Retrieve the Schema info from BigQuery Information Schema via the Storage API:\n",
    "- https://cloud.google.com/bigquery/docs/bigquery-storage-python-pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historical-pencil",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "bqclient = bigquery.Client()\n",
    "bqjob = bqclient.query(\n",
    "\"\"\"\n",
    "SELECT * FROM `\"\"\"+BQDATASET_ID+\"\"\".INFORMATION_SCHEMA.COLUMN_FIELD_PATHS`\n",
    "WHERE TABLE_NAME = '\"\"\"+BQTABLE_ID+\"\"\"' \"\"\"\n",
    ")\n",
    "schema = bqjob.result().to_dataframe()\n",
    "schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spiritual-communications",
   "metadata": {},
   "source": [
    "Use the the table schema to prepare the TensorFlow Model:\n",
    "- Omit unused columns\n",
    "- Create `feature_columns` for the model\n",
    "- Define the `dtypes` for TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "attractive-europe",
   "metadata": {},
   "outputs": [],
   "source": [
    "OMIT = ['target_OE','SPLITS']\n",
    "\n",
    "selected_fields = schema[~schema.column_name.isin(OMIT)].column_name.tolist()\n",
    "\n",
    "feature_columns = []\n",
    "feature_layer_inputs = {}\n",
    "for header in selected_fields:\n",
    "    if header != 'target':\n",
    "        feature_columns.append(tf.feature_column.numeric_column(header))\n",
    "        feature_layer_inputs[header] = tf.keras.Input(shape=(1,),name=header)\n",
    "\n",
    "from tensorflow.python.framework import dtypes\n",
    "output_types = schema[~schema.column_name.isin(OMIT)].data_type.tolist()\n",
    "output_types = [dtypes.float64 if x=='FLOAT64' else dtypes.int64 for x in output_types]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powered-delaware",
   "metadata": {},
   "source": [
    "Define a function that remaps the input data for TensorFlow into features, target and one_hot encodes the `target`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aggregate-pride",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transTable(row_dict):\n",
    "    target=row_dict.pop('target')\n",
    "    target = tf.one_hot(tf.cast(target,tf.int64),10)\n",
    "    target = tf.cast(target,tf.float32)\n",
    "    return(row_dict,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entire-chicken",
   "metadata": {},
   "source": [
    "Setup TensorFlow_IO client > session > table + table.map\n",
    "- https://www.tensorflow.org/io/api_docs/python/tfio/bigquery/BigQueryClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "coated-prisoner",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = BigQueryClient()\n",
    "session = client.read_session(\"projects/\"+PROJECT_ID,PROJECT_ID,BQTABLE_ID,BQDATASET_ID,selected_fields,output_types,row_restriction=\"SPLITS='TRAIN'\",requested_streams=3)\n",
    "table = session.parallel_read_rows()\n",
    "table = table.map(transTable)\n",
    "train = table.shuffle(100000).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "departmental-generation",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = BigQueryClient()\n",
    "session = client.read_session(\"projects/\"+PROJECT_ID,PROJECT_ID,BQTABLE_ID,BQDATASET_ID,selected_fields,output_types,row_restriction=\"SPLITS='TEST'\",requested_streams=3)\n",
    "table = session.parallel_read_rows()\n",
    "table = table.map(transTable)\n",
    "test = table.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imposed-interest",
   "metadata": {},
   "source": [
    "Review a single batch of the train data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "existing-disco",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns:  ['p0', 'p1', 'p10', 'p11', 'p12', 'p13', 'p14', 'p15', 'p16', 'p17', 'p18', 'p19', 'p2', 'p20', 'p21', 'p22', 'p23', 'p24', 'p25', 'p26', 'p27', 'p28', 'p29', 'p3', 'p30', 'p31', 'p32', 'p33', 'p34', 'p35', 'p36', 'p37', 'p38', 'p39', 'p4', 'p40', 'p41', 'p42', 'p43', 'p44', 'p45', 'p46', 'p47', 'p48', 'p49', 'p5', 'p50', 'p51', 'p52', 'p53', 'p54', 'p55', 'p56', 'p57', 'p58', 'p59', 'p6', 'p60', 'p61', 'p62', 'p63', 'p7', 'p8', 'p9']\n",
      "target:  tf.Tensor(\n",
      "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]], shape=(30, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for a, b in train.take(1):\n",
    "    columns=list(a.keys())\n",
    "    print('columns: ',columns)\n",
    "    print('target: ',b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "provincial-broadcasting",
   "metadata": {},
   "source": [
    "---\n",
    "## Train the Model\n",
    "\n",
    "Define the Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "split-abraham",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)\n",
    "feature_layer_outputs = feature_layer(feature_layer_inputs)\n",
    "model = tf.keras.Model(inputs=[v for v in feature_layer_inputs.values()],outputs=tf.keras.layers.Dense(10,activation=tf.nn.softmax)(feature_layer_outputs))\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#tf.keras.utils.plot_model(model,show_shapes=True, show_dtype=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "recovered-timer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressing-lounge",
   "metadata": {},
   "source": [
    "Fit the Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "similar-address",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "49/49 [==============================] - 3s 8ms/step - loss: 5.4327 - accuracy: 0.3615\n",
      "Epoch 2/25\n",
      "49/49 [==============================] - 1s 8ms/step - loss: 0.6904 - accuracy: 0.8120\n",
      "Epoch 3/25\n",
      "49/49 [==============================] - 1s 7ms/step - loss: 0.4632 - accuracy: 0.8692\n",
      "Epoch 4/25\n",
      "49/49 [==============================] - 1s 9ms/step - loss: 0.3334 - accuracy: 0.8935\n",
      "Epoch 5/25\n",
      "49/49 [==============================] - 1s 10ms/step - loss: 0.2654 - accuracy: 0.9265\n",
      "Epoch 6/25\n",
      "49/49 [==============================] - 1s 5ms/step - loss: 0.2185 - accuracy: 0.9378\n",
      "Epoch 7/25\n",
      "49/49 [==============================] - 1s 9ms/step - loss: 0.2198 - accuracy: 0.9306\n",
      "Epoch 8/25\n",
      "49/49 [==============================] - 1s 10ms/step - loss: 0.1562 - accuracy: 0.9490\n",
      "Epoch 9/25\n",
      "49/49 [==============================] - 1s 9ms/step - loss: 0.1232 - accuracy: 0.9576\n",
      "Epoch 10/25\n",
      "49/49 [==============================] - 1s 10ms/step - loss: 0.1234 - accuracy: 0.9741\n",
      "Epoch 11/25\n",
      "49/49 [==============================] - 1s 9ms/step - loss: 0.1220 - accuracy: 0.9622\n",
      "Epoch 12/25\n",
      "49/49 [==============================] - 1s 5ms/step - loss: 0.1144 - accuracy: 0.9629\n",
      "Epoch 13/25\n",
      "49/49 [==============================] - 1s 9ms/step - loss: 0.1090 - accuracy: 0.9684\n",
      "Epoch 14/25\n",
      "49/49 [==============================] - 1s 10ms/step - loss: 0.0771 - accuracy: 0.9787\n",
      "Epoch 15/25\n",
      "49/49 [==============================] - 1s 7ms/step - loss: 0.1051 - accuracy: 0.9719\n",
      "Epoch 16/25\n",
      "49/49 [==============================] - 1s 8ms/step - loss: 0.1195 - accuracy: 0.9671\n",
      "Epoch 17/25\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.0703 - accuracy: 0.9786\n",
      "Epoch 18/25\n",
      "49/49 [==============================] - 1s 9ms/step - loss: 0.0908 - accuracy: 0.9744\n",
      "Epoch 19/25\n",
      "49/49 [==============================] - 1s 7ms/step - loss: 0.0707 - accuracy: 0.9851\n",
      "Epoch 20/25\n",
      "49/49 [==============================] - 1s 9ms/step - loss: 0.0800 - accuracy: 0.9795\n",
      "Epoch 21/25\n",
      "49/49 [==============================] - 1s 6ms/step - loss: 0.0719 - accuracy: 0.9812\n",
      "Epoch 22/25\n",
      "49/49 [==============================] - 2s 11ms/step - loss: 0.0741 - accuracy: 0.9828\n",
      "Epoch 23/25\n",
      "49/49 [==============================] - 1s 8ms/step - loss: 0.0734 - accuracy: 0.9810\n",
      "Epoch 24/25\n",
      "49/49 [==============================] - 1s 8ms/step - loss: 0.0628 - accuracy: 0.9863\n",
      "Epoch 25/25\n",
      "49/49 [==============================] - 1s 9ms/step - loss: 0.0611 - accuracy: 0.9804\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train,epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adverse-sapphire",
   "metadata": {},
   "source": [
    "Evaluate the model with the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "based-webmaster",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 2s 11ms/step - loss: 0.1230 - accuracy: 0.9491\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-storm",
   "metadata": {},
   "source": [
    "Create Prediction from a batch of the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "enhanced-walter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.02995135e-07, 9.73487258e-01, 1.84339240e-06, 6.80787722e-03,\n",
       "        2.17787274e-05, 1.29038608e-05, 3.81712191e-08, 1.42034696e-05,\n",
       "        2.89012387e-04, 1.93645731e-02],\n",
       "       [1.04811237e-09, 4.58381295e-01, 5.80528103e-06, 1.38176896e-03,\n",
       "        7.20336247e-05, 7.80577200e-11, 5.48565549e-05, 1.55116959e-05,\n",
       "        5.40088713e-01, 5.36114797e-08],\n",
       "       [4.23839097e-09, 9.77244258e-01, 7.73140769e-08, 7.55626525e-06,\n",
       "        2.24697925e-02, 1.06107381e-08, 1.76585431e-07, 2.71904423e-06,\n",
       "        2.69031239e-04, 6.41386032e-06],\n",
       "       [5.41244723e-11, 9.99505639e-01, 3.32350640e-12, 1.76868454e-07,\n",
       "        4.40015050e-04, 2.05316292e-10, 7.37809103e-09, 1.90663388e-06,\n",
       "        4.72779102e-05, 4.97291967e-06],\n",
       "       [4.18799440e-11, 9.99966979e-01, 7.42060857e-10, 8.54187931e-07,\n",
       "        1.00361985e-05, 9.39127531e-09, 1.03046371e-09, 2.45011389e-08,\n",
       "        2.80012841e-06, 1.92962107e-05],\n",
       "       [1.95367070e-10, 9.94653940e-01, 7.72150486e-08, 6.16667285e-06,\n",
       "        5.33355586e-03, 4.50272886e-08, 1.23074983e-06, 1.69662869e-07,\n",
       "        3.72164641e-06, 1.23901953e-06],\n",
       "       [6.61269789e-11, 3.38954618e-03, 1.08089326e-09, 1.65108760e-10,\n",
       "        9.96552944e-01, 3.23359173e-10, 2.33406740e-06, 5.44278919e-05,\n",
       "        7.01713077e-07, 8.52085804e-14],\n",
       "       [3.63539669e-08, 1.29033215e-02, 1.73322618e-07, 2.72958641e-05,\n",
       "        9.38274443e-01, 6.58121166e-07, 4.82583372e-03, 5.43344649e-04,\n",
       "        4.34249267e-02, 2.24310459e-09],\n",
       "       [4.93555889e-02, 2.39570509e-03, 5.26465101e-07, 7.58812346e-10,\n",
       "        2.70732135e-01, 1.86980615e-05, 6.77353740e-01, 1.34496178e-04,\n",
       "        9.06589048e-06, 2.60140954e-12],\n",
       "       [2.64300586e-04, 2.05243155e-01, 3.79169229e-09, 1.06859488e-05,\n",
       "        4.55658883e-01, 5.73091500e-04, 1.14959747e-01, 1.28431851e-03,\n",
       "        9.59758312e-02, 1.26029909e-01],\n",
       "       [9.04473805e-12, 9.99846220e-01, 4.38288794e-07, 2.82746387e-05,\n",
       "        2.85935294e-05, 1.68672614e-08, 9.23314545e-08, 2.70883874e-07,\n",
       "        8.59923603e-05, 1.00880006e-05],\n",
       "       [7.47636548e-08, 2.99118511e-07, 4.28061666e-12, 6.33772534e-10,\n",
       "        9.99267519e-01, 1.75677954e-07, 7.31692533e-04, 3.86731891e-08,\n",
       "        2.43766294e-07, 1.78538824e-14],\n",
       "       [2.36622144e-09, 2.20960425e-03, 4.39468153e-07, 1.84381997e-06,\n",
       "        3.46995413e-01, 1.45898142e-07, 3.03818434e-01, 5.77825376e-05,\n",
       "        3.46916318e-01, 3.95205882e-11],\n",
       "       [3.16750478e-13, 2.66531715e-04, 2.28787394e-13, 1.12772701e-10,\n",
       "        9.99725759e-01, 2.77269296e-09, 6.96137113e-06, 6.58009526e-07,\n",
       "        1.15083346e-07, 1.43956272e-13],\n",
       "       [7.51711070e-07, 5.17376184e-01, 5.71215896e-05, 1.74965500e-03,\n",
       "        4.38298613e-01, 7.71551913e-06, 1.10045914e-03, 3.02417931e-08,\n",
       "        4.13246900e-02, 8.48078998e-05],\n",
       "       [1.56348975e-07, 2.88444971e-06, 1.55530398e-11, 3.47063578e-09,\n",
       "        9.99984264e-01, 2.46669657e-10, 1.13563488e-06, 8.96647089e-06,\n",
       "        2.58889577e-06, 3.59469010e-09],\n",
       "       [8.24410193e-08, 3.99193434e-09, 5.96294125e-11, 2.64466897e-17,\n",
       "        9.99947786e-01, 3.35263262e-09, 5.20414069e-05, 7.13740800e-09,\n",
       "        4.12052545e-11, 9.73093784e-18],\n",
       "       [7.30383907e-13, 1.48698464e-05, 1.96058908e-13, 1.37067330e-10,\n",
       "        9.99984264e-01, 7.95455628e-12, 3.32730421e-09, 9.01615749e-07,\n",
       "        2.13188169e-08, 3.11275528e-13],\n",
       "       [3.82666017e-11, 9.99619365e-01, 8.00632824e-06, 4.07697200e-07,\n",
       "        1.56618014e-04, 4.30288928e-05, 1.55054113e-06, 8.87912606e-08,\n",
       "        1.52750275e-04, 1.81901705e-05],\n",
       "       [1.87162404e-11, 5.32450431e-05, 1.45660775e-11, 1.24350660e-12,\n",
       "        9.99946594e-01, 2.29880980e-12, 4.19042401e-08, 1.16132789e-07,\n",
       "        2.06235420e-08, 2.86146873e-14],\n",
       "       [1.50194857e-11, 1.51568980e-04, 6.76432738e-12, 5.11021847e-09,\n",
       "        9.99841809e-01, 1.50231910e-10, 6.17211481e-06, 1.55963946e-07,\n",
       "        2.41703844e-07, 1.60827504e-12],\n",
       "       [3.44344997e-04, 7.45659985e-04, 2.48895535e-08, 1.17133470e-06,\n",
       "        1.29039904e-06, 6.27911186e-06, 1.94711677e-11, 5.29347344e-05,\n",
       "        5.33161119e-06, 9.98842955e-01],\n",
       "       [1.81953492e-05, 4.36623995e-05, 1.65648274e-02, 1.96703207e-02,\n",
       "        7.08689413e-06, 5.39548128e-05, 4.95459361e-04, 1.14033602e-01,\n",
       "        3.51670387e-05, 8.49077761e-01],\n",
       "       [1.67206492e-11, 9.99557793e-01, 6.82586290e-07, 1.61148055e-05,\n",
       "        3.08939896e-04, 9.43589157e-07, 4.60021920e-06, 1.47142938e-08,\n",
       "        1.08753513e-04, 2.16553394e-06],\n",
       "       [5.34551500e-11, 9.99925256e-01, 4.60211247e-08, 2.46396659e-09,\n",
       "        6.21822255e-05, 3.67418700e-08, 1.38583957e-07, 8.07621916e-08,\n",
       "        8.21250433e-06, 4.09607355e-06],\n",
       "       [4.39897007e-13, 1.23850150e-05, 3.09868708e-14, 2.81503744e-11,\n",
       "        9.99985099e-01, 2.71476308e-09, 2.76854166e-07, 2.28915405e-06,\n",
       "        1.27664523e-09, 5.63433978e-12],\n",
       "       [4.10913005e-11, 4.24427725e-07, 1.73072288e-12, 4.10207052e-13,\n",
       "        9.99999404e-01, 6.63756420e-12, 1.06310416e-07, 4.44733494e-08,\n",
       "        2.14195972e-09, 6.44759997e-15],\n",
       "       [1.29637023e-09, 6.83944882e-06, 2.10836708e-12, 7.54283025e-11,\n",
       "        9.99980688e-01, 2.90857061e-10, 7.76941889e-08, 1.23053615e-05,\n",
       "        3.23436105e-08, 1.59689026e-10],\n",
       "       [6.21719787e-09, 1.71697448e-11, 5.41473401e-14, 6.46363515e-15,\n",
       "        1.00000000e+00, 4.41832579e-13, 1.62406710e-08, 3.13641806e-08,\n",
       "        1.76737430e-10, 1.08691680e-12],\n",
       "       [1.25458928e-06, 5.51856682e-02, 2.01811185e-04, 1.96784214e-10,\n",
       "        1.02012450e-06, 3.50132834e-09, 9.44216371e-01, 2.48300630e-10,\n",
       "        3.93808383e-04, 3.20633520e-11]], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test.take(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designed-milwaukee",
   "metadata": {},
   "source": [
    "---\n",
    "## Save the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "vulnerable-vegetarian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: gs://statmike-mlops/digits/keras/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "british-breathing",
   "metadata": {},
   "source": [
    "---\n",
    "## Upload the Model to AI Platform\n",
    "\n",
    "Create a client to the Model Service, define the Model, and upload the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "valued-current",
   "metadata": {},
   "outputs": [],
   "source": [
    "clients['model'] = aiplatform.gapic.ModelServiceClient(client_options=client_options)\n",
    "\n",
    "MODEL = {\n",
    "    \"display_name\": MODEL_NAME,\n",
    "    \"metadata_schema_uri\": \"\",\n",
    "    \"artifact_uri\": MODEL_DIR,\n",
    "    \"container_spec\": {\n",
    "        \"image_uri\": DEPLOY_IMAGE,\n",
    "        \"command\": [],\n",
    "        \"args\": [],\n",
    "        \"env\": [],\n",
    "        \"ports\": [{\"container_port\": 8080}],\n",
    "        \"predict_route\": \"\",\n",
    "        \"health_route\": \"\"\n",
    "    }\n",
    "}\n",
    "\n",
    "uploaded_model = clients['model'].upload_model(parent=PARENT, model=MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vietnamese-vehicle",
   "metadata": {},
   "source": [
    "Retrieve the model information and view the name and display name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "norwegian-booking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('MODEL_KERAS-DIGITS',\n",
       " 'projects/691911073727/locations/us-central1/models/945703145189670912')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_info = clients['model'].get_model(name=uploaded_model.result(timeout=180).model)\n",
    "model_info.display_name, model_info.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appreciated-summary",
   "metadata": {},
   "source": [
    "---\n",
    "## Create the AI Platform Endpoint\n",
    "\n",
    "Create a client to the Endpoint Service and use it to create the endpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "saving-sponsorship",
   "metadata": {},
   "outputs": [],
   "source": [
    "clients['endpoint'] = aiplatform.gapic.EndpointServiceClient(client_options=client_options)\n",
    "\n",
    "endpoint = clients['endpoint'].create_endpoint(parent=PARENT, endpoint={\"display_name\": ENDPOINT_NAME})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "social-reliance",
   "metadata": {},
   "source": [
    "Retrieve the endpoint information and view the name and display name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "complimentary-institute",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ENDPOINT_KERAS-DIGITS',\n",
       " 'projects/691911073727/locations/us-central1/endpoints/6521933540060299264')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint_info = clients['endpoint'].get_endpoint(name=endpoint.result(timeout=180).name)\n",
    "endpoint_info.display_name, endpoint_info.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hairy-glenn",
   "metadata": {},
   "source": [
    "---\n",
    "## Deploy the Model to the AI Platform Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "eligible-poverty",
   "metadata": {},
   "outputs": [],
   "source": [
    "DMODEL = {\n",
    "        \"model\": model_info.name,\n",
    "        \"display_name\": 'DEPLOYED_'+MODEL_NAME,\n",
    "        \"dedicated_resources\": {\n",
    "            \"min_replica_count\": 1,\n",
    "            \"max_replica_count\": 1,\n",
    "            \"machine_spec\": {\n",
    "                    \"machine_type\": DEPLOY_COMPUTE,\n",
    "                    \"accelerator_count\": 0,\n",
    "                }\n",
    "        }   \n",
    "}\n",
    "\n",
    "TRAFFIC = {\n",
    "    '0' : 100\n",
    "}\n",
    "\n",
    "dmodel = clients['endpoint'].deploy_model(endpoint=endpoint_info.name, deployed_model=DMODEL, traffic_split=TRAFFIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-trance",
   "metadata": {},
   "source": [
    "Retrieve the deployed model information from the endpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "caring-circular",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[id: \"7863935860272529408\"\n",
       "model: \"projects/691911073727/locations/us-central1/models/945703145189670912\"\n",
       "display_name: \"DEPLOYED_MODEL_KERAS-DIGITS\"\n",
       "create_time {\n",
       "  seconds: 1618274179\n",
       "  nanos: 458109000\n",
       "}\n",
       "dedicated_resources {\n",
       "  machine_spec {\n",
       "    machine_type: \"n1-standard-4\"\n",
       "  }\n",
       "  min_replica_count: 1\n",
       "  max_replica_count: 1\n",
       "}\n",
       "]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients['endpoint'].get_endpoint(name=endpoint_info.name).deployed_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "british-resident",
   "metadata": {},
   "source": [
    "---\n",
    "## Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-dictionary",
   "metadata": {},
   "source": [
    "Create a client to the prediction service:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ethical-diagram",
   "metadata": {},
   "outputs": [],
   "source": [
    "clients['prediction'] = aiplatform.gapic.PredictionServiceClient(client_options=client_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baking-exchange",
   "metadata": {},
   "source": [
    "Setup an observation for prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "passing-living",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery pred\n",
    "SELECT *\n",
    "FROM `digits.digits_prepped`\n",
    "WHERE splits='TEST'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "through-frost",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p0</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>p5</th>\n",
       "      <th>p6</th>\n",
       "      <th>p7</th>\n",
       "      <th>p8</th>\n",
       "      <th>p9</th>\n",
       "      <th>...</th>\n",
       "      <th>p57</th>\n",
       "      <th>p58</th>\n",
       "      <th>p59</th>\n",
       "      <th>p60</th>\n",
       "      <th>p61</th>\n",
       "      <th>p62</th>\n",
       "      <th>p63</th>\n",
       "      <th>target</th>\n",
       "      <th>target_OE</th>\n",
       "      <th>SPLITS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Even</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    p0   p1   p2    p3    p4   p5   p6   p7   p8   p9  ...  p57  p58  p59  \\\n",
       "0  0.0  0.0  0.0  10.0  11.0  1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  9.0   \n",
       "\n",
       "    p60   p61  p62  p63  target  target_OE  SPLITS  \n",
       "0  15.0  14.0  5.0  0.0       0       Even    TEST  \n",
       "\n",
       "[1 rows x 67 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "wrapped-blond",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'p0': 0.0,\n",
       " 'p1': 0.0,\n",
       " 'p2': 0.0,\n",
       " 'p3': 10.0,\n",
       " 'p4': 11.0,\n",
       " 'p5': 1.0,\n",
       " 'p6': 0.0,\n",
       " 'p7': 0.0,\n",
       " 'p8': 0.0,\n",
       " 'p9': 0.0,\n",
       " 'p10': 1.0,\n",
       " 'p11': 15.0,\n",
       " 'p12': 8.0,\n",
       " 'p13': 8.0,\n",
       " 'p14': 0.0,\n",
       " 'p15': 0.0,\n",
       " 'p16': 0.0,\n",
       " 'p17': 5.0,\n",
       " 'p18': 4.0,\n",
       " 'p19': 10.0,\n",
       " 'p20': 0.0,\n",
       " 'p21': 12.0,\n",
       " 'p22': 0.0,\n",
       " 'p23': 0.0,\n",
       " 'p24': 0.0,\n",
       " 'p25': 7.0,\n",
       " 'p26': 8.0,\n",
       " 'p27': 10.0,\n",
       " 'p28': 0.0,\n",
       " 'p29': 7.0,\n",
       " 'p30': 5.0,\n",
       " 'p31': 0.0,\n",
       " 'p32': 0.0,\n",
       " 'p33': 6.0,\n",
       " 'p34': 10.0,\n",
       " 'p35': 0.0,\n",
       " 'p36': 0.0,\n",
       " 'p37': 2.0,\n",
       " 'p38': 9.0,\n",
       " 'p39': 0.0,\n",
       " 'p40': 0.0,\n",
       " 'p41': 1.0,\n",
       " 'p42': 13.0,\n",
       " 'p43': 0.0,\n",
       " 'p44': 0.0,\n",
       " 'p45': 2.0,\n",
       " 'p46': 11.0,\n",
       " 'p47': 0.0,\n",
       " 'p48': 0.0,\n",
       " 'p49': 0.0,\n",
       " 'p50': 6.0,\n",
       " 'p51': 11.0,\n",
       " 'p52': 4.0,\n",
       " 'p53': 10.0,\n",
       " 'p54': 11.0,\n",
       " 'p55': 0.0,\n",
       " 'p56': 0.0,\n",
       " 'p57': 0.0,\n",
       " 'p58': 0.0,\n",
       " 'p59': 9.0,\n",
       " 'p60': 15.0,\n",
       " 'p61': 14.0,\n",
       " 'p62': 5.0,\n",
       " 'p63': 0.0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newob = pred.loc[:0,'p0':'p63'].to_dict(orient='records')[0]\n",
    "newob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "professional-light",
   "metadata": {},
   "source": [
    "Request prediction from the prediction service:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "yellow-allen",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.protobuf import json_format\n",
    "from google.protobuf.struct_pb2 import Value\n",
    "\n",
    "response = clients['prediction'].predict(endpoint=endpoint_info.name, instances=[json_format.ParseDict(newob, Value())], parameters=json_format.ParseDict({}, Value()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "exact-monroe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5.02994226e-07, 0.973487377, 1.8433891e-06, 0.00680787489, 2.17787274e-05, 1.29038508e-05, 3.81712155e-08, 1.42034578e-05, 0.000289012154, 0.0193645582]]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "large-bottom",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.argmax(response.predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleared-investigation",
   "metadata": {},
   "source": [
    "# Remove Resources\n",
    "- undeploy-model\n",
    "- remove endpoint\n",
    "- remove model\n",
    "- delete model files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entire-newman",
   "metadata": {},
   "source": [
    "Undeploy Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "structured-cooperative",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.api_core.operation.Operation at 0x7feecd37de10>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dmodel = clients['endpoint'].get_endpoint(name=endpoint_info.name).deployed_models[0].id\n",
    "clients['endpoint'].undeploy_model(endpoint=endpoint_info.name, deployed_model_id=dmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "located-ideal",
   "metadata": {},
   "source": [
    "Delete Endpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "educational-agriculture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.api_core.operation.Operation at 0x7feecc28f6d0>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients['endpoint'].delete_endpoint(name=endpoint_info.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outstanding-baseline",
   "metadata": {},
   "source": [
    "Remove Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "demanding-average",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.api_core.operation.Operation at 0x7feecd37d910>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients['model'].delete_model(name=model_info.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compact-cheese",
   "metadata": {},
   "source": [
    "Delete Model Files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "extended-screening",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "gcs = storage.Client()\n",
    "\n",
    "path = gcs.bucket(PROJECT_ID)\n",
    "blobs = path.list_blobs(prefix='digits/keras')\n",
    "for blob in blobs:\n",
    "    blob.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laden-heavy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-4.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
