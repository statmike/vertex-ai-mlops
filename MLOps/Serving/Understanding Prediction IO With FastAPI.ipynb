{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e865d31c",
   "metadata": {},
   "source": [
    "![tracker](https://us-central1-vertex-ai-mlops-369716.cloudfunctions.net/pixel-tracking?path=statmike%2Fvertex-ai-mlops%2FMLOps%2FServing&file=Understanding+Prediction+IO+With+FastAPI.ipynb)\n",
    "<!--- header table --->\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/statmike/vertex-ai-mlops/blob/main/MLOps/Serving/Understanding%20Prediction%20IO%20With%20FastAPI.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://www.gstatic.com/pantheon/images/bigquery/welcome_page/colab-logo.svg\" alt=\"Google Colaboratory logo\">\n",
    "      <br>Run in<br>Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https%3A%2F%2Fraw.githubusercontent.com%2Fstatmike%2Fvertex-ai-mlops%2Fmain%2FMLOps%2FServing%2FUnderstanding%2520Prediction%2520IO%2520With%2520FastAPI.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\">\n",
    "      <br>Run in<br>Colab Enterprise\n",
    "    </a>\n",
    "  </td>      \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/statmike/vertex-ai-mlops/blob/main/MLOps/Serving/Understanding%20Prediction%20IO%20With%20FastAPI.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://www.svgrepo.com/download/217753/github.svg\" alt=\"GitHub logo\">\n",
    "      <br>View on<br>GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/statmike/vertex-ai-mlops/main/MLOps/Serving/Understanding%20Prediction%20IO%20With%20FastAPI.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://www.gstatic.com/images/branding/gcpiconscolors/vertexai/v1/32px.svg\" alt=\"Vertex AI logo\">\n",
    "      <br>Open in<br>Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dc51d2-3e40-4b95-83b9-315b32540410",
   "metadata": {},
   "source": [
    "# Understanding Prediction IO With FastAPI\n",
    "\n",
    "Use a simple FastAPI implementation to explore the processing of different input instance formats on:\n",
    "- Local Testing of Container\n",
    "- Vertex AI Endpoints\n",
    "- Cloud Run Endpoints\n",
    "- Vetex AI Batch Prediction\n",
    "\n",
    "Inputs to try:\n",
    "- [Vertex AI **Online Prediction** Instance Formats](https://cloud.google.com/vertex-ai/docs/predictions/get-online-predictions#formatting-prediction-input)\n",
    "    - [Custom container requirements for predictions](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#prediction)\n",
    "- [Vertex AI **Batch Prediction** Instance Formats](https://cloud.google.com/vertex-ai/docs/predictions/get-batch-predictions#input_data_requirements)\n",
    "\n",
    "Notes On Prediction Inputs:\n",
    "- This method builds a custom container with FastAPI application the repeats the input instances and outputs.  This is for demonstration of how serving options work: local, Vertex AI Batch and Online Endpoints, Cloud Run\n",
    "- Inputs are formated as JSON, a requirement for customer containers, and the default for Vertex AI Batch prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93add80c-4be3-4c58-9d4e-cfdb58a8aeea",
   "metadata": {
    "id": "od_UkDpvRmgD",
    "tags": []
   },
   "source": [
    "---\n",
    "## Colab Setup\n",
    "\n",
    "To run this notebook in Colab run the cells in this section.  Otherwise, skip this section.\n",
    "\n",
    "This cell will authenticate to GCP (follow prompts in the popup)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "773b731c-6ecd-436f-8de7-dc049e2ac23f",
   "metadata": {
    "executionInfo": {
     "elapsed": 195,
     "status": "ok",
     "timestamp": 1683726184843,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "8UO9FnqyKBlF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'statmike-mlops-349915' # replace with project ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "296f760d-24bc-4f47-a81d-1c70e6bcac74",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68869,
     "status": "ok",
     "timestamp": 1683726253709,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "N98-KK7LRkjm",
    "outputId": "09ec5008-0def-4e1a-c349-c598ee752f78",
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    !gcloud config set project {PROJECT_ID}\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36c66af-7ccb-4ac4-8d63-991d189dfc08",
   "metadata": {},
   "source": [
    "---\n",
    "## Installs\n",
    "\n",
    "The list `packages` contains tuples of package import names and install names.  If the import name is not found then the install name is used to install quitely for the current user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "273d19dc-bdb8-4be7-be6e-0d5fc8ededce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tuples of (import name, install name, min_version)\n",
    "packages = [\n",
    "    ('docker', 'docker'),\n",
    "    ('google.cloud.aiplatform', 'google-cloud-aiplatform'),\n",
    "    ('google.cloud.storage', 'google-cloud-storage'),\n",
    "    ('google.cloud.bigquery', 'google-cloud-bigquery'),\n",
    "    ('google.cloud.artifactregistry_v1', 'google-cloud-artifact-registry'),\n",
    "    ('google.cloud.devtools', 'google-cloud-build'),\n",
    "    ('google.cloud.run_v2', 'google-cloud-run'), \n",
    "    ('tensorflow', 'tensorflow')\n",
    "]\n",
    "\n",
    "import importlib\n",
    "install = False\n",
    "for package in packages:\n",
    "    if not importlib.util.find_spec(package[0]):\n",
    "        print(f'installing package {package[1]}')\n",
    "        install = True\n",
    "        !pip install {package[1]} -U -q --user\n",
    "    elif len(package) == 3:\n",
    "        if importlib.metadata.version(package[0]) < package[2]:\n",
    "            print(f'updating package {package[1]}')\n",
    "            install = True\n",
    "            !pip install {package[1]} -U -q --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705a353f-2b80-4109-840b-26ada0892e29",
   "metadata": {},
   "source": [
    "### API Enablement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d72f495-344a-4fa8-a2b8-122b5a4fc438",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gcloud services enable artifactregistry.googleapis.com\n",
    "!gcloud services enable cloudbuild.googleapis.com\n",
    "!gcloud services enable run.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e451ca25-de9d-4f94-9963-1df01908ffe6",
   "metadata": {},
   "source": [
    "### Restart Kernel (If Installs Occured)\n",
    "\n",
    "After a kernel restart the code submission can start with the next cell after this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e877065-c3eb-4a8a-9eed-b42ba320e506",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if install:\n",
    "    import IPython\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)\n",
    "    IPython.display.display(IPython.display.Markdown(\"\"\"<div class=\\\"alert alert-block alert-warning\\\">\n",
    "        <b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. The previous cells do not need to be run again⚠️</b>\n",
    "        </div>\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869468bd-1849-49eb-a30e-77756956b0bc",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffbdbb2-bdc7-4cab-a752-ba8838feba41",
   "metadata": {},
   "source": [
    "inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52196f7a-387d-4b9b-8125-7b3689f02c23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'statmike-mlops-349915'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "b1f9fee5-8748-4037-8c12-cf469670f3e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "SERIES = 'mlops-serving'\n",
    "EXPERIMENT = 'understand-io'\n",
    "\n",
    "# GCS Bucket to Use In this workflow\n",
    "GCS_BUCKET = PROJECT_ID\n",
    "\n",
    "# make this the BigQuery Project / Dataset / Table prefix to store results\n",
    "BQ_PROJECT = PROJECT_ID\n",
    "BQ_DATASET = SERIES.replace('-', '_')\n",
    "BQ_TABLE = EXPERIMENT\n",
    "BQ_REGION = REGION[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad097d7-8c48-4938-a7ad-a6611e2f7c77",
   "metadata": {},
   "source": [
    "packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "c85d3a07-1988-46b8-bf04-adb45e32a2ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json, os, base64, csv, io, tempfile, time\n",
    "import requests\n",
    "\n",
    "import docker\n",
    "import tensorflow as tf\n",
    "\n",
    "import google.auth\n",
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import artifactregistry_v1\n",
    "from google.cloud.devtools import cloudbuild_v1\n",
    "from google.cloud import run_v2\n",
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928ff1c5-9476-4064-ae46-58019f145f2b",
   "metadata": {},
   "source": [
    "clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "a756f32c-e880-4a9a-b5a0-1df2b5bf4144",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# gcs storage client\n",
    "gcs = storage.Client(project = GCS_BUCKET)\n",
    "bucket = gcs.bucket(GCS_BUCKET)\n",
    "\n",
    "# bigquery client\n",
    "bq = bigquery.Client(project = PROJECT_ID)\n",
    "\n",
    "# cloud build client\n",
    "cb = cloudbuild_v1.CloudBuildClient()\n",
    "\n",
    "# artifact registry client\n",
    "ar = artifactregistry_v1.ArtifactRegistryClient()\n",
    "\n",
    "# cloud run client\n",
    "cr = run_v2.ServicesClient()\n",
    "\n",
    "# vertex ai client\n",
    "aiplatform.init(project = PROJECT_ID, location = REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed05152-79ca-4b67-9a39-5b2045c4d4b8",
   "metadata": {},
   "source": [
    "Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14c2633b-f2fb-41fb-a050-6d4441c76723",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DIR = f\"files/{EXPERIMENT}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8de7b51-3cdd-4350-93aa-3a88c47f851b",
   "metadata": {},
   "source": [
    "Environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3eec3718-3390-426a-af74-76d80749b5f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(DIR):\n",
    "    os.makedirs(DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482a052f-3f05-4127-aec8-02f7bd891977",
   "metadata": {},
   "source": [
    "---\n",
    "## Build A Custom Prediction Container\n",
    "\n",
    "It is really not all that hard with Python!\n",
    "\n",
    "For this example [FastAPI](https://fastapi.tiangolo.com/) is used.\n",
    "\n",
    "This process uses docker to build a custom container and then runs the container locally, on Cloud Run, and Vertex AI Endpoints.\n",
    "\n",
    "This could be done locally with Docker and pushed to Artifact Registry before deployment to Cloud Run.  The process below assumes that docker is not available locally and uses Cloud Build to both build and push the resulting container to Artifact Registry."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6417e800-04f2-4dc8-84db-79942847be1e",
   "metadata": {},
   "source": [
    "---\n",
    "### Setup Artifact Registry\n",
    "\n",
    "[Artifact registry](https://cloud.google.com/artifact-registry/docs) organizes artifacts with repositories.  Each repository contains packages and is designated to hold a partifcular format of package: Docker images, Python Packages and [others](https://cloud.google.com/artifact-registry/docs/supported-formats#package)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e31ae69-004b-4923-9b3b-1d16ce6a4575",
   "metadata": {},
   "source": [
    "#### List Repositories\n",
    "\n",
    "This may be empty if no repositories have been created for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "413d6535-f166-4804-aa1f-d8d2195ac072",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projects/statmike-mlops-349915/locations/us-central1/repositories/frameworks\n",
      "projects/statmike-mlops-349915/locations/us-central1/repositories/frameworks-catboost\n",
      "projects/statmike-mlops-349915/locations/us-central1/repositories/gcf-artifacts\n",
      "projects/statmike-mlops-349915/locations/us-central1/repositories/mlops\n",
      "projects/statmike-mlops-349915/locations/us-central1/repositories/mlops-serving\n",
      "projects/statmike-mlops-349915/locations/us-central1/repositories/statmike-mlops-349915\n",
      "projects/statmike-mlops-349915/locations/us-central1/repositories/statmike-mlops-349915-docker\n",
      "projects/statmike-mlops-349915/locations/us-central1/repositories/statmike-mlops-349915-python\n"
     ]
    }
   ],
   "source": [
    "for repo in ar.list_repositories(parent = f'projects/{PROJECT_ID}/locations/{REGION}'):\n",
    "    print(repo.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d60d118-9147-4a21-9e97-e074329ad618",
   "metadata": {},
   "source": [
    "#### Create/Retrieve Docker Image Repository\n",
    "\n",
    "Create an Artifact Registry Repository to hold Docker Images created by this notebook.  First, check to see if it is already created by a previous run and retrieve it if it has.  Otherwise, create one named for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4378e760-aa9c-4791-969e-1068905b8c99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved existing repo: projects/statmike-mlops-349915/locations/us-central1/repositories/mlops-serving\n"
     ]
    }
   ],
   "source": [
    "docker_repo = None\n",
    "for repo in ar.list_repositories(parent = f'projects/{PROJECT_ID}/locations/{REGION}'):\n",
    "    if f'{SERIES}' == repo.name.split('/')[-1]:\n",
    "        docker_repo = repo\n",
    "        print(f'Retrieved existing repo: {docker_repo.name}')\n",
    "\n",
    "if not docker_repo:\n",
    "    operation = ar.create_repository(\n",
    "        request = artifactregistry_v1.CreateRepositoryRequest(\n",
    "            parent = f'projects/{PROJECT_ID}/locations/{REGION}',\n",
    "            repository_id = f'{SERIES}',\n",
    "            repository = artifactregistry_v1.Repository(\n",
    "                description = f'A repository for the {SERIES} series that holds docker images.',\n",
    "                name = f'{SERIES}',\n",
    "                format_ = artifactregistry_v1.Repository.Format.DOCKER,\n",
    "                labels = {'series': SERIES}\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    print('Creating Repository ...')\n",
    "    docker_repo = operation.result()\n",
    "    print(f'Completed creating repo: {docker_repo.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "546cc483-f056-4b45-95a1-6dbaff655579",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('projects/statmike-mlops-349915/locations/us-central1/repositories/mlops-serving',\n",
       " 'DOCKER')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docker_repo.name, docker_repo.format_.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f022b364-f5e5-4fb5-b5c0-90713c2c3dfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "REPOSITORY = f\"{REGION}-docker.pkg.dev/{PROJECT_ID}/{docker_repo.name.split('/')[-1]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04cd6c6c-eeca-4f61-ac09-571e738b9c05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'us-central1-docker.pkg.dev/statmike-mlops-349915/mlops-serving'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REPOSITORY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7be2ce-6cca-406c-b42b-58860578d1d9",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "### Create Application Files\n",
    "\n",
    "```\n",
    "|__ Dockerfile\n",
    "|__ requirements.txt\n",
    "|__ app\n",
    "    |__ __init__.py\n",
    "    |__ main.py\n",
    "    |__ prestart.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49e76138-256f-465b-bfd9-68df9103dcca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(DIR + '/source/app'):\n",
    "    os.makedirs(DIR + '/source/app')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abb23480-b572-4faf-8c3c-f0306e92483a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting files/understand-io/source/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile {DIR}/source/Dockerfile\n",
    "FROM tiangolo/uvicorn-gunicorn-fastapi:python3.9\n",
    "\n",
    "COPY ./app /app\n",
    "COPY ./requirements.txt requirements.txt\n",
    "\n",
    "RUN pip install --no-cache-dir --upgrade pip \\\n",
    "  && pip install --no-cache-dir -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6572dcbf-7ecd-4721-a407-86576bd3eb50",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting files/understand-io/source/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile {DIR}/source/requirements.txt\n",
    "numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef0099ff-1836-49de-9307-06f02ec97d55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting files/understand-io/source/app/__init__.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {DIR}/source/app/__init__.py\n",
    "# init file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "743e334f-984d-4f61-8e6a-b533c414eff9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting files/understand-io/source/app/main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {DIR}/source/app/main.py\n",
    "# a simple passthrough of instance to predictions\n",
    "\n",
    "# packages\n",
    "import os\n",
    "from fastapi import FastAPI, Request\n",
    "import numpy as np\n",
    "\n",
    "# clients\n",
    "app = FastAPI()\n",
    "\n",
    "# Define function for health route\n",
    "@app.get(os.environ['AIP_HEALTH_ROUTE'], status_code=200)\n",
    "def health():\n",
    "    return {}\n",
    "\n",
    "# Define function for prediction route\n",
    "@app.post(os.environ['AIP_PREDICT_ROUTE'])\n",
    "async def predict(request: Request):\n",
    "    # await the request\n",
    "    body = await request.json()\n",
    "    \n",
    "    # parse the request\n",
    "    instances = body[\"instances\"]\n",
    "    \n",
    "    # return the received inputs as the \"predictions\" - a simple pass through\n",
    "    predictions = instances\n",
    "\n",
    "    # this returns just the predicted probabilities:\n",
    "    return {\"predictions\": predictions}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4353b69-33d3-4e10-903c-ef3ddbb9d294",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting files/understand-io/source/app/prestart.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile {DIR}/source/app/prestart.sh\n",
    "#!/bin/bash\n",
    "export PORT=$AIP_HTTP_PORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f41e011-5b35-4b6d-b7e5-2d554e713edf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bucket.blob(f'{SERIES}/{EXPERIMENT}/source/Dockerfile').upload_from_filename(f'{DIR}/source/Dockerfile')\n",
    "bucket.blob(f'{SERIES}/{EXPERIMENT}/source/requirements.txt').upload_from_filename(f'{DIR}/source/requirements.txt')\n",
    "bucket.blob(f'{SERIES}/{EXPERIMENT}/source/app/__init__.py').upload_from_filename(f'{DIR}/source/app/__init__.py')\n",
    "bucket.blob(f'{SERIES}/{EXPERIMENT}/source/app/main.py').upload_from_filename(f'{DIR}/source/app/main.py')\n",
    "bucket.blob(f'{SERIES}/{EXPERIMENT}/source/app/prestart.sh').upload_from_filename(f'{DIR}/source/app/prestart.sh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cba9ee5c-ad32-483c-9bc8-4a78ea21cd4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Blob: statmike-mlops-349915, mlops-serving/understand-io/source/Dockerfile, 1741088729360795>,\n",
       " <Blob: statmike-mlops-349915, mlops-serving/understand-io/source/app/__init__.py, 1741088729633827>,\n",
       " <Blob: statmike-mlops-349915, mlops-serving/understand-io/source/app/main.py, 1741088729701223>,\n",
       " <Blob: statmike-mlops-349915, mlops-serving/understand-io/source/app/prestart.sh, 1741088729770839>,\n",
       " <Blob: statmike-mlops-349915, mlops-serving/understand-io/source/requirements.txt, 1741088729539287>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(bucket.list_blobs(prefix = f'{SERIES}/{EXPERIMENT}/source'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b163c5a8-ff1e-416c-8921-5ff632c7e7e0",
   "metadata": {},
   "source": [
    "---\n",
    "### Build Application Container\n",
    "\n",
    "Use the Cloud Build client to construct and run the build instructions. Here the files collected in GCS are copied to the build instance, then the Docker build is run in the folder with the `Dockerfile`. The resulting image is pushed to Artifact Registry (setup above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6eaa09ab-9fef-46b9-bbe6-9feb95cb3227",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setup the build config with empty list of steps - these will be added sequentially\n",
    "build = cloudbuild_v1.Build(\n",
    "    steps = []\n",
    ")\n",
    "# retrieve the source\n",
    "build.steps.append(\n",
    "    {\n",
    "        'name': 'gcr.io/cloud-builders/gsutil',\n",
    "        'args': ['cp', '-r', f'gs://{GCS_BUCKET}/{SERIES}/{EXPERIMENT}/source/*', '/workspace']\n",
    "    }\n",
    ")\n",
    "# docker build\n",
    "build.steps.append(\n",
    "    {\n",
    "        'name': 'gcr.io/cloud-builders/docker',\n",
    "        'args': ['build', '-t', f'{REPOSITORY}/{EXPERIMENT}', '/workspace']\n",
    "    }    \n",
    ")\n",
    "# docker push\n",
    "build.images = [f\"{REPOSITORY}/{EXPERIMENT}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14b21611-3de5-4a74-be6c-aa9c5e4aaaca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "operation = cb.create_build(\n",
    "    project_id = PROJECT_ID,\n",
    "    build = build\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2498ae0-50e4-406a-bc3f-70e999f7c73a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Status.SUCCESS: 3>,\n",
       " images: \"us-central1-docker.pkg.dev/statmike-mlops-349915/mlops-serving/understand-io\")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_response = operation.result()\n",
    "build_response.status, build_response.artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "811f3934-6ee8-41f6-8d4c-8a9d700b0afd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'us-central1-docker.pkg.dev/statmike-mlops-349915/mlops-serving/understand-io'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_response.artifacts.images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c953113c-11c7-4077-a6f5-1e8177857492",
   "metadata": {},
   "source": [
    "---\n",
    "## Example Instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7eb8250f-86fb-47f0-b2f4-18efbe51f447",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ=='"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b64_string = base64.b64encode(b'something to encode as binary here').decode('utf-8')\n",
    "b64_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e0fde783-c657-4244-8608-9446a8609142",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "example_instances = [\n",
    "    1,\n",
    "    2,\n",
    "    3,\n",
    "    4,\n",
    "    1.24578001,\n",
    "    'a',\n",
    "    'A',\n",
    "    {'key':'value'},\n",
    "    [1],\n",
    "    [1, 2, 3, 4],\n",
    "    [[1, 2], [3, 4]],\n",
    "    [[[1, 2], [3, 4]]],\n",
    "    [{'key':'value'}],\n",
    "    [{'key':'value'}, {'key':'value2'}],\n",
    "    ['gs://bucket/path/to/image/image1.jpg'],\n",
    "    b64_string,\n",
    "    [b64_string],\n",
    "    {'b64': b64_string}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a0adbe42-89f8-41b6-b062-5aabf58d1703",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 1.24578001,\n",
       " 'a',\n",
       " 'A',\n",
       " {'key': 'value'},\n",
       " [1],\n",
       " [1, 2, 3, 4],\n",
       " [[1, 2], [3, 4]],\n",
       " [[[1, 2], [3, 4]]],\n",
       " [{'key': 'value'}],\n",
       " [{'key': 'value'}, {'key': 'value2'}],\n",
       " ['gs://bucket/path/to/image/image1.jpg'],\n",
       " 'c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ==',\n",
       " ['c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ=='],\n",
       " {'b64': 'c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ=='}]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_instances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29641cd3-5ade-41d0-b713-9cde4bdd5778",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Test Locally\n",
    "\n",
    "If Docker is installed and running locally then use it to test the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8cda93bc-fc9e-4129-8fbf-1dbc6682a872",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docker is installed and running. Version: 20.10.17\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    local_test = True\n",
    "    docker_client = docker.from_env()\n",
    "    if docker_client.ping():\n",
    "        print(f\"Docker is installed and running. Version: {docker_client.version()['Version']}\")\n",
    "except Exception as e:\n",
    "    local_test = False\n",
    "    print('Docker is either not installed or not running - please fix before proceeding.\\nhttps://docs.docker.com/engine/install/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4addd901-8ab7-415e-aa63-4a92515ca41c",
   "metadata": {},
   "source": [
    "### Pull and Run Container\n",
    "\n",
    "Run the container image with:\n",
    "- ports: inside 8080 mapped to outside 80\n",
    "- set environment variables for:\n",
    "    - `AIP_HTTP_PORT` is `8080`\n",
    "    - `AIP_HEALTH_ROUTE` is `/health`\n",
    "    - `AIP_PREDICT_ROUTE` is `/predict`\n",
    "    - `AIP_STORAGE_URI` is the `gs://bucket/path/to/folder`\n",
    "    - `MODULE_NAME` is 'main'\n",
    "        - this actually defaults to main so is not required\n",
    "        - an alternative script with different prediction output is created in `main2.py` above\n",
    "        - use this environment variable to start the container using the alternative script in module `main2`\n",
    "        - see the [FastAPI Docker Image Advanced Usage](https://github.com/tiangolo/uvicorn-gunicorn-fastapi-docker?tab=readme-ov-file#advanced-usage) details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4cdaf92f-f156-464b-8869-bdda72f85f77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing image ...\n",
      "Starting container ...\n",
      "Container ready.\n",
      "\tUse `container.logs()` to view startup logs.\n"
     ]
    }
   ],
   "source": [
    "if local_test:\n",
    "    # make sure any prior runs are stopped:\n",
    "    try:\n",
    "        container = docker_client.containers.get('local-run')\n",
    "        container.stop()\n",
    "        container.remove()\n",
    "    except docker.errors.NotFound:\n",
    "        pass\n",
    "    \n",
    "    # get image:\n",
    "    image_uri = build_response.artifacts.images[0]\n",
    "    try:\n",
    "        local_image = docker_client.images.get(image_uri)\n",
    "        remote_image = docker_client.images.pull(image_uri)\n",
    "        if local_image.id != remote_image.id:\n",
    "            print('New image found, updating ...')\n",
    "            local_image = remote_image\n",
    "        else:\n",
    "            print('Using existing image ...')\n",
    "    except docker.errors.ImageNotFound:\n",
    "        print('Pulling image ...')\n",
    "        local_image = docker_client.images.pull(image_uri)\n",
    "        \n",
    "    # run container:\n",
    "    print('Starting container ...')\n",
    "    container = docker_client.containers.run(\n",
    "        image = image_uri,\n",
    "        detach = True,\n",
    "        ports = {'8080/tcp':80}, # Map inside:outside (where docker run -p is outside:inside)\n",
    "        name = 'local-run',\n",
    "        environment = {\n",
    "            'AIP_HTTP_PORT': '8080',\n",
    "            'AIP_HEALTH_ROUTE': '/health',\n",
    "            'AIP_PREDICT_ROUTE': '/predict',\n",
    "            'AIP_STORAGE_URI': f'gs://{bucket.name}/{SERIES}/catboost-overview',\n",
    "            'MODULE_NAME': 'main' # try main2 for alternative output\n",
    "        }\n",
    "    )\n",
    "    print('Container ready.\\n\\tUse `container.logs()` to view startup logs.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7f3b3ba4-fb2e-43c1-93d0-83985e077872",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time.sleep(5) # wait a few seconds!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1b6a2377-6a0d-4b7c-bbf1-e7bf497f82f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#container.logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2bf252-1d6d-4998-a6e4-ae23b1e1f7bb",
   "metadata": {},
   "source": [
    "### Health Check\n",
    "\n",
    "Want to see `200`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c4abddd4-a479-4554-94c2-c8a20f472e01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "if local_test:\n",
    "    response = requests.get(f\"http://localhost:80/health\")\n",
    "    print(response.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9850987-85fe-40ab-b789-090a2ad210c4",
   "metadata": {},
   "source": [
    "### Inference Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9c6e0968-5f79-4621-8e91-dfefaa4d1222",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(instances):\n",
    "    url = f\"http://localhost:80/predict\"\n",
    "    headers = {'Content_Type': 'application/json'}\n",
    "    data = json.dumps({'instances': instances})\n",
    "    response = requests.post(url, headers = headers, data = data)    \n",
    "    return json.loads(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72c293d-f161-46ad-9f1f-bd8ebfa14b55",
   "metadata": {},
   "source": [
    "#### Try Each Example Instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f1c4cf4d-25d5-4631-a47b-81db35f3899c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The example instance is:  1\n",
      "The prediction response is:  {'predictions': [1]}\n",
      "The prediction for the instance is: 1\n",
      "\n",
      "The example instance is:  2\n",
      "The prediction response is:  {'predictions': [2]}\n",
      "The prediction for the instance is: 2\n",
      "\n",
      "The example instance is:  3\n",
      "The prediction response is:  {'predictions': [3]}\n",
      "The prediction for the instance is: 3\n",
      "\n",
      "The example instance is:  4\n",
      "The prediction response is:  {'predictions': [4]}\n",
      "The prediction for the instance is: 4\n",
      "\n",
      "The example instance is:  1.24578001\n",
      "The prediction response is:  {'predictions': [1.24578001]}\n",
      "The prediction for the instance is: 1.24578001\n",
      "\n",
      "The example instance is:  a\n",
      "The prediction response is:  {'predictions': ['a']}\n",
      "The prediction for the instance is: a\n",
      "\n",
      "The example instance is:  A\n",
      "The prediction response is:  {'predictions': ['A']}\n",
      "The prediction for the instance is: A\n",
      "\n",
      "The example instance is:  {'key': 'value'}\n",
      "The prediction response is:  {'predictions': [{'key': 'value'}]}\n",
      "The prediction for the instance is: {'key': 'value'}\n",
      "\n",
      "The example instance is:  [1]\n",
      "The prediction response is:  {'predictions': [[1]]}\n",
      "The prediction for the instance is: [1]\n",
      "\n",
      "The example instance is:  [1, 2, 3, 4]\n",
      "The prediction response is:  {'predictions': [[1, 2, 3, 4]]}\n",
      "The prediction for the instance is: [1, 2, 3, 4]\n",
      "\n",
      "The example instance is:  [[1, 2], [3, 4]]\n",
      "The prediction response is:  {'predictions': [[[1, 2], [3, 4]]]}\n",
      "The prediction for the instance is: [[1, 2], [3, 4]]\n",
      "\n",
      "The example instance is:  [[[1, 2], [3, 4]]]\n",
      "The prediction response is:  {'predictions': [[[[1, 2], [3, 4]]]]}\n",
      "The prediction for the instance is: [[[1, 2], [3, 4]]]\n",
      "\n",
      "The example instance is:  [{'key': 'value'}]\n",
      "The prediction response is:  {'predictions': [[{'key': 'value'}]]}\n",
      "The prediction for the instance is: [{'key': 'value'}]\n",
      "\n",
      "The example instance is:  [{'key': 'value'}, {'key': 'value2'}]\n",
      "The prediction response is:  {'predictions': [[{'key': 'value'}, {'key': 'value2'}]]}\n",
      "The prediction for the instance is: [{'key': 'value'}, {'key': 'value2'}]\n",
      "\n",
      "The example instance is:  ['gs://bucket/path/to/image/image1.jpg']\n",
      "The prediction response is:  {'predictions': [['gs://bucket/path/to/image/image1.jpg']]}\n",
      "The prediction for the instance is: ['gs://bucket/path/to/image/image1.jpg']\n",
      "\n",
      "The example instance is:  c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ==\n",
      "The prediction response is:  {'predictions': ['c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ==']}\n",
      "The prediction for the instance is: c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ==\n",
      "\n",
      "The example instance is:  ['c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ==']\n",
      "The prediction response is:  {'predictions': [['c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ==']]}\n",
      "The prediction for the instance is: ['c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ==']\n",
      "\n",
      "The example instance is:  {'b64': 'c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ=='}\n",
      "The prediction response is:  {'predictions': [{'b64': 'c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ=='}]}\n",
      "The prediction for the instance is: {'b64': 'c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ=='}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for example in example_instances:\n",
    "    print('The example instance is: ', example)\n",
    "    print('The prediction response is: ', predict([example]))\n",
    "    print(f\"The prediction for the instance is: {predict([example])['predictions'][0]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579f1712-4283-4165-bb91-d8f9690ef7af",
   "metadata": {},
   "source": [
    "#### Try All Example Instances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8494af26-448f-4d7c-9c07-d2387c46dc41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  1.24578001,\n",
       "  'a',\n",
       "  'A',\n",
       "  {'key': 'value'},\n",
       "  [1],\n",
       "  [1, 2, 3, 4],\n",
       "  [[1, 2], [3, 4]],\n",
       "  [[[1, 2], [3, 4]]],\n",
       "  [{'key': 'value'}],\n",
       "  [{'key': 'value'}, {'key': 'value2'}],\n",
       "  ['gs://bucket/path/to/image/image1.jpg'],\n",
       "  'c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ==',\n",
       "  ['c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ=='],\n",
       "  {'b64': 'c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ=='}]}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(example_instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e17295c-1e05-4f15-b620-a5852118a38d",
   "metadata": {},
   "source": [
    "### Stop Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "da23b453-fcac-4eef-9574-01a31f882ea8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'local-run'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "container.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f32a9ad5-e31f-415b-ac02-08330795a918",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "container = docker_client.containers.get(container.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bfdd3aa6-5f09-485b-a280-c9c139618578",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'running'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "container.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8f25f55f-0364-4087-a020-f8671dbee328",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "container.stop()\n",
    "container.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34fd8a7-2b82-4fec-a1ac-ca2b874974f8",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Vertex AI Prediction Endpoint\n",
    "\n",
    "Register the model in the [Vertex AI Model Registry](https://cloud.google.com/vertex-ai/docs/model-registry/introduction) and [Deploy it to an endpoint](https://cloud.google.com/vertex-ai/docs/general/deployment)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cdb7c1-ead6-4d90-9963-670005b0f44e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model Registry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0dcf5b-9d35-45fa-91f7-bd875ea5e417",
   "metadata": {},
   "source": [
    "Check for existing version of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "793217c5-de15-4350-8ca7-355d403d0347",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/1026793852137/locations/us-central1/models/mlops-serving'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_model = ''\n",
    "for model in aiplatform.Model.list(filter=f'display_name=\"{SERIES}\"'):\n",
    "    parent_model = model.resource_name\n",
    "    break\n",
    "parent_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2403a781-aa56-4dc1-9b4a-8b4c02656c90",
   "metadata": {},
   "source": [
    "### Upload Model To Registry As New Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "57a523c1-cfd7-47af-9908-6276d7c49b1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n",
      "Create Model backing LRO: projects/1026793852137/locations/us-central1/models/mlops-serving/operations/3455690382388494336\n",
      "Model created. Resource name: projects/1026793852137/locations/us-central1/models/mlops-serving@4\n",
      "To use this Model in another session:\n",
      "model = aiplatform.Model('projects/1026793852137/locations/us-central1/models/mlops-serving@4')\n"
     ]
    }
   ],
   "source": [
    "vertex_model = aiplatform.Model.upload(\n",
    "    display_name = SERIES,\n",
    "    model_id = SERIES,\n",
    "    parent_model = parent_model,\n",
    "    serving_container_image_uri = build_response.artifacts.images[0],\n",
    "    serving_container_environment_variables = {'MODULE_NAME': 'main'},\n",
    "    serving_container_predict_route = \"/predict\",\n",
    "    serving_container_health_route = \"/health\",\n",
    "    artifact_uri = f'gs://{bucket.name}/{SERIES}/{EXPERIMENT}',\n",
    "    is_default_version = True,\n",
    "    version_aliases = [f'{EXPERIMENT}'],\n",
    "    version_description = EXPERIMENT,\n",
    "    labels = {'series': SERIES, 'experiment': EXPERIMENT}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b2582c-c21d-4ee6-a861-51edb01b6c4e",
   "metadata": {},
   "source": [
    "### Create Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418deed0-dc3e-40e2-89cd-77a0ea55a833",
   "metadata": {},
   "source": [
    "Check for existing endpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "588c73bb-8afa-4d84-bb18-f8297ab5b29c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vertex_endpoint = None\n",
    "for endpoint in aiplatform.Endpoint.list(filter=f'display_name=\"{SERIES}\"'):\n",
    "    vertex_endpoint = endpoint\n",
    "    break\n",
    "vertex_endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3971f2e6-c605-45f2-850f-32d8e39136e0",
   "metadata": {},
   "source": [
    "Create endpoint if missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "bfa3284d-df3c-4b70-a18e-73f973c8195e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Endpoint\n",
      "Create Endpoint backing LRO: projects/1026793852137/locations/us-central1/endpoints/7652043476925677568/operations/6047511967940214784\n",
      "Endpoint created. Resource name: projects/1026793852137/locations/us-central1/endpoints/7652043476925677568\n",
      "To use this Endpoint in another session:\n",
      "endpoint = aiplatform.Endpoint('projects/1026793852137/locations/us-central1/endpoints/7652043476925677568')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.models.Endpoint object at 0x7f50d114a800> \n",
       "resource name: projects/1026793852137/locations/us-central1/endpoints/7652043476925677568"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not vertex_endpoint:\n",
    "    vertex_endpoint = aiplatform.Endpoint.create(\n",
    "        display_name = SERIES,\n",
    "        labels = {'series': SERIES}   \n",
    "    )\n",
    "vertex_endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb22c20a-60c8-4fe1-855b-3d1f67ad11ac",
   "metadata": {},
   "source": [
    "### Deploy Model: Default version with `main.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cf94cd-4605-4a9f-a02a-dd0ef4de7c1d",
   "metadata": {},
   "source": [
    "Get the latest model version with alias that is the same as the variable `EXPERIMENT`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a6ffc496-729a-4809-968d-ba1789b58ac3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/1026793852137/locations/us-central1/models/mlops-serving@4'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vertex_model = aiplatform.Model(model_name = SERIES, version = f'{EXPERIMENT}')\n",
    "vertex_model.versioned_resource_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "09fc56aa-9cfc-4675-baaa-a366506d0eda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying model to Endpoint : projects/1026793852137/locations/us-central1/endpoints/7652043476925677568\n",
      "Deploy Endpoint model backing LRO: projects/1026793852137/locations/us-central1/endpoints/7652043476925677568/operations/636437015654563840\n",
      "Endpoint model deployed. Resource name: projects/1026793852137/locations/us-central1/endpoints/7652043476925677568\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.models.Endpoint object at 0x7f50d114a800> \n",
       "resource name: projects/1026793852137/locations/us-central1/endpoints/7652043476925677568"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vertex_model.deploy(\n",
    "    endpoint = vertex_endpoint,\n",
    "    traffic_percentage = 100,\n",
    "    machine_type = 'n1-standard-4',\n",
    "    min_replica_count = 1,\n",
    "    max_replica_count = 2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfea022-ecbc-44b4-8327-7669f6e5ac01",
   "metadata": {},
   "source": [
    "### Inference Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097f66f6-38d8-418b-a90b-e805de490783",
   "metadata": {},
   "source": [
    "#### Try Each Example Instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ddce378b-f381-43c7-8050-c45cb5b28468",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The example instance is:  1\n",
      "The prediction response is:  Prediction(predictions=[1.0], deployed_model_id='181301770838867968', metadata=None, model_version_id='4', model_resource_name='projects/1026793852137/locations/us-central1/models/mlops-serving', explanations=None)\n",
      "The prediction for the instance is: 1.0\n",
      "\n",
      "The example instance is:  2\n",
      "The prediction response is:  Prediction(predictions=[2.0], deployed_model_id='181301770838867968', metadata=None, model_version_id='4', model_resource_name='projects/1026793852137/locations/us-central1/models/mlops-serving', explanations=None)\n",
      "The prediction for the instance is: 2.0\n",
      "\n",
      "The example instance is:  3\n",
      "The prediction response is:  Prediction(predictions=[3.0], deployed_model_id='181301770838867968', metadata=None, model_version_id='4', model_resource_name='projects/1026793852137/locations/us-central1/models/mlops-serving', explanations=None)\n",
      "The prediction for the instance is: 3.0\n",
      "\n",
      "The example instance is:  4\n",
      "The prediction response is:  Prediction(predictions=[4.0], deployed_model_id='181301770838867968', metadata=None, model_version_id='4', model_resource_name='projects/1026793852137/locations/us-central1/models/mlops-serving', explanations=None)\n",
      "The prediction for the instance is: 4.0\n",
      "\n",
      "The example instance is:  1.24578001\n",
      "The prediction response is:  Prediction(predictions=[1.24578001], deployed_model_id='181301770838867968', metadata=None, model_version_id='4', model_resource_name='projects/1026793852137/locations/us-central1/models/mlops-serving', explanations=None)\n",
      "The prediction for the instance is: 1.24578001\n",
      "\n",
      "The example instance is:  a\n",
      "The prediction response is:  Prediction(predictions=['a'], deployed_model_id='181301770838867968', metadata=None, model_version_id='4', model_resource_name='projects/1026793852137/locations/us-central1/models/mlops-serving', explanations=None)\n",
      "The prediction for the instance is: a\n",
      "\n",
      "The example instance is:  A\n",
      "The prediction response is:  Prediction(predictions=['A'], deployed_model_id='181301770838867968', metadata=None, model_version_id='4', model_resource_name='projects/1026793852137/locations/us-central1/models/mlops-serving', explanations=None)\n",
      "The prediction for the instance is: A\n",
      "\n",
      "The example instance is:  {'key': 'value'}\n",
      "The prediction response is:  Prediction(predictions=[{'key': 'value'}], deployed_model_id='181301770838867968', metadata=None, model_version_id='4', model_resource_name='projects/1026793852137/locations/us-central1/models/mlops-serving', explanations=None)\n",
      "The prediction for the instance is: {'key': 'value'}\n",
      "\n",
      "The example instance is:  [1]\n",
      "The prediction response is:  Prediction(predictions=[[1.0]], deployed_model_id='181301770838867968', metadata=None, model_version_id='4', model_resource_name='projects/1026793852137/locations/us-central1/models/mlops-serving', explanations=None)\n",
      "The prediction for the instance is: [1.0]\n",
      "\n",
      "The example instance is:  [1, 2, 3, 4]\n",
      "The prediction response is:  Prediction(predictions=[[1.0, 2.0, 3.0, 4.0]], deployed_model_id='181301770838867968', metadata=None, model_version_id='4', model_resource_name='projects/1026793852137/locations/us-central1/models/mlops-serving', explanations=None)\n",
      "The prediction for the instance is: [1.0, 2.0, 3.0, 4.0]\n",
      "\n",
      "The example instance is:  [[1, 2], [3, 4]]\n",
      "The prediction response is:  Prediction(predictions=[[[1.0, 2.0], [3.0, 4.0]]], deployed_model_id='181301770838867968', metadata=None, model_version_id='4', model_resource_name='projects/1026793852137/locations/us-central1/models/mlops-serving', explanations=None)\n",
      "The prediction for the instance is: [[1.0, 2.0], [3.0, 4.0]]\n",
      "\n",
      "The example instance is:  [[[1, 2], [3, 4]]]\n",
      "The prediction response is:  Prediction(predictions=[[[[1.0, 2.0], [3.0, 4.0]]]], deployed_model_id='181301770838867968', metadata=None, model_version_id='4', model_resource_name='projects/1026793852137/locations/us-central1/models/mlops-serving', explanations=None)\n",
      "The prediction for the instance is: [[[1.0, 2.0], [3.0, 4.0]]]\n",
      "\n",
      "The example instance is:  [{'key': 'value'}]\n",
      "The prediction response is:  Prediction(predictions=[[{'key': 'value'}]], deployed_model_id='181301770838867968', metadata=None, model_version_id='4', model_resource_name='projects/1026793852137/locations/us-central1/models/mlops-serving', explanations=None)\n",
      "The prediction for the instance is: [{'key': 'value'}]\n",
      "\n",
      "The example instance is:  [{'key': 'value'}, {'key': 'value2'}]\n",
      "The prediction response is:  Prediction(predictions=[[{'key': 'value'}, {'key': 'value2'}]], deployed_model_id='181301770838867968', metadata=None, model_version_id='4', model_resource_name='projects/1026793852137/locations/us-central1/models/mlops-serving', explanations=None)\n",
      "The prediction for the instance is: [{'key': 'value'}, {'key': 'value2'}]\n",
      "\n",
      "The example instance is:  ['gs://bucket/path/to/image/image1.jpg']\n",
      "The prediction response is:  Prediction(predictions=[['gs://bucket/path/to/image/image1.jpg']], deployed_model_id='181301770838867968', metadata=None, model_version_id='4', model_resource_name='projects/1026793852137/locations/us-central1/models/mlops-serving', explanations=None)\n",
      "The prediction for the instance is: ['gs://bucket/path/to/image/image1.jpg']\n",
      "\n",
      "The example instance is:  c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ==\n",
      "The prediction response is:  Prediction(predictions=['c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ=='], deployed_model_id='181301770838867968', metadata=None, model_version_id='4', model_resource_name='projects/1026793852137/locations/us-central1/models/mlops-serving', explanations=None)\n",
      "The prediction for the instance is: c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ==\n",
      "\n",
      "The example instance is:  ['c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ==']\n",
      "The prediction response is:  Prediction(predictions=[['c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ==']], deployed_model_id='181301770838867968', metadata=None, model_version_id='4', model_resource_name='projects/1026793852137/locations/us-central1/models/mlops-serving', explanations=None)\n",
      "The prediction for the instance is: ['c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ==']\n",
      "\n",
      "The example instance is:  {'b64': 'c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ=='}\n",
      "The prediction response is:  Prediction(predictions=[{'b64': 'c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ=='}], deployed_model_id='181301770838867968', metadata=None, model_version_id='4', model_resource_name='projects/1026793852137/locations/us-central1/models/mlops-serving', explanations=None)\n",
      "The prediction for the instance is: {'b64': 'c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ=='}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for example in example_instances:\n",
    "    print('The example instance is: ', example)\n",
    "    print('The prediction response is: ', vertex_endpoint.predict([example]))\n",
    "    print(f\"The prediction for the instance is: {vertex_endpoint.predict([example]).predictions[0]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9473bddd-e15f-4b0f-a952-6e738e7309d8",
   "metadata": {},
   "source": [
    "#### Try All Example Instances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e4ef4a88-b9c3-4834-8aaf-b51a97d939fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 1.24578001,\n",
       " 'a',\n",
       " 'A',\n",
       " {'key': 'value'},\n",
       " [1.0],\n",
       " [1.0, 2.0, 3.0, 4.0],\n",
       " [[1.0, 2.0], [3.0, 4.0]],\n",
       " [[[1.0, 2.0], [3.0, 4.0]]],\n",
       " [{'key': 'value'}],\n",
       " [{'key': 'value'}, {'key': 'value2'}],\n",
       " ['gs://bucket/path/to/image/image1.jpg'],\n",
       " 'c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ==',\n",
       " ['c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ=='],\n",
       " {'b64': 'c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ=='}]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vertex_endpoint.predict(example_instances).predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4b9b21-fa60-47a2-8c1a-67fe0530738b",
   "metadata": {},
   "source": [
    "### Undeploy All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "97956125-c47a-4cde-8b1e-51ae98dc7ba1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undeploying Endpoint model: projects/1026793852137/locations/us-central1/endpoints/7652043476925677568\n",
      "Undeploy Endpoint model backing LRO: projects/1026793852137/locations/us-central1/endpoints/7652043476925677568/operations/3000263870070652928\n",
      "Endpoint model undeployed. Resource name: projects/1026793852137/locations/us-central1/endpoints/7652043476925677568\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for deployed_model in vertex_endpoint.list_models():\n",
    "    vertex_endpoint.undeploy(deployed_model_id = deployed_model.id)\n",
    "vertex_endpoint.list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60504839-f824-4e23-93e4-84bdce16b37d",
   "metadata": {},
   "source": [
    "### Delete Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "be38d376-c68d-4df1-99a3-c65ef650a201",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting Endpoint : projects/1026793852137/locations/us-central1/endpoints/7652043476925677568\n",
      "Endpoint deleted. . Resource name: projects/1026793852137/locations/us-central1/endpoints/7652043476925677568\n",
      "Deleting Endpoint resource: projects/1026793852137/locations/us-central1/endpoints/7652043476925677568\n",
      "Delete Endpoint backing LRO: projects/1026793852137/locations/us-central1/operations/474307429069225984\n",
      "Endpoint resource projects/1026793852137/locations/us-central1/endpoints/7652043476925677568 deleted.\n"
     ]
    }
   ],
   "source": [
    "vertex_endpoint.delete(force = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2474368f-3de2-4671-99fb-af744679a7d8",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Cloud Run\n",
    "\n",
    "Deploy the model to [Cloud Run](https://cloud.google.com/run/docs/overview/what-is-cloud-run) using the same container build and tested above from Artifact Registry.\n",
    "\n",
    "Some highlights for Cloud Run:\n",
    "- Rapid scaling to handle requests\n",
    "- Scale to zero (default) or other minimum if set\n",
    "- Can handle larger input (request) and output (response) sizes\n",
    "    - See [requests limits](https://cloud.google.com/run/quotas#request_limits)\n",
    "- Configure [memory limits](https://cloud.google.com/run/docs/configuring/services/memory-limits) and [cpu limits](https://cloud.google.com/run/docs/configuring/services/cpu) and [concurrency](https://cloud.google.com/run/docs/configuring/concurrency) and [autoscaling](https://cloud.google.com/run/docs/about-instance-autoscaling) and [request timeout](https://cloud.google.com/run/docs/configuring/request-timeout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0342cb37-6763-4abd-938a-8542a13f5422",
   "metadata": {},
   "source": [
    "### Deploy The Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b2806ef1-506b-47ee-980f-f7cf8666e9b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parent = f\"projects/{PROJECT_ID}/locations/{REGION}\"\n",
    "service = run_v2.Service()\n",
    "#service.name = f\"{parent}/services/{SERIES}\"\n",
    "service.template.containers = [\n",
    "    run_v2.Container(\n",
    "        image = build_response.artifacts.images[0],\n",
    "        ports = [run_v2.ContainerPort(container_port = 8080)],\n",
    "        env = [\n",
    "            run_v2.EnvVar(name = 'AIP_HTTP_PORT', value = '8080'),\n",
    "            run_v2.EnvVar(name = 'AIP_HEALTH_ROUTE', value = '/health'),\n",
    "            run_v2.EnvVar(name = 'AIP_PREDICT_ROUTE', value = '/predict'),\n",
    "            run_v2.EnvVar(name = 'AIP_STORAGE_URI', value = f'gs://{bucket.name}/{SERIES}/{EXPERIMENT}'),\n",
    "            run_v2.EnvVar(name = 'MODULE_NAME', value = 'main')\n",
    "        ],\n",
    "        resources = run_v2.ResourceRequirements(\n",
    "            limits = {\"cpu\": '8', \"memory\": '32Gi'}\n",
    "        )\n",
    "    )\n",
    "]\n",
    "service.ingress = run_v2.IngressTraffic.INGRESS_TRAFFIC_INTERNAL_ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "932884c9-9211-4b75-ae47-bde686f3e128",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Service: projects/statmike-mlops-349915/locations/us-central1/services/mlops-serving\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # create the service:\n",
    "    run_response = cr.create_service(request = {\"parent\": parent, \"service\": service, \"service_id\": SERIES})\n",
    "    # wait on the operation to complete:\n",
    "    run_response.result()\n",
    "    # print the name of the service\n",
    "    print(f\"Started Service: {run_response.metadata.name}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating service: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2cbad987-7df8-4a94-bcb3-22772f82f9df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://mlops-serving-urlxi72dpa-uc.a.run.app'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_response.metadata.uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1014098e-b9da-406d-a724-52a78e8808ff",
   "metadata": {},
   "source": [
    "### Permissions\n",
    "\n",
    "The endpoint requires authentication.  Check ou tthe [Authentication Overview](https://cloud.google.com/run/docs/authenticating/overview) and in the case below the [Authenticating service-to-service](https://cloud.google.com/run/docs/authenticating/service-to-service) method is used by giving the same service account used to run the notebook and create the endpoint the role to invoke the endpoint as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f4f482a9-b2da-4c12-8c3e-aee77dd354c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1026793852137-compute@developer.gserviceaccount.com'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SERVICE_ACCOUNT = !gcloud config list --format='value(core.account)' \n",
    "SERVICE_ACCOUNT = SERVICE_ACCOUNT[0]\n",
    "SERVICE_ACCOUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "88733872-e953-4065-befb-b5893e0aa367",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/statmike-mlops-349915/locations/us-central1/services/mlops-serving'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_response.metadata.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "62c9a136-bd7c-4ba8-84eb-12c8e84561d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IAM policy updated: [role: \"roles/run.invoker\"\n",
      "members: \"allUsers\"\n",
      "members: \"serviceAccount:1026793852137-compute@developer.gserviceaccount.com\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "policy = cr.get_iam_policy(request = {'resource': run_response.metadata.name})\n",
    "policy.bindings.add(\n",
    "    role = 'roles/run.invoker',\n",
    "    members = [f\"serviceAccount:{SERVICE_ACCOUNT}\", 'allUsers'] #'allUsers'\n",
    ")\n",
    "policy_response = cr.set_iam_policy(request = {\"resource\": run_response.metadata.name, \"policy\": policy})\n",
    "print(f\"IAM policy updated: {policy_response.bindings}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "06096490-053a-46eb-b92f-fe6ab7b188e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[role: \"roles/run.invoker\"\n",
       "members: \"serviceAccount:1026793852137-compute@developer.gserviceaccount.com\"\n",
       "members: \"allUsers\"\n",
       "]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy.bindings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458f9359-2011-4e55-bd83-7cf70049807e",
   "metadata": {
    "tags": []
   },
   "source": [
    "**WAIT: The update of the IAM Policy might take a few moments to take effect.  Rerun the following health check section until you get a `200` response code.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12ad137-4c80-4576-b00c-5ae0eafd759b",
   "metadata": {},
   "source": [
    "### Health Check\n",
    "\n",
    "Want to see `200`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fa3ccaf3-b44f-4d90-89f9-65d2fcb5f108",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def health(uri):\n",
    "    url = f\"{uri}/health\"\n",
    "    credentials, _ = google.auth.default()\n",
    "    auth_req = google.auth.transport.requests.Request()\n",
    "    credentials.refresh(auth_req)\n",
    "    headers = {'Authorization': f'Bearer {credentials.token}'}\n",
    "    response = requests.get(url, headers = headers)    \n",
    "    return response.status_code\n",
    "\n",
    "def check_health(uri, timeout_seconds = 200, retry_seconds = 10):\n",
    "    start_time = time.time()\n",
    "    while True:\n",
    "        status_code = health(uri)\n",
    "        if status_code == 200:\n",
    "            break\n",
    "        elapsed_time = time.time() - start_time\n",
    "        if elapsed_time > timeout_seconds:\n",
    "            break\n",
    "        time.sleep(retry_seconds)\n",
    "    return status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a21e1b6b-faea-4293-8443-ae211161b208",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_health(run_response.metadata.uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7a460d31-c8be-41f9-86b6-7f5f565f008e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "health(run_response.metadata.uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8ddfe5-3dfe-4c41-b409-c4666c29d9e7",
   "metadata": {},
   "source": [
    "### Inference Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6ab2abd7-e77a-482e-9576-f2f6b62c5938",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(instances):\n",
    "    credentials, _ = google.auth.default()\n",
    "    auth_req = google.auth.transport.requests.Request()\n",
    "    credentials.refresh(auth_req)\n",
    "    url = f\"{run_response.metadata.uri}/predict\"\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {credentials.token}',\n",
    "        'Content_Type': 'application/json'\n",
    "    }\n",
    "    data = json.dumps({'instances': instances})\n",
    "    response = requests.post(url, headers = headers, data = data)    \n",
    "    return json.loads(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af8a4b6-f4c2-4a60-96c6-0b405d5277bb",
   "metadata": {},
   "source": [
    "#### Try Each Example Instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c725bf57-4f3d-4ee1-ace7-c2ab836460d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The example instance is:  1\n",
      "The prediction response is:  {'predictions': [1]}\n",
      "The prediction for the instance is: 1\n",
      "\n",
      "The example instance is:  2\n",
      "The prediction response is:  {'predictions': [2]}\n",
      "The prediction for the instance is: 2\n",
      "\n",
      "The example instance is:  3\n",
      "The prediction response is:  {'predictions': [3]}\n",
      "The prediction for the instance is: 3\n",
      "\n",
      "The example instance is:  4\n",
      "The prediction response is:  {'predictions': [4]}\n",
      "The prediction for the instance is: 4\n",
      "\n",
      "The example instance is:  1.24578001\n",
      "The prediction response is:  {'predictions': [1.24578001]}\n",
      "The prediction for the instance is: 1.24578001\n",
      "\n",
      "The example instance is:  a\n",
      "The prediction response is:  {'predictions': ['a']}\n",
      "The prediction for the instance is: a\n",
      "\n",
      "The example instance is:  A\n",
      "The prediction response is:  {'predictions': ['A']}\n",
      "The prediction for the instance is: A\n",
      "\n",
      "The example instance is:  {'key': 'value'}\n",
      "The prediction response is:  {'predictions': [{'key': 'value'}]}\n",
      "The prediction for the instance is: {'key': 'value'}\n",
      "\n",
      "The example instance is:  [1]\n",
      "The prediction response is:  {'predictions': [[1]]}\n",
      "The prediction for the instance is: [1]\n",
      "\n",
      "The example instance is:  [1, 2, 3, 4]\n",
      "The prediction response is:  {'predictions': [[1, 2, 3, 4]]}\n",
      "The prediction for the instance is: [1, 2, 3, 4]\n",
      "\n",
      "The example instance is:  [[1, 2], [3, 4]]\n",
      "The prediction response is:  {'predictions': [[[1, 2], [3, 4]]]}\n",
      "The prediction for the instance is: [[1, 2], [3, 4]]\n",
      "\n",
      "The example instance is:  [[[1, 2], [3, 4]]]\n",
      "The prediction response is:  {'predictions': [[[[1, 2], [3, 4]]]]}\n",
      "The prediction for the instance is: [[[1, 2], [3, 4]]]\n",
      "\n",
      "The example instance is:  [{'key': 'value'}]\n",
      "The prediction response is:  {'predictions': [[{'key': 'value'}]]}\n",
      "The prediction for the instance is: [{'key': 'value'}]\n",
      "\n",
      "The example instance is:  [{'key': 'value'}, {'key': 'value2'}]\n",
      "The prediction response is:  {'predictions': [[{'key': 'value'}, {'key': 'value2'}]]}\n",
      "The prediction for the instance is: [{'key': 'value'}, {'key': 'value2'}]\n",
      "\n",
      "The example instance is:  ['gs://bucket/path/to/image/image1.jpg']\n",
      "The prediction response is:  {'predictions': [['gs://bucket/path/to/image/image1.jpg']]}\n",
      "The prediction for the instance is: ['gs://bucket/path/to/image/image1.jpg']\n",
      "\n",
      "The example instance is:  c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ==\n",
      "The prediction response is:  {'predictions': ['c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ==']}\n",
      "The prediction for the instance is: c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ==\n",
      "\n",
      "The example instance is:  ['c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ==']\n",
      "The prediction response is:  {'predictions': [['c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ==']]}\n",
      "The prediction for the instance is: ['c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ==']\n",
      "\n",
      "The example instance is:  {'b64': 'c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ=='}\n",
      "The prediction response is:  {'predictions': [{'b64': 'c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ=='}]}\n",
      "The prediction for the instance is: {'b64': 'c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ=='}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for example in example_instances:\n",
    "    print('The example instance is: ', example)\n",
    "    print('The prediction response is: ', predict([example]))\n",
    "    print(f\"The prediction for the instance is: {predict([example])['predictions'][0]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9c16b1-9817-4b07-a8c0-a9a31a6b1e94",
   "metadata": {},
   "source": [
    "#### Try All Example Instances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2dd26649-ae11-4a0d-8edd-d3510a562c74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  1.24578001,\n",
       "  'a',\n",
       "  'A',\n",
       "  {'key': 'value'},\n",
       "  [1],\n",
       "  [1, 2, 3, 4],\n",
       "  [[1, 2], [3, 4]],\n",
       "  [[[1, 2], [3, 4]]],\n",
       "  [{'key': 'value'}],\n",
       "  [{'key': 'value'}, {'key': 'value2'}],\n",
       "  ['gs://bucket/path/to/image/image1.jpg'],\n",
       "  'c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ==',\n",
       "  ['c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ=='],\n",
       "  {'b64': 'c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ=='}]}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(example_instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c5627c-6aee-4449-9d5a-80cc868c7fb6",
   "metadata": {},
   "source": [
    "### Remove The Service\n",
    "\n",
    "Cloud Run will scale to zero here since a minimum has not been set.  This notebook does proceed with deleting the service in the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1031a057-b0ea-4065-b1c3-880a23695e3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "remove_response = cr.delete_service(request = {\"name\": run_response.metadata.name})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b1a03544-912b-42d1-b9ab-976913d49cac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#remove_response.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496325d3-52cf-434f-87b9-387bfa9a703a",
   "metadata": {},
   "source": [
    "---\n",
    "## Vertex AI Batch Prediction\n",
    "\n",
    "This section shows how to use the same application built above with the Vertex AI Batch Prediction service.\n",
    "\n",
    "The approaches above use the hosted FastAPI application (local, Cloud Run, Vertex AI Endpoints) to serve on-demand prediction request.  For batch workflows the data to be inferenced is saved in an input format and then processed by the Vertex AI Batch Prediction service into an output destination.  Input instances are all converted to JSON before being sent to the prediction container - just like we did with the online serving example above.  \n",
    "\n",
    "Each possible file format for the service is covered here to help understand the data processing pipeline parts of the service.\n",
    "\n",
    "**References:**\n",
    "\n",
    "- SDK Link For Creating Batch Prediction Job From Model Reference: [`google.cloud.aiplatform.Model.batch_predict()`](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.Model#google_cloud_aiplatform_Model_batch_predict)\n",
    "- SDK Link For Creating Batch Predictions Jobs Directly: [`google.cloud.aiplatform.BatchPredictionJob.create()`](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.BatchPredictionJob#google_cloud_aiplatform_BatchPredictionJob_create)\n",
    "- The result (returned valued) is an object of type: [`google.cloud.aiplatform.BatchPredictionJob`](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.BatchPredictionJob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "275ff314-e628-4684-88ef-6fef5f24082a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jsonl', 'bigquery', 'csv', 'tf-record', 'tf-record-gzip', 'file-list']"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vertex_model.supported_input_storage_formats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81e9265-b1e6-4d85-90f6-b08217afa226",
   "metadata": {},
   "source": [
    "### JSON Lines File - Stored In GCS\n",
    "\n",
    "https://cloud.google.com/vertex-ai/docs/predictions/get-batch-predictions#input_data_requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8fbe24-b689-4ae6-93ce-91897e5d9b39",
   "metadata": {},
   "source": [
    "#### Save To GCS AS JSONL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d654cd3f-6ccd-40ac-9c59-d01353c399c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "blob = bucket.blob(f\"{SERIES}/{EXPERIMENT}/batch/jsonl/example_instances.jsonl\")\n",
    "blob.upload_from_string(\n",
    "    \"\\n\".join(json.dumps(instance) for instance in example_instances),\n",
    "    content_type=\"application/jsonl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e404a4-7169-459a-b1e8-4c9b5dd6646e",
   "metadata": {},
   "source": [
    "#### Start Batch Prediction Job On Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "297d592d-7555-4069-9ec2-429fb68c90d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating BatchPredictionJob\n",
      "BatchPredictionJob created. Resource name: projects/1026793852137/locations/us-central1/batchPredictionJobs/2498244367114829824\n",
      "To use this BatchPredictionJob in another session:\n",
      "bpj = aiplatform.BatchPredictionJob('projects/1026793852137/locations/us-central1/batchPredictionJobs/2498244367114829824')\n",
      "View Batch Prediction Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/batch-predictions/2498244367114829824?project=1026793852137\n",
      "BatchPredictionJob projects/1026793852137/locations/us-central1/batchPredictionJobs/2498244367114829824 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/1026793852137/locations/us-central1/batchPredictionJobs/2498244367114829824 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/1026793852137/locations/us-central1/batchPredictionJobs/2498244367114829824 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/1026793852137/locations/us-central1/batchPredictionJobs/2498244367114829824 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/1026793852137/locations/us-central1/batchPredictionJobs/2498244367114829824 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/1026793852137/locations/us-central1/batchPredictionJobs/2498244367114829824 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/1026793852137/locations/us-central1/batchPredictionJobs/2498244367114829824 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/1026793852137/locations/us-central1/batchPredictionJobs/2498244367114829824 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/1026793852137/locations/us-central1/batchPredictionJobs/2498244367114829824 current state:\n",
      "JobState.JOB_STATE_SUCCEEDED\n",
      "BatchPredictionJob run completed. Resource name: projects/1026793852137/locations/us-central1/batchPredictionJobs/2498244367114829824\n"
     ]
    }
   ],
   "source": [
    "batch_prediction_job_jsonl = vertex_model.batch_predict(\n",
    "    job_display_name = f\"{SERIES}-{EXPERIMENT}-JSONL\",\n",
    "    gcs_source = [f\"gs://{bucket.name}/{blob.name}\"],\n",
    "    gcs_destination_prefix = f\"gs://{bucket.name}/{SERIES}/{EXPERIMENT}/batch/jsonl\",\n",
    "    instances_format = 'jsonl',\n",
    "    machine_type = 'n1-standard-2',\n",
    "    accelerator_count = 0,\n",
    "    accelerator_type = None,\n",
    "    starting_replica_count = 1,\n",
    "    max_replica_count = 10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "5b0ec7cb-ed22-41db-9a03-dba77c9b5b43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<JobState.JOB_STATE_SUCCEEDED: 4>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_prediction_job_jsonl.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "fb03cfa4-20de-454f-bfe0-d135cb6ab316",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['JOB_STATE_UNSPECIFIED',\n",
       " 'JOB_STATE_QUEUED',\n",
       " 'JOB_STATE_PENDING',\n",
       " 'JOB_STATE_RUNNING',\n",
       " 'JOB_STATE_SUCCEEDED',\n",
       " 'JOB_STATE_FAILED',\n",
       " 'JOB_STATE_CANCELLING',\n",
       " 'JOB_STATE_CANCELLED',\n",
       " 'JOB_STATE_PAUSED',\n",
       " 'JOB_STATE_EXPIRED',\n",
       " 'JOB_STATE_UPDATING',\n",
       " 'JOB_STATE_PARTIALLY_SUCCEEDED']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_prediction_job_jsonl.state._member_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8c9a364c-94e5-4fce-a0b9-479b522efde3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_prediction_job_jsonl.done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c34bfcc2-82db-44fc-a8ee-58438d6dea44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(seconds=920, microseconds=655599)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_prediction_job_jsonl.end_time - batch_prediction_job_jsonl.start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a2d828c0-2ffe-435c-baa1-bf160916f183",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0:15:20.655599'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(batch_prediction_job_jsonl.end_time - batch_prediction_job_jsonl.start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ee4b78-49e2-4faf-8441-efa7170a800f",
   "metadata": {},
   "source": [
    "#### Retrieve Results From GCS\n",
    "\n",
    "There could be multiple files containing the prediction results depending on the number of serving nodes.  **Note** that there is also a series for errors files that contain per instance errors if there are any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "4a6f3cc3-2523-4c53-bfb3-ae6ec9e67bd6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gcs_output_directory: \"gs://statmike-mlops-349915/mlops-serving/understand-io/batch/jsonl/prediction-mlops-serving-2025_03_04T07_05_13_159Z\""
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_prediction_job_jsonl.output_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "d19635af-d38d-4a5f-acf0-87c221aeea79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Blob: statmike-mlops-349915, mlops-serving/understand-io/batch/jsonl/prediction-mlops-serving-2025_03_04T07_05_13_159Z/prediction.errors_stats-00000-of-00001, 1741101495088915>,\n",
       " <Blob: statmike-mlops-349915, mlops-serving/understand-io/batch/jsonl/prediction-mlops-serving-2025_03_04T07_05_13_159Z/prediction.results-00000-of-00001, 1741101494924910>]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blobs = list(bucket.list_blobs(prefix = batch_prediction_job_jsonl.output_info.gcs_output_directory.split(bucket.name)[-1][1:]))\n",
    "blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "47ed5fb1-1c63-432f-842d-6aa63f877805",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from:  mlops-serving/understand-io/batch/jsonl/prediction-mlops-serving-2025_03_04T07_05_13_159Z/prediction.results-00000-of-00001\n"
     ]
    }
   ],
   "source": [
    "jsonl_predictions = []\n",
    "for blob in blobs:\n",
    "    if blob.name.split('/')[-1].startswith('prediction.results-'):\n",
    "        print('Reading from: ', blob.name)\n",
    "        blob_content = blob.download_as_string().decode('utf-8')\n",
    "        for line in blob_content.splitlines():\n",
    "            jsonl_predictions.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "47925ebb-9ed5-45da-a940-cfa1a5b9489f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'instance': 1, 'prediction': 1},\n",
       " {'instance': 2, 'prediction': 2},\n",
       " {'instance': 3, 'prediction': 3},\n",
       " {'instance': 4, 'prediction': 4},\n",
       " {'instance': 1.24578001, 'prediction': 1.24578001},\n",
       " {'instance': 'a', 'prediction': 'a'},\n",
       " {'instance': 'A', 'prediction': 'A'},\n",
       " {'instance': {'key': 'value'}, 'prediction': {'key': 'value'}},\n",
       " {'instance': [1], 'prediction': [1]},\n",
       " {'instance': [1, 2, 3, 4], 'prediction': [1, 2, 3, 4]},\n",
       " {'instance': [[1, 2], [3, 4]], 'prediction': [[1, 2], [3, 4]]},\n",
       " {'instance': [[[1, 2], [3, 4]]], 'prediction': [[[1, 2], [3, 4]]]},\n",
       " {'instance': [{'key': 'value'}], 'prediction': [{'key': 'value'}]},\n",
       " {'instance': [{'key': 'value'}, {'key': 'value2'}],\n",
       "  'prediction': [{'key': 'value'}, {'key': 'value2'}]},\n",
       " {'instance': ['gs://bucket/path/to/image/image1.jpg'],\n",
       "  'prediction': ['gs://bucket/path/to/image/image1.jpg']},\n",
       " {'instance': 'c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ==',\n",
       "  'prediction': 'c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ=='},\n",
       " {'instance': ['c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ=='],\n",
       "  'prediction': ['c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ==']},\n",
       " {'instance': {'b64': 'c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ=='},\n",
       "  'prediction': {'b64': 'c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ=='}}]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonl_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a149a6-fbc8-4302-b0e4-3a467a91b217",
   "metadata": {},
   "source": [
    "### CSV File - Stored In GCS\n",
    "\n",
    "https://cloud.google.com/vertex-ai/docs/predictions/get-batch-predictions#input_data_requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1aa0c13-30c3-4aa3-9ab0-9a81b1bafd39",
   "metadata": {},
   "source": [
    "#### Save To GCS AS CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "37944f5b-5685-4fcc-a1fa-dfa0d566f41a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['input_1'],\n",
       " [1],\n",
       " [2],\n",
       " [3],\n",
       " [4],\n",
       " [1.24578001],\n",
       " ['a'],\n",
       " ['A'],\n",
       " [\"{'key': 'value'}\"],\n",
       " ['[1]'],\n",
       " ['[1, 2, 3, 4]'],\n",
       " ['[[1, 2], [3, 4]]'],\n",
       " ['[[[1, 2], [3, 4]]]'],\n",
       " [\"[{'key': 'value'}]\"],\n",
       " [\"[{'key': 'value'}, {'key': 'value2'}]\"],\n",
       " [\"['gs://bucket/path/to/image/image1.jpg']\"],\n",
       " ['c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ=='],\n",
       " [\"['c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ==']\"],\n",
       " [\"{'b64': 'c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ=='}\"]]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header = ['input_1']\n",
    "prepped_instances = [header]\n",
    "for instance in example_instances:\n",
    "    if isinstance(instance, (int, float)): prepped_instances.append([instance])\n",
    "    elif isinstance(instance, str): prepped_instances.append([instance])\n",
    "    else: prepped_instances.append([str(instance)])\n",
    "    \n",
    "prepped_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "96ce31f9-da9f-4c2c-b686-3a7112fa89b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output = io.StringIO()\n",
    "writer = csv.writer(output) #, quoting = csv.QUOTE_ALL) # Quote all fields\n",
    "writer.writerows(prepped_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "377a529b-b51c-493c-b122-2ada8904b76e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "blob = bucket.blob(f\"{SERIES}/{EXPERIMENT}/batch/csv/example_instances.csv\")\n",
    "blob.upload_from_string(\n",
    "    output.getvalue(),\n",
    "    content_type=\"text/csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84e5ac7-e332-4a1a-932d-b850516c7642",
   "metadata": {},
   "source": [
    "#### Start Batch Prediction Job On Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "d392d353-4fb8-4c61-8c95-98ebecad59da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating BatchPredictionJob\n",
      "BatchPredictionJob created. Resource name: projects/1026793852137/locations/us-central1/batchPredictionJobs/5260006469855608832\n",
      "To use this BatchPredictionJob in another session:\n",
      "bpj = aiplatform.BatchPredictionJob('projects/1026793852137/locations/us-central1/batchPredictionJobs/5260006469855608832')\n",
      "View Batch Prediction Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/batch-predictions/5260006469855608832?project=1026793852137\n",
      "BatchPredictionJob projects/1026793852137/locations/us-central1/batchPredictionJobs/5260006469855608832 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/1026793852137/locations/us-central1/batchPredictionJobs/5260006469855608832 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/1026793852137/locations/us-central1/batchPredictionJobs/5260006469855608832 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/1026793852137/locations/us-central1/batchPredictionJobs/5260006469855608832 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/1026793852137/locations/us-central1/batchPredictionJobs/5260006469855608832 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/1026793852137/locations/us-central1/batchPredictionJobs/5260006469855608832 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/1026793852137/locations/us-central1/batchPredictionJobs/5260006469855608832 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/1026793852137/locations/us-central1/batchPredictionJobs/5260006469855608832 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/1026793852137/locations/us-central1/batchPredictionJobs/5260006469855608832 current state:\n",
      "JobState.JOB_STATE_SUCCEEDED\n",
      "BatchPredictionJob run completed. Resource name: projects/1026793852137/locations/us-central1/batchPredictionJobs/5260006469855608832\n"
     ]
    }
   ],
   "source": [
    "batch_prediction_job_csv = vertex_model.batch_predict(\n",
    "    job_display_name = f\"{SERIES}-{EXPERIMENT}-CSV\",\n",
    "    gcs_source = [f\"gs://{bucket.name}/{blob.name}\"],\n",
    "    gcs_destination_prefix = f\"gs://{bucket.name}/{SERIES}/{EXPERIMENT}/batch/csv\",\n",
    "    instances_format = 'csv',\n",
    "    machine_type = 'n1-standard-2',\n",
    "    accelerator_count = 0,\n",
    "    accelerator_type = None,\n",
    "    starting_replica_count = 1,\n",
    "    max_replica_count = 10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "7043a4b4-60e8-4efa-8bfa-90f68b254127",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<JobState.JOB_STATE_SUCCEEDED: 4>"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_prediction_job_csv.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "21224a25-7040-4cd6-957c-c5bb3a5d7c62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['JOB_STATE_UNSPECIFIED',\n",
       " 'JOB_STATE_QUEUED',\n",
       " 'JOB_STATE_PENDING',\n",
       " 'JOB_STATE_RUNNING',\n",
       " 'JOB_STATE_SUCCEEDED',\n",
       " 'JOB_STATE_FAILED',\n",
       " 'JOB_STATE_CANCELLING',\n",
       " 'JOB_STATE_CANCELLED',\n",
       " 'JOB_STATE_PAUSED',\n",
       " 'JOB_STATE_EXPIRED',\n",
       " 'JOB_STATE_UPDATING',\n",
       " 'JOB_STATE_PARTIALLY_SUCCEEDED']"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_prediction_job_csv.state._member_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "bbc57f74-e7e8-4b11-b77d-a72102c8d4c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_prediction_job_csv.done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "32263586-15da-4f72-b5aa-7e2c2899c4b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(seconds=964, microseconds=761931)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_prediction_job_csv.end_time - batch_prediction_job_csv.start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "50f4f84e-adee-4371-824c-d34724533fc5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0:16:04.761931'"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(batch_prediction_job_csv.end_time - batch_prediction_job_csv.start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff0cbd3-0d62-40fb-b220-a1552a0592ea",
   "metadata": {},
   "source": [
    "#### Retrieve Results From GCS\n",
    "\n",
    "There could be multiple files containing the prediction results depending on the number of serving nodes.  **Note** that there is also a series for errors files that contain per instance errors if there are any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "baa30762-7afe-4f26-ae06-30e8a5074e35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gcs_output_directory: \"gs://statmike-mlops-349915/mlops-serving/understand-io/batch/csv/prediction-mlops-serving-2025_03_04T09_12_56_163Z\""
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_prediction_job_csv.output_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "f99595dc-0c2a-43cc-bc46-82fa7ef8e21f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Blob: statmike-mlops-349915, mlops-serving/understand-io/batch/csv/prediction-mlops-serving-2025_03_04T09_12_56_163Z/prediction.errors_stats-00000-of-00001, 1741109219072711>,\n",
       " <Blob: statmike-mlops-349915, mlops-serving/understand-io/batch/csv/prediction-mlops-serving-2025_03_04T09_12_56_163Z/prediction.results-00000-of-00002, 1741109218086521>,\n",
       " <Blob: statmike-mlops-349915, mlops-serving/understand-io/batch/csv/prediction-mlops-serving-2025_03_04T09_12_56_163Z/prediction.results-00001-of-00002, 1741109218077960>]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blobs = list(bucket.list_blobs(prefix = batch_prediction_job_csv.output_info.gcs_output_directory.split(bucket.name)[-1][1:]))\n",
    "blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "a85e2c47-528e-4eac-b81b-3bd3bd0153d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from:  mlops-serving/understand-io/batch/csv/prediction-mlops-serving-2025_03_04T09_12_56_163Z/prediction.results-00000-of-00002\n",
      "Reading from:  mlops-serving/understand-io/batch/csv/prediction-mlops-serving-2025_03_04T09_12_56_163Z/prediction.results-00001-of-00002\n"
     ]
    }
   ],
   "source": [
    "csv_predictions = []\n",
    "for blob in blobs:\n",
    "    if blob.name.split('/')[-1].startswith('prediction.results-'):\n",
    "        print('Reading from: ', blob.name)\n",
    "        blob_content = blob.download_as_string().decode('utf-8')\n",
    "        for line in blob_content.splitlines():\n",
    "            csv_predictions.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "cd60d164-6748-4137-874a-7ff3b4aeb766",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'instance': [2.0], 'prediction': [2.0]},\n",
       " {'instance': [3.0], 'prediction': [3.0]},\n",
       " {'instance': [1.0], 'prediction': [1.0]},\n",
       " {'instance': [4.0], 'prediction': [4.0]},\n",
       " {'instance': [1.24578001], 'prediction': [1.24578001]}]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfa5ba2-c0c7-4220-a56b-6556fd6ba26a",
   "metadata": {},
   "source": [
    "### BigQuery Table\n",
    "\n",
    "BigQuery tables can be the input and output for Vertex AI Batch Prediction jobs.  Since BQ columns have types, schemas, the example set of instances get converted to string first which changes the input types to the prediction service: 1 become \"1\" for example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1953ee71-aa05-408a-b746-70117dd61377",
   "metadata": {},
   "source": [
    "#### Save To BigQuery Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "62b78080-da35-4673-b44e-7ceffe5ee0fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = bigquery.Dataset(f\"{BQ_PROJECT}.{BQ_DATASET}\")\n",
    "dataset.location = BQ_REGION\n",
    "bq_dataset = bq.create_dataset(dataset, exists_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "45bada28-c504-4092-a042-ce11ff4f5e1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bq_table = bq_dataset.table(BQ_TABLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "d9f8b6bc-4c2f-44e9-9d21-8db672b9bbc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "job_config = bigquery.LoadJobConfig(\n",
    "    source_format = bigquery.SourceFormat.NEWLINE_DELIMITED_JSON,\n",
    "    write_disposition = bigquery.WriteDisposition.WRITE_TRUNCATE,\n",
    "    autodetect = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "241e8f8a-fe95-4d65-b9a9-c8087f723bc1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoadJob<project=statmike-mlops-349915, location=US, id=451f615b-6ce5-4dbb-ab95-68457ece2f72>"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_job = bq.load_table_from_json(\n",
    "    json_rows = [{\"input_1\" : str(instance)} for instance in example_instances],\n",
    "    destination = bq_table,\n",
    "    job_config = job_config\n",
    ")\n",
    "load_job.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "e308a0d4-179f-455b-a8ae-901a3ba6903a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.24578001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'key': 'value'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[[1, 2], [3, 4]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[[[1, 2], [3, 4]]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[{'key': 'value'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[{'key': 'value'}, {'key': 'value2'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>['gs://bucket/path/to/image/image1.jpg']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ==</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>['c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'b64': 'c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              input_1\n",
       "0                                                   1\n",
       "1                                                   2\n",
       "2                                                   3\n",
       "3                                                   4\n",
       "4                                          1.24578001\n",
       "5                                                   a\n",
       "6                                                   A\n",
       "7                                    {'key': 'value'}\n",
       "8                                                 [1]\n",
       "9                                        [1, 2, 3, 4]\n",
       "10                                   [[1, 2], [3, 4]]\n",
       "11                                 [[[1, 2], [3, 4]]]\n",
       "12                                 [{'key': 'value'}]\n",
       "13              [{'key': 'value'}, {'key': 'value2'}]\n",
       "14           ['gs://bucket/path/to/image/image1.jpg']\n",
       "15   c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ==\n",
       "16  ['c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVy...\n",
       "17  {'b64': 'c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hc..."
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bq.query(f\"SELECT * FROM `{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}`\").to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8533f268-adcd-4d79-bcb4-72b4525b9d3f",
   "metadata": {},
   "source": [
    "#### Start Batch Prediction Job On Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "37d3267a-6d09-497a-9eaa-c1fd7acb80ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating BatchPredictionJob\n",
      "BatchPredictionJob created. Resource name: projects/1026793852137/locations/us-central1/batchPredictionJobs/2740084148667416576\n",
      "To use this BatchPredictionJob in another session:\n",
      "bpj = aiplatform.BatchPredictionJob('projects/1026793852137/locations/us-central1/batchPredictionJobs/2740084148667416576')\n",
      "View Batch Prediction Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/batch-predictions/2740084148667416576?project=1026793852137\n",
      "BatchPredictionJob projects/1026793852137/locations/us-central1/batchPredictionJobs/2740084148667416576 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/1026793852137/locations/us-central1/batchPredictionJobs/2740084148667416576 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/1026793852137/locations/us-central1/batchPredictionJobs/2740084148667416576 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/1026793852137/locations/us-central1/batchPredictionJobs/2740084148667416576 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/1026793852137/locations/us-central1/batchPredictionJobs/2740084148667416576 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/1026793852137/locations/us-central1/batchPredictionJobs/2740084148667416576 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/1026793852137/locations/us-central1/batchPredictionJobs/2740084148667416576 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/1026793852137/locations/us-central1/batchPredictionJobs/2740084148667416576 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/1026793852137/locations/us-central1/batchPredictionJobs/2740084148667416576 current state:\n",
      "JobState.JOB_STATE_SUCCEEDED\n",
      "BatchPredictionJob run completed. Resource name: projects/1026793852137/locations/us-central1/batchPredictionJobs/2740084148667416576\n"
     ]
    }
   ],
   "source": [
    "batch_prediction_job_bq = vertex_model.batch_predict(\n",
    "    job_display_name = f\"{SERIES}-{EXPERIMENT}-BQ\",\n",
    "    bigquery_source = f\"bq://{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}\",\n",
    "    bigquery_destination_prefix = f\"bq://{BQ_PROJECT}.{BQ_DATASET}\",\n",
    "    instances_format = 'bigquery',\n",
    "    machine_type = 'n1-standard-2',\n",
    "    accelerator_count = 0,\n",
    "    accelerator_type = None,\n",
    "    starting_replica_count = 1,\n",
    "    max_replica_count = 10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "01dc7443-5990-4c11-9810-c3e94790cfa3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<JobState.JOB_STATE_SUCCEEDED: 4>"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_prediction_job_bq.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "e649ecb7-996f-465f-8013-ca25de34bd2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['JOB_STATE_UNSPECIFIED',\n",
       " 'JOB_STATE_QUEUED',\n",
       " 'JOB_STATE_PENDING',\n",
       " 'JOB_STATE_RUNNING',\n",
       " 'JOB_STATE_SUCCEEDED',\n",
       " 'JOB_STATE_FAILED',\n",
       " 'JOB_STATE_CANCELLING',\n",
       " 'JOB_STATE_CANCELLED',\n",
       " 'JOB_STATE_PAUSED',\n",
       " 'JOB_STATE_EXPIRED',\n",
       " 'JOB_STATE_UPDATING',\n",
       " 'JOB_STATE_PARTIALLY_SUCCEEDED']"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_prediction_job_bq.state._member_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "95d955a7-a2fc-436b-8087-2927fcf83e15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_prediction_job_bq.done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "ce5f1213-b78e-41a9-b601-f8ffc027c9ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(seconds=882, microseconds=226634)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_prediction_job_bq.end_time - batch_prediction_job_bq.start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "eb0cfa54-a8fc-4565-80c6-9e4bb8727def",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0:14:42.226634'"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(batch_prediction_job_bq.end_time - batch_prediction_job_bq.start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f160b36c-b097-4a19-bbbd-445b93657302",
   "metadata": {},
   "source": [
    "#### Retrieve Results From BigQuery\n",
    "\n",
    "Results are stored in a BigQuery table out the destination provided during the batch job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "effc2196-4794-47cf-944d-d2b0785581c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bigquery_output_dataset: \"bq://statmike-mlops-349915.mlops_serving\"\n",
       "bigquery_output_table: \"predictions_2025_03_05T05_32_55_714Z_576\""
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_prediction_job_bq.output_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "6a3dd4b6-176e-43e5-883f-9983e6017e23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_1</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[\"1\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[\"2\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[\"3\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[\"4\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.24578001</td>\n",
       "      <td>[\"1.24578001\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a</td>\n",
       "      <td>[\"a\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A</td>\n",
       "      <td>[\"A\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'key': 'value'}</td>\n",
       "      <td>[\"{'key': 'value'}\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[1]</td>\n",
       "      <td>[\"[1]\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "      <td>[\"[1, 2, 3, 4]\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[[1, 2], [3, 4]]</td>\n",
       "      <td>[\"[[1, 2], [3, 4]]\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[[[1, 2], [3, 4]]]</td>\n",
       "      <td>[\"[[[1, 2], [3, 4]]]\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[{'key': 'value'}]</td>\n",
       "      <td>[\"[{'key': 'value'}]\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[{'key': 'value'}, {'key': 'value2'}]</td>\n",
       "      <td>[\"[{'key': 'value'}, {'key': 'value2'}]\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>['gs://bucket/path/to/image/image1.jpg']</td>\n",
       "      <td>[\"['gs://bucket/path/to/image/image1.jpg']\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ==</td>\n",
       "      <td>[\"c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>['c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVy...</td>\n",
       "      <td>[\"['c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'b64': 'c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hc...</td>\n",
       "      <td>[\"{'b64': 'c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              input_1  \\\n",
       "0                                                   1   \n",
       "1                                                   2   \n",
       "2                                                   3   \n",
       "3                                                   4   \n",
       "4                                          1.24578001   \n",
       "5                                                   a   \n",
       "6                                                   A   \n",
       "7                                    {'key': 'value'}   \n",
       "8                                                 [1]   \n",
       "9                                        [1, 2, 3, 4]   \n",
       "10                                   [[1, 2], [3, 4]]   \n",
       "11                                 [[[1, 2], [3, 4]]]   \n",
       "12                                 [{'key': 'value'}]   \n",
       "13              [{'key': 'value'}, {'key': 'value2'}]   \n",
       "14           ['gs://bucket/path/to/image/image1.jpg']   \n",
       "15   c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ==   \n",
       "16  ['c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVy...   \n",
       "17  {'b64': 'c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hc...   \n",
       "\n",
       "                                           prediction  \n",
       "0                                               [\"1\"]  \n",
       "1                                               [\"2\"]  \n",
       "2                                               [\"3\"]  \n",
       "3                                               [\"4\"]  \n",
       "4                                      [\"1.24578001\"]  \n",
       "5                                               [\"a\"]  \n",
       "6                                               [\"A\"]  \n",
       "7                                [\"{'key': 'value'}\"]  \n",
       "8                                             [\"[1]\"]  \n",
       "9                                    [\"[1, 2, 3, 4]\"]  \n",
       "10                               [\"[[1, 2], [3, 4]]\"]  \n",
       "11                             [\"[[[1, 2], [3, 4]]]\"]  \n",
       "12                             [\"[{'key': 'value'}]\"]  \n",
       "13          [\"[{'key': 'value'}, {'key': 'value2'}]\"]  \n",
       "14       [\"['gs://bucket/path/to/image/image1.jpg']\"]  \n",
       "15  [\"c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVy...  \n",
       "16  [\"['c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaG...  \n",
       "17  [\"{'b64': 'c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5...  "
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bq.query(f\"SELECT * FROM `{BQ_PROJECT}.{BQ_DATASET}.{batch_prediction_job_bq.output_info.bigquery_output_table}`\").to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bd5ec1-121a-464c-9db9-1cdea413f69f",
   "metadata": {},
   "source": [
    "### File List - Stored In GCS\n",
    "\n",
    "Instances can be stored in gcs as files - any type of file really but this is particularly helpful for document file types or media files like images, and video.  Batch prediction input for this method is a file with a list of gcs locations for the individual instances stored in a gcs based file.  The individual instance files are read in base64 encoded binary and sent to the prediction container as a dictionary with single key `b64`.  The prediction container would then need to handle the decoding of this input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda10230-feba-442e-afc5-4519381e9257",
   "metadata": {},
   "source": [
    "#### Save Instances To Files In GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "ea759253-42fc-4ffa-ade5-48c6c6798a18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filelist = []\n",
    "for i, instance in enumerate(example_instances):\n",
    "    \n",
    "    blob = bucket.blob(f\"{SERIES}/{EXPERIMENT}/batch/filelist/files/instance_{i}.txt\")\n",
    "    blob.upload_from_string(\n",
    "        str(instance),\n",
    "        content_type = \"text/plain\",\n",
    "    )\n",
    "    filelist.append(f\"gs://{bucket.name}/{blob.name}\")\n",
    "\n",
    "blob = bucket.blob(f\"{SERIES}/{EXPERIMENT}/batch/filelist/filelist.txt\")\n",
    "blob.upload_from_string(\n",
    "    '\\n'.join(filelist),\n",
    "    content_type = 'text/plain'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c79856c-ce22-49cd-8aa7-c2ed11484256",
   "metadata": {},
   "source": [
    "#### Start Batch Prediction Job On Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "ed02d2aa-03c0-4c45-b7fb-ad7ed4ef933b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating BatchPredictionJob\n",
      "BatchPredictionJob created. Resource name: projects/1026793852137/locations/us-central1/batchPredictionJobs/3414990774075392000\n",
      "To use this BatchPredictionJob in another session:\n",
      "bpj = aiplatform.BatchPredictionJob('projects/1026793852137/locations/us-central1/batchPredictionJobs/3414990774075392000')\n",
      "View Batch Prediction Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/batch-predictions/3414990774075392000?project=1026793852137\n",
      "BatchPredictionJob projects/1026793852137/locations/us-central1/batchPredictionJobs/3414990774075392000 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/1026793852137/locations/us-central1/batchPredictionJobs/3414990774075392000 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/1026793852137/locations/us-central1/batchPredictionJobs/3414990774075392000 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/1026793852137/locations/us-central1/batchPredictionJobs/3414990774075392000 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/1026793852137/locations/us-central1/batchPredictionJobs/3414990774075392000 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/1026793852137/locations/us-central1/batchPredictionJobs/3414990774075392000 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/1026793852137/locations/us-central1/batchPredictionJobs/3414990774075392000 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/1026793852137/locations/us-central1/batchPredictionJobs/3414990774075392000 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/1026793852137/locations/us-central1/batchPredictionJobs/3414990774075392000 current state:\n",
      "JobState.JOB_STATE_SUCCEEDED\n",
      "BatchPredictionJob run completed. Resource name: projects/1026793852137/locations/us-central1/batchPredictionJobs/3414990774075392000\n"
     ]
    }
   ],
   "source": [
    "batch_prediction_job_filelist = vertex_model.batch_predict(\n",
    "    job_display_name = f\"{SERIES}-{EXPERIMENT}-FILELIST\",\n",
    "    gcs_source = [f\"gs://{bucket.name}/{blob.name}\"],\n",
    "    gcs_destination_prefix = f\"gs://{bucket.name}/{SERIES}/{EXPERIMENT}/batch/filelist\",\n",
    "    instances_format = 'file-list',\n",
    "    machine_type = 'n1-standard-2',\n",
    "    accelerator_count = 0,\n",
    "    accelerator_type = None,\n",
    "    starting_replica_count = 1,\n",
    "    max_replica_count = 10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "6f2bc65f-af6b-4da2-b7f1-5892bc6ca79f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<JobState.JOB_STATE_SUCCEEDED: 4>"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_prediction_job_filelist.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "ab41d355-b6ba-4229-b8eb-7196d0906f81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['JOB_STATE_UNSPECIFIED',\n",
       " 'JOB_STATE_QUEUED',\n",
       " 'JOB_STATE_PENDING',\n",
       " 'JOB_STATE_RUNNING',\n",
       " 'JOB_STATE_SUCCEEDED',\n",
       " 'JOB_STATE_FAILED',\n",
       " 'JOB_STATE_CANCELLING',\n",
       " 'JOB_STATE_CANCELLED',\n",
       " 'JOB_STATE_PAUSED',\n",
       " 'JOB_STATE_EXPIRED',\n",
       " 'JOB_STATE_UPDATING',\n",
       " 'JOB_STATE_PARTIALLY_SUCCEEDED']"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_prediction_job_filelist.state._member_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "94402c19-656f-4e9c-8119-8b325bc43fba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_prediction_job_filelist.done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "92586bd4-45af-4b9d-a15d-862ea5f64a02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(seconds=931, microseconds=898112)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_prediction_job_filelist.end_time - batch_prediction_job_filelist.start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "d228a1be-84ea-4398-a1d5-48dba72bc04e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0:15:31.898112'"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(batch_prediction_job_filelist.end_time - batch_prediction_job_filelist.start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b213ad1-7e57-4620-8602-96f30beaefb3",
   "metadata": {},
   "source": [
    "#### Retrieve Results From GCS\n",
    "\n",
    "There could be multiple files containing the prediction results depending on the number of serving nodes.  **Note** that there is also a series for errors files that contain per instance errors if there are any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "5f36a68e-fbf1-4181-a731-189f7538928f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gcs_output_directory: \"gs://statmike-mlops-349915/mlops-serving/understand-io/batch/filelist/prediction-mlops-serving-2025_03_05T06_53_04_021Z\""
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_prediction_job_filelist.output_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "610484a2-7e1a-4234-8203-077798728a0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Blob: statmike-mlops-349915, mlops-serving/understand-io/batch/filelist/prediction-mlops-serving-2025_03_05T06_53_04_021Z/prediction.errors_stats-00000-of-00001, 1741187180928168>,\n",
       " <Blob: statmike-mlops-349915, mlops-serving/understand-io/batch/filelist/prediction-mlops-serving-2025_03_05T06_53_04_021Z/prediction.results-00000-of-00004, 1741187180562990>,\n",
       " <Blob: statmike-mlops-349915, mlops-serving/understand-io/batch/filelist/prediction-mlops-serving-2025_03_05T06_53_04_021Z/prediction.results-00001-of-00004, 1741187180572141>,\n",
       " <Blob: statmike-mlops-349915, mlops-serving/understand-io/batch/filelist/prediction-mlops-serving-2025_03_05T06_53_04_021Z/prediction.results-00002-of-00004, 1741187180692006>,\n",
       " <Blob: statmike-mlops-349915, mlops-serving/understand-io/batch/filelist/prediction-mlops-serving-2025_03_05T06_53_04_021Z/prediction.results-00003-of-00004, 1741187180573352>]"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blobs = list(bucket.list_blobs(prefix = batch_prediction_job_filelist.output_info.gcs_output_directory.split(bucket.name)[-1][1:]))\n",
    "blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "7df7f714-9ce3-4333-9265-5da9790f36f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from:  mlops-serving/understand-io/batch/filelist/prediction-mlops-serving-2025_03_05T06_53_04_021Z/prediction.results-00000-of-00004\n",
      "Reading from:  mlops-serving/understand-io/batch/filelist/prediction-mlops-serving-2025_03_05T06_53_04_021Z/prediction.results-00001-of-00004\n",
      "Reading from:  mlops-serving/understand-io/batch/filelist/prediction-mlops-serving-2025_03_05T06_53_04_021Z/prediction.results-00002-of-00004\n",
      "Reading from:  mlops-serving/understand-io/batch/filelist/prediction-mlops-serving-2025_03_05T06_53_04_021Z/prediction.results-00003-of-00004\n"
     ]
    }
   ],
   "source": [
    "filelist_predictions = []\n",
    "for blob in blobs:\n",
    "    if blob.name.split('/')[-1].startswith('prediction.results-'):\n",
    "        print('Reading from: ', blob.name)\n",
    "        blob_content = blob.download_as_string().decode('utf-8')\n",
    "        for line in blob_content.splitlines():\n",
    "            filelist_predictions.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "b678352c-1f8d-4dfb-967c-fc6cfcb0d582",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instance': 'gs://statmike-mlops-349915/mlops-serving/understand-io/batch/filelist/files/instance_13.txt',\n",
       " 'prediction': {'b64': 'W3sna2V5JzogJ3ZhbHVlJ30sIHsna2V5JzogJ3ZhbHVlMid9XQ=='}}"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filelist_predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8bd425-021a-4122-af17-6387ae38a020",
   "metadata": {},
   "source": [
    "#### Decode Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "90a15bfd-3dd9-441a-8daa-f413da7e73ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for pred in filelist_predictions:\n",
    "    pred['prediction']['decoded'] = base64.b64decode(pred['prediction']['b64']).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "4e3fed19-77fd-485b-b2d3-d8d8223f505b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instance': 'gs://statmike-mlops-349915/mlops-serving/understand-io/batch/filelist/files/instance_13.txt',\n",
       " 'prediction': {'b64': 'W3sna2V5JzogJ3ZhbHVlJ30sIHsna2V5JzogJ3ZhbHVlMid9XQ==',\n",
       "  'decoded': \"[{'key': 'value'}, {'key': 'value2'}]\"}}"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filelist_predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "3be07722-3f1b-485a-a1e4-2cabb6513f99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'instance': 'gs://statmike-mlops-349915/mlops-serving/understand-io/batch/filelist/files/instance_13.txt',\n",
       "  'prediction': {'b64': 'W3sna2V5JzogJ3ZhbHVlJ30sIHsna2V5JzogJ3ZhbHVlMid9XQ==',\n",
       "   'decoded': \"[{'key': 'value'}, {'key': 'value2'}]\"}},\n",
       " {'instance': 'gs://statmike-mlops-349915/mlops-serving/understand-io/batch/filelist/files/instance_8.txt',\n",
       "  'prediction': {'b64': 'WzFd', 'decoded': '[1]'}},\n",
       " {'instance': 'gs://statmike-mlops-349915/mlops-serving/understand-io/batch/filelist/files/instance_15.txt',\n",
       "  'prediction': {'b64': 'YzI5dFpYUm9hVzVuSUhSdklHVnVZMjlrWlNCaGN5QmlhVzVoY25rZ2FHVnlaUT09',\n",
       "   'decoded': 'c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ=='}},\n",
       " {'instance': 'gs://statmike-mlops-349915/mlops-serving/understand-io/batch/filelist/files/instance_16.txt',\n",
       "  'prediction': {'b64': 'WydjMjl0WlhSb2FXNW5JSFJ2SUdWdVkyOWtaU0JoY3lCaWFXNWhjbmtnYUdWeVpRPT0nXQ==',\n",
       "   'decoded': \"['c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ==']\"}},\n",
       " {'instance': 'gs://statmike-mlops-349915/mlops-serving/understand-io/batch/filelist/files/instance_6.txt',\n",
       "  'prediction': {'b64': 'QQ==', 'decoded': 'A'}},\n",
       " {'instance': 'gs://statmike-mlops-349915/mlops-serving/understand-io/batch/filelist/files/instance_9.txt',\n",
       "  'prediction': {'b64': 'WzEsIDIsIDMsIDRd', 'decoded': '[1, 2, 3, 4]'}},\n",
       " {'instance': 'gs://statmike-mlops-349915/mlops-serving/understand-io/batch/filelist/files/instance_1.txt',\n",
       "  'prediction': {'b64': 'Mg==', 'decoded': '2'}},\n",
       " {'instance': 'gs://statmike-mlops-349915/mlops-serving/understand-io/batch/filelist/files/instance_0.txt',\n",
       "  'prediction': {'b64': 'MQ==', 'decoded': '1'}},\n",
       " {'instance': 'gs://statmike-mlops-349915/mlops-serving/understand-io/batch/filelist/files/instance_12.txt',\n",
       "  'prediction': {'b64': 'W3sna2V5JzogJ3ZhbHVlJ31d',\n",
       "   'decoded': \"[{'key': 'value'}]\"}},\n",
       " {'instance': 'gs://statmike-mlops-349915/mlops-serving/understand-io/batch/filelist/files/instance_5.txt',\n",
       "  'prediction': {'b64': 'YQ==', 'decoded': 'a'}},\n",
       " {'instance': 'gs://statmike-mlops-349915/mlops-serving/understand-io/batch/filelist/files/instance_17.txt',\n",
       "  'prediction': {'b64': 'eydiNjQnOiAnYzI5dFpYUm9hVzVuSUhSdklHVnVZMjlrWlNCaGN5QmlhVzVoY25rZ2FHVnlaUT09J30=',\n",
       "   'decoded': \"{'b64': 'c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ=='}\"}},\n",
       " {'instance': 'gs://statmike-mlops-349915/mlops-serving/understand-io/batch/filelist/files/instance_10.txt',\n",
       "  'prediction': {'b64': 'W1sxLCAyXSwgWzMsIDRdXQ==',\n",
       "   'decoded': '[[1, 2], [3, 4]]'}},\n",
       " {'instance': 'gs://statmike-mlops-349915/mlops-serving/understand-io/batch/filelist/files/instance_11.txt',\n",
       "  'prediction': {'b64': 'W1tbMSwgMl0sIFszLCA0XV1d',\n",
       "   'decoded': '[[[1, 2], [3, 4]]]'}},\n",
       " {'instance': 'gs://statmike-mlops-349915/mlops-serving/understand-io/batch/filelist/files/instance_3.txt',\n",
       "  'prediction': {'b64': 'NA==', 'decoded': '4'}},\n",
       " {'instance': 'gs://statmike-mlops-349915/mlops-serving/understand-io/batch/filelist/files/instance_4.txt',\n",
       "  'prediction': {'b64': 'MS4yNDU3ODAwMQ==', 'decoded': '1.24578001'}},\n",
       " {'instance': 'gs://statmike-mlops-349915/mlops-serving/understand-io/batch/filelist/files/instance_7.txt',\n",
       "  'prediction': {'b64': 'eydrZXknOiAndmFsdWUnfQ==',\n",
       "   'decoded': \"{'key': 'value'}\"}},\n",
       " {'instance': 'gs://statmike-mlops-349915/mlops-serving/understand-io/batch/filelist/files/instance_2.txt',\n",
       "  'prediction': {'b64': 'Mw==', 'decoded': '3'}},\n",
       " {'instance': 'gs://statmike-mlops-349915/mlops-serving/understand-io/batch/filelist/files/instance_14.txt',\n",
       "  'prediction': {'b64': 'WydnczovL2J1Y2tldC9wYXRoL3RvL2ltYWdlL2ltYWdlMS5qcGcnXQ==',\n",
       "   'decoded': \"['gs://bucket/path/to/image/image1.jpg']\"}}]"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filelist_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac1c9f5-a379-456d-89d2-607aff457dab",
   "metadata": {},
   "source": [
    "### TFRecord Files - Stored In GCS\n",
    "\n",
    "A TFRecord is a file that TensorFlow uses to store binary formated data for efficient reading and transport.  A single file can contain multiple records.  Read more details about TFRecords [here](https://www.tensorflow.org/tutorials/load_data/tfrecord) and [here](https://www.tensorflow.org/guide/data#consuming_tfrecord_data).\n",
    "\n",
    "You can use uncompressed or compressed versions of TFRecord files by specifying the instance format as either: 'tf-record', 'tf-record-gzip'.  \n",
    "\n",
    "The Vertex AI Batch Prediction service can read different record files from different serving replicas so make sure that the records files are split into smaller files and pass them to the job with a wildcard like `gcs_source = ['gs://bucket-name/path/*.tfrecord']`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398e20a1-ba4f-4917-a766-ed3c0d01057a",
   "metadata": {},
   "source": [
    "#### Save Instances To TFRecord Files In GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "45586f22-c925-43a1-b1ae-1af439cfad89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, instance in enumerate(example_instances):\n",
    "    blob = bucket.blob(f\"{SERIES}/{EXPERIMENT}/batch/tfrecord/records/instance_{i}.tfrecord\")\n",
    "    with tempfile.NamedTemporaryFile(delete = True, suffix = '.tfrecord') as temp_file:\n",
    "        with tf.io.TFRecordWriter(temp_file.name) as writer: # options = 'GZIP'\n",
    "            feature = tf.train.Feature(bytes_list = tf.train.BytesList(value = [str(instance).encode('utf-8')]))\n",
    "            example = tf.train.Example(features = tf.train.Features(feature = {\"value\": feature}))\n",
    "            writer.write(example.SerializeToString())\n",
    "        blob.upload_from_filename(temp_file.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084ec2b0-299b-4b3a-b9aa-a49509b5153a",
   "metadata": {},
   "source": [
    "#### Start Batch Prediction Job On Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "fc375c7b-11c1-474c-8b08-d295262d22ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating BatchPredictionJob\n",
      "BatchPredictionJob created. Resource name: projects/1026793852137/locations/us-central1/batchPredictionJobs/5510156360290926592\n",
      "To use this BatchPredictionJob in another session:\n",
      "bpj = aiplatform.BatchPredictionJob('projects/1026793852137/locations/us-central1/batchPredictionJobs/5510156360290926592')\n",
      "View Batch Prediction Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/batch-predictions/5510156360290926592?project=1026793852137\n",
      "BatchPredictionJob projects/1026793852137/locations/us-central1/batchPredictionJobs/5510156360290926592 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/1026793852137/locations/us-central1/batchPredictionJobs/5510156360290926592 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/1026793852137/locations/us-central1/batchPredictionJobs/5510156360290926592 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/1026793852137/locations/us-central1/batchPredictionJobs/5510156360290926592 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/1026793852137/locations/us-central1/batchPredictionJobs/5510156360290926592 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/1026793852137/locations/us-central1/batchPredictionJobs/5510156360290926592 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/1026793852137/locations/us-central1/batchPredictionJobs/5510156360290926592 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/1026793852137/locations/us-central1/batchPredictionJobs/5510156360290926592 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/1026793852137/locations/us-central1/batchPredictionJobs/5510156360290926592 current state:\n",
      "JobState.JOB_STATE_SUCCEEDED\n",
      "BatchPredictionJob run completed. Resource name: projects/1026793852137/locations/us-central1/batchPredictionJobs/5510156360290926592\n"
     ]
    }
   ],
   "source": [
    "batch_prediction_job_tfrecord = vertex_model.batch_predict(\n",
    "    job_display_name = f\"{SERIES}-{EXPERIMENT}-TFRECORD\",\n",
    "    gcs_source = [f\"gs://{bucket.name}/{SERIES}/{EXPERIMENT}/batch/tfrecord/records/*.tfrecord\"],\n",
    "    gcs_destination_prefix = f\"gs://{bucket.name}/{SERIES}/{EXPERIMENT}/batch/tfrecord\",\n",
    "    instances_format = 'tf-record',\n",
    "    machine_type = 'n1-standard-2',\n",
    "    accelerator_count = 0,\n",
    "    accelerator_type = None,\n",
    "    starting_replica_count = 1,\n",
    "    max_replica_count = 10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "10a9971e-4f6f-43ae-8a54-11915e91bd15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<JobState.JOB_STATE_SUCCEEDED: 4>"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_prediction_job_tfrecord.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "d2f7618a-d0b5-47a2-8394-fbe0e4ac815b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['JOB_STATE_UNSPECIFIED',\n",
       " 'JOB_STATE_QUEUED',\n",
       " 'JOB_STATE_PENDING',\n",
       " 'JOB_STATE_RUNNING',\n",
       " 'JOB_STATE_SUCCEEDED',\n",
       " 'JOB_STATE_FAILED',\n",
       " 'JOB_STATE_CANCELLING',\n",
       " 'JOB_STATE_CANCELLED',\n",
       " 'JOB_STATE_PAUSED',\n",
       " 'JOB_STATE_EXPIRED',\n",
       " 'JOB_STATE_UPDATING',\n",
       " 'JOB_STATE_PARTIALLY_SUCCEEDED']"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_prediction_job_tfrecord.state._member_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "08628bca-ba19-4aa7-bb3b-e9b07fe7f5a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_prediction_job_tfrecord.done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "8060daee-6f1e-4604-9477-cad8a59240a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(seconds=919, microseconds=210520)"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_prediction_job_tfrecord.end_time - batch_prediction_job_tfrecord.start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "c1567d70-ddc6-483c-9f7b-f367c75e7863",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0:15:19.210520'"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(batch_prediction_job_tfrecord.end_time - batch_prediction_job_tfrecord.start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3b9de4-4214-4c22-9681-05c51169c52c",
   "metadata": {},
   "source": [
    "#### Retrieve Results From GCS\n",
    "\n",
    "There could be multiple files containing the prediction results depending on the number of serving nodes.  **Note** that there is also a series for errors files that contain per instance errors if there are any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "f508852a-f6f3-4ae2-8c2c-5b4ef6f065d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gcs_output_directory: \"gs://statmike-mlops-349915/mlops-serving/understand-io/batch/tfrecord/prediction-mlops-serving-2025_03_05T09_59_44_728Z\""
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_prediction_job_tfrecord.output_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "58cb9616-7af2-418d-bb2a-cd9a2d308274",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Blob: statmike-mlops-349915, mlops-serving/understand-io/batch/tfrecord/prediction-mlops-serving-2025_03_05T09_59_44_728Z/prediction.errors_stats-00000-of-00001, 1741198360307693>,\n",
       " <Blob: statmike-mlops-349915, mlops-serving/understand-io/batch/tfrecord/prediction-mlops-serving-2025_03_05T09_59_44_728Z/prediction.results-00000-of-00002, 1741198359587390>,\n",
       " <Blob: statmike-mlops-349915, mlops-serving/understand-io/batch/tfrecord/prediction-mlops-serving-2025_03_05T09_59_44_728Z/prediction.results-00001-of-00002, 1741198359589120>]"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blobs = list(bucket.list_blobs(prefix = batch_prediction_job_tfrecord.output_info.gcs_output_directory.split(bucket.name)[-1][1:]))\n",
    "blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "a594cff5-6db7-4eb3-9c8f-34af0cb9cb67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from:  mlops-serving/understand-io/batch/tfrecord/prediction-mlops-serving-2025_03_05T09_59_44_728Z/prediction.results-00000-of-00002\n",
      "Reading from:  mlops-serving/understand-io/batch/tfrecord/prediction-mlops-serving-2025_03_05T09_59_44_728Z/prediction.results-00001-of-00002\n"
     ]
    }
   ],
   "source": [
    "tfrecord_predictions = []\n",
    "for blob in blobs:\n",
    "    if blob.name.split('/')[-1].startswith('prediction.results-'):\n",
    "        print('Reading from: ', blob.name)\n",
    "        blob_content = blob.download_as_string().decode('utf-8')\n",
    "        for line in blob_content.splitlines():\n",
    "            tfrecord_predictions.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "13921904-4045-4caf-9a8e-0969c631cc1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prediction': {'b64': 'CkoKSAoFdmFsdWUSPwo9Cjt7J2I2NCc6ICdjMjl0WlhSb2FXNW5JSFJ2SUdWdVkyOWtaU0JoY3lCaWFXNWhjbmtnYUdWeVpRPT0nfQ=='}}"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfrecord_predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310fe6fa-93a4-4155-be12-defc6e44bb1c",
   "metadata": {},
   "source": [
    "#### Decode Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "7e2b402e-b936-4856-b77f-1c7d2d38b95b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for pred in tfrecord_predictions:\n",
    "    pred['prediction']['decoded'] = base64.b64decode(pred['prediction']['b64']).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "8ea222cb-20b5-47d5-8c81-01f5f0c80d20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prediction': {'b64': 'CkoKSAoFdmFsdWUSPwo9Cjt7J2I2NCc6ICdjMjl0WlhSb2FXNW5JSFJ2SUdWdVkyOWtaU0JoY3lCaWFXNWhjbmtnYUdWeVpRPT0nfQ==',\n",
       "  'decoded': \"\\nJ\\nH\\n\\x05value\\x12?\\n=\\n;{'b64': 'c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ=='}\"}}"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfrecord_predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "8716d1a2-4440-4f42-bb1a-82562a15b4e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'prediction': {'b64': 'CkoKSAoFdmFsdWUSPwo9Cjt7J2I2NCc6ICdjMjl0WlhSb2FXNW5JSFJ2SUdWdVkyOWtaU0JoY3lCaWFXNWhjbmtnYUdWeVpRPT0nfQ==',\n",
       "   'decoded': \"\\nJ\\nH\\n\\x05value\\x12?\\n=\\n;{'b64': 'c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ=='}\"}},\n",
       " {'prediction': {'b64': 'ChAKDgoFdmFsdWUSBQoDCgEz',\n",
       "   'decoded': '\\n\\x10\\n\\x0e\\n\\x05value\\x12\\x05\\n\\x03\\n\\x013'}},\n",
       " {'prediction': {'b64': 'ChAKDgoFdmFsdWUSBQoDCgE0',\n",
       "   'decoded': '\\n\\x10\\n\\x0e\\n\\x05value\\x12\\x05\\n\\x03\\n\\x014'}},\n",
       " {'prediction': {'b64': 'ChkKFwoFdmFsdWUSDgoMCgoxLjI0NTc4MDAx',\n",
       "   'decoded': '\\n\\x19\\n\\x17\\n\\x05value\\x12\\x0e\\n\\x0c\\n\\n1.24578001'}},\n",
       " {'prediction': {'b64': 'ChAKDgoFdmFsdWUSBQoDCgFh',\n",
       "   'decoded': '\\n\\x10\\n\\x0e\\n\\x05value\\x12\\x05\\n\\x03\\n\\x01a'}},\n",
       " {'prediction': {'b64': 'ChAKDgoFdmFsdWUSBQoDCgFB',\n",
       "   'decoded': '\\n\\x10\\n\\x0e\\n\\x05value\\x12\\x05\\n\\x03\\n\\x01A'}},\n",
       " {'prediction': {'b64': 'Ch8KHQoFdmFsdWUSFAoSChB7J2tleSc6ICd2YWx1ZSd9',\n",
       "   'decoded': \"\\n\\x1f\\n\\x1d\\n\\x05value\\x12\\x14\\n\\x12\\n\\x10{'key': 'value'}\"}},\n",
       " {'prediction': {'b64': 'ChIKEAoFdmFsdWUSBwoFCgNbMV0=',\n",
       "   'decoded': '\\n\\x12\\n\\x10\\n\\x05value\\x12\\x07\\n\\x05\\n\\x03[1]'}},\n",
       " {'prediction': {'b64': 'ChsKGQoFdmFsdWUSEAoOCgxbMSwgMiwgMywgNF0=',\n",
       "   'decoded': '\\n\\x1b\\n\\x19\\n\\x05value\\x12\\x10\\n\\x0e\\n\\x0c[1, 2, 3, 4]'}},\n",
       " {'prediction': {'b64': 'ChAKDgoFdmFsdWUSBQoDCgEx',\n",
       "   'decoded': '\\n\\x10\\n\\x0e\\n\\x05value\\x12\\x05\\n\\x03\\n\\x011'}},\n",
       " {'prediction': {'b64': 'ChAKDgoFdmFsdWUSBQoDCgEy',\n",
       "   'decoded': '\\n\\x10\\n\\x0e\\n\\x05value\\x12\\x05\\n\\x03\\n\\x012'}},\n",
       " {'prediction': {'b64': 'Ch8KHQoFdmFsdWUSFAoSChBbWzEsIDJdLCBbMywgNF1d',\n",
       "   'decoded': '\\n\\x1f\\n\\x1d\\n\\x05value\\x12\\x14\\n\\x12\\n\\x10[[1, 2], [3, 4]]'}},\n",
       " {'prediction': {'b64': 'CiEKHwoFdmFsdWUSFgoUChJbW1sxLCAyXSwgWzMsIDRdXV0=',\n",
       "   'decoded': '\\n!\\n\\x1f\\n\\x05value\\x12\\x16\\n\\x14\\n\\x12[[[1, 2], [3, 4]]]'}},\n",
       " {'prediction': {'b64': 'CiEKHwoFdmFsdWUSFgoUChJbeydrZXknOiAndmFsdWUnfV0=',\n",
       "   'decoded': \"\\n!\\n\\x1f\\n\\x05value\\x12\\x16\\n\\x14\\n\\x12[{'key': 'value'}]\"}},\n",
       " {'prediction': {'b64': 'CjQKMgoFdmFsdWUSKQonCiVbeydrZXknOiAndmFsdWUnfSwgeydrZXknOiAndmFsdWUyJ31d',\n",
       "   'decoded': \"\\n4\\n2\\n\\x05value\\x12)\\n'\\n%[{'key': 'value'}, {'key': 'value2'}]\"}},\n",
       " {'prediction': {'b64': 'CjcKNQoFdmFsdWUSLAoqCihbJ2dzOi8vYnVja2V0L3BhdGgvdG8vaW1hZ2UvaW1hZ2UxLmpwZydd',\n",
       "   'decoded': \"\\n7\\n5\\n\\x05value\\x12,\\n*\\n(['gs://bucket/path/to/image/image1.jpg']\"}},\n",
       " {'prediction': {'b64': 'Cj8KPQoFdmFsdWUSNAoyCjBjMjl0WlhSb2FXNW5JSFJ2SUdWdVkyOWtaU0JoY3lCaWFXNWhjbmtnYUdWeVpRPT0=',\n",
       "   'decoded': '\\n?\\n=\\n\\x05value\\x124\\n2\\n0c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ=='}},\n",
       " {'prediction': {'b64': 'CkMKQQoFdmFsdWUSOAo2CjRbJ2MyOXRaWFJvYVc1bklIUnZJR1Z1WTI5a1pTQmhjeUJpYVc1aGNua2dhR1Z5WlE9PSdd',\n",
       "   'decoded': \"\\nC\\nA\\n\\x05value\\x128\\n6\\n4['c29tZXRoaW5nIHRvIGVuY29kZSBhcyBiaW5hcnkgaGVyZQ==']\"}}]"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfrecord_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d193e72-eb04-48c9-9521-b59d07b28dfe",
   "metadata": {},
   "source": [
    "## Filtering And Transformation During Batch Jobs\n",
    "\n",
    "As batch prediction jobs read records to process for inference it can optionally filter (subset fields/columns) and transform (change the order of fields/columns) the records.  Read more in the documentation [here](https://cloud.google.com/vertex-ai/docs/predictions/get-batch-predictions#filter_and_transform_input_data).\n",
    "\n",
    "This requires specifying an [instanceConfig](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform_v1.types.BatchPredictionJob.InstanceConfig) for the BatchPredictionJob, like:\n",
    "```\n",
    "\"instanceConfig\": {\n",
    "\"instance_type\":\"\"\n",
    "\"excluded_fields\":[]\n",
    "\"included_fields\":[]\n",
    "\"key_field\":[]\n",
    "}\n",
    "```\n",
    "**Notes**\n",
    "- `instance_type` is the instance type the Model accepts, like 'array' will create an array of values form the input record\n",
    "- `key_field` is a field that will not be included in the instance and will be provided in the output instead of repeating the instance (the default behavior)\n",
    "- `excluded_fields` are fields to ignore and not pass to the instance but will be included in the output unless a key_field was specified\n",
    "- `included_fields` are fields to include in the instance and also determine the field order or array order of the instance\n",
    "\n",
    "To use this the job needs to be submitted with the gapic/aiplatform_v1 SDK as follows:\n",
    "\n",
    "Create a jobs client:\n",
    "```\n",
    "client_options = {\"api_endpoint\": f\"{REGION}-aiplatform.googleapis.com\"}\n",
    "jobs_client = aiplatform.gapic.JobServiceClient(client_options = client_options)\n",
    "```\n",
    "\n",
    "Create a batch prediction job object:\n",
    "```\n",
    "batch_prediction_job = aiplatform.gapic.BatchPredictionJob(\n",
    "    display_name = f'{SERIES}_{EXPERIMENT}',\n",
    "    model = vertex_model.versioned_resource_name,\n",
    "    input_config = dict(\n",
    "        instances_format = 'bigquery',\n",
    "        bigquery_source = dict(input_uri = f'bq://{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}')\n",
    "    ),\n",
    "    output_config = dict(\n",
    "        predictions_format = 'bigquery',\n",
    "        bigquery_destination = dict(output_uri = f'bq://{BQ_PROJECT}.{BQ_DATASET}')\n",
    "    ),\n",
    "    dedicated_resources = dict(\n",
    "        machine_spec = dict(machine_type = 'n1-standard-2'),\n",
    "        starting_replica_count = 2,\n",
    "        max_replica_count = 10\n",
    "    ),\n",
    "    instance_config = dict(\n",
    "        instance_type = 'array',\n",
    "        included_fields = list(train_x.columns),\n",
    "        #excluded_fields = ['Class', 'splits', 'transaction_id']\n",
    "    )\n",
    ")\n",
    "```\n",
    "\n",
    "Submit the job with the jobs client:\n",
    "```\n",
    "BatchJob = jobs_client.create_batch_prediction_job(\n",
    "    parent = f'projects/{PROJECT_ID}/locations/{REGION}',\n",
    "    batch_prediction_job = batch_prediction_job\n",
    ")\n",
    "```\n",
    "\n",
    "Get the job and check the state:\n",
    "```\n",
    "BatchJob = jobs_client.get_batch_prediction_job(\n",
    "    name = BatchJob.name\n",
    ")\n",
    "BatchJob.state, BatchJob.state.value, BatchJob.state.name\n",
    "```\n",
    "\n",
    "Get the jobs output info:\n",
    "```\n",
    "BatchJob.output_info\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5424f84-f236-43cf-997d-9fdfb359b5e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1321ef-7f88-4c8c-a2b4-5fba563b7724",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
