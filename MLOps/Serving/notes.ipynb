{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d947942c-e6e0-467d-9a33-78eb561522c0",
   "metadata": {},
   "source": [
    "---\n",
    "# NOTES - IGNORE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8beb7d9-2224-4f6e-9ad2-8c9f375ccdd5",
   "metadata": {},
   "source": [
    "---\n",
    "# HOLD\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a03c4be9-fdec-455a-bf76-be6d33bfb5cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install transformers tensorflow torch tf-keras tensorflow_hub tensorflow_text keras-hub keras-nlp -U -q --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "88f2a3c9-889a-4568-be50-6e278b6e1897",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    'How do you play baseball?',\n",
    "    'How do you play monopoly?',\n",
    "    'How do you play chess?',\n",
    "    'How do you play football?',\n",
    "    'sports',\n",
    "    'board games'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8782ceff-76e3-4cd2-81bd-bae3deca2461",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5eb33b70-8ace-4fc0-a809-9d37d197b905",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")\n",
    "pt_bert_model = BertModel.from_pretrained(\"google-bert/bert-base-uncased\")\n",
    "\n",
    "inputs = tokenizer(prompts[0], return_tensors=\"pt\") # pt, tf, or np\n",
    "outputs = pt_bert_model(**inputs)\n",
    "\n",
    "last_hidden_states = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1892a42d-c250-4b23-8641-1b621fba0c24",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2129, 2079, 2017, 2377, 3598, 1029,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1604e69-2acc-4588-9ae5-d6e2e114d2ba",
   "metadata": {},
   "source": [
    "CLS Token or classification token\n",
    "BERT uses this to create a summary representation, capturing the overall meaning of the input sequence\n",
    "Averaging, shown next, will treat all token equal and can dilute important key words or phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b58cb4c8-fbf5-46e3-ab25-4ab4bca5b8e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "average_embedding = torch.mean(last_hidden_states, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5cba97b5-dda3-41a1-8727-e6f85ecfbb3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.5702,  0.0869, -0.3377, -0.2114,  0.1338, -0.3392, -0.1137,  0.3860,\n",
       "        -0.2058,  0.1436], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_embedding[0, 0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ed6b6ea5-0434-4427-9c35-e491410f9fb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cls_embedding = last_hidden_states[:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "33d46dbe-728e-40a7-b977-c6be9b0ce4cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1670,  0.1293, -0.2888,  0.0183, -0.1663, -0.4358,  0.2780,  0.4109,\n",
       "        -0.3145,  0.1231], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_embedding[0, 0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44353846-76e2-4a49-a7ce-4b83af9dc448",
   "metadata": {
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f18bef7d-31f1-45ff-9a28-f0d026fd4ad4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f10342b94a64f928ad1670c06e8b6cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5487bb9483ca473aa1f67303bbfd8efc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a231d982dc1493994919a5d0f7412ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ec2d51278bf4f5fbc1274706625b056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07295d976dd644eca53746897cfe5258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, TFBertModel\n",
    "import tensorflow as tf\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "tf_bert_model = TFBertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "inputs = tokenizer(prompts[0], return_tensors='tf')\n",
    "outputs = tf_bert_model(**inputs)\n",
    "\n",
    "last_hidden_states = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "de2221bd-2d4b-4bd1-ac87-16d736c7ca92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(1, 8), dtype=int32, numpy=array([[ 101, 2129, 2079, 2017, 2377, 3598, 1029,  102]], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(1, 8), dtype=int32, numpy=array([[0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(1, 8), dtype=int32, numpy=array([[1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)>}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "69386eff-3a26-4cdc-ac6c-aa22694bf063",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "average_embedding = tf.reduce_mean(last_hidden_states, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "211709e4-1176-4872-ae7c-ebcdb1404007",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([ 0.57020056,  0.08687384, -0.33770347, -0.21141008,  0.13380972,\n",
       "       -0.33915833, -0.11369041,  0.38600746, -0.20583639,  0.14364798],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_embedding[0, 0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e2eaad03-26ad-4942-8905-640ccb51aed7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cls_embedding = last_hidden_states[:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b69dcb76-2307-4998-813c-9bac0138f0c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([ 0.16698106,  0.12934545, -0.2888183 ,  0.01831304, -0.16634001,\n",
       "       -0.43576777,  0.2779695 ,  0.4108801 , -0.31453484,  0.12307177],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_embedding[0, 0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c2e1c3-e5af-4d81-ab92-0d456e26bec2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a340750e-57e7-427a-bbc9-e62291e58523",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")\n",
    "\n",
    "tf_inputs = tokenizer(prompts[0], return_tensors='tf')\n",
    "tf_outputs = tf_bert_model(**tf_inputs)\n",
    "\n",
    "pt_inputs = tokenizer(prompts[0], return_tensors='pt')\n",
    "pt_outputs = pt_bert_model(**pt_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4f65b80a-fa77-4dd4-af9e-510e7ac63c67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(1, 8), dtype=int32, numpy=array([[ 101, 2129, 2079, 2017, 2377, 3598, 1029,  102]], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(1, 8), dtype=int32, numpy=array([[0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(1, 8), dtype=int32, numpy=array([[1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)>}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a8de394f-18c7-4758-8769-a031379fcb35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2129, 2079, 2017, 2377, 3598, 1029,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f3a2aa1f-2972-4fc6-a4ea-64b55bf09b7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "tf_inputs = tokenizer(prompts[0], return_tensors='tf')\n",
    "tf_outputs = tf_bert_model(**tf_inputs)\n",
    "\n",
    "pt_inputs = tokenizer(prompts[0], return_tensors='pt')\n",
    "pt_outputs = pt_bert_model(**pt_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "234e4a2f-8bdf-4af3-8ebc-047ca26783b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(1, 8), dtype=int32, numpy=array([[ 101, 2129, 2079, 2017, 2377, 3598, 1029,  102]], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(1, 8), dtype=int32, numpy=array([[0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(1, 8), dtype=int32, numpy=array([[1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)>}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "658ef163-4eff-4f24-a148-33703c50033e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2129, 2079, 2017, 2377, 3598, 1029,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ec4633-b84f-42bb-96eb-375d4525ec29",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c6d5b12b-dec5-47ef-9115-c1f0aa96bbcf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./tf_bert_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./tf_bert_model/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(tf_bert_model, \"./tf_bert_model\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "6086e380-5066-4a27-b70a-1306db4f6e43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loaded_model = tf.saved_model.load(\"./tf_bert_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "7e133bd2-79d5-4b3f-b611-a31f26d72185",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf_outputs = loaded_model(tf_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "22d7eeb4-eab6-4f64-8602-c081b0c26906",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 8, 768), dtype=float32, numpy=\n",
       "array([[[ 0.16698128,  0.12934516, -0.28881842, ..., -0.37237155,\n",
       "          0.30332196,  0.45915374],\n",
       "        [ 0.54928696,  0.36820287, -0.48872763, ...,  0.05694058,\n",
       "          0.9668212 ,  0.04267411],\n",
       "        [ 0.9764617 ,  0.28813305, -0.02539649, ..., -0.780278  ,\n",
       "          0.7897879 ,  0.158675  ],\n",
       "        ...,\n",
       "        [ 0.82881975,  0.32954416, -0.24702382, ..., -0.10966089,\n",
       "          0.17899686,  0.12884353],\n",
       "        [ 0.14773697, -0.17064634, -1.1840162 , ..., -0.28526413,\n",
       "          0.25177714, -0.1390629 ],\n",
       "        [ 0.9357985 ,  0.07366893, -0.51816905, ...,  0.3814011 ,\n",
       "         -0.45790046, -0.15736234]]], dtype=float32)>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_outputs['last_hidden_state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "063a8f6f-71d4-4e74-95c8-9ca0614ef681",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cls_embedding = tf_outputs['last_hidden_state'][:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "cc99d14a-7af5-4d2e-ae08-3d25cfc8e9d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([ 0.16698128,  0.12934516, -0.28881842,  0.01831267, -0.16634007,\n",
       "       -0.4357676 ,  0.27796954,  0.41088063, -0.31453493,  0.12307151],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_embedding[0, 0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87624530-89a8-4b67-9507-70c78b25d45d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "30a99d0c-d7c5-40e6-bf96-c54e58c38596",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import tensorflow_text as text\n",
    "import tensorflow_hub as hub\n",
    "import keras_hub\n",
    "import keras_nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "39024355-02f1-4afc-85e7-df3888068712",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.18.0', '3.6.0')"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__, keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "208f770b-231c-41e6-a493-9a99a895f723",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = keras_nlp.models.BertTokenizer.from_preset(\"bert_base_en_uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "52ed6810-7978-47d7-9db6-281b7784670c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocessor = keras_nlp.models.BertPreprocessor.from_preset(\"bert_base_en_uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "816acc98-a5ae-48bf-a466-0c4936e25322",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "backbone = keras_nlp.models.BertBackbone.from_preset('bert_base_en_uncased', load_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fff7655-e6a4-4d8e-b4cf-84c3183d7609",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5ad4e4-a1d9-4eb0-a8a0-209f9f1fdf59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "66f35833-1c5f-4eee-9246-47de012730f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#dir(preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "abb0ae9b-8845-430e-8a9c-cd519edd8231",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocessor.input_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "4beacfe1-0634-4345-8ceb-ecadfb6c3915",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Layer.compute_output_shape of <BertTextClassifierPreprocessor name=bert_text_classifier_preprocessor_4, built=True>>"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.compute_output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b62040-fc96-4fb9-a3f6-470cbec04965",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8de692d-430b-4991-b919-b6cea56b6a96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59959eeb-f282-43e8-81ab-270b457655f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d0b9c0-1f2c-4081-8e29-73a14fc68a44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b0addf-c6ce-416c-b27d-f2fa825aeebd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "7a1ca42a-ceaa-42fb-b0c1-91038d77e4e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokens = tokenizer(prompts[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "d8845ec0-04d3-4cd6-9d64-cc85364ff24f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder_inputs = preprocessor(prompts[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "73cad6c2-18a6-4852-9db3-30f900bc095c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outputs = backbone(encoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "98b1b1d3-3315-4217-bd92-b78d0ad568f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sequence_output', 'pooled_output'])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "4f12ae28-e5ad-465d-b232-3d1a45f0a606",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 768])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs['pooled_output'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "db465fd1-6019-4f7e-86ee-f4111e55b40e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"bert_backbone\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"bert_backbone\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ token_ids           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ token_embedding     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │ <span style=\"color: #00af00; text-decoration-color: #00af00\">23,440,896</span> │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbeddi…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ segment_ids         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ position_embedding  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">393,216</span> │ token_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionEmbedding</span>) │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ segment_embedding   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │ segment_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embeddings_add      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ token_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │                   │            │ position_embeddi… │\n",
       "│                     │                   │            │ segment_embeddin… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embeddings_layer_n… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │ embeddings_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embeddings_dropout  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embeddings_layer… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ padding_mask        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_0 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,087,872</span> │ embeddings_dropo… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_1 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,087,872</span> │ transformer_laye… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_2 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,087,872</span> │ transformer_laye… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_3 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,087,872</span> │ transformer_laye… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_4 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,087,872</span> │ transformer_laye… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_5 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,087,872</span> │ transformer_laye… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_6 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,087,872</span> │ transformer_laye… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_7 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,087,872</span> │ transformer_laye… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_8 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,087,872</span> │ transformer_laye… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_9 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,087,872</span> │ transformer_laye… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,087,872</span> │ transformer_laye… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,087,872</span> │ transformer_laye… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ get_item_9          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ transformer_laye… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ pooled_dense        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">590,592</span> │ get_item_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ token_ids           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ token_embedding     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │ \u001b[38;5;34m23,440,896\u001b[0m │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mReversibleEmbeddi…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ segment_ids         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ position_embedding  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │    \u001b[38;5;34m393,216\u001b[0m │ token_embedding[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mPositionEmbedding\u001b[0m) │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ segment_embedding   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │      \u001b[38;5;34m1,536\u001b[0m │ segment_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embeddings_add      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ token_embedding[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │                   │            │ position_embeddi… │\n",
       "│                     │                   │            │ segment_embeddin… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embeddings_layer_n… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │      \u001b[38;5;34m1,536\u001b[0m │ embeddings_add[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embeddings_dropout  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ embeddings_layer… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ padding_mask        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_0 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │  \u001b[38;5;34m7,087,872\u001b[0m │ embeddings_dropo… │\n",
       "│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_1 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │  \u001b[38;5;34m7,087,872\u001b[0m │ transformer_laye… │\n",
       "│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_2 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │  \u001b[38;5;34m7,087,872\u001b[0m │ transformer_laye… │\n",
       "│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_3 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │  \u001b[38;5;34m7,087,872\u001b[0m │ transformer_laye… │\n",
       "│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_4 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │  \u001b[38;5;34m7,087,872\u001b[0m │ transformer_laye… │\n",
       "│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_5 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │  \u001b[38;5;34m7,087,872\u001b[0m │ transformer_laye… │\n",
       "│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_6 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │  \u001b[38;5;34m7,087,872\u001b[0m │ transformer_laye… │\n",
       "│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_7 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │  \u001b[38;5;34m7,087,872\u001b[0m │ transformer_laye… │\n",
       "│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_8 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │  \u001b[38;5;34m7,087,872\u001b[0m │ transformer_laye… │\n",
       "│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_9 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │  \u001b[38;5;34m7,087,872\u001b[0m │ transformer_laye… │\n",
       "│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │  \u001b[38;5;34m7,087,872\u001b[0m │ transformer_laye… │\n",
       "│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │  \u001b[38;5;34m7,087,872\u001b[0m │ transformer_laye… │\n",
       "│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ get_item_9          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ transformer_laye… │\n",
       "│ (\u001b[38;5;33mGetItem\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ pooled_dense        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)       │    \u001b[38;5;34m590,592\u001b[0m │ get_item_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,482,240</span> (417.64 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m109,482,240\u001b[0m (417.64 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,482,240</span> (417.64 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m109,482,240\u001b[0m (417.64 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "backbone.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a95035-0298-4a1e-9063-9e4d356b0b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "91c223c8-aa99-4217-b0f6-0dbf4327568b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#backbone(encoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "2aaed0c6-b4d3-4767-9095-76490d8aad10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "backbone.save(\"bert_backbone.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "d7779a56-2b0d-4a1e-8c48-f1487eca78a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loaded_backbone = keras.saving.load_model(\"bert_backbone.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "0cebee48-1e00-4749-9819-17ea5e4988c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#loaded_backbone(encoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4eaf3e-9b2d-474c-80a6-9560316aac15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93137419-2e19-40be-8640-4661f783c77f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "545f269d-8bd0-4de0-87f1-6ab2bc1281a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#dir(backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "a98c528f-ebb5-4c6a-9ab6-0ab3c96cbc82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor shape=(None, None), dtype=int32, sparse=False, name=padding_mask>,\n",
       " <KerasTensor shape=(None, None), dtype=int32, sparse=False, name=segment_ids>,\n",
       " <KerasTensor shape=(None, None), dtype=int32, sparse=False, name=token_ids>]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "2ebd245e-e433-41da-b939-06d2a24ccd4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[InputSpec(shape=(None, None), ndim=2),\n",
       " InputSpec(shape=(None, None), ndim=2),\n",
       " InputSpec(shape=(None, None), ndim=2)]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone.input_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "5ea868d8-f4cf-48a6-824d-c2ac57d1b4bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/keras/src/models/functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: {'token_ids': 'token_ids', 'segment_ids': 'segment_ids', 'padding_mask': 'padding_mask'}. Received: the structure of inputs=['*', '*', '*']\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./bert_backbone/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./bert_backbone/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at './bert_backbone'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): List[TensorSpec(shape=(None, None), dtype=tf.int32, name='padding_mask'), TensorSpec(shape=(None, None), dtype=tf.int32, name='segment_ids'), TensorSpec(shape=(None, None), dtype=tf.int32, name='token_ids')]\n",
      "Output Type:\n",
      "  Dict[['sequence_output', TensorSpec(shape=(None, None, 768), dtype=tf.float32, name=None)], ['pooled_output', TensorSpec(shape=(None, 768), dtype=tf.float32, name=None)]]\n",
      "Captures:\n",
      "  140596254374576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596253732080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596253723808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596253725392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596253734544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596253733664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596390449872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596390446880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596390449520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596390454448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596390454096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596390454272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596390446176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596390283920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596390281456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596390290960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596390292544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596390292016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596390294128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596390286912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596390289376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596390713424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596390719584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596390710432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596390715184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596390718000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596390717648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596390708848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596390718352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596408403040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596408404448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596408415712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596408415888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596408410960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596408416416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596408405504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596408407440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596408411136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596408402688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596408403568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596408536224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596408543968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596408534992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596408549072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596408539216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596408537808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596407747856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596407751728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596407750672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596407758768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596407754192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596407757888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596407762112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596407761584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596407752256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596407752784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596408161680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596408158336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596408156576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596408160624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596408171888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596408160272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596408170832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596366579792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596366586480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596366587888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596366589120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596366584192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596366578032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140597248896064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596366574336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596366587360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596366585248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596366573808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596366646560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596366643216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596366655008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596366654128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596366654832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268463760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268454256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268456368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268451616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268451264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268454080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268453024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268456192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268455312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268457776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268461824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268641168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268646096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268642928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268645216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268643632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268631136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268638528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268516272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268525600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268630432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268631312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268526832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268525776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268522608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268521904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140598467413616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268531232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268553088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268549744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268552208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268550448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268557488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268551680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268551328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268551504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268555904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268554320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596418699056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596418697296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596418704160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596248857584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596248862336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596248860048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140599618896112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596248869552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596248856528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596762799168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596762797760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596762798112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596762802512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596762788256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596762790368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596762797584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596412412880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596764079936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596764080288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596764078176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596764069024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596762388512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596762382528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596762386928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596762380944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596762386400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596422629456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596422627520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596422634736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596422631392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140598470357440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140598470350048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596422624880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596422623648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596422626288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596422625408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596422630864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596248091408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596248089648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596248093168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596248091056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596248094224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596249458320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596249456560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596249445296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596249458848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140598468769248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596249447760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596249455328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596249459024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596249459376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596249450400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596249451280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596247857632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596247866080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596247863968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596247858160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596247868720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596247860800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596247207376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596247205264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596247204912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596247858864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596247865376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596247204560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596247215472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596247201392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596247211952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596247202976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596247207904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596247894976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596247893920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596247888288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596247903952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596247897088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596247896560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596247901312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596764203264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596247897616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596247900256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596764198688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596247952400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    }
   ],
   "source": [
    "backbone.export('./bert_backbone', format = 'tf_saved_model', verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "b35c4206-f7c0-4197-949f-f08834f22375",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reload_backbone = tf.saved_model.load('./bert_backbone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "a6fa9b58-f3b0-404e-875e-d02ca10f8d89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_SignatureMap({'serve': <ConcreteFunction (*, padding_mask: TensorSpec(shape=(None, None), dtype=tf.int32, name='padding_mask'), segment_ids: TensorSpec(shape=(None, None), dtype=tf.int32, name='segment_ids'), token_ids: TensorSpec(shape=(None, None), dtype=tf.int32, name='token_ids')) -> Dict[['pooled_output', TensorSpec(shape=(None, 768), dtype=tf.float32, name='pooled_output')], ['sequence_output', TensorSpec(shape=(None, None, 768), dtype=tf.float32, name='sequence_output')]] at 0x7FDF26FD86A0>, 'serving_default': <ConcreteFunction (*, padding_mask: TensorSpec(shape=(None, None), dtype=tf.int32, name='padding_mask'), segment_ids: TensorSpec(shape=(None, None), dtype=tf.int32, name='segment_ids'), token_ids: TensorSpec(shape=(None, None), dtype=tf.int32, name='token_ids')) -> Dict[['pooled_output', TensorSpec(shape=(None, 768), dtype=tf.float32, name='pooled_output')], ['sequence_output', TensorSpec(shape=(None, None, 768), dtype=tf.float32, name='sequence_output')]] at 0x7FDF26FDB490>})"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload_backbone.signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "3c17ec86-5cd8-4221-ba05-81c94eed5aee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#reload_backbone.serve(encoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "76e41918-6adb-49a3-9d8f-6edb4e03383d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['token_ids', 'padding_mask', 'segment_ids'])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8a908d-f96e-4aa6-a56d-6d5ec84c22c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80fee74-7f68-4fb0-a9ba-08cc4b65cb60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25a1797-0696-4951-8f0f-4a4fd9b7a7fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61313bbe-11f9-4da3-abf8-078f7ab44915",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d76712f-8ea8-463f-9ce5-9d6b0d763d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "b5db4d4f-255f-4709-b1c6-e777fdd6167b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define input layers for the modified backbone\n",
    "input_tokens = tf.keras.Input(shape=(None,), dtype=tf.int32, name=\"token_ids\")\n",
    "input_padding_mask = tf.keras.Input(shape=(None,), dtype=tf.bool, name=\"padding_mask\")\n",
    "input_segment_ids = tf.keras.Input(shape=(None,), dtype=tf.int32, name=\"segment_ids\")\n",
    "inputs = dict(token_ids = input_tokens, padding_mask = input_padding_mask, segment_ids = input_segment_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "36adfd8a-767e-4cae-84eb-94ec1489d8fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pass the inputs to the original backbone\n",
    "outputs = backbone(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "9341accb-ba56-438c-827e-b945c7de3923",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the modified model\n",
    "modified_backbone = tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "1dadcbdd-9411-4695-aa48-2182a879d284",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor shape=(None, None), dtype=int32, sparse=False, name=padding_mask>,\n",
       " <KerasTensor shape=(None, None), dtype=int32, sparse=False, name=segment_ids>,\n",
       " <KerasTensor shape=(None, None), dtype=int32, sparse=False, name=token_ids>]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "8448d0d3-9a96-49db-b974-eb165676419b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor shape=(None, None), dtype=bool, sparse=False, name=padding_mask>,\n",
       " <KerasTensor shape=(None, None), dtype=int32, sparse=False, name=segment_ids>,\n",
       " <KerasTensor shape=(None, None), dtype=int32, sparse=False, name=token_ids>]"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_backbone.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "8ddde4a2-5232-4733-afd6-2458f34637aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#modified_backbone(encoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "daae2587-866d-48ac-9453-3ba4da7e3646",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/keras/src/models/functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: {'token_ids': 'token_ids', 'padding_mask': 'padding_mask', 'segment_ids': 'segment_ids'}. Received: the structure of inputs=['*', '*', '*']\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./bert_backbone/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./bert_backbone/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at './bert_backbone'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): List[TensorSpec(shape=(None, None), dtype=tf.bool, name='padding_mask'), TensorSpec(shape=(None, None), dtype=tf.int32, name='segment_ids'), TensorSpec(shape=(None, None), dtype=tf.int32, name='token_ids')]\n",
      "Output Type:\n",
      "  Dict[['sequence_output', TensorSpec(shape=(None, None, 768), dtype=tf.float32, name=None)], ['pooled_output', TensorSpec(shape=(None, 768), dtype=tf.float32, name=None)]]\n",
      "Captures:\n",
      "  140596254374576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596253732080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596253723808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596253725392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596253734544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596253733664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596390449872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596390446880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596390449520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596390454448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596390454096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596390454272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596390446176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596390283920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596390281456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596390290960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596390292544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596390292016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596390294128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596390286912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596390289376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596390713424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596390719584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596390710432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596390715184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596390718000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596390717648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596390708848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596390718352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596408403040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596408404448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596408415712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596408415888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596408410960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596408416416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596408405504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596408407440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596408411136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596408402688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596408403568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596408536224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596408543968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596408534992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596408549072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596408539216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596408537808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596407747856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596407751728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596407750672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596407758768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596407754192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596407757888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596407762112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596407761584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596407752256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596407752784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596408161680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596408158336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596408156576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596408160624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596408171888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596408160272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596408170832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596366579792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596366586480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596366587888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596366589120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596366584192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596366578032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140597248896064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596366574336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596366587360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596366585248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596366573808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596366646560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596366643216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596366655008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596366654128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596366654832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268463760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268454256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268456368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268451616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268451264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268454080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268453024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268456192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268455312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268457776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268461824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268641168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268646096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268642928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268645216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268643632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268631136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268638528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268516272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268525600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268630432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268631312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268526832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268525776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268522608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268521904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140598467413616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268531232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268553088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268549744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268552208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268550448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268557488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268551680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268551328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268551504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268555904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596268554320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596418699056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596418697296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596418704160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596248857584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596248862336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596248860048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140599618896112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596248869552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596248856528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596762799168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596762797760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596762798112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596762802512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596762788256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596762790368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596762797584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596412412880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596764079936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596764080288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596764078176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596764069024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596762388512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596762382528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596762386928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596762380944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596762386400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596422629456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596422627520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596422634736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596422631392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140598470357440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140598470350048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596422624880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596422623648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596422626288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596422625408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596422630864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596248091408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596248089648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596248093168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596248091056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596248094224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596249458320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596249456560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596249445296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596249458848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140598468769248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596249447760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596249455328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596249459024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596249459376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596249450400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596249451280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596247857632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596247866080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596247863968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596247858160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596247868720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596247860800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596247207376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596247205264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596247204912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596247858864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596247865376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596247204560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596247215472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596247201392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596247211952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596247202976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596247207904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596247894976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596247893920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596247888288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596247903952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596247897088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596247896560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596247901312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596764203264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596247897616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596247900256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596764198688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140596247952400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    }
   ],
   "source": [
    "modified_backbone.export('./bert_backbone', format = 'tf_saved_model', verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "9d9e6466-64fd-4b5b-bc95-a504b7a6be18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reload_backbone = tf.saved_model.load('./bert_backbone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "d66683c5-6762-488f-98d6-96109fa3a0b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_SignatureMap({'serving_default': <ConcreteFunction (*, inputs: TensorSpec(shape=(None, None), dtype=tf.bool, name='inputs'), inputs_1: TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs_1'), inputs_2: TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs_2')) -> Dict[['pooled_output', TensorSpec(shape=(None, 768), dtype=tf.float32, name='pooled_output')], ['sequence_output', TensorSpec(shape=(None, None, 768), dtype=tf.float32, name='sequence_output')]] at 0x7FDF4C4774C0>})"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload_backbone.signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "9743949d-17d2-4494-81ee-14895dc1f6b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'_UserObject' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[306], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mreload_backbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: '_UserObject' object is not callable"
     ]
    }
   ],
   "source": [
    "reload_backbone(encoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "e7383ce7-d9fe-4025-bbfc-b8b9b8fb7f9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = reload_backbone.signatures['serving_default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "cc426faf-3ba6-4f21-8488-b706c9f8ca6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Binding inputs to tf.function failed due to `too many positional arguments`. Received args: ({'token_ids': <tf.Tensor: shape=(1, 512), dtype=int32, numpy=\narray([[ 101, 2129, 2079, 2017, 2377, 3598, 1029,  102,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0]], dtype=int32)>, 'padding_mask': <tf.Tensor: shape=(1, 512), dtype=bool, numpy=\narray([[ True,  True,  True,  True,  True,  True,  True,  True, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False]])>, 'segment_ids': <tf.Tensor: shape=(1, 512), dtype=int32, numpy=\narray([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0]], dtype=int32)>},) and kwargs: {} for signature: (*, inputs: TensorSpec(shape=(None, None), dtype=tf.bool, name='inputs'), inputs_1: TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs_1'), inputs_2: TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs_2')) -> Dict[['pooled_output', TensorSpec(shape=(None, 768), dtype=tf.float32, name='pooled_output')], ['sequence_output', TensorSpec(shape=(None, None, 768), dtype=tf.float32, name='sequence_output')]].\nFallback to flat signature also failed due to: signature_wrapper_serving_default(inputs, inputs_1, inputs_2) takes 0 positional arguments, got 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/function_type_utils.py:442\u001b[0m, in \u001b[0;36mbind_function_inputs\u001b[0;34m(args, kwargs, function_type, default_values)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 442\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m \u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind_with_defaults\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msanitized_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_values\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/core/function/polymorphism/function_type.py:264\u001b[0m, in \u001b[0;36mFunctionType.bind_with_defaults\u001b[0;34m(self, args, kwargs, default_values)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns BoundArguments with default values filled in.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 264\u001b[0m bound_arguments \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    265\u001b[0m bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/inspect.py:3186\u001b[0m, in \u001b[0;36mSignature.bind\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3182\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001b[39;00m\n\u001b[1;32m   3183\u001b[0m \u001b[38;5;124;03mand `kwargs` to the function's signature.  Raises `TypeError`\u001b[39;00m\n\u001b[1;32m   3184\u001b[0m \u001b[38;5;124;03mif the passed arguments can not be bound.\u001b[39;00m\n\u001b[1;32m   3185\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 3186\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/inspect.py:3112\u001b[0m, in \u001b[0;36mSignature._bind\u001b[0;34m(self, args, kwargs, partial)\u001b[0m\n\u001b[1;32m   3109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m param\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m (_VAR_KEYWORD, _KEYWORD_ONLY):\n\u001b[1;32m   3110\u001b[0m     \u001b[38;5;66;03m# Looks like we have no parameter for this positional\u001b[39;00m\n\u001b[1;32m   3111\u001b[0m     \u001b[38;5;66;03m# argument\u001b[39;00m\n\u001b[0;32m-> 3112\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   3113\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoo many positional arguments\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m param\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m _VAR_POSITIONAL:\n\u001b[1;32m   3116\u001b[0m     \u001b[38;5;66;03m# We have an '*args'-like argument, let's fill it with\u001b[39;00m\n\u001b[1;32m   3117\u001b[0m     \u001b[38;5;66;03m# all positional arguments we have left and move on to\u001b[39;00m\n\u001b[1;32m   3118\u001b[0m     \u001b[38;5;66;03m# the next phase\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: too many positional arguments",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1179\u001b[0m, in \u001b[0;36mConcreteFunction._call_impl\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1179\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_structured_signature\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m structured_err:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1259\u001b[0m, in \u001b[0;36mConcreteFunction._call_with_structured_signature\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1245\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Executes the wrapped function with the structured signature.\u001b[39;00m\n\u001b[1;32m   1246\u001b[0m \n\u001b[1;32m   1247\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[38;5;124;03m    of this `ConcreteFunction`.\u001b[39;00m\n\u001b[1;32m   1257\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1258\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1259\u001b[0m     \u001b[43mfunction_type_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanonicalize_function_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1260\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1261\u001b[0m )\n\u001b[1;32m   1262\u001b[0m filtered_flat_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/function_type_utils.py:422\u001b[0m, in \u001b[0;36mcanonicalize_function_inputs\u001b[0;34m(args, kwargs, function_type, default_values, is_pure)\u001b[0m\n\u001b[1;32m    421\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m _convert_variables_to_tensors(args, kwargs)\n\u001b[0;32m--> 422\u001b[0m bound_arguments \u001b[38;5;241m=\u001b[39m \u001b[43mbind_function_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_values\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m bound_arguments\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/function_type_utils.py:446\u001b[0m, in \u001b[0;36mbind_function_inputs\u001b[0;34m(args, kwargs, function_type, default_values)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 446\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    447\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBinding inputs to tf.function failed due to `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    448\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived args: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and kwargs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msanitized_kwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for signature:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    449\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunction_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    450\u001b[0m   ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m bound_arguments\n",
      "\u001b[0;31mTypeError\u001b[0m: Binding inputs to tf.function failed due to `too many positional arguments`. Received args: ({'token_ids': <tf.Tensor: shape=(1, 512), dtype=int32, numpy=\narray([[ 101, 2129, 2079, 2017, 2377, 3598, 1029,  102,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0]], dtype=int32)>, 'padding_mask': <tf.Tensor: shape=(1, 512), dtype=bool, numpy=\narray([[ True,  True,  True,  True,  True,  True,  True,  True, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False]])>, 'segment_ids': <tf.Tensor: shape=(1, 512), dtype=int32, numpy=\narray([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0]], dtype=int32)>},) and kwargs: {} for signature: (*, inputs: TensorSpec(shape=(None, None), dtype=tf.bool, name='inputs'), inputs_1: TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs_1'), inputs_2: TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs_2')) -> Dict[['pooled_output', TensorSpec(shape=(None, 768), dtype=tf.float32, name='pooled_output')], ['sequence_output', TensorSpec(shape=(None, None, 768), dtype=tf.float32, name='sequence_output')]].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1182\u001b[0m, in \u001b[0;36mConcreteFunction._call_impl\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_flat_signature\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m flat_err:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1207\u001b[0m, in \u001b[0;36mConcreteFunction._call_with_flat_signature\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_positional_args:\n\u001b[0;32m-> 1207\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   1208\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_signature_summary()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m takes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_positional_args\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1209\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositional arguments, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(args)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1210\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(args)\n",
      "\u001b[0;31mTypeError\u001b[0m: signature_wrapper_serving_default(inputs, inputs_1, inputs_2) takes 0 positional arguments, got 1.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[310], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1170\u001b[0m, in \u001b[0;36mConcreteFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Executes the wrapped function.\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m \n\u001b[1;32m   1123\u001b[0m \u001b[38;5;124;03m  ConcreteFunctions have two signatures:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1168\u001b[0m \u001b[38;5;124;03m    TypeError: If the arguments do not match the function's signature.\u001b[39;00m\n\u001b[1;32m   1169\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1170\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1184\u001b[0m, in \u001b[0;36mConcreteFunction._call_impl\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_flat_signature(args, kwargs)\n\u001b[1;32m   1183\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m flat_err:\n\u001b[0;32m-> 1184\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(  \u001b[38;5;66;03m# pylint: disable=raise-missing-from\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m           \u001b[38;5;28mstr\u001b[39m(structured_err)\n\u001b[1;32m   1186\u001b[0m           \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFallback to flat signature also failed due to: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1187\u001b[0m           \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(flat_err)\n\u001b[1;32m   1188\u001b[0m       )\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_flat_signature(args, kwargs)\n",
      "\u001b[0;31mTypeError\u001b[0m: Binding inputs to tf.function failed due to `too many positional arguments`. Received args: ({'token_ids': <tf.Tensor: shape=(1, 512), dtype=int32, numpy=\narray([[ 101, 2129, 2079, 2017, 2377, 3598, 1029,  102,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0]], dtype=int32)>, 'padding_mask': <tf.Tensor: shape=(1, 512), dtype=bool, numpy=\narray([[ True,  True,  True,  True,  True,  True,  True,  True, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False]])>, 'segment_ids': <tf.Tensor: shape=(1, 512), dtype=int32, numpy=\narray([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0]], dtype=int32)>},) and kwargs: {} for signature: (*, inputs: TensorSpec(shape=(None, None), dtype=tf.bool, name='inputs'), inputs_1: TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs_1'), inputs_2: TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs_2')) -> Dict[['pooled_output', TensorSpec(shape=(None, 768), dtype=tf.float32, name='pooled_output')], ['sequence_output', TensorSpec(shape=(None, None, 768), dtype=tf.float32, name='sequence_output')]].\nFallback to flat signature also failed due to: signature_wrapper_serving_default(inputs, inputs_1, inputs_2) takes 0 positional arguments, got 1."
     ]
    }
   ],
   "source": [
    "model(encoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e64e484-47b7-4b4f-a152-61d8e88b2adf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25ff254-a9f4-4d54-a925-33131de37082",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "6a8869b5-f525-4e4d-ac49-4e097571d381",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'get_concrete_function'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[314], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m tf\u001b[38;5;241m.\u001b[39msaved_model\u001b[38;5;241m.\u001b[39msave(\n\u001b[1;32m      2\u001b[0m     modified_backbone,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./bert_backbone\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m----> 4\u001b[0m     signatures\u001b[38;5;241m=\u001b[39m\u001b[43mmodified_backbone\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_concrete_function\u001b[49m(\n\u001b[1;32m      5\u001b[0m         {\n\u001b[1;32m      6\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m: tf\u001b[38;5;241m.\u001b[39mTensorSpec(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m), dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mint32),\n\u001b[1;32m      7\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpadding_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m: tf\u001b[38;5;241m.\u001b[39mTensorSpec(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m), dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mbool),\n\u001b[1;32m      8\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msegment_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m: tf\u001b[38;5;241m.\u001b[39mTensorSpec(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m), dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mint32),\n\u001b[1;32m      9\u001b[0m         }\n\u001b[1;32m     10\u001b[0m     ),\n\u001b[1;32m     11\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'get_concrete_function'"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(\n",
    "    modified_backbone,\n",
    "    './bert_backbone',\n",
    "    signatures=modified_backbone.call.get_concrete_function(\n",
    "        {\n",
    "            \"token_ids\": tf.TensorSpec(shape=(None, None), dtype=tf.int32),\n",
    "            \"padding_mask\": tf.TensorSpec(shape=(None, None), dtype=tf.bool),\n",
    "            \"segment_ids\": tf.TensorSpec(shape=(None, None), dtype=tf.int32),\n",
    "        }\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "ec764c2e-a053-42ec-9d49-f59fac8e43d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Attempt to convert a value (TensorSpec(shape=(None, None), dtype=tf.bool, name=None)) with an unsupported type (<class 'tensorflow.python.framework.tensor.TensorSpec'>) to a Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[316], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m tf\u001b[38;5;241m.\u001b[39msaved_model\u001b[38;5;241m.\u001b[39msave(\n\u001b[1;32m      2\u001b[0m     modified_backbone,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./albert_backbone\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     signatures\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m----> 5\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mserving_default\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mmodified_backbone\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Call the method directly\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtoken_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensorSpec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpadding_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensorSpec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbool\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msegment_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensorSpec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     },\n\u001b[1;32m     13\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/models/functional.py:174\u001b[0m, in \u001b[0;36mFunctional.call\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;66;03m# Add support for training, masking\u001b[39;00m\n\u001b[0;32m--> 174\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_standardize_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m         masks \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(inputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/models/functional.py:280\u001b[0m, in \u001b[0;36mFunctional._standardize_inputs\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_warn_inputs_struct_mismatch(inputs)\n\u001b[1;32m    279\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mflatten(inputs)\n\u001b[0;32m--> 280\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_inputs_to_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adjust_input_rank(flat_inputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/models/functional.py:238\u001b[0m, in \u001b[0;36mFunctional._convert_inputs_to_tensors\u001b[0;34m(self, flat_inputs)\u001b[0m\n\u001b[1;32m    235\u001b[0m         converted\u001b[38;5;241m.\u001b[39mappend(x)\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    237\u001b[0m         converted\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 238\u001b[0m             \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m                \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m         )\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m converted\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/ops/core.py:917\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(x, dtype, sparse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.ops.convert_to_tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    899\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_to_tensor\u001b[39m(x, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    900\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert a NumPy array to a tensor.\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \n\u001b[1;32m    902\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[38;5;124;03m    >>> y = keras.ops.convert_to_tensor(x)\u001b[39;00m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/backend/tensorflow/core.py:123\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(x, dtype, sparse)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mis_tensor(x):\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbool\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    121\u001b[0m         \u001b[38;5;66;03m# TensorFlow boolean conversion is stricter than other backends.\u001b[39;00m\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;66;03m# It does not allow ints. We convert without dtype and cast instead.\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcast(x, dtype)\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:108\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    106\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    107\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Attempt to convert a value (TensorSpec(shape=(None, None), dtype=tf.bool, name=None)) with an unsupported type (<class 'tensorflow.python.framework.tensor.TensorSpec'>) to a Tensor."
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(\n",
    "    modified_backbone,\n",
    "    \"./albert_backbone\",\n",
    "    signatures={\n",
    "        'serving_default': modified_backbone.call(  # Call the method directly\n",
    "            {\n",
    "                \"token_ids\": tf.TensorSpec(shape=(None, None), dtype=tf.int32),\n",
    "                \"padding_mask\": tf.TensorSpec(shape=(None, None), dtype=tf.bool),\n",
    "                \"segment_ids\": tf.TensorSpec(shape=(None, None), dtype=tf.int32),\n",
    "            }\n",
    "        )\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073d4033-ee49-4b9c-a96f-5e8d8865c260",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7a025a-be1c-4ba8-b7ad-92d99e335f88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4f3adb-5383-4910-8d2c-2541ce922113",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35602bb3-b4a1-4d34-b65b-f10c22492faf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d232c44e-bff0-426a-8670-3f31d72d48f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20eae163-c356-4c00-a7eb-93073026bf2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfe1ac3-3e88-41e4-9e41-239fdc929e24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b4666e-4bd1-4452-839b-2831c2c10c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b670ee27-9c65-4854-9a03-98bd7193c8b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "0508c244-e7e3-4d5a-87a0-8c22554b01f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/models/keras/falcon/keras/falcon_refinedweb_1b_en/1/download/config.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [00:00<00:00, 793kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/models/keras/falcon/keras/falcon_refinedweb_1b_en/1/download/model.weights.h5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.89G/4.89G [01:35<00:00, 55.1MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/models/keras/falcon/keras/falcon_refinedweb_1b_en/1/download/tokenizer.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 454/454 [00:00<00:00, 310kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/models/keras/falcon/keras/falcon_refinedweb_1b_en/1/download/assets/tokenizer/vocabulary.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 0.99M/0.99M [00:00<00:00, 4.77MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/models/keras/falcon/keras/falcon_refinedweb_1b_en/1/download/assets/tokenizer/merges.txt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 446k/446k [00:00<00:00, 3.06MB/s]\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732309199.252247  449453 service.cc:148] XLA service 0x5629d97709b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1732309199.256200  449453 service.cc:156]   StreamExecutor device (0): Host, Default Version\n",
      "I0000 00:00:1732309199.500683  449453 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I want to say a few words about the new “Sleeping Giant” series of novels by John G. Hemry (the'"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "falcon_lm = keras_hub.models.FalconCausalLM.from_preset(\"falcon_refinedweb_1b_en\")\n",
    "falcon_lm.generate(\"I want to say\", max_length=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "3304cf46-19b9-470f-a9e3-30cc901a1cab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_add_trackable_child',\n",
       " '_add_variable_with_custom_getter',\n",
       " '_adjust_input_rank',\n",
       " '_allow_non_tensor_positional_args',\n",
       " '_api_export_path',\n",
       " '_api_export_symbol_id',\n",
       " '_assert_compile_called',\n",
       " '_assert_input_compatibility',\n",
       " '_assign_variable_values',\n",
       " '_auto_config',\n",
       " '_backbone',\n",
       " '_build_by_run_for_kwargs',\n",
       " '_build_by_run_for_single_pos_arg',\n",
       " '_build_cache',\n",
       " '_build_shapes_dict',\n",
       " '_call_has_mask_arg',\n",
       " '_call_has_training_arg',\n",
       " '_call_signature',\n",
       " '_called',\n",
       " '_check_quantize_args',\n",
       " '_check_super_called',\n",
       " '_checkpoint_adapter',\n",
       " '_checkpoint_dependencies',\n",
       " '_clear_losses',\n",
       " '_clear_previous_trainer_metrics',\n",
       " '_compile_config',\n",
       " '_compile_loss',\n",
       " '_compile_metrics',\n",
       " '_compiled_metrics_update_state',\n",
       " '_compute_loss',\n",
       " '_compute_loss_has_training_arg',\n",
       " '_convert_input_args',\n",
       " '_convert_inputs_to_tensors',\n",
       " '_copy_trackable_to_cpu',\n",
       " '_create_nested_dict',\n",
       " '_default_save_signature',\n",
       " '_deferred_dependencies',\n",
       " '_delete_tracking',\n",
       " '_deserialization_dependencies',\n",
       " '_deserialize_from_proto',\n",
       " '_distribute_strategy',\n",
       " '_dtype_policy',\n",
       " '_export_to_saved_model_graph',\n",
       " '_flatten_layers',\n",
       " '_flatten_metrics_in_order',\n",
       " '_flatten_nested_dict',\n",
       " '_float8_call',\n",
       " '_functional_layer_ids',\n",
       " '_gather_saveables_for_checkpoint',\n",
       " '_get_call_context',\n",
       " '_get_metrics_result_or_logs',\n",
       " '_get_node_attribute_at_index',\n",
       " '_get_own_losses',\n",
       " '_get_own_metrics',\n",
       " '_get_regularization_losses',\n",
       " '_get_variable_map',\n",
       " '_handle_deferred_dependencies',\n",
       " '_inbound_nodes',\n",
       " '_initial_epoch',\n",
       " '_initialize_tracker',\n",
       " '_initialized',\n",
       " '_input_spec',\n",
       " '_inputs',\n",
       " '_inputs_struct',\n",
       " '_int8_call',\n",
       " '_jit_compile',\n",
       " '_layers',\n",
       " '_lock',\n",
       " '_lock_state',\n",
       " '_lookup_dependency',\n",
       " '_loss_ids',\n",
       " '_loss_tracker',\n",
       " '_losses',\n",
       " '_losses_override',\n",
       " '_maybe_build',\n",
       " '_maybe_initialize_trackable',\n",
       " '_maybe_reset_call_context',\n",
       " '_maybe_symbolic_build',\n",
       " '_maybe_warn_inputs_struct_mismatch',\n",
       " '_metrics',\n",
       " '_name_based_attribute_restore',\n",
       " '_name_based_restores',\n",
       " '_no_dependency',\n",
       " '_nodes',\n",
       " '_nodes_by_depth',\n",
       " '_non_trainable_variables',\n",
       " '_normalize_generate_inputs',\n",
       " '_normalize_generate_outputs',\n",
       " '_not_implemented_error',\n",
       " '_obj_type',\n",
       " '_object_identifier',\n",
       " '_open_name_scope',\n",
       " '_operations',\n",
       " '_operations_by_depth',\n",
       " '_outbound_nodes',\n",
       " '_outputs',\n",
       " '_outputs_struct',\n",
       " '_parent_path',\n",
       " '_path',\n",
       " '_post_build',\n",
       " '_post_track_variable',\n",
       " '_post_untrack_variable',\n",
       " '_preload_simple_restoration',\n",
       " '_preprocessor',\n",
       " '_pythonify_logs',\n",
       " '_quantization_mode_error',\n",
       " '_resolve_auto_jit_compile',\n",
       " '_restore_from_tensors',\n",
       " '_run_eagerly',\n",
       " '_run_through_graph',\n",
       " '_saved_model_arg_spec',\n",
       " '_saved_model_inputs_spec',\n",
       " '_seed_generators',\n",
       " '_self_name_based_restores',\n",
       " '_self_saveable_object_factories',\n",
       " '_self_setattr_tracking',\n",
       " '_self_unconditional_checkpoint_dependencies',\n",
       " '_self_unconditional_deferred_dependencies',\n",
       " '_self_unconditional_dependency_names',\n",
       " '_self_update_uid',\n",
       " '_serialize_to_proto',\n",
       " '_serialize_to_tensors',\n",
       " '_set_mask_metadata',\n",
       " '_set_save_spec',\n",
       " '_setattr_hook',\n",
       " '_setattr_tracking',\n",
       " '_should_eval',\n",
       " '_standardize_inputs',\n",
       " '_supports_masking',\n",
       " '_symbolic_build',\n",
       " '_tf_api_names',\n",
       " '_tf_api_names_v1',\n",
       " '_track_trackable',\n",
       " '_track_variable',\n",
       " '_trackable_children',\n",
       " '_tracked',\n",
       " '_tracker',\n",
       " '_trainable',\n",
       " '_trainable_variables',\n",
       " '_unconditional_checkpoint_dependencies',\n",
       " '_unconditional_dependency_names',\n",
       " '_unpickle_model',\n",
       " '_untrack_variable',\n",
       " '_update_uid',\n",
       " 'activity_regularizer',\n",
       " 'add_loss',\n",
       " 'add_metric',\n",
       " 'add_variable',\n",
       " 'add_weight',\n",
       " 'autocast',\n",
       " 'backbone',\n",
       " 'backbone_cls',\n",
       " 'build',\n",
       " 'build_from_config',\n",
       " 'built',\n",
       " 'call',\n",
       " 'call_with_cache',\n",
       " 'compile',\n",
       " 'compile_from_config',\n",
       " 'compiled',\n",
       " 'compiled_loss',\n",
       " 'compiled_metrics',\n",
       " 'compute_dtype',\n",
       " 'compute_loss',\n",
       " 'compute_mask',\n",
       " 'compute_metrics',\n",
       " 'compute_output_shape',\n",
       " 'compute_output_spec',\n",
       " 'count_params',\n",
       " 'distribute_reduction_method',\n",
       " 'distribute_strategy',\n",
       " 'dtype',\n",
       " 'dtype_policy',\n",
       " 'evaluate',\n",
       " 'export',\n",
       " 'fit',\n",
       " 'from_config',\n",
       " 'from_preset',\n",
       " 'generate',\n",
       " 'generate_function',\n",
       " 'generate_step',\n",
       " 'get_build_config',\n",
       " 'get_compile_config',\n",
       " 'get_config',\n",
       " 'get_layer',\n",
       " 'get_metrics_result',\n",
       " 'get_state_tree',\n",
       " 'get_weights',\n",
       " 'has_task_weights',\n",
       " 'input',\n",
       " 'input_dtype',\n",
       " 'input_shape',\n",
       " 'input_spec',\n",
       " 'inputs',\n",
       " 'jit_compile',\n",
       " 'layers',\n",
       " 'load_own_variables',\n",
       " 'load_task_weights',\n",
       " 'load_weights',\n",
       " 'loss',\n",
       " 'losses',\n",
       " 'make_generate_function',\n",
       " 'make_predict_function',\n",
       " 'make_test_function',\n",
       " 'make_train_function',\n",
       " 'metrics',\n",
       " 'metrics_names',\n",
       " 'metrics_variables',\n",
       " 'name',\n",
       " 'non_trainable_variables',\n",
       " 'non_trainable_weights',\n",
       " 'operations',\n",
       " 'optimizer',\n",
       " 'output',\n",
       " 'output_names',\n",
       " 'output_shape',\n",
       " 'outputs',\n",
       " 'path',\n",
       " 'predict',\n",
       " 'predict_function',\n",
       " 'predict_on_batch',\n",
       " 'predict_step',\n",
       " 'preprocess_samples',\n",
       " 'preprocessor',\n",
       " 'preprocessor_cls',\n",
       " 'presets',\n",
       " 'quantization_mode',\n",
       " 'quantize',\n",
       " 'quantized_build',\n",
       " 'quantized_call',\n",
       " 'reset_metrics',\n",
       " 'run_eagerly',\n",
       " 'sampler',\n",
       " 'save',\n",
       " 'save_own_variables',\n",
       " 'save_task_weights',\n",
       " 'save_to_preset',\n",
       " 'save_weights',\n",
       " 'set_state_tree',\n",
       " 'set_weights',\n",
       " 'stateless_call',\n",
       " 'stateless_compute_loss',\n",
       " 'steps_per_execution',\n",
       " 'stop_training',\n",
       " 'summary',\n",
       " 'supports_jit',\n",
       " 'supports_masking',\n",
       " 'symbolic_call',\n",
       " 'test_function',\n",
       " 'test_on_batch',\n",
       " 'test_step',\n",
       " 'to_json',\n",
       " 'train_function',\n",
       " 'train_on_batch',\n",
       " 'train_step',\n",
       " 'trainable',\n",
       " 'trainable_variables',\n",
       " 'trainable_weights',\n",
       " 'variable_dtype',\n",
       " 'variables',\n",
       " 'weights']"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(falcon_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "49841614-cd17-4758-9f10-c09c068b3907",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"falcon_causal_lm_preprocessor\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mPreprocessor: \"falcon_causal_lm_preprocessor\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ falcon_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">FalconTokenizer</span>)                            │                       Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">50,257</span> │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ falcon_tokenizer (\u001b[38;5;33mFalconTokenizer\u001b[0m)                            │                       Vocab size: \u001b[38;5;34m50,257\u001b[0m │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"falcon_causal_lm\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"falcon_causal_lm\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ falcon_backbone               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">1,311,625,216</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">FalconBackbone</span>)              │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50304</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">103,022,592</span> │ falcon_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ falcon_backbone               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │   \u001b[38;5;34m1,311,625,216\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│ (\u001b[38;5;33mFalconBackbone\u001b[0m)              │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50304\u001b[0m)       │     \u001b[38;5;34m103,022,592\u001b[0m │ falcon_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,311,625,216</span> (4.89 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,311,625,216\u001b[0m (4.89 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,311,625,216</span> (4.89 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,311,625,216\u001b[0m (4.89 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "falcon_lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "cf4baa1f-1ac7-4b85-8404-f612b9975e0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'token_ids': <tf.Tensor: shape=(1024,), dtype=int32, numpy=array([50256,  1212,   318, ...,     0,     0,     0], dtype=int32)>,\n",
       "  'padding_mask': <tf.Tensor: shape=(1024,), dtype=bool, numpy=array([ True,  True,  True, ..., False, False, False])>},\n",
       " <tf.Tensor: shape=(1024,), dtype=int32, numpy=array([1212,  318,  257, ...,    0,    0,    0], dtype=int32)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=bool, numpy=array([ True,  True,  True, ..., False, False, False])>)"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "falcon_lm.preprocessor('This is a sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "e1bfff6b-69ef-44bd-a1cc-f8fe59a68a7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer \"falcon_causal_lm\" expects 2 input(s), but it received 4 input tensors. Inputs received: [<tf.Tensor: shape=(1024,), dtype=bool, numpy=array([ True,  True,  True, ..., False, False, False])>, <tf.Tensor: shape=(1024,), dtype=int32, numpy=array([50256,  1212,   318, ...,     0,     0,     0], dtype=int32)>, <tf.Tensor: shape=(1024,), dtype=int32, numpy=array([1212,  318,  257, ...,    0,    0,    0], dtype=int32)>, <tf.Tensor: shape=(1024,), dtype=bool, numpy=array([ True,  True,  True, ..., False, False, False])>]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[324], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfalcon_lm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfalcon_lm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocessor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mThis is a sentence\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/layers/input_spec.py:160\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    158\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mflatten(inputs)\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(inputs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(input_spec):\n\u001b[0;32m--> 160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLayer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m expects \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(input_spec)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m input(s),\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but it received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(inputs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m input tensors. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    163\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInputs received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minputs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    164\u001b[0m     )\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m input_index, (x, spec) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(inputs, input_spec)):\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Layer \"falcon_causal_lm\" expects 2 input(s), but it received 4 input tensors. Inputs received: [<tf.Tensor: shape=(1024,), dtype=bool, numpy=array([ True,  True,  True, ..., False, False, False])>, <tf.Tensor: shape=(1024,), dtype=int32, numpy=array([50256,  1212,   318, ...,     0,     0,     0], dtype=int32)>, <tf.Tensor: shape=(1024,), dtype=int32, numpy=array([1212,  318,  257, ...,    0,    0,    0], dtype=int32)>, <tf.Tensor: shape=(1024,), dtype=bool, numpy=array([ True,  True,  True, ..., False, False, False])>]"
     ]
    }
   ],
   "source": [
    "falcon_lm(falcon_lm.preprocessor('This is a sentence'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f04dbd-7f70-4864-8334-7b4feb5b4ef1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
