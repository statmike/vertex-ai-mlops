{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1adf83c3",
   "metadata": {},
   "source": [
    "![tracker](https://us-central1-vertex-ai-mlops-369716.cloudfunctions.net/pixel-tracking?path=statmike%2Fvertex-ai-mlops%2FMLOps%2FPipelines&file=Vertex+AI+Pipelines+-+GCS+Read+and+Write.ipynb)\n",
    "<!--- header table --->\n",
    "<table align=\"left\">\n",
    "<tr>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/statmike/vertex-ai-mlops/blob/main/MLOps/Pipelines/Vertex%20AI%20Pipelines%20-%20GCS%20Read%20and%20Write.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://www.svgrepo.com/download/217753/github.svg\" alt=\"GitHub logo\">\n",
    "      <br>View on<br>GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/statmike/vertex-ai-mlops/blob/main/MLOps/Pipelines/Vertex%20AI%20Pipelines%20-%20GCS%20Read%20and%20Write.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://www.gstatic.com/pantheon/images/bigquery/welcome_page/colab-logo.svg\" alt=\"Google Colaboratory logo\">\n",
    "      <br>Run in<br>Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https%3A%2F%2Fraw.githubusercontent.com%2Fstatmike%2Fvertex-ai-mlops%2Fmain%2FMLOps%2FPipelines%2FVertex%2520AI%2520Pipelines%2520-%2520GCS%2520Read%2520and%2520Write.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\">\n",
    "      <br>Run in<br>Colab Enterprise\n",
    "    </a>\n",
    "  </td>      \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/bigquery/import?url=https://github.com/statmike/vertex-ai-mlops/blob/main/MLOps/Pipelines/Vertex%20AI%20Pipelines%20-%20GCS%20Read%20and%20Write.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://www.gstatic.com/images/branding/gcpiconscolors/bigquery/v1/32px.svg\" alt=\"BigQuery logo\">\n",
    "      <br>Open in<br>BigQuery Studio\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/statmike/vertex-ai-mlops/main/MLOps/Pipelines/Vertex%20AI%20Pipelines%20-%20GCS%20Read%20and%20Write.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://www.gstatic.com/images/branding/gcpiconscolors/vertexai/v1/32px.svg\" alt=\"Vertex AI logo\">\n",
    "      <br>Open in<br>Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td colspan=\"5\" style=\"text-align: right\">\n",
    "    <b>Share This On: </b> \n",
    "    <a href=\"https://www.linkedin.com/sharing/share-offsite/?url=https%3A//github.com/statmike/vertex-ai-mlops/blob/main/MLOps/Pipelines/Vertex%20AI%20Pipelines%20-%20GCS%20Read%20and%20Write.ipynb\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"Linkedin Logo\" width=\"20px\"></a> \n",
    "    <a href=\"https://reddit.com/submit?url=https%3A//github.com/statmike/vertex-ai-mlops/blob/main/MLOps/Pipelines/Vertex%20AI%20Pipelines%20-%20GCS%20Read%20and%20Write.ipynb\"><img src=\"https://redditinc.com/hubfs/Reddit%20Inc/Brand/Reddit_Logo.png\" alt=\"Reddit Logo\" width=\"20px\"></a> \n",
    "    <a href=\"https://bsky.app/intent/compose?text=https%3A//github.com/statmike/vertex-ai-mlops/blob/main/MLOps/Pipelines/Vertex%20AI%20Pipelines%20-%20GCS%20Read%20and%20Write.ipynb\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"BlueSky Logo\" width=\"20px\"></a> \n",
    "    <a href=\"https://twitter.com/intent/tweet?url=https%3A//github.com/statmike/vertex-ai-mlops/blob/main/MLOps/Pipelines/Vertex%20AI%20Pipelines%20-%20GCS%20Read%20and%20Write.ipynb\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/5/5a/X_icon_2.svg\" alt=\"X (Twitter) Logo\" width=\"20px\"></a> \n",
    "  </td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td colspan=\"5\" style=\"text-align: right\">\n",
    "    <b>Connect With Author On: </b> \n",
    "    <a href=\"https://www.linkedin.com/in/statmike\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"Linkedin Logo\" width=\"20px\"></a>\n",
    "    <a href=\"https://www.github.com/statmike\"><img src=\"https://www.svgrepo.com/download/217753/github.svg\" alt=\"GitHub Logo\" width=\"20px\"></a> \n",
    "    <a href=\"https://www.youtube.com/@statmike-channel\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/f/fd/YouTube_full-color_icon_%282024%29.svg\" alt=\"YouTube Logo\" width=\"20px\"></a>\n",
    "    <a href=\"https://bsky.app/profile/statmike.bsky.social\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"BlueSky Logo\" width=\"20px\"></a> \n",
    "    <a href=\"https://x.com/statmike\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/5/5a/X_icon_2.svg\" alt=\"X (Twitter) Logo\" width=\"20px\"></a>\n",
    "  </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d7a436-ba0d-42df-b1d8-e58ccaf6df66",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "---\n",
    "This is part of a [series of notebook based workflows](./readme.md) that teach all the ways to use pipelines within Vertex AI. The suggested order and description/reason is:\n",
    "\n",
    "||Notebook Workflow|Description|\n",
    "|---|---|---|\n",
    "||[Vertex AI Pipelines - Start Here](./Vertex%20AI%20Pipelines%20-%20Start%20Here.ipynb)|What are pipelines? Start here to go from code to pipeline and see it in action.|\n",
    "||[Vertex AI Pipelines - Introduction](./Vertex%20AI%20Pipelines%20-%20Introduction.ipynb)|Introduction to pipelines with the console and Vertex AI SDK|\n",
    "||[Vertex AI Pipelines - Components](./Vertex%20AI%20Pipelines%20-%20Components.ipynb)|An introduction to all the ways to create pipeline components from your code|\n",
    "||[Vertex AI Pipelines - IO](./Vertex%20AI%20Pipelines%20-%20IO.ipynb)|An overview of all the type of inputs and outputs for pipeline components|\n",
    "||[Vertex AI Pipelines - Control](./Vertex%20AI%20Pipelines%20-%20Control.ipynb)|An overview of controlling the flow of exectution for pipelines|\n",
    "||[Vertex AI Pipelines - Secret Manager](./Vertex%20AI%20Pipelines%20-%20Secret%20Manager.ipynb)|How to pass sensitive information to pipelines and components|\n",
    "|_**This Notebook**_|[Vertex AI Pipelines - GCS Read and Write](./Vertex%20AI%20Pipelines%20-%20GCS%20Read%20and%20Write.ipynb)|How to read/write to GCS from components, including container components.|\n",
    "||[Vertex AI Pipelines - Scheduling](./Vertex%20AI%20Pipelines%20-%20Scheduling.ipynb)|How to schedule pipeline execution|\n",
    "||[Vertex AI Pipelines - Notifications](./Vertex%20AI%20Pipelines%20-%20Notifications.ipynb)|How to send email notification of pipeline status.|\n",
    "||[Vertex AI Pipelines - Management](./Vertex%20AI%20Pipelines%20-%20Management.ipynb)|Managing, Reusing, and Storing pipelines and components|\n",
    "||[Vertex AI Pipelines - Testing](./Vertex%20AI%20Pipelines%20-%20Testing.ipynb)|Strategies for testing components and pipeliens locally and remotely to aide development.|\n",
    "||[Vertex AI Pipelines - Managing Pipeline Jobs](./Vertex%20AI%20Pipelines%20-%20Managing%20Pipeline%20Jobs.ipynb)|Manage runs of pipelines in an environment: list, check status, filtered list, cancel and delete jobs.|\n",
    "\n",
    "To discover these notebooks as part of an introduction to MLOps orchestration [start here](./readme.md).  To read more about MLOps also check out [the parent folder](../readme.md).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c93360d-b4a3-495d-b367-a11a4cc866f8",
   "metadata": {},
   "source": [
    "# Vertex AI Pipelines - GCS Read and Write With Fuse Mount\n",
    "\n",
    "As a pipeline job executes each component instance (task) as a Vertex AI Custom Training Job.  A core feature of these training jobs is that they automatcally setup [Cloud Storage as a mounted file system](https://cloud.google.com/vertex-ai/docs/training/cloud-storage-file-system). This workflow examines how to interact with data stored in GCS from these jobs.\n",
    "\n",
    "**Workflow:**\n",
    "- Create a lightweight Python component, essentially a Python function, that reads and writes to GCS during execution\n",
    "- Create a container component that runs an input Python script which reads and writes to GCS during execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c522793-29c6-4693-aee8-838e31ab88ba",
   "metadata": {
    "id": "od_UkDpvRmgD",
    "tags": []
   },
   "source": [
    "---\n",
    "## Colab Setup\n",
    "\n",
    "To run this notebook in Colab run the cells in this section.  Otherwise, skip this section.\n",
    "\n",
    "This cell will authenticate to GCP (follow prompts in the popup)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a641daef-7888-45e2-bf8e-fc9b15acfb1f",
   "metadata": {
    "executionInfo": {
     "elapsed": 195,
     "status": "ok",
     "timestamp": 1683726184843,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "8UO9FnqyKBlF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'statmike-mlops-349915' # replace with project ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdeab0c7-a6c4-4dc4-af70-4faf11a769ee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68869,
     "status": "ok",
     "timestamp": 1683726253709,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "N98-KK7LRkjm",
    "outputId": "09ec5008-0def-4e1a-c349-c598ee752f78",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not a Colab Environment\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    !gcloud config set project {PROJECT_ID}\n",
    "    print('Colab authorized to GCP')\n",
    "except Exception:\n",
    "    print('Not a Colab Environment')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c4878e-a111-4863-b77c-7a80bcb5fcac",
   "metadata": {},
   "source": [
    "---\n",
    "## Installs\n",
    "\n",
    "The list `packages` contains tuples of package import names and install names.  If the import name is not found then the install name is used to install quitely for the current user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13c34306-42b5-4ac8-aad7-024fd67f84d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tuples of (import name, install name, min_version)\n",
    "packages = [\n",
    "    ('google.cloud.aiplatform', 'google-cloud-aiplatform'),\n",
    "    ('google.cloud.aiplatform', 'google-cloud-storage'),\n",
    "    ('kfp', 'kfp'),\n",
    "]\n",
    "\n",
    "import importlib\n",
    "install = False\n",
    "for package in packages:\n",
    "    if not importlib.util.find_spec(package[0]):\n",
    "        print(f'installing package {package[1]}')\n",
    "        install = True\n",
    "        !pip install {package[1]} -U -q --user\n",
    "    elif len(package) == 3:\n",
    "        if importlib.metadata.version(package[0]) < package[2]:\n",
    "            print(f'updating package {package[1]}')\n",
    "            install = True\n",
    "            !pip install {package[1]} -U -q --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e72d96-91e1-410c-b3d4-d3452976715d",
   "metadata": {},
   "source": [
    "### API Enablement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82f69234-7245-473b-a356-a6c11ab32910",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gcloud services enable aiplatform.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa555ce9-01fb-4689-9684-1bb7ab71d138",
   "metadata": {},
   "source": [
    "### Restart Kernel (If Installs Occured)\n",
    "\n",
    "After a kernel restart the code submission can start with the next cell after this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d83f84fa-ef02-4bb8-acd0-6154b281750f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if install:\n",
    "    import IPython\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)\n",
    "    IPython.display.display(IPython.display.Markdown(\"\"\"<div class=\\\"alert alert-block alert-warning\\\">\n",
    "        <b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. The previous cells do not need to be run again⚠️</b>\n",
    "        </div>\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31cb128-faf4-4a00-ab39-828464aa60c6",
   "metadata": {
    "id": "appt8-yVRtJ1"
   },
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cace07-8665-4f49-9ebf-459004ab876a",
   "metadata": {
    "id": "63mx2EozRxFP"
   },
   "source": [
    "Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63063e6e-f549-4051-bba9-4e51ad1bb697",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 2124,
     "status": "ok",
     "timestamp": 1683726390544,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "xzcoXjM5Rky5",
    "outputId": "b3bdcbc1-70d5-472e-aea2-42c74a42efde",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'statmike-mlops-349915'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24e16872-fd80-468f-ba92-0b0e32961f6f",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1683726390712,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "IxWrFtqYMfku",
    "tags": []
   },
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "SERIES = 'mlops'\n",
    "EXPERIMENT = 'pipeline-gcs-data'\n",
    "\n",
    "# gcs bucket\n",
    "GCS_BUCKET = PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3780ce0a-bd56-4532-8761-8faaa7348412",
   "metadata": {
    "id": "LuajVwCiO6Yg"
   },
   "source": [
    "Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f054242-0fff-40b9-a398-bf60aad4578c",
   "metadata": {
    "executionInfo": {
     "elapsed": 17761,
     "status": "ok",
     "timestamp": 1683726409304,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "LVC7zzSLRk2C",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, datetime\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import storage\n",
    "import kfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26b7c02c-2152-4716-8e9b-63110a20ee7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.12.1'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfp.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58443f19-496f-4efc-8066-72317cdf8a34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.78.0'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aiplatform.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a92bff0-35fc-4eb4-bc73-1c334f91548f",
   "metadata": {
    "id": "EyAVFG9TO9H-"
   },
   "source": [
    "Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e41b8ff9-013e-4f7d-b7dd-32e8f46db6ec",
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1683726409306,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "L0RPE13LOZce",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vertex ai clients\n",
    "aiplatform.init(project = PROJECT_ID, location = REGION)\n",
    "\n",
    "# gcs clients\n",
    "gcs = storage.Client(project = PROJECT_ID)\n",
    "bucket = gcs.bucket(GCS_BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9919bfb0-52ff-4a63-887b-20dd84eb0587",
   "metadata": {},
   "source": [
    "parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bf6f56a-a475-45e3-948c-415ef30b99b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DIR = f\"temp/{SERIES}-{EXPERIMENT}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abfd52d4-56b7-4d8e-ac0a-93c235081ada",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1026793852137-compute@developer.gserviceaccount.com'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SERVICE_ACCOUNT = !gcloud config list --format='value(core.account)' \n",
    "SERVICE_ACCOUNT = SERVICE_ACCOUNT[0]\n",
    "SERVICE_ACCOUNT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c34f70-22ba-41a8-9e71-002e84516c69",
   "metadata": {},
   "source": [
    "environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a5ba41f-9ac1-4964-9dbd-b72aee47e100",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(DIR):\n",
    "    os.makedirs(DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca330e0-4c9e-451e-a813-c27f44433b4b",
   "metadata": {},
   "source": [
    "---\n",
    "## Example File In GCS\n",
    "\n",
    "Your component might need to read data, like training records, from a GCS bucket.  The following code create an example file `example_instance.txt` to use in this workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec68f185-e46b-4736-81ca-6fd88891ccb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is my example text instance as of 2025-04-02 19:26:20'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_str = 'This is my example text instance as of ' + datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "example_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9539e06b-2f67-45d5-9434-ea788cf9dda1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mlops/pipeline-gcs-data/example_instance.txt'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = bucket.blob(f'{SERIES}/{EXPERIMENT}/example_instance.txt')\n",
    "blob.upload_from_string(example_str)\n",
    "blob.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "feb2dd60-7ef8-45e5-ab30-438d6dafadca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mlops/pipeline-gcs-data/example_instance.txt']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[b.name for b in bucket.list_blobs(prefix = f'{SERIES}/{EXPERIMENT}/example')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b057a4-2d5c-4a3a-82fa-0101d2159e45",
   "metadata": {},
   "source": [
    "---\n",
    "## Lightweight Component That Reads/Writes To GCS with Fuse Mount\n",
    "\n",
    "Components run as Vertex AI custom training jobs which already have [Cloud Storage as a mounted file system](https://cloud.google.com/vertex-ai/docs/training/cloud-storage-file-system).\n",
    "\n",
    "> **Note:** a Fuse Mount is not a POSIX file system (see [limitations](https://cloud.google.com/storage/docs/cloud-storage-fuse/overview#differences-and-limitations)).  Some methods may not work correctly with direct read/write - such as exporting model files in some frameworks.  A potential work around is to first write locally, then copy to the fuse mount location."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b58bc9-d5e6-4a0f-bad0-7cbab30a67c6",
   "metadata": {},
   "source": [
    "### Create Component: Read/Write GCS With Fuse Mount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "daf3b4ed-792c-4968-aa7d-3a2f951500a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mlops-pipeline-gcs-data-gcs-fuse'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_str = f'{SERIES}-{EXPERIMENT}-gcs-fuse'\n",
    "name_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9daac54-625c-4134-a23d-3ea80b7a2a3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.component(\n",
    "    base_image = \"python:3.11\"\n",
    ")\n",
    "def gcs_fuse(\n",
    "    instance_bucket: str,\n",
    "    instance_path: str,\n",
    "    instance_file: str\n",
    ") -> str:\n",
    "    \n",
    "    import datetime\n",
    "    \n",
    "    # read from GCS\n",
    "    with open(f'/gcs/{instance_bucket}/{instance_path}/{instance_file}', 'r') as f:\n",
    "        instance = f.read()\n",
    "    \n",
    "    # write to GCS\n",
    "    with open(f'/gcs/{instance_bucket}/{instance_path}/gcs_fuse.txt', 'w') as f:\n",
    "        f.write(\n",
    "            'Successfully used GCS as a mounted file system to create this file at ' + datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        )\n",
    "        \n",
    "    return instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3b6b88-d3d1-4ac8-a3d8-37ac4b196311",
   "metadata": {},
   "source": [
    "### Compile and Run Component On Vertex AI Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d26aadd5-99c6-4370-b175-efaa75441aef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kfp.compiler.Compiler().compile(\n",
    "    pipeline_func = gcs_fuse,\n",
    "    package_path = f'{DIR}/{name_str}.yaml',\n",
    "    pipeline_name = name_str\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e020c56-8155-4eec-9359-13dfd4b4a9b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_job = aiplatform.PipelineJob(\n",
    "    display_name = name_str,\n",
    "    template_path = f\"{DIR}/{name_str}.yaml\",\n",
    "    parameter_values = dict(\n",
    "        instance_bucket = GCS_BUCKET,\n",
    "        instance_path = f'{SERIES}/{EXPERIMENT}',\n",
    "        instance_file = 'example_instance.txt'\n",
    "    ),\n",
    "    pipeline_root = f'gs://{GCS_BUCKET}/{SERIES}/{EXPERIMENT}/pipeline_root',\n",
    "    enable_caching = False # True (enabled), False (disable), None (defer to component level caching) \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bdbeb755-1b5f-4407-a673-89d6892b829d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-gcs-data-gcs-fuse-20250402192620\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-gcs-data-gcs-fuse-20250402192620')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-gcs-data-gcs-fuse-20250402192620?project=1026793852137\n"
     ]
    }
   ],
   "source": [
    "response = pipeline_job.submit(\n",
    "    service_account = SERVICE_ACCOUNT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97e3a341-7241-4913-9ad0-1f31442944ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-gcs-data-gcs-fuse-20250402192620 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-gcs-data-gcs-fuse-20250402192620 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-gcs-data-gcs-fuse-20250402192620 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-gcs-data-gcs-fuse-20250402192620 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-gcs-data-gcs-fuse-20250402192620\n"
     ]
    }
   ],
   "source": [
    "pipeline_job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8064b1-82da-4e82-8ab9-e0f24e94725f",
   "metadata": {},
   "source": [
    "### Review Outputs From Run:\n",
    "\n",
    "- The pipeline(component) should output the text of the example instance (created earlier) that it reads.\n",
    "- The pipeline should create/update an output file in GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "039bad0d-0d52-4e3b-92f1-fdd51616e01f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is my example text instance as of 2025-04-02 19:26:20'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aiplatform.get_pipeline_df(pipeline = name_str)['param.output:Output'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f37963b-73a5-4687-b57e-491ad8d532a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Successfully used GCS as a mounted file system to create this file at 2025-04-02 19:27:36'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_blob = bucket.blob(f'{SERIES}/{EXPERIMENT}/gcs_fuse.txt')\n",
    "output_blob.download_as_bytes().decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23c8f7b-e84c-4e04-b1ee-fb677b2f7c8e",
   "metadata": {},
   "source": [
    "---\n",
    "## Container Components That Read/Write To GCS Fuse Mount\n",
    "\n",
    "One way or the other, code ends up in the container to be executed.  It might be built into the container with `docker build` or a service like Cloud Build.  Or, it might be provided as an input via commands or args.  The approach here supplies a Python script to a container at run time.  The script expects the fuse mount at the `/gcs` path."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c63490-a40d-4418-b2c3-7f5b3cec6cc5",
   "metadata": {},
   "source": [
    "### Create Script That Uses Fuse Mount To Read/Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1abd14a4-cde4-4af2-a5c4-05a97ad450c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mlops-pipeline-gcs-data-gcs-fuse-container'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_str = f'{SERIES}-{EXPERIMENT}-gcs-fuse-container'\n",
    "name_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "54c9a800-2442-4ef4-a437-7c6fc1f7f270",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "example_script = \"\"\"\n",
    "import argparse\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "# import argument to local variables\n",
    "parser = argparse.ArgumentParser()\n",
    "# the passed param, dest: a name for the param, default: if absent fetch this param from the OS, type: type to convert to, help: description of argument\n",
    "parser.add_argument('--bucket', dest = 'instance_bucket', type = str, help = 'GCS Bucket name')\n",
    "parser.add_argument('--path', dest = 'instance_path', type = str, help = 'Path to file')\n",
    "parser.add_argument('--name', dest = 'instance_name', type = str, help = 'Filename')\n",
    "args = parser.parse_args()\n",
    "\n",
    "# read from GCS\n",
    "with open(f'/gcs/{args.instance_bucket}/{args.instance_path}/{args.instance_name}', 'r') as f:\n",
    "    instance = f.read()\n",
    "\n",
    "# write to GCS\n",
    "with open(f'/gcs/{args.instance_bucket}/{args.instance_path}/gcs_fuse.txt', 'w') as f:\n",
    "    f.write(\n",
    "        'Successfully used GCS as a mounted file system to create this file at ' + datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    )\n",
    "    \n",
    "print(instance)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee269ef-dcc9-484d-ad70-1727a89ce384",
   "metadata": {},
   "source": [
    "### Create Pipeline: Run Python Script That Uses GCS With Fuse Mount\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "97005362-da4f-48c5-85f4-47f799b8e312",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.component(\n",
    "    base_image = 'python:3.11'\n",
    ")\n",
    "def example_job(\n",
    "    args: list,\n",
    "    libs: list,\n",
    "    script: str\n",
    ") -> kfp.dsl.Artifact:\n",
    "    \n",
    "    import base64\n",
    "    \n",
    "    # libs\n",
    "    if libs:\n",
    "        install_command = f\"python -m pip install --upgrade pip && python -m pip install {' '.join(libs)}\"\n",
    "    else:\n",
    "        install_command = ''\n",
    "    \n",
    "    # args\n",
    "    script_args = ' '.join(args)\n",
    "    \n",
    "    # script\n",
    "    script_bytes = script.encode('utf-8')\n",
    "    encoded_script = base64.b64encode(script_bytes).decode('utf-8')\n",
    "    \n",
    "    # output artifact\n",
    "    job = kfp.dsl.Artifact(\n",
    "        metadata = dict(\n",
    "            install_command = install_command,\n",
    "            script_args = script_args,\n",
    "            encoded_script = encoded_script\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "5190ea94-ebb2-42a3-81c7-10437a4d324a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.container_component\n",
    "def example_container(\n",
    "    job: kfp.dsl.Input[kfp.dsl.Artifact],\n",
    "    instance: kfp.dsl.OutputPath(str)\n",
    "):\n",
    "\n",
    "    return kfp.dsl.ContainerSpec(\n",
    "        image = 'python:3.12-alpine3.19',\n",
    "        command = [\n",
    "            'sh',\n",
    "            '-c',\n",
    "            f'''\n",
    "            {job.metadata['install_command']}\\\n",
    "            && mkdir -p $(dirname $0)\\\n",
    "            && echo {job.metadata['encoded_script']} | base64 -d > script.py\\\n",
    "            && python script.py {job.metadata['script_args']} > $0\n",
    "            '''\n",
    "        ],\n",
    "        args = [instance]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "5c763181-46bf-418d-8c0e-eb4223377c77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline()\n",
    "def example_pipeline(\n",
    "    libs: list,\n",
    "    args: list,\n",
    "    script: str\n",
    ") -> str:\n",
    "    \n",
    "    job_op = example_job(\n",
    "        args = args,\n",
    "        libs = libs,\n",
    "        script = script\n",
    "    )\n",
    "    \n",
    "    run_op = example_container(job = job_op.output)\n",
    "    \n",
    "    return run_op.outputs['instance']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a753cd33-0930-49ed-893b-e80cbdde86bb",
   "metadata": {},
   "source": [
    "### Compile and Run Pipeline On Vertex AI Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "580750b3-1115-4929-bc7c-884cd114fa15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kfp.compiler.Compiler().compile(\n",
    "    pipeline_func = example_pipeline,\n",
    "    package_path = f'{DIR}/{name_str}.yaml',\n",
    "    pipeline_name = name_str\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "a8ff0c27-ef53-4e51-8cd1-e34df957b821",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CMDARGS = [\n",
    "    f\"--bucket='{GCS_BUCKET}'\",\n",
    "    f\"--path='{SERIES}/{EXPERIMENT}'\",\n",
    "    f\"--name='example_instance.txt'\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "fefdb215-5ff3-43f6-96fb-0b7794525e0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_job = aiplatform.PipelineJob(\n",
    "    display_name = name_str,\n",
    "    template_path = f\"{DIR}/{name_str}.yaml\",\n",
    "    parameter_values = dict(\n",
    "        libs = ['numpy'],\n",
    "        args = CMDARGS,\n",
    "        script = example_script\n",
    "    ),\n",
    "    pipeline_root = f'gs://{GCS_BUCKET}/{SERIES}/{EXPERIMENT}/pipeline_root',\n",
    "    enable_caching = False # True (enabled), False (disable), None (defer to component level caching) \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "edf39eac-8067-479a-a108-9f313c12fa72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-gcs-data-gcs-fuse-container-20250403001252\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-gcs-data-gcs-fuse-container-20250403001252')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-gcs-data-gcs-fuse-container-20250403001252?project=1026793852137\n"
     ]
    }
   ],
   "source": [
    "response = pipeline_job.submit(\n",
    "    service_account = SERVICE_ACCOUNT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "c3144935-e1c8-40e9-8361-1cb402f7bd49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-gcs-data-gcs-fuse-container-20250403001252 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-gcs-data-gcs-fuse-container-20250403001252 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-gcs-data-gcs-fuse-container-20250403001252 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-gcs-data-gcs-fuse-container-20250403001252\n"
     ]
    }
   ],
   "source": [
    "pipeline_job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c210a9-54a2-4d5d-8f73-6e8ba7fe83d4",
   "metadata": {},
   "source": [
    "### Review Outputs From Run:\n",
    "\n",
    "- The pipeline(component) should output the text of the example instance (created earlier) that it reads.\n",
    "- The pipeline should create/update an output file in GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "e24bf502-8766-468e-9061-9c1d33b066c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is my example text instance as of 2025-04-02 19:26:20\\n'"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aiplatform.get_pipeline_df(pipeline = name_str)['param.output:Output'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "5baff1b3-0067-48b9-bb83-2f4fd0f6508c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Successfully used GCS as a mounted file system to create this file at 2025-04-03 00:13:58'"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_blob = bucket.blob(f'{SERIES}/{EXPERIMENT}/gcs_fuse.txt')\n",
    "output_blob.download_as_bytes().decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2850de66-a80a-42ab-a0c1-c44c0b3b1c59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m128",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m128"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
