{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57cd1c7a",
   "metadata": {},
   "source": [
    "![tracker](https://us-central1-vertex-ai-mlops-369716.cloudfunctions.net/pixel-tracking?path=statmike%2Fvertex-ai-mlops%2FMLOps%2FPipelines&file=Vertex+AI+Pipelines+-+Components.ipynb)\n",
    "<!--- header table --->\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/statmike/vertex-ai-mlops/blob/main/MLOps/Pipelines/Vertex%20AI%20Pipelines%20-%20Components.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\">\n",
    "      <br>Run in<br>Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https%3A%2F%2Fraw.githubusercontent.com%2Fstatmike%2Fvertex-ai-mlops%2Fmain%2FMLOps%2FPipelines%2FVertex%2520AI%2520Pipelines%2520-%2520Components.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\">\n",
    "      <br>Run in<br>Colab Enterprise\n",
    "    </a>\n",
    "  </td>      \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/statmike/vertex-ai-mlops/blob/main/MLOps/Pipelines/Vertex%20AI%20Pipelines%20-%20Components.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      <br>View on<br>GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/statmike/vertex-ai-mlops/main/MLOps/Pipelines/Vertex%20AI%20Pipelines%20-%20Components.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      <br>Open in<br>Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee4a1b5-0f22-452b-b1fe-c0b15c457373",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "This is part of a [series of notebook based workflows](./readme.md) that teach all the ways to use pipelines within Vertex AI. The suggested order and description/reason is:\n",
    "\n",
    "|Link To Section|Notebook Workflow|Description|\n",
    "|---|---|---|\n",
    "||[Vertex AI Pipelines - Start Here](./Vertex%20AI%20Pipelines%20-%20Start%20Here.ipynb)|What are pipelines? Start here to go from code to pipeline and see it in action.|\n",
    "||[Vertex AI Pipelines - Introduction](./Vertex%20AI%20Pipelines%20-%20Introduction.ipynb)|Introduction to pipelines with the console and Vertex AI SDK|\n",
    "||[Vertex AI Pipelines - Components](./Vertex%20AI%20Pipelines%20-%20Components.ipynb)|An introduction to all the ways to create pipeline components from your code|\n",
    "||[Vertex AI Pipelines - IO](./Vertex%20AI%20Pipelines%20-%20IO.ipynb)|An overview of all the type of inputs and outputs for pipeline components|\n",
    "||[Vertex AI Pipelines - Control](./Vertex%20AI%20Pipelines%20-%20Control.ipynb)|An overview of controlling the flow of exectution for pipelines|\n",
    "||[Vertex AI Pipelines - Secret Manager](./Vertex%20AI%20Pipelines%20-%20Secret%20Manager.ipynb)|How to pass sensitive information to pipelines and components|\n",
    "||[Vertex AI Pipelines - Scheduling](./Vertex%20AI%20Pipelines%20-%20Scheduling.ipynb)|How to schedule pipeline execution|\n",
    "||[Vertex AI Pipelines - Notifications](./Vertex%20AI%20Pipelines%20-%20Notifications.ipynb)|How to send email notification of pipeline status.|\n",
    "||[Vertex AI Pipelines - Management](./Vertex%20AI%20Pipelines%20-%20Management.ipynb)|Managing, Reusing, and Storing pipelines and components|\n",
    "||[Vertex AI Pipelines - Testing](./Vertex%20AI%20Pipelines%20-%20Testing.ipynb)|Strategies for testing components and pipeliens locally and remotely to aide development.|\n",
    "\n",
    "\n",
    "To discover these notebooks as part of an introduction to MLOps orchestration [start here](./readme.md).  To read more about MLOps also check out [the parent folder](../readme.md).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1929c5a0-5d97-4621-8868-671bc916c485",
   "metadata": {},
   "source": [
    "# Vertex AI Pipelines - Components \n",
    "\n",
    "[Vertex AI Pipelines](https://cloud.google.com/vertex-ai/docs/pipelines/introduction) is a serverless  runner for Kubeflow Pipelines [(KFP)](https://www.kubeflow.org/docs/components/pipelines/v2/introduction/) and the [TensorFlow Extended (TFX)](https://www.tensorflow.org/tfx/guide/understanding_tfx_pipelines) framework.\n",
    "\n",
    "Components are used to run the steps of a pipelines.  A pipeline task runs the component with inputs and results in the components outputs.  The components execute code on compute with a container image.\n",
    "\n",
    "This notebook will focus on the different types of component construction:\n",
    "- [Pre-built Google Cloud Pipeline Components](https://cloud.google.com/vertex-ai/docs/pipelines/components-introduction)\n",
    "- [Custom KFP Components](https://www.kubeflow.org/docs/components/pipelines/v2/components/)\n",
    "    - Python Components:\n",
    "        - Lightweight Python Components\n",
    "        - Containerized Python Components\n",
    "    - Arbitrary Containers:\n",
    "        - Container Components\n",
    "    - Importer Components\n",
    "        - A provided importer for artifact created prior to the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d02fd35-3db1-4b73-a1b8-37c89f304645",
   "metadata": {
    "id": "od_UkDpvRmgD",
    "tags": []
   },
   "source": [
    "---\n",
    "## Colab Setup\n",
    "\n",
    "To run this notebook in Colab run the cells in this section.  Otherwise, skip this section.\n",
    "\n",
    "This cell will authenticate to GCP (follow prompts in the popup)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc575cc2-c70e-47a6-921b-895899795f2d",
   "metadata": {
    "executionInfo": {
     "elapsed": 195,
     "status": "ok",
     "timestamp": 1683726184843,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "8UO9FnqyKBlF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'statmike-mlops-349915' # replace with project ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abbc374a-98b8-495a-a9e3-cc9609b5f9b2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68869,
     "status": "ok",
     "timestamp": 1683726253709,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "N98-KK7LRkjm",
    "outputId": "09ec5008-0def-4e1a-c349-c598ee752f78",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not a Colab Environment\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    !gcloud config set project {PROJECT_ID}\n",
    "    print('Colab authorized to GCP')\n",
    "except Exception:\n",
    "    print('Not a Colab Environment')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff344ce5-0d5d-45b5-83b9-977e858ef9ea",
   "metadata": {},
   "source": [
    "---\n",
    "## Installs\n",
    "\n",
    "The list `packages` contains tuples of package import names and install names.  If the import name is not found then the install name is used to install quitely for the current user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f8458ef-b50a-41f4-a6f0-39c9c202f71b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tuples of (import name, install name, min_version)\n",
    "packages = [\n",
    "    ('google.cloud.aiplatform', 'google-cloud-aiplatform'),\n",
    "    ('google.cloud.storage', 'google-cloud-storage'),\n",
    "    ('google.cloud.artifactregistry_v1', 'google-cloud-artifact-registry'),\n",
    "    ('kfp', 'kfp'),\n",
    "    ('google_cloud_pipeline_components', 'google-cloud-pipeline-components'),\n",
    "    ('docker', 'docker')\n",
    "]\n",
    "\n",
    "import importlib\n",
    "install = False\n",
    "for package in packages:\n",
    "    if not importlib.util.find_spec(package[0]):\n",
    "        print(f'installing package {package[1]}')\n",
    "        install = True\n",
    "        !pip install {package[1]} -U -q --user\n",
    "    elif len(package) == 3:\n",
    "        if importlib.metadata.version(package[0]) < package[2]:\n",
    "            print(f'updating package {package[1]}')\n",
    "            install = True\n",
    "            !pip install {package[1]} -U -q --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786142cf-32b6-4ac3-bbf4-4a58c04f297a",
   "metadata": {},
   "source": [
    "### API Enablement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "699277a0-dd25-46ba-86f9-b99f17217cac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gcloud services enable aiplatform.googleapis.com\n",
    "!gcloud services enable artifactregistry.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f4d728-766d-49c1-bc25-3c85ede7ab02",
   "metadata": {},
   "source": [
    "### Restart Kernel (If Installs Occured)\n",
    "\n",
    "After a kernel restart the code submission can start with the next cell after this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3af76386-9523-42f4-9ec2-a60f1baad867",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if install:\n",
    "    import IPython\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)\n",
    "    IPython.display.display(IPython.display.Markdown(\"\"\"<div class=\\\"alert alert-block alert-warning\\\">\n",
    "        <b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. The previous cells do not need to be run again⚠️</b>\n",
    "        </div>\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af26c69b-e6af-407a-ab7c-2416d6732d3b",
   "metadata": {
    "id": "appt8-yVRtJ1"
   },
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b76b7a-7e87-4413-845e-b8a632a76ad1",
   "metadata": {
    "id": "63mx2EozRxFP"
   },
   "source": [
    "Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00588e3a-4f48-4e3c-bc94-6625dda5401a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 2124,
     "status": "ok",
     "timestamp": 1683726390544,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "xzcoXjM5Rky5",
    "outputId": "b3bdcbc1-70d5-472e-aea2-42c74a42efde",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'statmike-mlops-349915'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1547b468-991b-4123-8ee9-b91037855450",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1683726390712,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "IxWrFtqYMfku",
    "tags": []
   },
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "EXPERIMENT = 'pipeline-components'\n",
    "SERIES = 'mlops'\n",
    "\n",
    "# gcs bucket\n",
    "GCS_BUCKET = PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663ee568-7d4d-4f16-8ea9-015925765cac",
   "metadata": {
    "id": "LuajVwCiO6Yg"
   },
   "source": [
    "Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1aa5728-0bf7-40d9-8e7c-6786c4b9bb26",
   "metadata": {
    "executionInfo": {
     "elapsed": 17761,
     "status": "ok",
     "timestamp": 1683726409304,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "LVC7zzSLRk2C",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import importlib\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import storage\n",
    "from google.cloud import artifactregistry_v1\n",
    "import kfp\n",
    "from typing import NamedTuple\n",
    "import docker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6609a397-bfd4-422e-ac55-9218a5b80e30",
   "metadata": {
    "id": "EyAVFG9TO9H-"
   },
   "source": [
    "Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6067ea47-5acb-48da-ba36-1e5932b50e21",
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1683726409306,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "L0RPE13LOZce",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vertex ai clients\n",
    "aiplatform.init(project = PROJECT_ID, location = REGION)\n",
    "\n",
    "# gcs storage client\n",
    "gcs = storage.Client(project = GCS_BUCKET)\n",
    "\n",
    "# artifact registry client\n",
    "ar_client = artifactregistry_v1.ArtifactRegistryClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa2bc2f-b99f-4eba-97ec-0e3a807d5413",
   "metadata": {},
   "source": [
    "Docker Check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2381797d-3a61-49cf-aeb1-7eb3eae5f6c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docker is installed and running. Version: 20.10.17\n"
     ]
    }
   ],
   "source": [
    "docker_client = docker.from_env()\n",
    "\n",
    "if docker_client.ping():\n",
    "    print(f\"Docker is installed and running. Version: {docker_client.version()['Version']}\")\n",
    "else:\n",
    "    print('Docker is either not installed or not running - please fix before proceeding.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b8c07f-c967-4913-a6cc-ff0e4e29e4c4",
   "metadata": {},
   "source": [
    "parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ef26020-b237-4360-9f1c-4182ee57c35a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DIR = f\"temp/{SERIES}-{EXPERIMENT}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0eb47fe2-2b45-4e49-b1d1-06670fab07fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1026793852137-compute@developer.gserviceaccount.com'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SERVICE_ACCOUNT = !gcloud config list --format='value(core.account)' \n",
    "SERVICE_ACCOUNT = SERVICE_ACCOUNT[0]\n",
    "SERVICE_ACCOUNT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b9736b-dda0-4415-9280-e099677ef90f",
   "metadata": {},
   "source": [
    "environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4630938-bac8-426a-8b3e-56aeac49aba2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(DIR):\n",
    "    os.makedirs(DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e818b5-a3a6-466f-a890-fc7ad1fc0bdb",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup Artifact Registry\n",
    "\n",
    "[Artifact registry](https://cloud.google.com/artifact-registry/docs) organizes artifacts with repositories.  Each repository contains packages and is designated to hold a partifcular format of package: Docker images, Python Packages and [others](https://cloud.google.com/artifact-registry/docs/supported-formats#package).  There is even a registry type specifically for [Kubeflow pipeline templates](https://cloud.google.com/artifact-registry/docs/kfp?hl=en)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da33fd95-7d5b-4d47-97e7-79e041632dda",
   "metadata": {},
   "source": [
    "### List Repositories\n",
    "\n",
    "This may be empty if no repositories have been created for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac649690-c689-4a72-a6b9-c67b9ef5e0fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projects/statmike-mlops-349915/locations/us-central1/repositories/gcf-artifacts\n",
      "projects/statmike-mlops-349915/locations/us-central1/repositories/statmike-mlops-349915\n",
      "projects/statmike-mlops-349915/locations/us-central1/repositories/statmike-mlops-349915-docker\n",
      "projects/statmike-mlops-349915/locations/us-central1/repositories/statmike-mlops-349915-python\n"
     ]
    }
   ],
   "source": [
    "for repo in ar_client.list_repositories(parent = f'projects/{PROJECT_ID}/locations/{REGION}'):\n",
    "    print(repo.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a72369-5a94-45d8-8bf2-3a496ad86d50",
   "metadata": {},
   "source": [
    "### Create/Retrieve Docker Image Repository\n",
    "\n",
    "Create an Artifact Registry Repository to hold Docker Images created by this notebook.  First, check to see if it is already created by a previous run and retrieve it if it has.  Otherwise, create one named for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b211df4-bad1-415b-8f41-ebd43b92a8af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved existing repo: projects/statmike-mlops-349915/locations/us-central1/repositories/statmike-mlops-349915\n"
     ]
    }
   ],
   "source": [
    "docker_repo = None\n",
    "for repo in ar_client.list_repositories(parent = f'projects/{PROJECT_ID}/locations/{REGION}'):\n",
    "    if f'{PROJECT_ID}' == repo.name.split('/')[-1]:\n",
    "        docker_repo = repo\n",
    "        print(f'Retrieved existing repo: {docker_repo.name}')\n",
    "\n",
    "if not docker_repo:\n",
    "    operation = ar_client.create_repository(\n",
    "        request = artifactregistry_v1.CreateRepositoryRequest(\n",
    "            parent = f'projects/{PROJECT_ID}/locations/{REGION}',\n",
    "            repository_id = f'{PROJECT_ID}',\n",
    "            repository = artifactregistry_v1.Repository(\n",
    "                description = f'A repository for the {SERIES} series that holds docker images.',\n",
    "                name = f'{PROJECT_ID}',\n",
    "                format_ = artifactregistry_v1.Repository.Format.DOCKER,\n",
    "                labels = {'series': SERIES}\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    print('Creating Repository ...')\n",
    "    docker_repo = operation.result()\n",
    "    print(f'Completed creating repo: {docker_repo.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28e2f731-70b1-4cbf-8982-8a67523b0dfc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('projects/statmike-mlops-349915/locations/us-central1/repositories/statmike-mlops-349915',\n",
       " 'DOCKER')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docker_repo.name, docker_repo.format_.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ba64f46-081f-46cd-8780-0506c5cf13a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "REPOSITORY = f\"{REGION}-docker.pkg.dev/{PROJECT_ID}/{docker_repo.name.split('/')[-1]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3123529a-67df-47d1-868c-89ff73ee62f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'us-central1-docker.pkg.dev/statmike-mlops-349915/statmike-mlops-349915'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REPOSITORY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f913cf78-472c-43d4-afec-8dd397a37837",
   "metadata": {},
   "source": [
    "---\n",
    "## Components\n",
    "\n",
    "[KFP Components](https://www.kubeflow.org/docs/components/pipelines/v2/components/) are the runners for pipelines tasks. They run code in a container as a job.  The container is specified as a [`base_image` parameter](https://www.kubeflow.org/docs/components/pipelines/v2/components/), which defaults to `python:3.7` currently and can be specified at component creation which is demonstrated throughout this workflow.\n",
    "\n",
    "\n",
    "**Compute Resources** For Components:\n",
    "\n",
    "Running pipleines on Vertex AI Pipelines runs each component as a Vertex AI Training `CustomJob`.  This defaults to a vm based on `e2-standard-4` (4 core CPU, 16GB memory).  This can be modified at the task level of pipelines to choose different computing resources, including GPUs.  For example:\n",
    "\n",
    "```Python\n",
    "@kfp.dsl.pipeline()\n",
    "def pipeline():\n",
    "    task = component().set_cpu_limit(C).set_memory_limit(M).add_node_selector_constraint(A).set_accelerator_limit(G).\n",
    "```\n",
    "Where the inputs are defining [machine configuration for the step](https://cloud.google.com/vertex-ai/docs/pipelines/machine-types):\n",
    "- C = a string representing the number of CPUs (up to 96).\n",
    "- M = a string represent the memory limit.  An integer follwed by K, M, or G (up to 624GB).\n",
    "- A = a string representing the desired GPU  or TPU type\n",
    "- G = an integer representing the multiple of A desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c24a367f-2982-4683-b28c-cb54b2e36c8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google_cloud_pipeline_components.v1.model import ModelGetOp\n",
    "from google_cloud_pipeline_components.types import artifact_types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c198e4ba-bd12-4344-b7e6-3f6ceb3ecb14",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Prebuilt Google Cloud Pipeline Components\n",
    "\n",
    "Google Cloud provides a growing list of components covering AutoML, Batch Prediction, BigQuery Ml, .... and MANY more services!  \n",
    "\n",
    "The benefits of a prebuilt components include:\n",
    "- simple debugging\n",
    "- standarized artifact types that are tracked with Vertex AI ML Metadata.  Ths makes lineage easy!\n",
    "- These don't have to launch a container to then launch a service - which is more cost effective!\n",
    "\n",
    "These can be reviewed several ways:\n",
    "- Directly in the documentation: [Google Cloud Pipeline Components List](https://cloud.google.com/vertex-ai/docs/pipelines/gcpc-list)\n",
    "- At their accompanying [API Reference](https://google-cloud-pipeline-components.readthedocs.io/en/google-cloud-pipeline-components-2.10.0/api/index.html)\n",
    "- At their source in the GitHub repository for kubeflow pipeliens: [GitHub/kubeflow/pipelines/components/google-cloud](https://github.com/kubeflow/pipelines/tree/master/components/google-cloud)\n",
    "\n",
    "These prebuilt component also include prebuilt artifact types for Google Cloud Resources:\n",
    "- [Google Cloud Artifact Types](https://google-cloud-pipeline-components.readthedocs.io/en/google-cloud-pipeline-components-2.10.0/api/artifact_types.html)\n",
    "\n",
    "Here, the `ModelGetOp` component is used to retrieve an artifact for a model in the Vertex AI Model Registry.\n",
    "\n",
    "```python\n",
    "from google_cloud_pipeline_components.v1.model import ModelGetOp\n",
    "\n",
    "    vertex_model_1 = ModelGetOp(\n",
    "        model_name = model_name.outputs['model_name'],\n",
    "        project = project,\n",
    "        location = region\n",
    "    ).set_display_name('Prebuilt Component')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbac2f5a-f4bb-4259-a3e6-1d60e561d0c9",
   "metadata": {},
   "source": [
    "### Lightweight Python Components\n",
    "\n",
    "A simple way to create a component from a Python function.  This will create the container at the runtime of the task from the `base_image` and install the `packages_to_install`.\n",
    "\n",
    "References:\n",
    "- [Lightweight Python Components](https://www.kubeflow.org/docs/components/pipelines/v2/components/lightweight-python-components/)\n",
    "\n",
    "Here, a simple function will use the Vertex AI SDK to retrieve a list of all models and pass the the versioned resource name of the first one as an ouput."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4ee1f66-6b2a-4844-ba52-651522e35ac9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.component(\n",
    "    base_image = 'python:3.10',\n",
    "    packages_to_install = ['google-cloud-aiplatform']\n",
    ")\n",
    "def example_lightweight(\n",
    "    project: str,\n",
    "    region: str\n",
    ") -> NamedTuple('lightweight_outputs', model_name = str, model_resource_name = str, uri = str):\n",
    "    \n",
    "    # vertex ai client\n",
    "    from google.cloud import aiplatform\n",
    "    aiplatform.init(project = project, location = region)\n",
    "    \n",
    "    # list models in region\n",
    "    models = aiplatform.Model.list()\n",
    "    \n",
    "    outputs = NamedTuple('lightweight_outputs', model_name = str, model_resource_name = str, uri = str)\n",
    "    \n",
    "    return outputs(\n",
    "        models[0].versioned_resource_name.split('/')[-1],\n",
    "        models[0].versioned_resource_name,\n",
    "        f\"https://{region}-aiplatform.googleapis.com/v1/{models[0].versioned_resource_name}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ed62d0-eef2-4f92-b620-002f3d091c74",
   "metadata": {},
   "source": [
    "### Containerized Python Components\n",
    "\n",
    "This extends the idea of the lightweight Python components.  This builds the container for the component and installs the `packages_to_install` so that they are already installed at the time it runs.\n",
    "\n",
    "References:\n",
    "- [Containerized Python Components](https://www.kubeflow.org/docs/components/pipelines/v2/components/containerized-python-components/)\n",
    "    - There is even a registry type specifically for [Kubeflow pipeline templates](https://cloud.google.com/artifact-registry/docs/kfp?hl=en).\n",
    "- [Developer Note](https://github.com/kubeflow/pipelines/issues/9568#issuecomment-1622223720) from a GitHub issue that describes the Containerized Python Components very well.\n",
    "\n",
    "The container images need to be saved for usage in Google Cloud.  This section makes use of the Artifact Registry docker container repository created/retrieved above.\n",
    "\n",
    "This example replicates the lightweight Python component above as a containerized Python component."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe423c8-b58f-4f44-b86b-53627a6c0148",
   "metadata": {
    "tags": []
   },
   "source": [
    "First, create a local folder to hold the Python source code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87826f04-f923-4b78-a30e-df8593ea62d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(DIR + '/src'):\n",
    "    os.makedirs(DIR + '/src')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe466b44-0008-46e2-845d-d1aa0ff0634d",
   "metadata": {},
   "source": [
    "Now, create the Python file(s) in the folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c965047-b6b1-4b2c-9c75-b0b186fab4bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting temp/mlops-pipeline-components/src/__init__.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {DIR}/src/__init__.py\n",
    "# init file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "03ce891c-ef55-488f-b0df-f080110ed6f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting temp/mlops-pipeline-components/src/my_code.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {DIR}/src/my_code.py\n",
    "\n",
    "def example_function(project, region):\n",
    "\n",
    "    # vertex ai client\n",
    "    from google.cloud import aiplatform\n",
    "    \n",
    "    # vertex ai initialize SDK\n",
    "    aiplatform.init(project = project, location = region)\n",
    "    \n",
    "    # list models in region\n",
    "    models = aiplatform.Model.list()\n",
    "    \n",
    "    model_name = models[0].versioned_resource_name.split('/')[-1],\n",
    "    model_resource_name = models[0].versioned_resource_name,\n",
    "    uri = f\"https://{region}-aiplatform.googleapis.com/v1/{models[0].versioned_resource_name}\"\n",
    "    \n",
    "    return [model_name, model_resource_name, uri]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d1b87f-0fd1-4935-8860-375e2bfe704c",
   "metadata": {},
   "source": [
    "Create the component in the folder also and have it import and use the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2e9dcad8-e764-454b-aee8-779ace6d5f0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-central1-docker.pkg.dev/statmike-mlops-349915/statmike-mlops-349915/mlops-pipeline-components\n"
     ]
    }
   ],
   "source": [
    "print(f'{REPOSITORY}/{SERIES}-{EXPERIMENT}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2e7ea7ff-c40e-4770-8ad1-9053bbf3a8a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting temp/mlops-pipeline-components/src/my_component.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {DIR}/src/my_component.py\n",
    "import kfp\n",
    "from my_code import example_function\n",
    "from google_cloud_pipeline_components.types import artifact_types\n",
    "\n",
    "@kfp.dsl.component(\n",
    "    base_image = 'python:3.10',\n",
    "    target_image = 'us-central1-docker.pkg.dev/statmike-mlops-349915/statmike-mlops-349915/mlops-pipeline-components',\n",
    "    packages_to_install = ['google-cloud-aiplatform', 'google_cloud_pipeline_components']\n",
    ")\n",
    "def example_python_container(\n",
    "    project: str,\n",
    "    region: str,\n",
    "    vertex_model: kfp.dsl.Output[artifact_types.VertexModel]\n",
    "):\n",
    "    \n",
    "    response = example_function(project, region)\n",
    "    vertex_model.uri = response[2]\n",
    "    vertex_model.metadata['model_resource_name'] = response[1]\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6741c1c-14e4-4fa1-8e9b-1ddca4c0d576",
   "metadata": {},
   "source": [
    "The source code is created in a structure that now looks like:\n",
    "\n",
    "```\n",
    "src/\n",
    "├── __init__.py\n",
    "├── my_code.py\n",
    "└── my_component.py\n",
    "```\n",
    "\n",
    "Unlike other component types, this one needs to be built.  Behind the scenes KFP will create a `Dockerfile` and do the `docker build` process while also pushing the resulting image to container repository specified in Artifact Registry by the `target_image`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b97c34f-ab68-4086-9d11-6c643fea5c17",
   "metadata": {},
   "source": [
    "Configure authentication to Artifact Registry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "28c881de-9a10-49e7-b8ba-1f014fac24c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mWARNING:\u001b[0m Your config file at [/home/jupyter/.docker/config.json] contains these credential helper entries:\n",
      "\n",
      "{\n",
      "  \"credHelpers\": {\n",
      "    \"gcr.io\": \"gcloud\",\n",
      "    \"us.gcr.io\": \"gcloud\",\n",
      "    \"eu.gcr.io\": \"gcloud\",\n",
      "    \"asia.gcr.io\": \"gcloud\",\n",
      "    \"staging-k8s.gcr.io\": \"gcloud\",\n",
      "    \"marketplace.gcr.io\": \"gcloud\",\n",
      "    \"us-central1-docker.pkg.dev\": \"gcloud\"\n",
      "  }\n",
      "}\n",
      "Adding credentials for: us-central1-docker.pkg.dev\n",
      "gcloud credential helpers already registered correctly.\n"
     ]
    }
   ],
   "source": [
    "!gcloud auth configure-docker $REGION-docker.pkg.dev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5810858-c237-4580-aeb3-e6acda622ee1",
   "metadata": {},
   "source": [
    "Build the component and push to Artifact Registry:\n",
    "\n",
    "This uses the KFP CLI command [`kfp component build`](https://kubeflow-pipelines.readthedocs.io/en/stable/source/cli.html#kfp-component-build)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "056001dc-733c-4b13-8fbf-e91575ab0aa8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building component using KFP package path: kfp==2.7.0\n",
      "Found 1 component(s) in file /home/jupyter/vertex-ai-mlops/MLOps/temp/mlops-pipeline-components/src/my_component.py:\n",
      "Example python container: ComponentInfo(name='Example python container', function_name='example_python_container', func=<function example_python_container at 0x7f0cf1095b40>, target_image='us-central1-docker.pkg.dev/statmike-mlops-349915/statmike-mlops-349915/mlops-pipeline-components', module_path=PosixPath('/home/jupyter/vertex-ai-mlops/MLOps/temp/mlops-pipeline-components/src/my_component.py'), component_spec=ComponentSpec(name='example-python-container', implementation=Implementation(container=ContainerSpecImplementation(image='us-central1-docker.pkg.dev/statmike-mlops-349915/statmike-mlops-349915/mlops-pipeline-components', command=['sh', '-c', '\\nif ! [ -x \"$(command -v pip)\" ]; then\\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\\nfi\\n\\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location \\'google-cloud-aiplatform\\' \\'google_cloud_pipeline_components\\' && \"$0\" \"$@\"\\n', 'python3', '-m', 'kfp.dsl.executor_main'], args=['--executor_input', '{{$}}', '--function_to_execute', 'example_python_container'], env=None, resources=None), importer=None, graph=None), description=None, inputs={'project': InputSpec(type='String', default=None, optional=False, is_artifact_list=False, description=None), 'region': InputSpec(type='String', default=None, optional=False, is_artifact_list=False, description=None)}, outputs={'vertex_model': OutputSpec(type='google.VertexModel@0.0.1', is_artifact_list=False, description=None)}, platform_spec=), output_component_file=None, base_image='python:3.10', packages_to_install=['google-cloud-aiplatform', 'google_cloud_pipeline_components'], pip_index_urls=None)\n",
      "Using base image: python:3.10\n",
      "Using target image: us-central1-docker.pkg.dev/statmike-mlops-349915/statmike-mlops-349915/mlops-pipeline-components\n",
      "Found existing file runtime-requirements.txt under /home/jupyter/vertex-ai-mlops/MLOps/temp/mlops-pipeline-components/src.\n",
      "Overwriting existing file runtime-requirements.txt\n",
      "Generated file /home/jupyter/vertex-ai-mlops/MLOps/temp/mlops-pipeline-components/src/runtime-requirements.txt.\n",
      "Found existing file .dockerignore under /home/jupyter/vertex-ai-mlops/MLOps/temp/mlops-pipeline-components/src.\n",
      "Leaving this file untouched.\n",
      "Found existing file Dockerfile under /home/jupyter/vertex-ai-mlops/MLOps/temp/mlops-pipeline-components/src.\n",
      "Leaving this file untouched.\n",
      "Building image us-central1-docker.pkg.dev/statmike-mlops-349915/statmike-mlops-349915/mlops-pipeline-components using Docker...\n",
      "Docker: Step 1/6 : FROM python:3.10\n",
      "Docker:  ---> 22546fe66182\n",
      "Docker: Step 2/6 : WORKDIR /usr/local/src/kfp/components\n",
      "Docker:  ---> Using cache\n",
      "Docker:  ---> 9f83e9176888\n",
      "Docker: Step 3/6 : COPY runtime-requirements.txt runtime-requirements.txt\n",
      "Docker:  ---> Using cache\n",
      "Docker:  ---> 940b0f92c5f9\n",
      "Docker: Step 4/6 : RUN pip install --no-cache-dir -r runtime-requirements.txt\n",
      "Docker:  ---> Using cache\n",
      "Docker:  ---> 33e0c77ef044\n",
      "Docker: Step 5/6 : RUN pip install --no-cache-dir kfp==2.7.0\n",
      "Docker:  ---> Using cache\n",
      "Docker:  ---> acbc957a37d9\n",
      "Docker: Step 6/6 : COPY . .\n",
      "Docker:  ---> f22f98f04dba\n",
      "Docker: Successfully built f22f98f04dba\n",
      "Docker: Successfully tagged us-central1-docker.pkg.dev/statmike-mlops-349915/statmike-mlops-349915/mlops-pipeline-components:latest\n",
      "Pushing image us-central1-docker.pkg.dev/statmike-mlops-349915/statmike-mlops-349915/mlops-pipeline-components...\n",
      "Docker:  The push refers to repository [us-central1-docker.pkg.dev/statmike-mlops-349915/statmike-mlops-349915/mlops-pipeline-components]\n",
      "Docker: 8ddd80879460 Preparing\n",
      "Docker: 3fbd80ec358e Preparing\n",
      "Docker: 522dc26f660f Preparing\n",
      "Docker: ee55602fd430 Preparing\n",
      "Docker: 0e0a58abfaab Preparing\n",
      "Docker: 13e9fcf92c67 Preparing\n",
      "Docker: 5b8a506fb91c Preparing\n",
      "Docker: a6267a497621 Preparing\n",
      "Docker: 84f540ade319 Preparing\n",
      "Docker: 9fe4e8a1862c Preparing\n",
      "Docker: 909275a3eaaa Preparing\n",
      "Docker: f3f47b3309ca Preparing\n",
      "Docker: 1a5fc1184c48 Preparing\n",
      "Docker: f3f47b3309ca Waiting\n",
      "Docker: 9fe4e8a1862c Waiting\n",
      "Docker: 13e9fcf92c67 Waiting\n",
      "Docker: 909275a3eaaa Waiting\n",
      "Docker: 5b8a506fb91c Waiting\n",
      "Docker: 84f540ade319 Waiting\n",
      "Docker: a6267a497621 Waiting\n",
      "Docker: 1a5fc1184c48 Waiting\n",
      "Docker: 8ddd80879460 Pushing\n",
      "Docker: 8ddd80879460 Pushing\n",
      "Docker: ee55602fd430 Layer already exists\n",
      "Docker: 3fbd80ec358e Layer already exists\n",
      "Docker: 522dc26f660f Layer already exists\n",
      "Docker: 0e0a58abfaab Layer already exists\n",
      "Docker: 5b8a506fb91c Layer already exists\n",
      "Docker: 84f540ade319 Layer already exists\n",
      "Docker: 13e9fcf92c67 Layer already exists\n",
      "Docker: a6267a497621 Layer already exists\n",
      "Docker: 9fe4e8a1862c Layer already exists\n",
      "Docker: f3f47b3309ca Layer already exists\n",
      "Docker: 909275a3eaaa Layer already exists\n",
      "Docker: 1a5fc1184c48 Layer already exists\n",
      "Docker: 8ddd80879460 Pushed\n",
      "Docker:  latest: digest: sha256:1608eb4d9c762e69d2cac74269347450e3893059c9a745990a89c437ff81593a size: 3047\n",
      "Built and pushed component container us-central1-docker.pkg.dev/statmike-mlops-349915/statmike-mlops-349915/mlops-pipeline-components\n"
     ]
    }
   ],
   "source": [
    "!kfp component build $DIR/src/ --component-filepattern my_component.py --push-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e6663ead-4007-4336-a364-37e38762ea22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review the Custom Container with Artifact Registry in the Google Cloud Console:\n",
      "https://console.cloud.google.com/artifacts/docker/statmike-mlops-349915/us-central1/statmike-mlops-349915?project=statmike-mlops-349915\n"
     ]
    }
   ],
   "source": [
    "print(f\"Review the Custom Container with Artifact Registry in the Google Cloud Console:\\nhttps://console.cloud.google.com/artifacts/docker/{PROJECT_ID}/{REGION}/{PROJECT_ID}?project={PROJECT_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047058bf-5805-4b76-9baa-d273facaa95a",
   "metadata": {},
   "source": [
    "Import the component to use it in the pipeline definition below\n",
    "\n",
    ">**NOTE:** Re-running this section of the notebook with iterative changes to the functions requires forcing the reload of the function from the file/module.  This is forced here by using the `importlib.reload(my_component)` action.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "01d7b75e-6f66-4fbc-9d32-83d2ef3c54af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/vertex-ai-mlops/MLOps'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fa62459a-2783-4294-a1da-2753db498fcc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/vertex-ai-mlops/MLOps/temp/mlops-pipeline-components/src\n",
      "/home/jupyter/vertex-ai-mlops/MLOps\n"
     ]
    }
   ],
   "source": [
    "%cd {DIR}/src\n",
    "import my_component\n",
    "importlib.reload(my_component)\n",
    "from my_component import example_python_container\n",
    "%cd ../../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d9d4e2e4-046d-4758-9885-abc911cad7e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/vertex-ai-mlops/MLOps'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b106fbf-76ae-41b4-8dce-10a6555983e8",
   "metadata": {},
   "source": [
    "### Container Components\n",
    "\n",
    "Any container can be a component with [Container Components](https://www.kubeflow.org/docs/components/pipelines/v2/components/container-components/).  \n",
    "\n",
    "This looks a lot like a lightweight Python component but it orchestrates the running of the specified container image with inputs and ouputs.\n",
    "\n",
    "The example below takes the [alpine docker image](https://hub.docker.com/_/alpine) and runs a simple command that takes the `model_resource_name` of an artifact created by the Importer Component (created below) and prints it out as part of a string which is returned as an output.  The output type here is [`kfp.dsl.OutputPath`](https://kubeflow-pipelines.readthedocs.io/en/2.0.0b6/source/dsl.html#kfp.dsl.OutputPath)  which indicates the named parameter is a link to a filepath (the output of the container in this case).\n",
    "- The shell command for `mkdir` is used to create an output loation  with the `kfp.dsl.OutputPath` variable\n",
    "- The `echo` command along with the `>` write to instruction are used to write values to the `kfp.dsl_OutputPath` using the directory created\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "49332e7c-d65b-4c64-8b18-738d6a0642be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.container_component\n",
    "def example_container(\n",
    "    vertex_model_a: kfp.dsl.Input[artifact_types.VertexModel],\n",
    "    note: kfp.dsl.OutputPath(str)\n",
    "):\n",
    "    return kfp.dsl.ContainerSpec(\n",
    "        image = 'alpine',\n",
    "        command = [\n",
    "            'sh', '-c', '''RESPONSE=\"The Model is: $0!\"\\\n",
    "                            && echo $RESPONSE\\\n",
    "                            && mkdir -p $(dirname $1)\\\n",
    "                            && echo $RESPONSE > $1\n",
    "                            '''\n",
    "        ],\n",
    "        args = [vertex_model_a.metadata['model_resource_name'], note]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daebbcf-d108-4c96-b476-41e63bcd5aff",
   "metadata": {},
   "source": [
    "### Importer Components\n",
    "\n",
    "Sometime the artifact that is need is created before the pipeline.  The `dsl.importer` component is a quick way to import the artifact. [More on the Importer Component](https://www.kubeflow.org/docs/components/pipelines/v2/components/importer-component/).\n",
    "\n",
    "While the `dsl.importer` component can be used to import [generic artifacts](https://www.kubeflow.org/docs/components/pipelines/v2/data-types/artifacts/) it can also be used to import predefined [Google Cloud Artifact Types](https://google-cloud-pipeline-components.readthedocs.io/en/google-cloud-pipeline-components-2.10.0/api/artifact_types.html) as shown in the Vertex AI documentation page for [Create an ML artifact](https://cloud.google.com/vertex-ai/docs/pipelines/use-components#use_an_importer_node).\n",
    "\n",
    "Here, the `dsl.importer` component is used to load a model in the Vertex AI Model Registry.\n",
    "\n",
    "```python\n",
    "vertex_model_2 = kfp.dsl.importer(\n",
    "        artifact_uri = model_name.outputs['uri'],\n",
    "        artifact_class = artifact_types.VertexModel,\n",
    "        metadata = {'model_resource_name': model_name.outputs['model_resource_name']}\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb3ad5e-534b-4a81-bb89-59dcb1266ae3",
   "metadata": {},
   "source": [
    "---\n",
    "## Vertex AI Pipelines\n",
    "\n",
    "- [Vertex AI Python SDK for Pipeline Jobs](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.PipelineJob)\n",
    "- [Specify machine configurations for a component](https://cloud.google.com/vertex-ai/docs/pipelines/machine-types)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afd1394-8827-4323-8b79-7ce564e4c1d4",
   "metadata": {},
   "source": [
    "### Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7e6f2597-c548-4b6c-96a6-949c7a21f5d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(\n",
    "    name = f'{SERIES}-{EXPERIMENT}',\n",
    "    description = 'A simple pipeline for testing',\n",
    "    pipeline_root = f'gs://{GCS_BUCKET}/{SERIES}/{EXPERIMENT}/pipeline_root'\n",
    ")\n",
    "def example_pipeline(\n",
    "    project: str,\n",
    "    region: str,\n",
    "    \n",
    "):\n",
    "    from google_cloud_pipeline_components.types import artifact_types\n",
    "    from google_cloud_pipeline_components.v1.model import ModelGetOp\n",
    "    \n",
    "    # Lightweight Python Components\n",
    "    model_name = example_lightweight(\n",
    "        project = project,\n",
    "        region = region\n",
    "    ).set_display_name('Lightweight Python Component').set_cpu_limit('1')\n",
    "    \n",
    "    # prebuilt Google Cloud Pipeline Component\n",
    "    vertex_model_1 = ModelGetOp(\n",
    "        model_name = model_name.outputs['model_name'],\n",
    "        project = project,\n",
    "        location = region\n",
    "    ).set_display_name('Prebuilt Component')\n",
    "    \n",
    "    # importer component\n",
    "    vertex_model_2 = kfp.dsl.importer(\n",
    "        artifact_uri = model_name.outputs['uri'],\n",
    "        artifact_class = artifact_types.VertexModel,\n",
    "        metadata = {'model_resource_name': model_name.outputs['model_resource_name']}\n",
    "    ).set_display_name('Importer Component')\n",
    "    \n",
    "    # container component\n",
    "    container = example_container(\n",
    "        vertex_model_a = vertex_model_2.outputs['artifact']\n",
    "    ).set_display_name('Container Component').set_cpu_limit('1')\n",
    "    \n",
    "    # python container component\n",
    "    python_container = example_python_container(\n",
    "        project = project,\n",
    "        region = region\n",
    "    ).set_display_name('Python Container Component').set_cpu_limit('1').set_caching_options(False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cddd264-0a05-4574-910d-4c7c0182ca58",
   "metadata": {},
   "source": [
    "### Compile Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ac0047df-74ed-4c73-9d10-730eb17537c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kfp.compiler.Compiler().compile(\n",
    "    pipeline_func = example_pipeline,\n",
    "    package_path = f'{DIR}/{SERIES}-{EXPERIMENT}.yaml'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2f9526-fc26-4f8e-97dc-051f8f6438e7",
   "metadata": {},
   "source": [
    "### Create Pipeline Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3eb4828f-03bf-409e-a991-784fba1572ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameters = dict(\n",
    "    project = PROJECT_ID,\n",
    "    region = REGION,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a47f8ca7-55a0-4f7e-ab2d-39248c108d27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_job = aiplatform.PipelineJob(\n",
    "    display_name = f\"{SERIES}-{EXPERIMENT}\",\n",
    "    template_path = f\"{DIR}/{SERIES}-{EXPERIMENT}.yaml\",\n",
    "    parameter_values = parameters,\n",
    "    pipeline_root = f'gs://{GCS_BUCKET}/{SERIES}/{EXPERIMENT}/pipeline_root',\n",
    "    enable_caching = None # True (enabled), False (disable), None (defer to component level caching) \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c5a9cd-954b-41c4-8fee-448a4bf1e4d5",
   "metadata": {},
   "source": [
    "### Submit Pipeline Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "605953d8-86b5-463a-b1eb-256d31b8acbe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-components-20240317185545\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-components-20240317185545')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-components-20240317185545?project=1026793852137\n"
     ]
    }
   ],
   "source": [
    "response = pipeline_job.submit(\n",
    "    service_account = SERVICE_ACCOUNT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5e4cd403-99ae-4b02-9416-547decff7dd8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dashboard can be viewed here:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-components-20240317185545?project=1026793852137\n"
     ]
    }
   ],
   "source": [
    "print(f'The Dashboard can be viewed here:\\n{pipeline_job._dashboard_uri()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "dea6308f-9dd2-4e75-9647-71efe4ea8f4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-components-20240317185545 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-components-20240317185545 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-components-20240317185545\n"
     ]
    }
   ],
   "source": [
    "pipeline_job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6497813c-c5c7-4eea-9c1d-fcb780a0ad1d",
   "metadata": {},
   "source": [
    "### Retrieve Pipeline Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a01068ac-e0c5-4d4b-9678-e58d49d247e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pipeline_name</th>\n",
       "      <th>run_name</th>\n",
       "      <th>param.vmlmd_lineage_integration</th>\n",
       "      <th>param.input:project</th>\n",
       "      <th>param.input:region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mlops-pipeline-components</td>\n",
       "      <td>mlops-pipeline-components-20240317185545</td>\n",
       "      <td>{'pipeline_run_component': {'pipeline_run_id':...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>us-central1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mlops-pipeline-components</td>\n",
       "      <td>mlops-pipeline-components-20240317184845</td>\n",
       "      <td>{'pipeline_run_component': {'project_id': 'sta...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>us-central1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mlops-pipeline-components</td>\n",
       "      <td>mlops-pipeline-components-20240317184016</td>\n",
       "      <td>{'pipeline_run_component': {'pipeline_run_id':...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>us-central1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mlops-pipeline-components</td>\n",
       "      <td>mlops-pipeline-components-20240317183641</td>\n",
       "      <td>{'pipeline_run_component': {'location_id': 'us...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>us-central1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mlops-pipeline-components</td>\n",
       "      <td>mlops-pipeline-components-20240317183407</td>\n",
       "      <td>{'pipeline_run_component': {'location_id': 'us...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>us-central1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mlops-pipeline-components</td>\n",
       "      <td>mlops-pipeline-components-20240317141033</td>\n",
       "      <td>{'pipeline_run_component': {'task_name': 'mlop...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>us-central1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mlops-pipeline-components</td>\n",
       "      <td>mlops-pipeline-components-20240317134615</td>\n",
       "      <td>{'pipeline_run_component': {'pipeline_run_id':...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>us-central1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mlops-pipeline-components</td>\n",
       "      <td>mlops-pipeline-components-20240317132352</td>\n",
       "      <td>{'pipeline_run_component': {'location_id': 'us...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>us-central1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mlops-pipeline-components</td>\n",
       "      <td>mlops-pipeline-components-20240317131702</td>\n",
       "      <td>{'pipeline_run_component': {'parent_task_names...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>us-central1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mlops-pipeline-components</td>\n",
       "      <td>mlops-pipeline-components-20240317125135</td>\n",
       "      <td>{'pipeline_run_component': {'task_name': 'mlop...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>us-central1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mlops-pipeline-components</td>\n",
       "      <td>mlops-pipeline-components-20240317124217</td>\n",
       "      <td>{'pipeline_run_component': {'parent_task_names...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>us-central1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mlops-pipeline-components</td>\n",
       "      <td>mlops-pipeline-components-20240317123655</td>\n",
       "      <td>{'pipeline_run_component': {'project_id': 'sta...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>us-central1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mlops-pipeline-components</td>\n",
       "      <td>mlops-pipeline-components-20240317120652</td>\n",
       "      <td>{'pipeline_run_component': {'project_id': 'sta...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>us-central1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mlops-pipeline-components</td>\n",
       "      <td>mlops-pipeline-components-20240317005601</td>\n",
       "      <td>{'pipeline_run_component': {'pipeline_run_id':...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>us-central1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mlops-pipeline-components</td>\n",
       "      <td>mlops-pipeline-components-20240317005017</td>\n",
       "      <td>{'pipeline_run_component': {'pipeline_run_id':...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>us-central1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>mlops-pipeline-components</td>\n",
       "      <td>mlops-pipeline-components-20240317003130</td>\n",
       "      <td>{'pipeline_run_component': {'location_id': 'us...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>us-central1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mlops-pipeline-components</td>\n",
       "      <td>mlops-pipeline-components-20240316211748</td>\n",
       "      <td>{'pipeline_run_component': {'location_id': 'us...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>us-central1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mlops-pipeline-components</td>\n",
       "      <td>mlops-pipeline-components-20240316204613</td>\n",
       "      <td>{'pipeline_run_component': {'location_id': 'us...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>us-central1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>mlops-pipeline-components</td>\n",
       "      <td>mlops-pipeline-components-20240316203545</td>\n",
       "      <td>{'pipeline_run_component': {'location_id': 'us...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>us-central1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>mlops-pipeline-components</td>\n",
       "      <td>mlops-pipeline-components-20240316202355</td>\n",
       "      <td>{'pipeline_run_component': {'parent_task_names...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>us-central1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>mlops-pipeline-components</td>\n",
       "      <td>mlops-pipeline-components-20240316194018</td>\n",
       "      <td>{'pipeline_run_component': {'pipeline_run_id':...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>us-central1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                pipeline_name                                  run_name  \\\n",
       "0   mlops-pipeline-components  mlops-pipeline-components-20240317185545   \n",
       "1   mlops-pipeline-components  mlops-pipeline-components-20240317184845   \n",
       "2   mlops-pipeline-components  mlops-pipeline-components-20240317184016   \n",
       "3   mlops-pipeline-components  mlops-pipeline-components-20240317183641   \n",
       "4   mlops-pipeline-components  mlops-pipeline-components-20240317183407   \n",
       "5   mlops-pipeline-components  mlops-pipeline-components-20240317141033   \n",
       "6   mlops-pipeline-components  mlops-pipeline-components-20240317134615   \n",
       "7   mlops-pipeline-components  mlops-pipeline-components-20240317132352   \n",
       "8   mlops-pipeline-components  mlops-pipeline-components-20240317131702   \n",
       "9   mlops-pipeline-components  mlops-pipeline-components-20240317125135   \n",
       "10  mlops-pipeline-components  mlops-pipeline-components-20240317124217   \n",
       "11  mlops-pipeline-components  mlops-pipeline-components-20240317123655   \n",
       "12  mlops-pipeline-components  mlops-pipeline-components-20240317120652   \n",
       "13  mlops-pipeline-components  mlops-pipeline-components-20240317005601   \n",
       "14  mlops-pipeline-components  mlops-pipeline-components-20240317005017   \n",
       "15  mlops-pipeline-components  mlops-pipeline-components-20240317003130   \n",
       "16  mlops-pipeline-components  mlops-pipeline-components-20240316211748   \n",
       "17  mlops-pipeline-components  mlops-pipeline-components-20240316204613   \n",
       "18  mlops-pipeline-components  mlops-pipeline-components-20240316203545   \n",
       "19  mlops-pipeline-components  mlops-pipeline-components-20240316202355   \n",
       "20  mlops-pipeline-components  mlops-pipeline-components-20240316194018   \n",
       "\n",
       "                      param.vmlmd_lineage_integration    param.input:project  \\\n",
       "0   {'pipeline_run_component': {'pipeline_run_id':...  statmike-mlops-349915   \n",
       "1   {'pipeline_run_component': {'project_id': 'sta...  statmike-mlops-349915   \n",
       "2   {'pipeline_run_component': {'pipeline_run_id':...  statmike-mlops-349915   \n",
       "3   {'pipeline_run_component': {'location_id': 'us...  statmike-mlops-349915   \n",
       "4   {'pipeline_run_component': {'location_id': 'us...  statmike-mlops-349915   \n",
       "5   {'pipeline_run_component': {'task_name': 'mlop...  statmike-mlops-349915   \n",
       "6   {'pipeline_run_component': {'pipeline_run_id':...  statmike-mlops-349915   \n",
       "7   {'pipeline_run_component': {'location_id': 'us...  statmike-mlops-349915   \n",
       "8   {'pipeline_run_component': {'parent_task_names...  statmike-mlops-349915   \n",
       "9   {'pipeline_run_component': {'task_name': 'mlop...  statmike-mlops-349915   \n",
       "10  {'pipeline_run_component': {'parent_task_names...  statmike-mlops-349915   \n",
       "11  {'pipeline_run_component': {'project_id': 'sta...  statmike-mlops-349915   \n",
       "12  {'pipeline_run_component': {'project_id': 'sta...  statmike-mlops-349915   \n",
       "13  {'pipeline_run_component': {'pipeline_run_id':...  statmike-mlops-349915   \n",
       "14  {'pipeline_run_component': {'pipeline_run_id':...  statmike-mlops-349915   \n",
       "15  {'pipeline_run_component': {'location_id': 'us...  statmike-mlops-349915   \n",
       "16  {'pipeline_run_component': {'location_id': 'us...  statmike-mlops-349915   \n",
       "17  {'pipeline_run_component': {'location_id': 'us...  statmike-mlops-349915   \n",
       "18  {'pipeline_run_component': {'location_id': 'us...  statmike-mlops-349915   \n",
       "19  {'pipeline_run_component': {'parent_task_names...  statmike-mlops-349915   \n",
       "20  {'pipeline_run_component': {'pipeline_run_id':...  statmike-mlops-349915   \n",
       "\n",
       "   param.input:region  \n",
       "0         us-central1  \n",
       "1         us-central1  \n",
       "2         us-central1  \n",
       "3         us-central1  \n",
       "4         us-central1  \n",
       "5         us-central1  \n",
       "6         us-central1  \n",
       "7         us-central1  \n",
       "8         us-central1  \n",
       "9         us-central1  \n",
       "10        us-central1  \n",
       "11        us-central1  \n",
       "12        us-central1  \n",
       "13        us-central1  \n",
       "14        us-central1  \n",
       "15        us-central1  \n",
       "16        us-central1  \n",
       "17        us-central1  \n",
       "18        us-central1  \n",
       "19        us-central1  \n",
       "20        us-central1  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aiplatform.get_pipeline_df(pipeline = f'{SERIES}-{EXPERIMENT}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8d18fda1-f4d9-4eeb-ae29-33f57eecaf99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tasks = {task.task_name: task for task in pipeline_job.task_details}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0fcd75fc-819a-4722-a2bc-542790b0425f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example-lightweight State.SKIPPED\n",
      "mlops-pipeline-components-20240317185545 State.SUCCEEDED\n",
      "importer State.SUCCEEDED\n",
      "model-get State.SKIPPED\n",
      "example-container State.SKIPPED\n",
      "example-python-container State.SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "for task in tasks:\n",
    "  print(task, tasks[task].state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d16c678c-7339-4454-828b-1ce05c003027",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example-lightweight\n",
      "mlops-pipeline-components-20240317185545\n",
      "importer\n",
      "model-get\n",
      "example-container\n",
      "example-python-container\n"
     ]
    }
   ],
   "source": [
    "for task in tasks:\n",
    "    print(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "14f23660-63fa-482a-8406-2ad0f6ebf4f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "task_id: 388922620231286784\n",
       "task_name: \"model-get\"\n",
       "create_time {\n",
       "  seconds: 1710701747\n",
       "  nanos: 11807000\n",
       "}\n",
       "start_time {\n",
       "  seconds: 1710701748\n",
       "  nanos: 279817000\n",
       "}\n",
       "end_time {\n",
       "  seconds: 1710701748\n",
       "  nanos: 279817000\n",
       "}\n",
       "executor_detail {\n",
       "  container_detail {\n",
       "    main_job: \"projects/1026793852137/locations/us-central1/customJobs/2955894006044688384\"\n",
       "  }\n",
       "}\n",
       "state: SKIPPED\n",
       "execution {\n",
       "  name: \"projects/1026793852137/locations/us-central1/metadataStores/default/executions/18032667361741787548\"\n",
       "  display_name: \"model-get\"\n",
       "  state: CACHED\n",
       "  etag: \"1710701748099\"\n",
       "  create_time {\n",
       "    seconds: 1710701747\n",
       "    nanos: 709000000\n",
       "  }\n",
       "  update_time {\n",
       "    seconds: 1710701748\n",
       "    nanos: 99000000\n",
       "  }\n",
       "  schema_title: \"system.ContainerExecution\"\n",
       "  schema_version: \"0.0.1\"\n",
       "  metadata {\n",
       "    fields {\n",
       "      key: \"input:location\"\n",
       "      value {\n",
       "        string_value: \"us-central1\"\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:model_name\"\n",
       "      value {\n",
       "        string_value: \"model_dev_sklearn-workflow@14\"\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:project\"\n",
       "      value {\n",
       "        string_value: \"statmike-mlops-349915\"\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"vertex-ai-pipelines-artifact-argument-binding\"\n",
       "      value {\n",
       "        struct_value {\n",
       "          fields {\n",
       "            key: \"output:model\"\n",
       "            value {\n",
       "              list_value {\n",
       "                values {\n",
       "                  string_value: \"projects/1026793852137/locations/us-central1/metadataStores/default/artifacts/6016066555852663148\"\n",
       "                }\n",
       "              }\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"vmlmd_lineage_integration\"\n",
       "      value {\n",
       "        struct_value {\n",
       "          fields {\n",
       "            key: \"pipeline_run_component\"\n",
       "            value {\n",
       "              struct_value {\n",
       "                fields {\n",
       "                  key: \"location_id\"\n",
       "                  value {\n",
       "                    string_value: \"us-central1\"\n",
       "                  }\n",
       "                }\n",
       "                fields {\n",
       "                  key: \"parent_task_names\"\n",
       "                  value {\n",
       "                    list_value {\n",
       "                      values {\n",
       "                        string_value: \"mlops-pipeline-components-20240316203545\"\n",
       "                      }\n",
       "                    }\n",
       "                  }\n",
       "                }\n",
       "                fields {\n",
       "                  key: \"pipeline_run_id\"\n",
       "                  value {\n",
       "                    string_value: \"mlops-pipeline-components-20240316203545\"\n",
       "                  }\n",
       "                }\n",
       "                fields {\n",
       "                  key: \"project_id\"\n",
       "                  value {\n",
       "                    string_value: \"statmike-mlops-349915\"\n",
       "                  }\n",
       "                }\n",
       "                fields {\n",
       "                  key: \"task_name\"\n",
       "                  value {\n",
       "                    string_value: \"model-get\"\n",
       "                  }\n",
       "                }\n",
       "              }\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "outputs {\n",
       "  key: \"model\"\n",
       "  value {\n",
       "    artifacts {\n",
       "      name: \"projects/1026793852137/locations/us-central1/metadataStores/default/artifacts/6016066555852663148\"\n",
       "      display_name: \"model\"\n",
       "      uri: \"https://us-central1-aiplatform.googleapis.com/v1/projects/1026793852137/locations/us-central1/models/model_dev_sklearn-workflow@14\"\n",
       "      etag: \"1710701748070\"\n",
       "      create_time {\n",
       "        seconds: 1710621502\n",
       "        nanos: 469000000\n",
       "      }\n",
       "      update_time {\n",
       "        seconds: 1710701748\n",
       "        nanos: 70000000\n",
       "      }\n",
       "      state: LIVE\n",
       "      schema_title: \"google.VertexModel\"\n",
       "      schema_version: \"0.0.1\"\n",
       "      metadata {\n",
       "        fields {\n",
       "          key: \"resourceName\"\n",
       "          value {\n",
       "            string_value: \"projects/1026793852137/locations/us-central1/models/model_dev_sklearn-workflow@14\"\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "parent_task_id: -4150705804158173184\n",
       "pipeline_task_status {\n",
       "  update_time {\n",
       "    seconds: 1710701748\n",
       "    nanos: 3442605\n",
       "  }\n",
       "  state: SKIPPED\n",
       "}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks['model-get']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5256b48-d92b-4f0f-8ef1-4c151a1110ff",
   "metadata": {},
   "source": [
    "---\n",
    "## More!\n",
    "\n",
    "Want to schedule a pipeline like this? Check out this workflow:\n",
    "- [Vertex AI Pipelines - Scheduling](./Vertex%20AI%20Pipelines%20-%20Scheduling.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1cd126-ab67-49db-9c6d-da673d7373d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
