{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57cd1c7a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "![tracker](https://us-central1-vertex-ai-mlops-369716.cloudfunctions.net/pixel-tracking?path=statmike%2Fvertex-ai-mlops%2FMLOps%2FPipelines&file=Vertex+AI+Pipelines+-+Components.ipynb)\n",
    "<!--- header table --->\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/statmike/vertex-ai-mlops/blob/main/MLOps/Pipelines/Vertex%20AI%20Pipelines%20-%20Components.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\">\n",
    "      <br>Run in<br>Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https%3A%2F%2Fraw.githubusercontent.com%2Fstatmike%2Fvertex-ai-mlops%2Fmain%2FMLOps%2FPipelines%2FVertex%2520AI%2520Pipelines%2520-%2520Components.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\">\n",
    "      <br>Run in<br>Colab Enterprise\n",
    "    </a>\n",
    "  </td>      \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/statmike/vertex-ai-mlops/blob/main/MLOps/Pipelines/Vertex%20AI%20Pipelines%20-%20Components.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      <br>View on<br>GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/statmike/vertex-ai-mlops/main/MLOps/Pipelines/Vertex%20AI%20Pipelines%20-%20Components.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      <br>Open in<br>Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee4a1b5-0f22-452b-b1fe-c0b15c457373",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "This is part of a [series of notebook based workflows](./readme.md) that teach all the ways to use pipelines within Vertex AI. The suggested order and description/reason is:\n",
    "\n",
    "|Link To Section|Notebook Workflow|Description|\n",
    "|---|---|---|\n",
    "||[Vertex AI Pipelines - Start Here](./Vertex%20AI%20Pipelines%20-%20Start%20Here.ipynb)|What are pipelines? Start here to go from code to pipeline and see it in action.|\n",
    "||[Vertex AI Pipelines - Introduction](./Vertex%20AI%20Pipelines%20-%20Introduction.ipynb)|Introduction to pipelines with the console and Vertex AI SDK|\n",
    "|_**This Notebook**_|[Vertex AI Pipelines - Components](./Vertex%20AI%20Pipelines%20-%20Components.ipynb)|An introduction to all the ways to create pipeline components from your code|\n",
    "||[Vertex AI Pipelines - IO](./Vertex%20AI%20Pipelines%20-%20IO.ipynb)|An overview of all the type of inputs and outputs for pipeline components|\n",
    "||[Vertex AI Pipelines - Control](./Vertex%20AI%20Pipelines%20-%20Control.ipynb)|An overview of controlling the flow of exectution for pipelines|\n",
    "||[Vertex AI Pipelines - Secret Manager](./Vertex%20AI%20Pipelines%20-%20Secret%20Manager.ipynb)|How to pass sensitive information to pipelines and components|\n",
    "||[Vertex AI Pipelines - GCS Read and Write](./Vertex%20AI%20Pipelines%20-%20GCS%20Read%20and%20Write.ipynb)|How to read/write to GCS from components, including container components.|\n",
    "||[Vertex AI Pipelines - Scheduling](./Vertex%20AI%20Pipelines%20-%20Scheduling.ipynb)|How to schedule pipeline execution|\n",
    "||[Vertex AI Pipelines - Notifications](./Vertex%20AI%20Pipelines%20-%20Notifications.ipynb)|How to send email notification of pipeline status.|\n",
    "||[Vertex AI Pipelines - Management](./Vertex%20AI%20Pipelines%20-%20Management.ipynb)|Managing, Reusing, and Storing pipelines and components|\n",
    "||[Vertex AI Pipelines - Testing](./Vertex%20AI%20Pipelines%20-%20Testing.ipynb)|Strategies for testing components and pipeliens locally and remotely to aide development.|\n",
    "||[Vertex AI Pipelines - Managing Pipeline Jobs](./Vertex%20AI%20Pipelines%20-%20Managing%20Pipeline%20Jobs.ipynb)|Manage runs of pipelines in an environment: list, check status, filtered list, cancel and delete jobs.|\n",
    "\n",
    "\n",
    "To discover these notebooks as part of an introduction to MLOps orchestration [start here](./readme.md).  To read more about MLOps also check out [the parent folder](../readme.md).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1929c5a0-5d97-4621-8868-671bc916c485",
   "metadata": {},
   "source": [
    "# Vertex AI Pipelines - Components \n",
    "\n",
    "[Vertex AI Pipelines](https://cloud.google.com/vertex-ai/docs/pipelines/introduction) is a serverless  runner for Kubeflow Pipelines [(KFP)](https://www.kubeflow.org/docs/components/pipelines/v2/introduction/) and the [TensorFlow Extended (TFX)](https://www.tensorflow.org/tfx/guide/understanding_tfx_pipelines) framework.\n",
    "\n",
    "Components are used to run the steps of a pipelines.  A pipeline task runs the component with inputs and results in the components outputs.  The components execute code on compute with a container image.\n",
    "\n",
    "This notebook will focus on the different types of component construction:\n",
    "- [Pre-built Google Cloud Pipeline Components](https://cloud.google.com/vertex-ai/docs/pipelines/components-introduction)\n",
    "- [Custom KFP Components](https://www.kubeflow.org/docs/components/pipelines/v2/components/)\n",
    "    - Python Components:\n",
    "        - Lightweight Python Components\n",
    "        - Containerized Python Components\n",
    "    - Arbitrary Containers:\n",
    "        - Container Components\n",
    "    - Importer Components\n",
    "        - A provided importer for artifact created prior to the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d02fd35-3db1-4b73-a1b8-37c89f304645",
   "metadata": {
    "id": "od_UkDpvRmgD",
    "tags": []
   },
   "source": [
    "---\n",
    "## Colab Setup\n",
    "\n",
    "To run this notebook in Colab run the cells in this section.  Otherwise, skip this section.\n",
    "\n",
    "This cell will authenticate to GCP (follow prompts in the popup)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc575cc2-c70e-47a6-921b-895899795f2d",
   "metadata": {
    "executionInfo": {
     "elapsed": 195,
     "status": "ok",
     "timestamp": 1683726184843,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "8UO9FnqyKBlF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'statmike-mlops-349915' # replace with project ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abbc374a-98b8-495a-a9e3-cc9609b5f9b2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68869,
     "status": "ok",
     "timestamp": 1683726253709,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "N98-KK7LRkjm",
    "outputId": "09ec5008-0def-4e1a-c349-c598ee752f78",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not a Colab Environment\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    !gcloud config set project {PROJECT_ID}\n",
    "    print('Colab authorized to GCP')\n",
    "except Exception:\n",
    "    print('Not a Colab Environment')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff344ce5-0d5d-45b5-83b9-977e858ef9ea",
   "metadata": {},
   "source": [
    "---\n",
    "## Installs\n",
    "\n",
    "The list `packages` contains tuples of package import names and install names.  If the import name is not found then the install name is used to install quitely for the current user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6f8458ef-b50a-41f4-a6f0-39c9c202f71b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tuples of (import name, install name, min_version)\n",
    "packages = [\n",
    "    ('google.cloud.aiplatform', 'google-cloud-aiplatform'),\n",
    "    ('google.cloud.storage', 'google-cloud-storage'),\n",
    "    ('google.cloud.artifactregistry_v1', 'google-cloud-artifact-registry'),\n",
    "    ('kfp', 'kfp'),\n",
    "    ('google_cloud_pipeline_components', 'google-cloud-pipeline-components'),\n",
    "    ('docker', 'docker'),\n",
    "    ('yaml', 'pyyaml')\n",
    "]\n",
    "\n",
    "import importlib\n",
    "install = False\n",
    "for package in packages:\n",
    "    if not importlib.util.find_spec(package[0]):\n",
    "        print(f'installing package {package[1]}')\n",
    "        install = True\n",
    "        !pip install {package[1]} -U -q --user\n",
    "    elif len(package) == 3:\n",
    "        if importlib.metadata.version(package[0]) < package[2]:\n",
    "            print(f'updating package {package[1]}')\n",
    "            install = True\n",
    "            !pip install {package[1]} -U -q --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786142cf-32b6-4ac3-bbf4-4a58c04f297a",
   "metadata": {},
   "source": [
    "### API Enablement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "699277a0-dd25-46ba-86f9-b99f17217cac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gcloud services enable aiplatform.googleapis.com\n",
    "!gcloud services enable artifactregistry.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f4d728-766d-49c1-bc25-3c85ede7ab02",
   "metadata": {},
   "source": [
    "### Restart Kernel (If Installs Occured)\n",
    "\n",
    "After a kernel restart the code submission can start with the next cell after this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3af76386-9523-42f4-9ec2-a60f1baad867",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if install:\n",
    "    import IPython\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)\n",
    "    IPython.display.display(IPython.display.Markdown(\"\"\"<div class=\\\"alert alert-block alert-warning\\\">\n",
    "        <b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. The previous cells do not need to be run again⚠️</b>\n",
    "        </div>\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af26c69b-e6af-407a-ab7c-2416d6732d3b",
   "metadata": {
    "id": "appt8-yVRtJ1"
   },
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b76b7a-7e87-4413-845e-b8a632a76ad1",
   "metadata": {
    "id": "63mx2EozRxFP"
   },
   "source": [
    "Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00588e3a-4f48-4e3c-bc94-6625dda5401a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 2124,
     "status": "ok",
     "timestamp": 1683726390544,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "xzcoXjM5Rky5",
    "outputId": "b3bdcbc1-70d5-472e-aea2-42c74a42efde",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'statmike-mlops-349915'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1547b468-991b-4123-8ee9-b91037855450",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1683726390712,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "IxWrFtqYMfku",
    "tags": []
   },
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "SERIES = 'mlops'\n",
    "EXPERIMENT = 'pipeline-components'\n",
    "\n",
    "# gcs bucket\n",
    "GCS_BUCKET = PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663ee568-7d4d-4f16-8ea9-015925765cac",
   "metadata": {
    "id": "LuajVwCiO6Yg"
   },
   "source": [
    "Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e1aa5728-0bf7-40d9-8e7c-6786c4b9bb26",
   "metadata": {
    "executionInfo": {
     "elapsed": 17761,
     "status": "ok",
     "timestamp": 1683726409304,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "LVC7zzSLRk2C",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, time, importlib\n",
    "from typing import NamedTuple\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import storage\n",
    "from google.cloud import artifactregistry_v1\n",
    "import kfp\n",
    "import docker\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6609a397-bfd4-422e-ac55-9218a5b80e30",
   "metadata": {
    "id": "EyAVFG9TO9H-"
   },
   "source": [
    "Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6067ea47-5acb-48da-ba36-1e5932b50e21",
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1683726409306,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "L0RPE13LOZce",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vertex ai clients\n",
    "aiplatform.init(project = PROJECT_ID, location = REGION)\n",
    "\n",
    "# gcs storage client\n",
    "gcs = storage.Client(project = GCS_BUCKET)\n",
    "\n",
    "# artifact registry client\n",
    "ar_client = artifactregistry_v1.ArtifactRegistryClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa2bc2f-b99f-4eba-97ec-0e3a807d5413",
   "metadata": {},
   "source": [
    "Docker Check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2381797d-3a61-49cf-aeb1-7eb3eae5f6c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docker is installed and running. Version: 20.10.17\n"
     ]
    }
   ],
   "source": [
    "docker_client = docker.from_env()\n",
    "\n",
    "if docker_client.ping():\n",
    "    print(f\"Docker is installed and running. Version: {docker_client.version()['Version']}\")\n",
    "else:\n",
    "    print('Docker is either not installed or not running - please fix before proceeding.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b8c07f-c967-4913-a6cc-ff0e4e29e4c4",
   "metadata": {},
   "source": [
    "parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ef26020-b237-4360-9f1c-4182ee57c35a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DIR = f\"temp/{SERIES}-{EXPERIMENT}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0eb47fe2-2b45-4e49-b1d1-06670fab07fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1026793852137-compute@developer.gserviceaccount.com'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SERVICE_ACCOUNT = !gcloud config list --format='value(core.account)' \n",
    "SERVICE_ACCOUNT = SERVICE_ACCOUNT[0]\n",
    "SERVICE_ACCOUNT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b9736b-dda0-4415-9280-e099677ef90f",
   "metadata": {},
   "source": [
    "environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4630938-bac8-426a-8b3e-56aeac49aba2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(DIR):\n",
    "    os.makedirs(DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e818b5-a3a6-466f-a890-fc7ad1fc0bdb",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup Artifact Registry\n",
    "\n",
    "[Artifact registry](https://cloud.google.com/artifact-registry/docs) organizes artifacts with repositories.  Each repository contains packages and is designated to hold a partifcular format of package: Docker images, Python Packages and [others](https://cloud.google.com/artifact-registry/docs/supported-formats#package).  There is even a registry type specifically for [Kubeflow pipeline templates](https://cloud.google.com/artifact-registry/docs/kfp?hl=en)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da33fd95-7d5b-4d47-97e7-79e041632dda",
   "metadata": {},
   "source": [
    "### List Repositories\n",
    "\n",
    "This may be empty if no repositories have been created for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac649690-c689-4a72-a6b9-c67b9ef5e0fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projects/statmike-mlops-349915/locations/us-central1/repositories/frameworks\n",
      "projects/statmike-mlops-349915/locations/us-central1/repositories/frameworks-catboost\n",
      "projects/statmike-mlops-349915/locations/us-central1/repositories/gcf-artifacts\n",
      "projects/statmike-mlops-349915/locations/us-central1/repositories/mlops\n",
      "projects/statmike-mlops-349915/locations/us-central1/repositories/mlops-serving\n",
      "projects/statmike-mlops-349915/locations/us-central1/repositories/statmike-mlops-349915\n",
      "projects/statmike-mlops-349915/locations/us-central1/repositories/statmike-mlops-349915-docker\n",
      "projects/statmike-mlops-349915/locations/us-central1/repositories/statmike-mlops-349915-python\n"
     ]
    }
   ],
   "source": [
    "for repo in ar_client.list_repositories(parent = f'projects/{PROJECT_ID}/locations/{REGION}'):\n",
    "    print(repo.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a72369-5a94-45d8-8bf2-3a496ad86d50",
   "metadata": {},
   "source": [
    "### Create/Retrieve Docker Image Repository\n",
    "\n",
    "Create an Artifact Registry Repository to hold Docker Images created by this notebook.  First, check to see if it is already created by a previous run and retrieve it if it has.  Otherwise, create one named for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b211df4-bad1-415b-8f41-ebd43b92a8af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved existing repo: projects/statmike-mlops-349915/locations/us-central1/repositories/statmike-mlops-349915\n"
     ]
    }
   ],
   "source": [
    "docker_repo = None\n",
    "for repo in ar_client.list_repositories(parent = f'projects/{PROJECT_ID}/locations/{REGION}'):\n",
    "    if f'{PROJECT_ID}' == repo.name.split('/')[-1]:\n",
    "        docker_repo = repo\n",
    "        print(f'Retrieved existing repo: {docker_repo.name}')\n",
    "\n",
    "if not docker_repo:\n",
    "    operation = ar_client.create_repository(\n",
    "        request = artifactregistry_v1.CreateRepositoryRequest(\n",
    "            parent = f'projects/{PROJECT_ID}/locations/{REGION}',\n",
    "            repository_id = f'{PROJECT_ID}',\n",
    "            repository = artifactregistry_v1.Repository(\n",
    "                description = f'A repository for the {SERIES} series that holds docker images.',\n",
    "                name = f'{PROJECT_ID}',\n",
    "                format_ = artifactregistry_v1.Repository.Format.DOCKER,\n",
    "                labels = {'series': SERIES}\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    print('Creating Repository ...')\n",
    "    docker_repo = operation.result()\n",
    "    print(f'Completed creating repo: {docker_repo.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28e2f731-70b1-4cbf-8982-8a67523b0dfc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('projects/statmike-mlops-349915/locations/us-central1/repositories/statmike-mlops-349915',\n",
       " 'DOCKER')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docker_repo.name, docker_repo.format_.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ba64f46-081f-46cd-8780-0506c5cf13a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "REPOSITORY = f\"{REGION}-docker.pkg.dev/{PROJECT_ID}/{docker_repo.name.split('/')[-1]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3123529a-67df-47d1-868c-89ff73ee62f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'us-central1-docker.pkg.dev/statmike-mlops-349915/statmike-mlops-349915'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REPOSITORY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f913cf78-472c-43d4-afec-8dd397a37837",
   "metadata": {},
   "source": [
    "---\n",
    "## Components\n",
    "\n",
    "[KFP Components](https://www.kubeflow.org/docs/components/pipelines/v2/components/) are the runners for pipelines tasks. They run code in a container as a job.  The container is specified as a [`base_image` parameter](https://www.kubeflow.org/docs/components/pipelines/v2/components/), which defaults to `python:3.7` currently and can be specified at component creation which is demonstrated throughout this workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c198e4ba-bd12-4344-b7e6-3f6ceb3ecb14",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Prebuilt Google Cloud Pipeline Components\n",
    "\n",
    "Google Cloud provides a growing list of components covering AutoML, Batch Prediction, BigQuery Ml, .... and MANY more services!  \n",
    "\n",
    "The benefits of a prebuilt components include:\n",
    "- simple debugging\n",
    "- standarized artifact types that are tracked with Vertex AI ML Metadata.  Ths makes lineage easy!\n",
    "- These don't have to launch a container to then launch a service - which is more cost effective!\n",
    "\n",
    "These can be reviewed several ways:\n",
    "- Directly in the documentation: [Google Cloud Pipeline Components List](https://cloud.google.com/vertex-ai/docs/pipelines/gcpc-list)\n",
    "- At their accompanying [API Reference](https://google-cloud-pipeline-components.readthedocs.io/en/google-cloud-pipeline-components-2.10.0/api/index.html)\n",
    "- At their source in the GitHub repository for kubeflow pipeliens: [GitHub/kubeflow/pipelines/components/google-cloud](https://github.com/kubeflow/pipelines/tree/master/components/google-cloud)\n",
    "\n",
    "These prebuilt component also include prebuilt artifact types for Google Cloud Resources:\n",
    "- [Google Cloud Artifact Types](https://google-cloud-pipeline-components.readthedocs.io/en/google-cloud-pipeline-components-2.10.0/api/artifact_types.html)\n",
    "\n",
    "Here, the `ModelGetOp` component is used to retrieve an artifact for a model in the Vertex AI Model Registry.\n",
    "\n",
    "```python\n",
    "from google_cloud_pipeline_components.v1.model import ModelGetOp\n",
    "\n",
    "    vertex_model_1 = ModelGetOp(\n",
    "        model_name = model_name.outputs['model_name'],\n",
    "        project = project,\n",
    "        location = region\n",
    "    ).set_display_name('Prebuilt Component')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c24a367f-2982-4683-b28c-cb54b2e36c8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google_cloud_pipeline_components.v1.model import ModelGetOp\n",
    "from google_cloud_pipeline_components.types import artifact_types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbac2f5a-f4bb-4259-a3e6-1d60e561d0c9",
   "metadata": {},
   "source": [
    "### Lightweight Python Components\n",
    "\n",
    "A simple way to create a component from a Python function.  This will create the container at the runtime of the task from the `base_image` and install the `packages_to_install`.\n",
    "\n",
    "References:\n",
    "- [Lightweight Python Components](https://www.kubeflow.org/docs/components/pipelines/v2/components/lightweight-python-components/)\n",
    "\n",
    "Here, a simple function will use the Vertex AI SDK to retrieve a list of all models and pass the the versioned resource name of the first one as an ouput."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f37adfa3-d229-4ed8-b302-6ea20b6669fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.component(\n",
    "    base_image = 'python:3.10',\n",
    "    packages_to_install = ['google-cloud-aiplatform']\n",
    ")\n",
    "def example_lightweight(\n",
    "    project: str,\n",
    "    region: str\n",
    ") -> NamedTuple('lightweight_outputs', model_name = str, model_resource_name = str, uri = str):\n",
    "    \n",
    "    # vertex ai client\n",
    "    from google.cloud import aiplatform\n",
    "    aiplatform.init(project = project, location = region)\n",
    "    \n",
    "    # list models in region\n",
    "    models = aiplatform.Model.list()\n",
    "    \n",
    "    outputs = NamedTuple('lightweight_outputs', model_name = str, model_resource_name = str, uri = str)\n",
    "    \n",
    "    return outputs(\n",
    "        models[0].versioned_resource_name.split('/')[-1],\n",
    "        models[0].versioned_resource_name,\n",
    "        f\"https://{region}-aiplatform.googleapis.com/v1/{models[0].versioned_resource_name}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ed62d0-eef2-4f92-b620-002f3d091c74",
   "metadata": {},
   "source": [
    "### Containerized Python Components\n",
    "\n",
    "This extends the idea of the lightweight Python components.  This builds the container for the component and installs the `packages_to_install` so that they are already installed at the time it runs.\n",
    "\n",
    "References:\n",
    "- [Containerized Python Components](https://www.kubeflow.org/docs/components/pipelines/v2/components/containerized-python-components/)\n",
    "    - There is even a registry type specifically for [Kubeflow pipeline templates](https://cloud.google.com/artifact-registry/docs/kfp?hl=en).\n",
    "- [Developer Note](https://github.com/kubeflow/pipelines/issues/9568#issuecomment-1622223720) from a GitHub issue that describes the Containerized Python Components very well.\n",
    "\n",
    "The container images need to be saved for usage in Google Cloud.  This section makes use of the Artifact Registry docker container repository created/retrieved above.\n",
    "\n",
    "This example replicates the lightweight Python component above as a containerized Python component."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe423c8-b58f-4f44-b86b-53627a6c0148",
   "metadata": {
    "tags": []
   },
   "source": [
    "First, create a local folder to hold the Python source code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87826f04-f923-4b78-a30e-df8593ea62d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(DIR + '/src'):\n",
    "    os.makedirs(DIR + '/src')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe466b44-0008-46e2-845d-d1aa0ff0634d",
   "metadata": {},
   "source": [
    "Now, create the Python file(s) in the folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c965047-b6b1-4b2c-9c75-b0b186fab4bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing temp/mlops-pipeline-components/src/__init__.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {DIR}/src/__init__.py\n",
    "# init file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03ce891c-ef55-488f-b0df-f080110ed6f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing temp/mlops-pipeline-components/src/my_code.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {DIR}/src/my_code.py\n",
    "\n",
    "def example_function(project, region):\n",
    "\n",
    "    # vertex ai client\n",
    "    from google.cloud import aiplatform\n",
    "    \n",
    "    # vertex ai initialize SDK\n",
    "    aiplatform.init(project = project, location = region)\n",
    "    \n",
    "    # list models in region\n",
    "    models = aiplatform.Model.list()\n",
    "    \n",
    "    model_name = models[0].versioned_resource_name.split('/')[-1],\n",
    "    model_resource_name = models[0].versioned_resource_name,\n",
    "    uri = f\"https://{region}-aiplatform.googleapis.com/v1/{models[0].versioned_resource_name}\"\n",
    "    \n",
    "    return [model_name, model_resource_name, uri]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d1b87f-0fd1-4935-8860-375e2bfe704c",
   "metadata": {},
   "source": [
    "Create the component in the folder also and have it import and use the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e9dcad8-e764-454b-aee8-779ace6d5f0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-central1-docker.pkg.dev/statmike-mlops-349915/statmike-mlops-349915/mlops-pipeline-components\n"
     ]
    }
   ],
   "source": [
    "print(f'{REPOSITORY}/{SERIES}-{EXPERIMENT}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e7ea7ff-c40e-4770-8ad1-9053bbf3a8a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing temp/mlops-pipeline-components/src/my_component.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {DIR}/src/my_component.py\n",
    "import kfp\n",
    "from my_code import example_function\n",
    "from google_cloud_pipeline_components.types import artifact_types\n",
    "\n",
    "@kfp.dsl.component(\n",
    "    base_image = 'python:3.10',\n",
    "    target_image = 'us-central1-docker.pkg.dev/statmike-mlops-349915/statmike-mlops-349915/mlops-pipeline-components',\n",
    "    packages_to_install = ['google-cloud-aiplatform', 'google_cloud_pipeline_components']\n",
    ")\n",
    "def example_python_container(\n",
    "    project: str,\n",
    "    region: str,\n",
    "    vertex_model: kfp.dsl.Output[artifact_types.VertexModel]\n",
    "):\n",
    "    \n",
    "    response = example_function(project, region)\n",
    "    vertex_model.uri = response[2]\n",
    "    vertex_model.metadata['model_resource_name'] = response[1]\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6741c1c-14e4-4fa1-8e9b-1ddca4c0d576",
   "metadata": {},
   "source": [
    "The source code is created in a structure that now looks like:\n",
    "\n",
    "```\n",
    "src/\n",
    "├── __init__.py\n",
    "├── my_code.py\n",
    "└── my_component.py\n",
    "```\n",
    "\n",
    "Unlike other component types, this one needs to be built.  Behind the scenes KFP will create a `Dockerfile` and do the `docker build` process while also pushing the resulting image to container repository specified in Artifact Registry by the `target_image`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b97c34f-ab68-4086-9d11-6c643fea5c17",
   "metadata": {},
   "source": [
    "Configure authentication to Artifact Registry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28c881de-9a10-49e7-b8ba-1f014fac24c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mWARNING:\u001b[0m Your config file at [/home/jupyter/.docker/config.json] contains these credential helper entries:\n",
      "\n",
      "{\n",
      "  \"credHelpers\": {\n",
      "    \"gcr.io\": \"gcloud\",\n",
      "    \"us.gcr.io\": \"gcloud\",\n",
      "    \"eu.gcr.io\": \"gcloud\",\n",
      "    \"asia.gcr.io\": \"gcloud\",\n",
      "    \"staging-k8s.gcr.io\": \"gcloud\",\n",
      "    \"marketplace.gcr.io\": \"gcloud\",\n",
      "    \"us-central1-docker.pkg.dev\": \"gcloud\"\n",
      "  }\n",
      "}\n",
      "Adding credentials for: us-central1-docker.pkg.dev\n",
      "gcloud credential helpers already registered correctly.\n"
     ]
    }
   ],
   "source": [
    "!gcloud auth configure-docker $REGION-docker.pkg.dev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5810858-c237-4580-aeb3-e6acda622ee1",
   "metadata": {},
   "source": [
    "Build the component and push to Artifact Registry:\n",
    "\n",
    "This uses the KFP CLI command [`kfp component build`](https://kubeflow-pipelines.readthedocs.io/en/stable/source/cli.html#kfp-component-build)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "056001dc-733c-4b13-8fbf-e91575ab0aa8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building component using KFP package path: kfp==2.10.1\n",
      "Found 1 component(s) in file /home/jupyter/vertex-ai-mlops/MLOps/Pipelines/temp/mlops-pipeline-components/src/my_component.py:\n",
      "Example python container: ComponentInfo(name='Example python container', function_name='example_python_container', func=<function example_python_container at 0x7f7cd6f72c20>, target_image='us-central1-docker.pkg.dev/statmike-mlops-349915/statmike-mlops-349915/mlops-pipeline-components', module_path=PosixPath('/home/jupyter/vertex-ai-mlops/MLOps/Pipelines/temp/mlops-pipeline-components/src/my_component.py'), component_spec=ComponentSpec(name='example-python-container', implementation=Implementation(container=ContainerSpecImplementation(image='us-central1-docker.pkg.dev/statmike-mlops-349915/statmike-mlops-349915/mlops-pipeline-components', command=['sh', '-c', '\\nif ! [ -x \"$(command -v pip)\" ]; then\\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\\nfi\\n\\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location \\'google-cloud-aiplatform\\' \\'google_cloud_pipeline_components\\' && \"$0\" \"$@\"\\n', 'python3', '-m', 'kfp.dsl.executor_main'], args=['--executor_input', '{{$}}', '--function_to_execute', 'example_python_container'], env=None, resources=None), importer=None, graph=None), description=None, inputs={'project': InputSpec(type='String', default=None, optional=False, is_artifact_list=False, description=None), 'region': InputSpec(type='String', default=None, optional=False, is_artifact_list=False, description=None)}, outputs={'vertex_model': OutputSpec(type='google.VertexModel@0.0.1', is_artifact_list=False, description=None)}, platform_spec=), output_component_file=None, base_image='python:3.10', packages_to_install=['google-cloud-aiplatform', 'google_cloud_pipeline_components'], pip_index_urls=None, pip_trusted_hosts=None, use_venv=False)\n",
      "Using base image: python:3.10\n",
      "Using target image: us-central1-docker.pkg.dev/statmike-mlops-349915/statmike-mlops-349915/mlops-pipeline-components\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/kfp/dsl/kfp_config.py:69: UserWarning: No existing KFP Config file found\n",
      "  warnings.warn('No existing KFP Config file found')\n",
      "runtime-requirements.txt not found under /home/jupyter/vertex-ai-mlops/MLOps/Pipelines/temp/mlops-pipeline-components/src. Creating one.\n",
      "Generated file /home/jupyter/vertex-ai-mlops/MLOps/Pipelines/temp/mlops-pipeline-components/src/runtime-requirements.txt.\n",
      ".dockerignore not found under /home/jupyter/vertex-ai-mlops/MLOps/Pipelines/temp/mlops-pipeline-components/src. Creating one.\n",
      "Generated file /home/jupyter/vertex-ai-mlops/MLOps/Pipelines/temp/mlops-pipeline-components/src/.dockerignore.\n",
      "Dockerfile not found under /home/jupyter/vertex-ai-mlops/MLOps/Pipelines/temp/mlops-pipeline-components/src. Creating one.\n",
      "Generated file /home/jupyter/vertex-ai-mlops/MLOps/Pipelines/temp/mlops-pipeline-components/src/Dockerfile.\n",
      "Building image us-central1-docker.pkg.dev/statmike-mlops-349915/statmike-mlops-349915/mlops-pipeline-components using Docker...\n",
      "Docker: Step 1/6 : FROM python:3.10\n",
      "Docker:  ---> e83a01774710\n",
      "Docker: Step 2/6 : WORKDIR /usr/local/src/kfp/components\n",
      "Docker:  ---> Running in 3a33920188a6\n",
      "Docker:  ---> 847b7192ccd5\n",
      "Docker: Step 3/6 : COPY runtime-requirements.txt runtime-requirements.txt\n",
      "Docker:  ---> 110701079047\n",
      "Docker: Step 4/6 : RUN pip install --no-cache-dir -r runtime-requirements.txt\n",
      "Docker:  ---> Running in 713c85fbfe6e\n",
      "Docker: Collecting google-cloud-aiplatform\n",
      "Docker:   Downloading google_cloud_aiplatform-1.83.0-py2.py3-none-any.whl (7.3 MB)\n",
      "Docker:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.3/7.3 MB 76.0 MB/s eta 0:00:00\n",
      "Docker: Collecting google_cloud_pipeline_components\n",
      "Docker:   Downloading google_cloud_pipeline_components-2.19.0-py3-none-any.whl (1.5 MB)\n",
      "Docker:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.5/1.5 MB 267.7 MB/s eta 0:00:00\n",
      "Docker: Collecting docstring-parser<1\n",
      "Docker:   Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Docker: Collecting pydantic<3\n",
      "Docker:   Downloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "Docker:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 431.7/431.7 kB 245.0 MB/s eta 0:00:00\n",
      "Docker: Collecting google-auth<3.0.0dev,>=2.14.1\n",
      "Docker:   Downloading google_auth-2.38.0-py2.py3-none-any.whl (210 kB)\n",
      "Docker:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 210.8/210.8 kB 239.7 MB/s eta 0:00:00\n",
      "Docker: Collecting google-cloud-storage<3.0.0dev,>=1.32.0\n",
      "Docker:   Downloading google_cloud_storage-2.19.0-py2.py3-none-any.whl (131 kB)\n",
      "Docker:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 131.8/131.8 kB 236.1 MB/s eta 0:00:00\n",
      "Docker: Collecting google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0\n",
      "Docker:   Downloading google_cloud_bigquery-3.30.0-py2.py3-none-any.whl (247 kB)\n",
      "Docker:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 247.9/247.9 kB 214.0 MB/s eta 0:00:00\n",
      "Docker: Collecting shapely<3.0.0dev\n",
      "Docker:   Downloading shapely-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
      "Docker:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.5/2.5 MB 277.6 MB/s eta 0:00:00\n",
      "Docker: Collecting google-cloud-resource-manager<3.0.0dev,>=1.3.3\n",
      "Docker:   Downloading google_cloud_resource_manager-1.14.1-py2.py3-none-any.whl (392 kB)\n",
      "Docker:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 392.3/392.3 kB 276.4 MB/s eta 0:00:00\n",
      "Docker: Collecting packaging>=14.3\n",
      "Docker:   Downloading packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Docker:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 65.5/65.5 kB 216.4 MB/s eta 0:00:00\n",
      "Docker: Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2\n",
      "Docker:   Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "Docker:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 319.7/319.7 kB 157.8 MB/s eta 0:00:00\n",
      "Docker: Collecting proto-plus<2.0.0dev,>=1.22.3\n",
      "Docker:   Downloading proto_plus-1.26.0-py3-none-any.whl (50 kB)\n",
      "Docker:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.2/50.2 kB 142.8 MB/s eta 0:00:00\n",
      "Docker: Collecting typing-extensions\n",
      "Docker:   Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Docker: Collecting google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1\n",
      "Docker:   Downloading google_api_core-2.24.1-py3-none-any.whl (160 kB)\n",
      "Docker:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 160.1/160.1 kB 133.6 MB/s eta 0:00:00\n",
      "Docker: Collecting kfp<2.11.0,>=2.6.0\n",
      "Docker:   Downloading kfp-2.10.1.tar.gz (343 kB)\n",
      "Docker:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 343.6/343.6 kB 247.2 MB/s eta 0:00:00\n",
      "Docker:   Preparing metadata (setup.py): started\n",
      "Docker:   Preparing metadata (setup.py): finished with status 'done'\n",
      "Docker: Collecting Jinja2<4,>=3.1.2\n",
      "Docker:   Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Docker:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.9/134.9 kB 240.8 MB/s eta 0:00:00\n",
      "Docker: Collecting googleapis-common-protos<2.0.dev0,>=1.56.2\n",
      "Docker:   Downloading googleapis_common_protos-1.69.1-py2.py3-none-any.whl (293 kB)\n",
      "Docker:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 293.2/293.2 kB 231.6 MB/s eta 0:00:00\n",
      "Docker: Collecting requests<3.0.0.dev0,>=2.18.0\n",
      "Docker:   Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Docker:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 64.9/64.9 kB 195.8 MB/s eta 0:00:00\n",
      "Docker: Collecting grpcio<2.0dev,>=1.33.2\n",
      "Docker:   Downloading grpcio-1.70.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "Docker:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.9/5.9 MB 193.4 MB/s eta 0:00:00\n",
      "Docker: Collecting grpcio-status<2.0.dev0,>=1.33.2\n",
      "Docker:   Downloading grpcio_status-1.70.0-py3-none-any.whl (14 kB)\n",
      "Docker: Collecting pyasn1-modules>=0.2.1\n",
      "Docker:   Downloading pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "Docker:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 181.5/181.5 kB 249.6 MB/s eta 0:00:00\n",
      "Docker: Collecting rsa<5,>=3.1.4\n",
      "Docker:   Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Docker: Collecting cachetools<6.0,>=2.0.0\n",
      "Docker:   Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Docker: Collecting google-cloud-core<3.0.0dev,>=2.4.1\n",
      "Docker:   Downloading google_cloud_core-2.4.2-py2.py3-none-any.whl (29 kB)\n",
      "Docker: Collecting python-dateutil<3.0dev,>=2.7.3\n",
      "Docker:   Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Docker:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 229.9/229.9 kB 142.2 MB/s eta 0:00:00\n",
      "Docker: Collecting google-resumable-media<3.0dev,>=2.0.0\n",
      "Docker:   Downloading google_resumable_media-2.7.2-py2.py3-none-any.whl (81 kB)\n",
      "Docker:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.3/81.3 kB 184.5 MB/s eta 0:00:00\n",
      "Docker: Collecting grpc-google-iam-v1<1.0.0dev,>=0.14.0\n",
      "Docker:   Downloading grpc_google_iam_v1-0.14.1-py2.py3-none-any.whl (19 kB)\n",
      "Docker: Collecting google-crc32c<2.0dev,>=1.0\n",
      "Docker:   Downloading google_crc32c-1.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37 kB)\n",
      "Docker: Collecting MarkupSafe>=2.0\n",
      "Docker:   Downloading MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20 kB)\n",
      "Docker: Collecting click<9,>=8.0.0\n",
      "Docker:   Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Docker:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 98.2/98.2 kB 195.7 MB/s eta 0:00:00\n",
      "Docker: Collecting kfp-pipeline-spec==0.5.0\n",
      "Docker:   Downloading kfp_pipeline_spec-0.5.0-py3-none-any.whl (9.1 kB)\n",
      "Docker: Collecting kfp-server-api<2.4.0,>=2.1.0\n",
      "Docker:   Downloading kfp_server_api-2.3.0.tar.gz (84 kB)\n",
      "Docker:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 84.0/84.0 kB 229.9 MB/s eta 0:00:00\n",
      "Docker:   Preparing metadata (setup.py): started\n",
      "Docker:   Preparing metadata (setup.py): finished with status 'done'\n",
      "Docker: Collecting kubernetes<31,>=8.0.0\n",
      "Docker:   Downloading kubernetes-30.1.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Docker:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 206.8 MB/s eta 0:00:00\n",
      "Docker: Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2\n",
      "Docker:   Downloading protobuf-4.25.6-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "Docker:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 294.6/294.6 kB 253.6 MB/s eta 0:00:00\n",
      "Docker: Collecting PyYAML<7,>=5.3\n",
      "Docker:   Downloading PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (751 kB)\n",
      "Docker:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 751.2/751.2 kB 278.4 MB/s eta 0:00:00\n",
      "Docker: Collecting requests-toolbelt<1,>=0.8.0\n",
      "Docker:   Downloading requests_toolbelt-0.10.1-py2.py3-none-any.whl (54 kB)\n",
      "Docker:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.5/54.5 kB 146.4 MB/s eta 0:00:00\n",
      "Docker: Collecting tabulate<1,>=0.8.6\n",
      "Docker:   Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Docker: Collecting urllib3<2.0.0\n",
      "Docker:   Downloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
      "Docker:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 144.2/144.2 kB 160.5 MB/s eta 0:00:00\n",
      "Docker: Collecting pydantic-core==2.27.2\n",
      "Docker:   Downloading pydantic_core-2.27.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "Docker:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.0/2.0 MB 294.0 MB/s eta 0:00:00\n",
      "Docker: Collecting annotated-types>=0.6.0\n",
      "Docker:   Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Docker: Collecting numpy<3,>=1.14\n",
      "Docker:   Downloading numpy-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
      "Docker:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 16.4/16.4 MB 196.2 MB/s eta 0:00:00\n",
      "Docker: Collecting grpcio-status<2.0.dev0,>=1.33.2\n",
      "Docker:   Downloading grpcio_status-1.69.0-py3-none-any.whl (14 kB)\n",
      "Docker:   Downloading grpcio_status-1.68.1-py3-none-any.whl (14 kB)\n",
      "Docker:   Downloading grpcio_status-1.68.0-py3-none-any.whl (14 kB)\n",
      "Docker:   Downloading grpcio_status-1.67.1-py3-none-any.whl (14 kB)\n",
      "Docker:   Downloading grpcio_status-1.67.0-py3-none-any.whl (14 kB)\n",
      "Docker:   Downloading grpcio_status-1.66.2-py3-none-any.whl (14 kB)\n",
      "Docker:   Downloading grpcio_status-1.66.1-py3-none-any.whl (14 kB)\n",
      "Docker:   Downloading grpcio_status-1.66.0-py3-none-any.whl (14 kB)\n",
      "Docker:   Downloading grpcio_status-1.65.5-py3-none-any.whl (14 kB)\n",
      "Docker:   Downloading grpcio_status-1.65.4-py3-none-any.whl (14 kB)\n",
      "Docker:   Downloading grpcio_status-1.65.2-py3-none-any.whl (14 kB)\n",
      "Docker:   Downloading grpcio_status-1.65.1-py3-none-any.whl (14 kB)\n",
      "Docker:   Downloading grpcio_status-1.64.3-py3-none-any.whl (14 kB)\n",
      "Docker:   Downloading grpcio_status-1.64.1-py3-none-any.whl (14 kB)\n",
      "Docker:   Downloading grpcio_status-1.64.0-py3-none-any.whl (14 kB)\n",
      "Docker:   Downloading grpcio_status-1.63.2-py3-none-any.whl (14 kB)\n",
      "Docker:   Downloading grpcio_status-1.63.0-py3-none-any.whl (14 kB)\n",
      "Docker:   Downloading grpcio_status-1.62.3-py3-none-any.whl (14 kB)\n",
      "Docker: Collecting six>=1.10\n",
      "Docker:   Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
      "Docker: Collecting certifi\n",
      "Docker:   Downloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Docker:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 166.4/166.4 kB 246.2 MB/s eta 0:00:00\n",
      "Docker: Collecting requests-oauthlib\n",
      "Docker:   Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Docker: Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0\n",
      "Docker:   Downloading websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "Docker:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.8/58.8 kB 158.2 MB/s eta 0:00:00\n",
      "Docker: Collecting oauthlib>=3.2.2\n",
      "Docker:   Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Docker:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 151.7/151.7 kB 207.2 MB/s eta 0:00:00\n",
      "Docker: Collecting pyasn1<0.7.0,>=0.4.6\n",
      "Docker:   Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Docker:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 83.1/83.1 kB 218.3 MB/s eta 0:00:00\n",
      "Docker: Collecting idna<4,>=2.5\n",
      "Docker:   Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Docker:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 70.4/70.4 kB 210.5 MB/s eta 0:00:00\n",
      "Docker: Collecting charset-normalizer<4,>=2\n",
      "Docker:   Downloading charset_normalizer-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (146 kB)\n",
      "Docker:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 146.1/146.1 kB 223.3 MB/s eta 0:00:00\n",
      "Docker: Building wheels for collected packages: kfp, kfp-server-api\n",
      "Docker:   Building wheel for kfp (setup.py): started\n",
      "Docker:   Building wheel for kfp (setup.py): finished with status 'done'\n",
      "Docker:   Created wheel for kfp: filename=kfp-2.10.1-py3-none-any.whl size=364799 sha256=14cb46b9bcae812df884b9aca9662667d7ae2c83454dd58dff106dd11963f613\n",
      "Docker:   Stored in directory: /tmp/pip-ephem-wheel-cache-nk6qf87i/wheels/ec/3a/e6/68b6a5de8fec76d3e68c2ca3c7149c81aff126da47c105417d\n",
      "Docker:   Building wheel for kfp-server-api (setup.py): started\n",
      "Docker:   Building wheel for kfp-server-api (setup.py): finished with status 'done'\n",
      "Docker:   Created wheel for kfp-server-api: filename=kfp_server_api-2.3.0-py3-none-any.whl size=116407 sha256=444df96d21bb84c1353a695a27f33b86ea1f2e3b5a4461cd173345b51feb78a6\n",
      "Docker:   Stored in directory: /tmp/pip-ephem-wheel-cache-nk6qf87i/wheels/4f/f2/84/e4da136339a1cf32250c1e1ba680a8d1e1c5ca07e322facb7e\n",
      "Docker: Successfully built kfp kfp-server-api\n",
      "Docker: Installing collected packages: websocket-client, urllib3, typing-extensions, tabulate, six, PyYAML, pyasn1, protobuf, packaging, oauthlib, numpy, MarkupSafe, idna, grpcio, google-crc32c, docstring-parser, click, charset-normalizer, certifi, cachetools, annotated-types, shapely, rsa, requests, python-dateutil, pydantic-core, pyasn1-modules, proto-plus, kfp-pipeline-spec, Jinja2, googleapis-common-protos, google-resumable-media, requests-toolbelt, requests-oauthlib, pydantic, kfp-server-api, grpcio-status, google-auth, kubernetes, grpc-google-iam-v1, google-api-core, google-cloud-core, google-cloud-storage, google-cloud-resource-manager, google-cloud-bigquery, kfp, google-cloud-aiplatform, google_cloud_pipeline_components\n",
      "Docker: Successfully installed Jinja2-3.1.6 MarkupSafe-3.0.2 PyYAML-6.0.2 annotated-types-0.7.0 cachetools-5.5.2 certifi-2025.1.31 charset-normalizer-3.4.1 click-8.1.8 docstring-parser-0.16 google-api-core-2.24.1 google-auth-2.38.0 google-cloud-aiplatform-1.83.0 google-cloud-bigquery-3.30.0 google-cloud-core-2.4.2 google-cloud-resource-manager-1.14.1 google-cloud-storage-2.19.0 google-crc32c-1.6.0 google-resumable-media-2.7.2 google_cloud_pipeline_components-2.19.0 googleapis-common-protos-1.69.1 grpc-google-iam-v1-0.14.1 grpcio-1.70.0 grpcio-status-1.62.3 idna-3.10 kfp-2.10.1 kfp-pipeline-spec-0.5.0 kfp-server-api-2.3.0 kubernetes-30.1.0 numpy-2.2.3 oauthlib-3.2.2 packaging-24.2 proto-plus-1.26.0 protobuf-4.25.6 pyasn1-0.6.1 pyasn1-modules-0.4.1 pydantic-2.10.6 pydantic-core-2.27.2 python-dateutil-2.9.0.post0 requests-2.32.3 requests-oauthlib-2.0.0 requests-toolbelt-0.10.1 rsa-4.9 shapely-2.0.7 six-1.17.0 tabulate-0.9.0 typing-extensions-4.12.2 urllib3-1.26.20 websocket-client-1.8.0\n",
      "Docker: \u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0m\n",
      "Docker: \u001b[91m\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.0.1\n",
      "[notice] To update, run: pip install --upgrade pip\n",
      "\u001b[0m\n",
      "Docker:  ---> 0057fcf1d31d\n",
      "Docker: Step 5/6 : RUN pip install --no-cache-dir kfp==2.10.1\n",
      "Docker:  ---> Running in 048633b54591\n",
      "Docker: Requirement already satisfied: kfp==2.10.1 in /usr/local/lib/python3.10/site-packages (2.10.1)\n",
      "Docker: Requirement already satisfied: docstring-parser<1,>=0.7.3 in /usr/local/lib/python3.10/site-packages (from kfp==2.10.1) (0.16)\n",
      "Docker: Requirement already satisfied: protobuf<5,>=4.21.1 in /usr/local/lib/python3.10/site-packages (from kfp==2.10.1) (4.25.6)\n",
      "Docker: Requirement already satisfied: PyYAML<7,>=5.3 in /usr/local/lib/python3.10/site-packages (from kfp==2.10.1) (6.0.2)\n",
      "Docker: Requirement already satisfied: urllib3<2.0.0 in /usr/local/lib/python3.10/site-packages (from kfp==2.10.1) (1.26.20)\n",
      "Docker: Requirement already satisfied: kfp-pipeline-spec==0.5.0 in /usr/local/lib/python3.10/site-packages (from kfp==2.10.1) (0.5.0)\n",
      "Requirement already satisfied: click<9,>=8.0.0 in /usr/local/lib/python3.10/site-packages (from kfp==2.10.1) (8.1.8)\n",
      "Docker: Requirement already satisfied: kfp-server-api<2.4.0,>=2.1.0 in /usr/local/lib/python3.10/site-packages (from kfp==2.10.1) (2.3.0)\n",
      "Docker: Requirement already satisfied: requests-toolbelt<1,>=0.8.0 in /usr/local/lib/python3.10/site-packages (from kfp==2.10.1) (0.10.1)\n",
      "Docker: Requirement already satisfied: google-cloud-storage<3,>=2.2.1 in /usr/local/lib/python3.10/site-packages (from kfp==2.10.1) (2.19.0)\n",
      "Docker: Requirement already satisfied: google-auth<3,>=1.6.1 in /usr/local/lib/python3.10/site-packages (from kfp==2.10.1) (2.38.0)\n",
      "Docker: Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/site-packages (from kfp==2.10.1) (2.24.1)\n",
      "Docker: Requirement already satisfied: tabulate<1,>=0.8.6 in /usr/local/lib/python3.10/site-packages (from kfp==2.10.1) (0.9.0)\n",
      "Docker: Requirement already satisfied: kubernetes<31,>=8.0.0 in /usr/local/lib/python3.10/site-packages (from kfp==2.10.1) (30.1.0)\n",
      "Docker: Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp==2.10.1) (1.26.0)\n",
      "Docker: Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp==2.10.1) (1.69.1)\n",
      "Docker: Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp==2.10.1) (2.32.3)\n",
      "Docker: Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/site-packages (from google-auth<3,>=1.6.1->kfp==2.10.1) (0.4.1)\n",
      "Docker: Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/site-packages (from google-auth<3,>=1.6.1->kfp==2.10.1) (5.5.2)\n",
      "Docker: Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/site-packages (from google-auth<3,>=1.6.1->kfp==2.10.1) (4.9)\n",
      "Docker: Requirement already satisfied: google-resumable-media>=2.7.2 in /usr/local/lib/python3.10/site-packages (from google-cloud-storage<3,>=2.2.1->kfp==2.10.1) (2.7.2)\n",
      "Docker: Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.10/site-packages (from google-cloud-storage<3,>=2.2.1->kfp==2.10.1) (2.4.2)\n",
      "Docker: Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/site-packages (from google-cloud-storage<3,>=2.2.1->kfp==2.10.1) (1.6.0)\n",
      "Docker: Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/site-packages (from kfp-server-api<2.4.0,>=2.1.0->kfp==2.10.1) (2.9.0.post0)\n",
      "Docker: Requirement already satisfied: certifi in /usr/local/lib/python3.10/site-packages (from kfp-server-api<2.4.0,>=2.1.0->kfp==2.10.1) (2025.1.31)\n",
      "Docker: Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/site-packages (from kfp-server-api<2.4.0,>=2.1.0->kfp==2.10.1) (1.17.0)\n",
      "Docker: Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/site-packages (from kubernetes<31,>=8.0.0->kfp==2.10.1) (1.8.0)\n",
      "Docker: Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/site-packages (from kubernetes<31,>=8.0.0->kfp==2.10.1) (3.2.2)\n",
      "Docker: Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/site-packages (from kubernetes<31,>=8.0.0->kfp==2.10.1) (2.0.0)\n",
      "Docker: Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.1->kfp==2.10.1) (0.6.1)\n",
      "Docker: Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp==2.10.1) (3.10)\n",
      "Docker: Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp==2.10.1) (3.4.1)\n",
      "Docker: \u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0m\n",
      "Docker: \u001b[91m\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.0.1\n",
      "[notice] To update, run: pip install --upgrade pip\n",
      "\u001b[0m\n",
      "Docker:  ---> 75e0357c3da7\n",
      "Docker: Step 6/6 : COPY . .\n",
      "Docker:  ---> 07d51c883cfa\n",
      "Docker: Successfully built 07d51c883cfa\n",
      "Docker: Successfully tagged us-central1-docker.pkg.dev/statmike-mlops-349915/statmike-mlops-349915/mlops-pipeline-components:latest\n",
      "Pushing image us-central1-docker.pkg.dev/statmike-mlops-349915/statmike-mlops-349915/mlops-pipeline-components...\n",
      "Docker:  The push refers to repository [us-central1-docker.pkg.dev/statmike-mlops-349915/statmike-mlops-349915/mlops-pipeline-components]\n",
      "Docker: e76422bddde4 Preparing\n",
      "Docker: eeb0aaa9376a Preparing\n",
      "Docker: bdfc4e1cc250 Preparing\n",
      "Docker: eb3bc76bd65f Preparing\n",
      "Docker: 3f3eeb5e0440 Preparing\n",
      "Docker: fb29abb2209e Preparing\n",
      "Docker: 784c5d2bb2c2 Preparing\n",
      "Docker: ecbadaa33ad9 Preparing\n",
      "Docker: 4b017a36fd9c Preparing\n",
      "Docker: 20a9b386e10e Preparing\n",
      "Docker: f8217d7865d2 Preparing\n",
      "Docker: 01c9a2a5f237 Preparing\n",
      "Docker: fb29abb2209e Waiting\n",
      "Docker: 784c5d2bb2c2 Waiting\n",
      "Docker: 4b017a36fd9c Waiting\n",
      "Docker: ecbadaa33ad9 Waiting\n",
      "Docker: 20a9b386e10e Waiting\n",
      "Docker: 01c9a2a5f237 Waiting\n",
      "Docker: f8217d7865d2 Waiting\n",
      "Docker: eb3bc76bd65f Pushing\n",
      "Docker: eb3bc76bd65f Pushing\n",
      "Docker: 3f3eeb5e0440 Pushing\n",
      "Docker: e76422bddde4 Pushing\n",
      "Docker: eeb0aaa9376a Pushing\n",
      "Docker: e76422bddde4 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 3f3eeb5e0440 Pushed\n",
      "Docker: eeb0aaa9376a Pushed\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: eb3bc76bd65f Pushed\n",
      "Docker: fb29abb2209e Pushing\n",
      "Docker: fb29abb2209e Pushing\n",
      "Docker: 784c5d2bb2c2 Pushing\n",
      "Docker: e76422bddde4 Pushed\n",
      "Docker: ecbadaa33ad9 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 784c5d2bb2c2 Pushing\n",
      "Docker: ecbadaa33ad9 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: ecbadaa33ad9 Pushing\n",
      "Docker: 784c5d2bb2c2 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: fb29abb2209e Pushed\n",
      "Docker: ecbadaa33ad9 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 784c5d2bb2c2 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: ecbadaa33ad9 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 784c5d2bb2c2 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: ecbadaa33ad9 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: ecbadaa33ad9 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 784c5d2bb2c2 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: ecbadaa33ad9 Pushing\n",
      "Docker: 784c5d2bb2c2 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: ecbadaa33ad9 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 784c5d2bb2c2 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: ecbadaa33ad9 Pushing\n",
      "Docker: 784c5d2bb2c2 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: ecbadaa33ad9 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: ecbadaa33ad9 Pushing\n",
      "Docker: 784c5d2bb2c2 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: ecbadaa33ad9 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 784c5d2bb2c2 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: ecbadaa33ad9 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 784c5d2bb2c2 Pushing\n",
      "Docker: ecbadaa33ad9 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 784c5d2bb2c2 Pushing\n",
      "Docker: ecbadaa33ad9 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 784c5d2bb2c2 Pushing\n",
      "Docker: ecbadaa33ad9 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: ecbadaa33ad9 Pushing\n",
      "Docker: 784c5d2bb2c2 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: ecbadaa33ad9 Pushing\n",
      "Docker: ecbadaa33ad9 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 784c5d2bb2c2 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 784c5d2bb2c2 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 784c5d2bb2c2 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 784c5d2bb2c2 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: ecbadaa33ad9 Pushed\n",
      "Docker: 784c5d2bb2c2 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 784c5d2bb2c2 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 784c5d2bb2c2 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 784c5d2bb2c2 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 784c5d2bb2c2 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 784c5d2bb2c2 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 784c5d2bb2c2 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: f8217d7865d2 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 784c5d2bb2c2 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: f8217d7865d2 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 784c5d2bb2c2 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: f8217d7865d2 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 784c5d2bb2c2 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: f8217d7865d2 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 784c5d2bb2c2 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 784c5d2bb2c2 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: f8217d7865d2 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 784c5d2bb2c2 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: f8217d7865d2 Pushing\n",
      "Docker: 784c5d2bb2c2 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: f8217d7865d2 Pushing\n",
      "Docker: 784c5d2bb2c2 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: f8217d7865d2 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: f8217d7865d2 Pushing\n",
      "Docker: 784c5d2bb2c2 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: f8217d7865d2 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 784c5d2bb2c2 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 784c5d2bb2c2 Pushing\n",
      "Docker: f8217d7865d2 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 784c5d2bb2c2 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: f8217d7865d2 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: f8217d7865d2 Pushing\n",
      "Docker: 784c5d2bb2c2 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: f8217d7865d2 Pushing\n",
      "Docker: 784c5d2bb2c2 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: f8217d7865d2 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 784c5d2bb2c2 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: f8217d7865d2 Pushing\n",
      "Docker: 784c5d2bb2c2 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: f8217d7865d2 Pushing\n",
      "Docker: 784c5d2bb2c2 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 784c5d2bb2c2 Pushing\n",
      "Docker: f8217d7865d2 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: f8217d7865d2 Pushing\n",
      "Docker: 784c5d2bb2c2 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: f8217d7865d2 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 784c5d2bb2c2 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: f8217d7865d2 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 784c5d2bb2c2 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: f8217d7865d2 Pushing\n",
      "Docker: 784c5d2bb2c2 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: f8217d7865d2 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 784c5d2bb2c2 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: f8217d7865d2 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 784c5d2bb2c2 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: f8217d7865d2 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 784c5d2bb2c2 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: f8217d7865d2 Pushing\n",
      "Docker: 784c5d2bb2c2 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: f8217d7865d2 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 784c5d2bb2c2 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: f8217d7865d2 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 784c5d2bb2c2 Pushing\n",
      "Docker: f8217d7865d2 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 784c5d2bb2c2 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: f8217d7865d2 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: f8217d7865d2 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 784c5d2bb2c2 Pushed\n",
      "Docker: f8217d7865d2 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: f8217d7865d2 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: f8217d7865d2 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: f8217d7865d2 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: f8217d7865d2 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: f8217d7865d2 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: f8217d7865d2 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: f8217d7865d2 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: f8217d7865d2 Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: f8217d7865d2 Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: f8217d7865d2 Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: f8217d7865d2 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: f8217d7865d2 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: f8217d7865d2 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: f8217d7865d2 Pushing\n",
      "Docker: f8217d7865d2 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: f8217d7865d2 Pushed\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 20a9b386e10e Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 20a9b386e10e Pushed\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 01c9a2a5f237 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 01c9a2a5f237 Pushed\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: bdfc4e1cc250 Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: bdfc4e1cc250 Pushed\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushing\n",
      "Docker: 4b017a36fd9c Pushed\n",
      "Docker:  latest: digest: sha256:dda42ab445851cec07f2e672522c9a0b835324f2fd7079438dc1c0de55122840 size: 2836\n",
      "Built and pushed component container us-central1-docker.pkg.dev/statmike-mlops-349915/statmike-mlops-349915/mlops-pipeline-components\n"
     ]
    }
   ],
   "source": [
    "!kfp component build $DIR/src/ --component-filepattern my_component.py --push-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e6663ead-4007-4336-a364-37e38762ea22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review the Custom Container with Artifact Registry in the Google Cloud Console:\n",
      "https://console.cloud.google.com/artifacts/docker/statmike-mlops-349915/us-central1/statmike-mlops-349915?project=statmike-mlops-349915\n"
     ]
    }
   ],
   "source": [
    "print(f\"Review the Custom Container with Artifact Registry in the Google Cloud Console:\\nhttps://console.cloud.google.com/artifacts/docker/{PROJECT_ID}/{REGION}/{PROJECT_ID}?project={PROJECT_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047058bf-5805-4b76-9baa-d273facaa95a",
   "metadata": {},
   "source": [
    "Import the component to use it in the pipeline definition below\n",
    "\n",
    ">**NOTE:** Re-running this section of the notebook with iterative changes to the functions requires forcing the reload of the function from the file/module.  This is forced here by using the `importlib.reload(my_component)` action.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "01d7b75e-6f66-4fbc-9d32-83d2ef3c54af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/vertex-ai-mlops/MLOps/Pipelines'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fa62459a-2783-4294-a1da-2753db498fcc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/vertex-ai-mlops/MLOps/Pipelines/temp/mlops-pipeline-components/src\n",
      "/home/jupyter/vertex-ai-mlops/MLOps/Pipelines\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd {DIR}/src\n",
    "import my_component\n",
    "importlib.reload(my_component)\n",
    "from my_component import example_python_container\n",
    "%cd ../../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d9d4e2e4-046d-4758-9885-abc911cad7e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/vertex-ai-mlops/MLOps/Pipelines'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b106fbf-76ae-41b4-8dce-10a6555983e8",
   "metadata": {},
   "source": [
    "### Container Components\n",
    "\n",
    "Any container can be a component with [Container Components](https://www.kubeflow.org/docs/components/pipelines/v2/components/container-components/).  \n",
    "\n",
    "This looks a lot like a lightweight Python component but it orchestrates the running of the specified container image with inputs and ouputs.\n",
    "\n",
    "The example below takes the [alpine docker image](https://hub.docker.com/_/alpine) and runs a simple command that takes the `model_resource_name` of an artifact created by the Importer Component (created below) and prints it out as part of a string which is returned as an output.  The output type here is [`kfp.dsl.OutputPath`](https://kubeflow-pipelines.readthedocs.io/en/2.0.0b6/source/dsl.html#kfp.dsl.OutputPath)  which indicates the named parameter is a link to a filepath (the output of the container in this case).\n",
    "- The shell command for `mkdir` is used to create an output loation  with the `kfp.dsl.OutputPath` variable\n",
    "- The `echo` command along with the `>` write to instruction are used to write values to the `kfp.dsl_OutputPath` using the directory created\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "49332e7c-d65b-4c64-8b18-738d6a0642be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.container_component\n",
    "def example_container(\n",
    "    vertex_model_a: kfp.dsl.Input[artifact_types.VertexModel],\n",
    "    note: kfp.dsl.OutputPath(str)\n",
    "):\n",
    "    return kfp.dsl.ContainerSpec(\n",
    "        image = 'alpine',\n",
    "        command = [\n",
    "            'sh', '-c', '''RESPONSE=\"The Model is: $0!\"\\\n",
    "                            && echo $RESPONSE\\\n",
    "                            && mkdir -p $(dirname $1)\\\n",
    "                            && echo $RESPONSE > $1\n",
    "                            '''\n",
    "        ],\n",
    "        args = [vertex_model_a.metadata['model_resource_name'], note]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585e9fc6-4aed-4df7-b15a-f8239622f54b",
   "metadata": {},
   "source": [
    "**More Examples of Container Components In Thir Repository**\n",
    "\n",
    "An example of submitting a Python script directly to a pipeline with a container component for execution is included in:\n",
    "- [Vertex AI Pipelines - GCS Read and Write](Vertex%20AI%20Pipelines%20-%20GCS%20Read%20and%20Write.ipynb) \n",
    "\n",
    "Easily use any container to run even non-Python code in a KFP pipeline.  For instance, run an R script using this approach:\n",
    "\n",
    "- Run [R on Vertex AI Pipelines](../../Framework%20Workflows/R/R%20on%20Vertex%20AI%20Pipelines.ipynb)\n",
    "    - Use a prebuilt container to easily run an R script with inputs for the required libraries and command line arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daebbcf-d108-4c96-b476-41e63bcd5aff",
   "metadata": {},
   "source": [
    "### Importer Components\n",
    "\n",
    "Sometime the artifact that is needed inside a pipeline is created before the pipeline.  The `dsl.importer` component is a quick way to import the artifact. [More on the Importer Component](https://www.kubeflow.org/docs/components/pipelines/v2/components/importer-component/).\n",
    "\n",
    "While the `dsl.importer` component can be used to import [generic artifacts](https://www.kubeflow.org/docs/components/pipelines/v2/data-types/artifacts/) it can also be used to import predefined [Google Cloud Artifact Types](https://google-cloud-pipeline-components.readthedocs.io/en/google-cloud-pipeline-components-2.10.0/api/artifact_types.html) as shown in the Vertex AI documentation page for [Create an ML artifact](https://cloud.google.com/vertex-ai/docs/pipelines/use-components#use_an_importer_node).\n",
    "\n",
    "Here, the `dsl.importer` component is used to load a model in the Vertex AI Model Registry.\n",
    "\n",
    "```python\n",
    "vertex_model_2 = kfp.dsl.importer(\n",
    "        artifact_uri = model_name.outputs['uri'],\n",
    "        artifact_class = artifact_types.VertexModel,\n",
    "        metadata = {'model_resource_name': model_name.outputs['model_resource_name']}\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb3ad5e-534b-4a81-bb89-59dcb1266ae3",
   "metadata": {},
   "source": [
    "---\n",
    "## Vertex AI Pipelines\n",
    "\n",
    "Create a workflow, a pipeline, where each task is conducted by a component\n",
    "\n",
    "- [Vertex AI Python SDK for Pipeline Jobs](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.PipelineJob)\n",
    "- [Specify machine configurations for a component](https://cloud.google.com/vertex-ai/docs/pipelines/machine-types)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a61da5-750e-4b88-bc18-e9f9f53347bc",
   "metadata": {},
   "source": [
    "### Compute Resources For Tasks\n",
    "\n",
    "**Compute Resources** For Components:\n",
    "\n",
    "Running pipleines on Vertex AI Pipelines runs each task (use of a component) as a Vertex AI Training `CustomJob`.  This defaults to a vm based on `e2-standard-4` (4 core CPU, 16GB memory).  This can be modified at the task level of pipelines to choose different computing resources, including GPUs.  For example:\n",
    "\n",
    "```Python\n",
    "@kfp.dsl.pipeline()\n",
    "def pipeline():\n",
    "    task = component().set_cpu_limit(C).set_memory_limit(M).add_node_selector_constraint(A).set_accelerator_limit(G).\n",
    "```\n",
    "Where the inputs are defining [machine configuration for the step](https://cloud.google.com/vertex-ai/docs/pipelines/machine-types):\n",
    "- C = a string representing the number of CPUs (up to 96).\n",
    "- M = a string represent the memory limit.  An integer follwed by K, M, or G (up to 624GB).\n",
    "- A = a string representing the desired GPU  or TPU type\n",
    "- G = an integer representing the multiple of A desired."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afd1394-8827-4323-8b79-7ce564e4c1d4",
   "metadata": {},
   "source": [
    "### Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7e6f2597-c548-4b6c-96a6-949c7a21f5d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(\n",
    "    name = f'{SERIES}-{EXPERIMENT}',\n",
    "    description = 'A simple pipeline for testing'\n",
    ")\n",
    "def example_pipeline(\n",
    "    project: str,\n",
    "    region: str,\n",
    "    \n",
    "):\n",
    "    from google_cloud_pipeline_components.types import artifact_types\n",
    "    from google_cloud_pipeline_components.v1.model import ModelGetOp\n",
    "    \n",
    "    # Lightweight Python Components\n",
    "    model_name = example_lightweight(\n",
    "        project = project,\n",
    "        region = region\n",
    "    ).set_display_name('Lightweight Python Component').set_cpu_limit('4')\n",
    "    \n",
    "    # prebuilt Google Cloud Pipeline Component\n",
    "    vertex_model_1 = ModelGetOp(\n",
    "        model_name = model_name.outputs['model_name'],\n",
    "        project = project,\n",
    "        location = region\n",
    "    ).set_display_name('Prebuilt Component')\n",
    "    \n",
    "    # importer component\n",
    "    vertex_model_2 = kfp.dsl.importer(\n",
    "        artifact_uri = model_name.outputs['uri'],\n",
    "        artifact_class = artifact_types.VertexModel,\n",
    "        metadata = {'model_resource_name': model_name.outputs['model_resource_name']}\n",
    "    ).set_display_name('Importer Component')\n",
    "    \n",
    "    # container component\n",
    "    container = example_container(\n",
    "        vertex_model_a = vertex_model_2.outputs['artifact']\n",
    "    ).set_display_name('Container Component').set_cpu_limit('1')\n",
    "    \n",
    "    # python container component\n",
    "    python_container = example_python_container(\n",
    "        project = project,\n",
    "        region = region\n",
    "    ).set_display_name('Python Container Component').set_cpu_limit('1').set_caching_options(False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cddd264-0a05-4574-910d-4c7c0182ca58",
   "metadata": {},
   "source": [
    "### Compile Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ac0047df-74ed-4c73-9d10-730eb17537c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kfp.compiler.Compiler().compile(\n",
    "    pipeline_func = example_pipeline,\n",
    "    package_path = f'{DIR}/{SERIES}-{EXPERIMENT}.yaml'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2f9526-fc26-4f8e-97dc-051f8f6438e7",
   "metadata": {},
   "source": [
    "### Create Pipeline Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3eb4828f-03bf-409e-a991-784fba1572ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameters = dict(\n",
    "    project = PROJECT_ID,\n",
    "    region = REGION,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a47f8ca7-55a0-4f7e-ab2d-39248c108d27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_job = aiplatform.PipelineJob(\n",
    "    display_name = f\"{SERIES}-{EXPERIMENT}\",\n",
    "    template_path = f\"{DIR}/{SERIES}-{EXPERIMENT}.yaml\",\n",
    "    parameter_values = parameters,\n",
    "    pipeline_root = f'gs://{GCS_BUCKET}/{SERIES}/{EXPERIMENT}/pipeline_root',\n",
    "    enable_caching = None # True (enabled), False (disable), None (defer to component level caching) \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c5a9cd-954b-41c4-8fee-448a4bf1e4d5",
   "metadata": {},
   "source": [
    "### Submit Pipeline Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "605953d8-86b5-463a-b1eb-256d31b8acbe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-components-20250310142429\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-components-20250310142429')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-components-20250310142429?project=1026793852137\n"
     ]
    }
   ],
   "source": [
    "response = pipeline_job.submit(\n",
    "    service_account = SERVICE_ACCOUNT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5e4cd403-99ae-4b02-9416-547decff7dd8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dashboard can be viewed here:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-components-20250310142429?project=1026793852137\n"
     ]
    }
   ],
   "source": [
    "print(f'The Dashboard can be viewed here:\\n{pipeline_job._dashboard_uri()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "dea6308f-9dd2-4e75-9647-71efe4ea8f4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-components-20250310142429 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-components-20250310142429 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-components-20250310142429 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-components-20250310142429 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-components-20250310142429\n"
     ]
    }
   ],
   "source": [
    "pipeline_job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781f2953-dbf3-477f-b219-9b98065b2ec2",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Review The Pipeline: Completed With Multiple Components And Artifacts**\n",
    "<p align=\"center\"><center>\n",
    "    <img align=\"center\" alt=\"Pipeline Complete\" src=\"../resources/images/screenshots/pipelines/components/pipeline.png\" width=\"70%\">\n",
    "</center></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6497813c-c5c7-4eea-9c1d-fcb780a0ad1d",
   "metadata": {},
   "source": [
    "### Retrieve Pipeline Information\n",
    "\n",
    "The SDK is used to retrieve all previous runs of pipeliens with this name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a01068ac-e0c5-4d4b-9678-e58d49d247e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pipeline_name</th>\n",
       "      <th>run_name</th>\n",
       "      <th>param.input:region</th>\n",
       "      <th>param.vmlmd_lineage_integration</th>\n",
       "      <th>param.input:project</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mlops-pipeline-components</td>\n",
       "      <td>mlops-pipeline-components-20250310142429</td>\n",
       "      <td>us-central1</td>\n",
       "      <td>{'pipeline_run_component': {'parent_task_names...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mlops-pipeline-components</td>\n",
       "      <td>mlops-pipeline-components-20250310130213</td>\n",
       "      <td>us-central1</td>\n",
       "      <td>{'pipeline_run_component': {'parent_task_names...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mlops-pipeline-components</td>\n",
       "      <td>mlops-pipeline-components-20240317185545</td>\n",
       "      <td>us-central1</td>\n",
       "      <td>{'pipeline_run_component': {'parent_task_names...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mlops-pipeline-components</td>\n",
       "      <td>mlops-pipeline-components-20240317184845</td>\n",
       "      <td>us-central1</td>\n",
       "      <td>{'pipeline_run_component': {'parent_task_names...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mlops-pipeline-components</td>\n",
       "      <td>mlops-pipeline-components-20240317184016</td>\n",
       "      <td>us-central1</td>\n",
       "      <td>{'pipeline_run_component': {'location_id': 'us...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mlops-pipeline-components</td>\n",
       "      <td>mlops-pipeline-components-20240317183641</td>\n",
       "      <td>us-central1</td>\n",
       "      <td>{'pipeline_run_component': {'parent_task_names...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mlops-pipeline-components</td>\n",
       "      <td>mlops-pipeline-components-20240317183407</td>\n",
       "      <td>us-central1</td>\n",
       "      <td>{'pipeline_run_component': {'parent_task_names...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mlops-pipeline-components</td>\n",
       "      <td>mlops-pipeline-components-20240317141033</td>\n",
       "      <td>us-central1</td>\n",
       "      <td>{'pipeline_run_component': {'parent_task_names...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mlops-pipeline-components</td>\n",
       "      <td>mlops-pipeline-components-20240317134615</td>\n",
       "      <td>us-central1</td>\n",
       "      <td>{'pipeline_run_component': {'location_id': 'us...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mlops-pipeline-components</td>\n",
       "      <td>mlops-pipeline-components-20240317132352</td>\n",
       "      <td>us-central1</td>\n",
       "      <td>{'pipeline_run_component': {'location_id': 'us...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mlops-pipeline-components</td>\n",
       "      <td>mlops-pipeline-components-20240317131702</td>\n",
       "      <td>us-central1</td>\n",
       "      <td>{'pipeline_run_component': {'location_id': 'us...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mlops-pipeline-components</td>\n",
       "      <td>mlops-pipeline-components-20240317125135</td>\n",
       "      <td>us-central1</td>\n",
       "      <td>{'pipeline_run_component': {'parent_task_names...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mlops-pipeline-components</td>\n",
       "      <td>mlops-pipeline-components-20240317124217</td>\n",
       "      <td>us-central1</td>\n",
       "      <td>{'pipeline_run_component': {'location_id': 'us...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mlops-pipeline-components</td>\n",
       "      <td>mlops-pipeline-components-20240317123655</td>\n",
       "      <td>us-central1</td>\n",
       "      <td>{'pipeline_run_component': {'parent_task_names...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mlops-pipeline-components</td>\n",
       "      <td>mlops-pipeline-components-20240317120652</td>\n",
       "      <td>us-central1</td>\n",
       "      <td>{'pipeline_run_component': {'location_id': 'us...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>mlops-pipeline-components</td>\n",
       "      <td>mlops-pipeline-components-20240317005601</td>\n",
       "      <td>us-central1</td>\n",
       "      <td>{'pipeline_run_component': {'location_id': 'us...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mlops-pipeline-components</td>\n",
       "      <td>mlops-pipeline-components-20240317005017</td>\n",
       "      <td>us-central1</td>\n",
       "      <td>{'pipeline_run_component': {'location_id': 'us...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mlops-pipeline-components</td>\n",
       "      <td>mlops-pipeline-components-20240317003130</td>\n",
       "      <td>us-central1</td>\n",
       "      <td>{'pipeline_run_component': {'location_id': 'us...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>mlops-pipeline-components</td>\n",
       "      <td>mlops-pipeline-components-20240316211748</td>\n",
       "      <td>us-central1</td>\n",
       "      <td>{'pipeline_run_component': {'parent_task_names...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>mlops-pipeline-components</td>\n",
       "      <td>mlops-pipeline-components-20240316204613</td>\n",
       "      <td>us-central1</td>\n",
       "      <td>{'pipeline_run_component': {'location_id': 'us...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>mlops-pipeline-components</td>\n",
       "      <td>mlops-pipeline-components-20240316203545</td>\n",
       "      <td>us-central1</td>\n",
       "      <td>{'pipeline_run_component': {'parent_task_names...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>mlops-pipeline-components</td>\n",
       "      <td>mlops-pipeline-components-20240316202355</td>\n",
       "      <td>us-central1</td>\n",
       "      <td>{'pipeline_run_component': {'parent_task_names...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>mlops-pipeline-components</td>\n",
       "      <td>mlops-pipeline-components-20240316194018</td>\n",
       "      <td>us-central1</td>\n",
       "      <td>{'pipeline_run_component': {'location_id': 'us...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                pipeline_name                                  run_name  \\\n",
       "0   mlops-pipeline-components  mlops-pipeline-components-20250310142429   \n",
       "1   mlops-pipeline-components  mlops-pipeline-components-20250310130213   \n",
       "2   mlops-pipeline-components  mlops-pipeline-components-20240317185545   \n",
       "3   mlops-pipeline-components  mlops-pipeline-components-20240317184845   \n",
       "4   mlops-pipeline-components  mlops-pipeline-components-20240317184016   \n",
       "5   mlops-pipeline-components  mlops-pipeline-components-20240317183641   \n",
       "6   mlops-pipeline-components  mlops-pipeline-components-20240317183407   \n",
       "7   mlops-pipeline-components  mlops-pipeline-components-20240317141033   \n",
       "8   mlops-pipeline-components  mlops-pipeline-components-20240317134615   \n",
       "9   mlops-pipeline-components  mlops-pipeline-components-20240317132352   \n",
       "10  mlops-pipeline-components  mlops-pipeline-components-20240317131702   \n",
       "11  mlops-pipeline-components  mlops-pipeline-components-20240317125135   \n",
       "12  mlops-pipeline-components  mlops-pipeline-components-20240317124217   \n",
       "13  mlops-pipeline-components  mlops-pipeline-components-20240317123655   \n",
       "14  mlops-pipeline-components  mlops-pipeline-components-20240317120652   \n",
       "15  mlops-pipeline-components  mlops-pipeline-components-20240317005601   \n",
       "16  mlops-pipeline-components  mlops-pipeline-components-20240317005017   \n",
       "17  mlops-pipeline-components  mlops-pipeline-components-20240317003130   \n",
       "18  mlops-pipeline-components  mlops-pipeline-components-20240316211748   \n",
       "19  mlops-pipeline-components  mlops-pipeline-components-20240316204613   \n",
       "20  mlops-pipeline-components  mlops-pipeline-components-20240316203545   \n",
       "21  mlops-pipeline-components  mlops-pipeline-components-20240316202355   \n",
       "22  mlops-pipeline-components  mlops-pipeline-components-20240316194018   \n",
       "\n",
       "   param.input:region                    param.vmlmd_lineage_integration  \\\n",
       "0         us-central1  {'pipeline_run_component': {'parent_task_names...   \n",
       "1         us-central1  {'pipeline_run_component': {'parent_task_names...   \n",
       "2         us-central1  {'pipeline_run_component': {'parent_task_names...   \n",
       "3         us-central1  {'pipeline_run_component': {'parent_task_names...   \n",
       "4         us-central1  {'pipeline_run_component': {'location_id': 'us...   \n",
       "5         us-central1  {'pipeline_run_component': {'parent_task_names...   \n",
       "6         us-central1  {'pipeline_run_component': {'parent_task_names...   \n",
       "7         us-central1  {'pipeline_run_component': {'parent_task_names...   \n",
       "8         us-central1  {'pipeline_run_component': {'location_id': 'us...   \n",
       "9         us-central1  {'pipeline_run_component': {'location_id': 'us...   \n",
       "10        us-central1  {'pipeline_run_component': {'location_id': 'us...   \n",
       "11        us-central1  {'pipeline_run_component': {'parent_task_names...   \n",
       "12        us-central1  {'pipeline_run_component': {'location_id': 'us...   \n",
       "13        us-central1  {'pipeline_run_component': {'parent_task_names...   \n",
       "14        us-central1  {'pipeline_run_component': {'location_id': 'us...   \n",
       "15        us-central1  {'pipeline_run_component': {'location_id': 'us...   \n",
       "16        us-central1  {'pipeline_run_component': {'location_id': 'us...   \n",
       "17        us-central1  {'pipeline_run_component': {'location_id': 'us...   \n",
       "18        us-central1  {'pipeline_run_component': {'parent_task_names...   \n",
       "19        us-central1  {'pipeline_run_component': {'location_id': 'us...   \n",
       "20        us-central1  {'pipeline_run_component': {'parent_task_names...   \n",
       "21        us-central1  {'pipeline_run_component': {'parent_task_names...   \n",
       "22        us-central1  {'pipeline_run_component': {'location_id': 'us...   \n",
       "\n",
       "      param.input:project  \n",
       "0   statmike-mlops-349915  \n",
       "1   statmike-mlops-349915  \n",
       "2   statmike-mlops-349915  \n",
       "3   statmike-mlops-349915  \n",
       "4   statmike-mlops-349915  \n",
       "5   statmike-mlops-349915  \n",
       "6   statmike-mlops-349915  \n",
       "7   statmike-mlops-349915  \n",
       "8   statmike-mlops-349915  \n",
       "9   statmike-mlops-349915  \n",
       "10  statmike-mlops-349915  \n",
       "11  statmike-mlops-349915  \n",
       "12  statmike-mlops-349915  \n",
       "13  statmike-mlops-349915  \n",
       "14  statmike-mlops-349915  \n",
       "15  statmike-mlops-349915  \n",
       "16  statmike-mlops-349915  \n",
       "17  statmike-mlops-349915  \n",
       "18  statmike-mlops-349915  \n",
       "19  statmike-mlops-349915  \n",
       "20  statmike-mlops-349915  \n",
       "21  statmike-mlops-349915  \n",
       "22  statmike-mlops-349915  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aiplatform.get_pipeline_df(pipeline = f'{SERIES}-{EXPERIMENT}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6f8529-c795-491e-b8c9-e5d0061cbbfb",
   "metadata": {},
   "source": [
    "### Task Level Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8d18fda1-f4d9-4eeb-ae29-33f57eecaf99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tasks = {task.task_name: task for task in pipeline_job.task_details}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0fcd75fc-819a-4722-a2bc-542790b0425f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model-get State.SKIPPED\n",
      "example-container State.SKIPPED\n",
      "example-python-container State.SUCCEEDED\n",
      "importer State.SUCCEEDED\n",
      "mlops-pipeline-components-20250310142429 State.SUCCEEDED\n",
      "example-lightweight State.SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "for task in tasks:\n",
    "  print(task, tasks[task].state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d16c678c-7339-4454-828b-1ce05c003027",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model-get\n",
      "example-container\n",
      "example-python-container\n",
      "importer\n",
      "mlops-pipeline-components-20250310142429\n",
      "example-lightweight\n"
     ]
    }
   ],
   "source": [
    "for task in tasks:\n",
    "    print(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "14f23660-63fa-482a-8406-2ad0f6ebf4f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "task_id: -7867295108813553664\n",
       "parent_task_id: 3905114317132922880\n",
       "task_name: \"model-get\"\n",
       "create_time {\n",
       "  seconds: 1741616671\n",
       "  nanos: 825391000\n",
       "}\n",
       "start_time {\n",
       "  seconds: 1741616795\n",
       "  nanos: 690355000\n",
       "}\n",
       "end_time {\n",
       "  seconds: 1741616795\n",
       "  nanos: 690355000\n",
       "}\n",
       "executor_detail {\n",
       "  container_detail {\n",
       "    main_job: \"projects/1026793852137/locations/us-central1/customJobs/4080329449298460672\"\n",
       "  }\n",
       "}\n",
       "state: SKIPPED\n",
       "execution {\n",
       "  name: \"projects/1026793852137/locations/us-central1/metadataStores/default/executions/4589105006510922746\"\n",
       "  display_name: \"model-get\"\n",
       "  state: CACHED\n",
       "  etag: \"1741616795592\"\n",
       "  create_time {\n",
       "    seconds: 1741616795\n",
       "    nanos: 246000000\n",
       "  }\n",
       "  update_time {\n",
       "    seconds: 1741616795\n",
       "    nanos: 592000000\n",
       "  }\n",
       "  schema_title: \"system.ContainerExecution\"\n",
       "  schema_version: \"0.0.1\"\n",
       "  metadata {\n",
       "    fields {\n",
       "      key: \"vmlmd_lineage_integration\"\n",
       "      value {\n",
       "        struct_value {\n",
       "          fields {\n",
       "            key: \"pipeline_run_component\"\n",
       "            value {\n",
       "              struct_value {\n",
       "                fields {\n",
       "                  key: \"task_name\"\n",
       "                  value {\n",
       "                    string_value: \"model-get\"\n",
       "                  }\n",
       "                }\n",
       "                fields {\n",
       "                  key: \"project_id\"\n",
       "                  value {\n",
       "                    string_value: \"statmike-mlops-349915\"\n",
       "                  }\n",
       "                }\n",
       "                fields {\n",
       "                  key: \"pipeline_run_id\"\n",
       "                  value {\n",
       "                    string_value: \"mlops-pipeline-components-20250310130213\"\n",
       "                  }\n",
       "                }\n",
       "                fields {\n",
       "                  key: \"parent_task_names\"\n",
       "                  value {\n",
       "                    list_value {\n",
       "                      values {\n",
       "                        string_value: \"mlops-pipeline-components-20250310130213\"\n",
       "                      }\n",
       "                    }\n",
       "                  }\n",
       "                }\n",
       "                fields {\n",
       "                  key: \"location_id\"\n",
       "                  value {\n",
       "                    string_value: \"us-central1\"\n",
       "                  }\n",
       "                }\n",
       "              }\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"vertex-ai-pipelines-artifact-argument-binding\"\n",
       "      value {\n",
       "        struct_value {\n",
       "          fields {\n",
       "            key: \"output:model\"\n",
       "            value {\n",
       "              list_value {\n",
       "                values {\n",
       "                  string_value: \"projects/1026793852137/locations/us-central1/metadataStores/default/artifacts/1132205097486173558\"\n",
       "                }\n",
       "              }\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:project\"\n",
       "      value {\n",
       "        string_value: \"statmike-mlops-349915\"\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:model_name\"\n",
       "      value {\n",
       "        string_value: \"classify_species_rf@89\"\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:location\"\n",
       "      value {\n",
       "        string_value: \"us-central1\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "pipeline_task_status {\n",
       "  update_time {\n",
       "    seconds: 1741616795\n",
       "    nanos: 519509832\n",
       "  }\n",
       "  state: SKIPPED\n",
       "}\n",
       "outputs {\n",
       "  key: \"model\"\n",
       "  value {\n",
       "    artifacts {\n",
       "      name: \"projects/1026793852137/locations/us-central1/metadataStores/default/artifacts/1132205097486173558\"\n",
       "      display_name: \"model\"\n",
       "      uri: \"https://us-central1-aiplatform.googleapis.com/v1/projects/1026793852137/locations/us-central1/models/classify_species_rf@89\"\n",
       "      etag: \"1741616795574\"\n",
       "      create_time {\n",
       "        seconds: 1741611904\n",
       "        nanos: 854000000\n",
       "      }\n",
       "      update_time {\n",
       "        seconds: 1741616795\n",
       "        nanos: 574000000\n",
       "      }\n",
       "      state: LIVE\n",
       "      schema_title: \"google.VertexModel\"\n",
       "      schema_version: \"0.0.1\"\n",
       "      metadata {\n",
       "        fields {\n",
       "          key: \"resourceName\"\n",
       "          value {\n",
       "            string_value: \"projects/1026793852137/locations/us-central1/models/classify_species_rf@89\"\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks['model-get']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c054b3a-579f-4781-b961-26d707e961a1",
   "metadata": {},
   "source": [
    "---\n",
    "## Understand Components\n",
    "\n",
    "Let's dig into the compiled pipelien to understand how each components is represented."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7173154-3c42-4671-b77a-dd96cf8d059d",
   "metadata": {},
   "source": [
    "### Read Pipeline YAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e2bf830a-150f-4dd1-a382-843256145d32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(f\"{DIR}/{SERIES}-{EXPERIMENT}.yaml\", 'r') as file:\n",
    "    pipeline_yaml = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f7f75f98-63e1-4bc0-b001-8344e54b49c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['components', 'deploymentSpec', 'pipelineInfo', 'root', 'schemaVersion', 'sdkVersion'])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_yaml.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15719e39-96f5-4747-b0d4-182ab0b628d2",
   "metadata": {},
   "source": [
    "### Review Pipeline Specification: Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "aa938aa2-1ba1-45c3-890e-a1ca7ba42a6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp-example-container\n",
      "\t executorLabel\n",
      "\t\t exec-example-container\n",
      "\t inputDefinitions\n",
      "\t\t {'artifacts': {'vertex_model_a': {'artifactType': {'schemaTitle': 'google.VertexModel', 'schemaVersion': '0.0.1'}}}}\n",
      "\t outputDefinitions\n",
      "\t\t {'parameters': {'note': {'parameterType': 'STRING'}}}\n",
      "\n",
      "\n",
      "\n",
      "comp-example-lightweight\n",
      "\t executorLabel\n",
      "\t\t exec-example-lightweight\n",
      "\t inputDefinitions\n",
      "\t\t {'parameters': {'project': {'parameterType': 'STRING'}, 'region': {'parameterType': 'STRING'}}}\n",
      "\t outputDefinitions\n",
      "\t\t {'parameters': {'model_name': {'parameterType': 'STRING'}, 'model_resource_name': {'parameterType': 'STRING'}, 'uri': {'parameterType': 'STRING'}}}\n",
      "\n",
      "\n",
      "\n",
      "comp-example-python-container\n",
      "\t executorLabel\n",
      "\t\t exec-example-python-container\n",
      "\t inputDefinitions\n",
      "\t\t {'parameters': {'project': {'parameterType': 'STRING'}, 'region': {'parameterType': 'STRING'}}}\n",
      "\t outputDefinitions\n",
      "\t\t {'artifacts': {'vertex_model': {'artifactType': {'schemaTitle': 'google.VertexModel', 'schemaVersion': '0.0.1'}}}}\n",
      "\n",
      "\n",
      "\n",
      "comp-importer\n",
      "\t executorLabel\n",
      "\t\t exec-importer\n",
      "\t inputDefinitions\n",
      "\t\t {'parameters': {'metadata': {'parameterType': 'STRING'}, 'uri': {'parameterType': 'STRING'}}}\n",
      "\t outputDefinitions\n",
      "\t\t {'artifacts': {'artifact': {'artifactType': {'schemaTitle': 'google.VertexModel', 'schemaVersion': '0.0.1'}}}}\n",
      "\n",
      "\n",
      "\n",
      "comp-model-get\n",
      "\t executorLabel\n",
      "\t\t exec-model-get\n",
      "\t inputDefinitions\n",
      "\t\t {'parameters': {'location': {'defaultValue': 'us-central1', 'description': 'Location from which to get the VertexModel. Defaults to `us-central1`.', 'isOptional': True, 'parameterType': 'STRING'}, 'model_name': {'description': 'Specify the model name in one of the following formats: {model}: Fetches the default model version. {model}@{model_version_id}: Fetches the model version specified by its ID. {model}@{model_version_alias}: Fetches the model version specified by its alias.', 'parameterType': 'STRING'}, 'project': {'defaultValue': '{{$.pipeline_google_cloud_project_id}}', 'description': 'Project from which to get the VertexModel. Defaults to the project in which the PipelineJob is run.', 'isOptional': True, 'parameterType': 'STRING'}}}\n",
      "\t outputDefinitions\n",
      "\t\t {'artifacts': {'model': {'artifactType': {'schemaTitle': 'google.VertexModel', 'schemaVersion': '0.0.1'}, 'description': 'Artifact of the Vertex Model.'}}}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "components = pipeline_yaml.get('components', {})\n",
    "for component in components:\n",
    "    print(component)\n",
    "    for part in components[component]:\n",
    "        print('\\t', part)\n",
    "        print('\\t\\t', components[component][part])\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b63a58f-d94a-4248-b66c-10cd3cd05915",
   "metadata": {},
   "source": [
    "### Review Pipeline Specification: Deployment Specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "bf91cbc0-9250-4069-aee6-7c71190eb343",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "deploymentSpec = pipeline_yaml.get('deploymentSpec', {})\n",
    "executors = deploymentSpec.get('executors', {})\n",
    "\n",
    "def get_executor(component):\n",
    "    for a in executors:\n",
    "        if a.endswith(component):\n",
    "            print(a)\n",
    "            for b in executors[a]:\n",
    "                print('\\t', b)\n",
    "                for c in executors[a][b]:\n",
    "                    print('\\t\\t', c)\n",
    "                    print('\\t\\t\\t', executors[a][b][c])\n",
    "            print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a47d3f3-7b44-420c-b3f7-43655376eba9",
   "metadata": {},
   "source": [
    "#### Prebuilt Google Cloud Pipeline Components\n",
    "\n",
    "Recall this was defined with:\n",
    "```python\n",
    "    from google_cloud_pipeline_components.v1.model import ModelGetOp\n",
    "```\n",
    "\n",
    "And it was used in the Pipeline like this:\n",
    "```python\n",
    "    # prebuilt Google Cloud Pipeline Component\n",
    "    vertex_model_1 = ModelGetOp(\n",
    "        model_name = model_name.outputs['model_name'],\n",
    "        project = project,\n",
    "        location = region\n",
    "    ).set_display_name('Prebuilt Component')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "71870212-6857-4df0-92d3-7880c704afba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exec-model-get\n",
      "\t container\n",
      "\t\t args\n",
      "\t\t\t ['--project', \"{{$.inputs.parameters['project']}}\", '--location', \"{{$.inputs.parameters['location']}}\", '--model_name', \"{{$.inputs.parameters['model_name']}}\", '--executor_input', '{{$}}']\n",
      "\t\t command\n",
      "\t\t\t ['python3', '-u', '-m', 'google_cloud_pipeline_components.container.v1.model.get_model.launcher']\n",
      "\t\t image\n",
      "\t\t\t gcr.io/ml-pipeline/google-cloud-pipeline-components:2.19.0\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_executor('model-get')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755f0b36-54f0-412f-b85c-36b70d6b5e54",
   "metadata": {},
   "source": [
    "#### Lightweight Python Components\n",
    "\n",
    "Recall this was defined with:\n",
    "```python\n",
    "@kfp.dsl.component(\n",
    "    base_image = 'python:3.10',\n",
    "    packages_to_install = ['google-cloud-aiplatform']\n",
    ")\n",
    "def example_lightweight(\n",
    "    project: str,\n",
    "    region: str\n",
    ") -> NamedTuple('lightweight_outputs', model_name = str, model_resource_name = str, uri = str):\n",
    "    \n",
    "    # vertex ai client\n",
    "    from google.cloud import aiplatform\n",
    "    aiplatform.init(project = project, location = region)\n",
    "    \n",
    "    # list models in region\n",
    "    models = aiplatform.Model.list()\n",
    "    \n",
    "    outputs = NamedTuple('lightweight_outputs', model_name = str, model_resource_name = str, uri = str)\n",
    "    \n",
    "    return outputs(\n",
    "        models[0].versioned_resource_name.split('/')[-1],\n",
    "        models[0].versioned_resource_name,\n",
    "        f\"https://{region}-aiplatform.googleapis.com/v1/{models[0].versioned_resource_name}\"\n",
    "    )\n",
    "```\n",
    "\n",
    "And it was used in the Pipeline like this:\n",
    "```python\n",
    "    # Lightweight Python Components\n",
    "    model_name = example_lightweight(\n",
    "        project = project,\n",
    "        region = region\n",
    "    ).set_display_name('Lightweight Python Component').set_cpu_limit('4')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7eab5a60-035b-4e14-81d6-b089a022c606",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exec-example-lightweight\n",
      "\t container\n",
      "\t\t args\n",
      "\t\t\t ['--executor_input', '{{$}}', '--function_to_execute', 'example_lightweight']\n",
      "\t\t command\n",
      "\t\t\t ['sh', '-c', '\\nif ! [ -x \"$(command -v pip)\" ]; then\\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\\nfi\\n\\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location \\'kfp==2.10.1\\' \\'--no-deps\\' \\'typing-extensions>=3.7.4,<5; python_version<\"3.9\"\\'  &&  python3 -m pip install --quiet --no-warn-script-location \\'google-cloud-aiplatform\\' && \"$0\" \"$@\"\\n', 'sh', '-ec', 'program_path=$(mktemp -d)\\n\\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\\n', '\\nimport kfp\\nfrom kfp import dsl\\nfrom kfp.dsl import *\\nfrom typing import *\\n\\ndef example_lightweight(\\n    project: str,\\n    region: str\\n) -> NamedTuple(\\'lightweight_outputs\\', model_name = str, model_resource_name = str, uri = str):\\n\\n    # vertex ai client\\n    from google.cloud import aiplatform\\n    aiplatform.init(project = project, location = region)\\n\\n    # list models in region\\n    models = aiplatform.Model.list()\\n\\n    outputs = NamedTuple(\\'lightweight_outputs\\', model_name = str, model_resource_name = str, uri = str)\\n\\n    return outputs(\\n        models[0].versioned_resource_name.split(\\'/\\')[-1],\\n        models[0].versioned_resource_name,\\n        f\"https://{region}-aiplatform.googleapis.com/v1/{models[0].versioned_resource_name}\"\\n    )\\n\\n']\n",
      "\t\t image\n",
      "\t\t\t python:3.10\n",
      "\t\t resources\n",
      "\t\t\t {'resourceCpuLimit': '4'}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_executor('example-lightweight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c0ba2e-e027-41e1-b8dc-7d0a227f896b",
   "metadata": {},
   "source": [
    "#### Containerized Python Components\n",
    "\n",
    "Recall this was defined with:\n",
    "```python\n",
    "!kfp component build $DIR/src/ --component-filepattern my_component.py --push-image\n",
    "\n",
    "import my_component\n",
    "importlib.reload(my_component)\n",
    "from my_component import example_python_container\n",
    "```\n",
    "\n",
    "And it was used in the Pipeline like this:\n",
    "```python\n",
    "    # python container component\n",
    "    python_container = example_python_container(\n",
    "        project = project,\n",
    "        region = region\n",
    "    ).set_display_name('Python Container Component').set_cpu_limit('1').set_caching_options(False)\n",
    "``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7a7a812b-9f05-4c64-b55c-37fbd0175aa1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exec-example-python-container\n",
      "\t container\n",
      "\t\t args\n",
      "\t\t\t ['--executor_input', '{{$}}', '--function_to_execute', 'example_python_container']\n",
      "\t\t command\n",
      "\t\t\t ['sh', '-c', '\\nif ! [ -x \"$(command -v pip)\" ]; then\\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\\nfi\\n\\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location \\'google-cloud-aiplatform\\' \\'google_cloud_pipeline_components\\' && \"$0\" \"$@\"\\n', 'python3', '-m', 'kfp.dsl.executor_main']\n",
      "\t\t image\n",
      "\t\t\t us-central1-docker.pkg.dev/statmike-mlops-349915/statmike-mlops-349915/mlops-pipeline-components\n",
      "\t\t resources\n",
      "\t\t\t {'resourceCpuLimit': '1'}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_executor('example-python-container')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43733f07-304e-4d7c-baab-8b2c51e11753",
   "metadata": {},
   "source": [
    "#### Container Components\n",
    "\n",
    "Recall this was defined with:\n",
    "```python\n",
    "@kfp.dsl.container_component\n",
    "def example_container(\n",
    "    vertex_model_a: kfp.dsl.Input[artifact_types.VertexModel],\n",
    "    note: kfp.dsl.OutputPath(str)\n",
    "):\n",
    "    return kfp.dsl.ContainerSpec(\n",
    "        image = 'alpine',\n",
    "        command = [\n",
    "            'sh', '-c', '''RESPONSE=\"The Model is: $0!\"\\\n",
    "                            && echo $RESPONSE\\\n",
    "                            && mkdir -p $(dirname $1)\\\n",
    "                            && echo $RESPONSE > $1\n",
    "                            '''\n",
    "        ],\n",
    "        args = [vertex_model_a.metadata['model_resource_name'], note]\n",
    "    )\n",
    "```\n",
    "\n",
    "And it was used in the Pipeline like this:\n",
    "```python\n",
    "    # container component\n",
    "    container = example_container(\n",
    "        vertex_model_a = vertex_model_2.outputs['artifact']\n",
    "    ).set_display_name('Container Component').set_cpu_limit('1')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5e8ed49e-67b5-44f2-9086-8ecbf385e018",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exec-example-container\n",
      "\t container\n",
      "\t\t args\n",
      "\t\t\t [\"{{$.inputs.artifacts['vertex_model_a'].metadata['model_resource_name']}}\", \"{{$.outputs.parameters['note'].output_file}}\"]\n",
      "\t\t command\n",
      "\t\t\t ['sh', '-c', 'RESPONSE=\"The Model is: $0!\"                            && echo $RESPONSE                            && mkdir -p $(dirname $1)                            && echo $RESPONSE > $1\\n                            ']\n",
      "\t\t image\n",
      "\t\t\t alpine\n",
      "\t\t resources\n",
      "\t\t\t {'resourceCpuLimit': '1'}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_executor('example-container')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0327dd-9aab-488e-828f-799128254312",
   "metadata": {},
   "source": [
    "#### Importer Components\n",
    "\n",
    "And it was used in the Pipeline like this:\n",
    "```python\n",
    "    # importer component\n",
    "    vertex_model_2 = kfp.dsl.importer(\n",
    "        artifact_uri = model_name.outputs['uri'],\n",
    "        artifact_class = artifact_types.VertexModel,\n",
    "        metadata = {'model_resource_name': model_name.outputs['model_resource_name']}\n",
    "    ).set_display_name('Importer Component')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ae02157c-4cca-4d45-bbc3-c3972f27ca21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exec-importer\n",
      "\t importer\n",
      "\t\t artifactUri\n",
      "\t\t\t {'runtimeParameter': 'uri'}\n",
      "\t\t metadata\n",
      "\t\t\t {'model_resource_name': \"{{$.inputs.parameters['metadata']}}\"}\n",
      "\t\t typeSchema\n",
      "\t\t\t {'schemaTitle': 'google.VertexModel', 'schemaVersion': '0.0.1'}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_executor('importer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5256b48-d92b-4f0f-8ef1-4c151a1110ff",
   "metadata": {},
   "source": [
    "---\n",
    "## More!\n",
    "\n",
    "Want to schedule a pipeline like this? Check out this workflow:\n",
    "- [Vertex AI Pipelines - Scheduling](./Vertex%20AI%20Pipelines%20-%20Scheduling.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1cd126-ab67-49db-9c6d-da673d7373d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m128",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m128"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
