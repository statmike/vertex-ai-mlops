{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "200c2ad1",
   "metadata": {},
   "source": [
    "![tracker](https://us-central1-vertex-ai-mlops-369716.cloudfunctions.net/pixel-tracking?path=statmike%2Fvertex-ai-mlops%2FMLOps%2FPipelines&file=Vertex+AI+Pipelines+-+Control.ipynb)\n",
    "<!--- header table --->\n",
    "<table align=\"left\">\n",
    "<tr>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/statmike/vertex-ai-mlops/blob/main/MLOps/Pipelines/Vertex%20AI%20Pipelines%20-%20Control.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://www.svgrepo.com/download/217753/github.svg\" alt=\"GitHub logo\">\n",
    "      <br>View on<br>GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/statmike/vertex-ai-mlops/blob/main/MLOps/Pipelines/Vertex%20AI%20Pipelines%20-%20Control.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://www.gstatic.com/pantheon/images/bigquery/welcome_page/colab-logo.svg\" alt=\"Google Colaboratory logo\">\n",
    "      <br>Run in<br>Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https%3A%2F%2Fraw.githubusercontent.com%2Fstatmike%2Fvertex-ai-mlops%2Fmain%2FMLOps%2FPipelines%2FVertex%2520AI%2520Pipelines%2520-%2520Control.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\">\n",
    "      <br>Run in<br>Colab Enterprise\n",
    "    </a>\n",
    "  </td>      \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/bigquery/import?url=https://github.com/statmike/vertex-ai-mlops/blob/main/MLOps/Pipelines/Vertex%20AI%20Pipelines%20-%20Control.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://www.gstatic.com/images/branding/gcpiconscolors/bigquery/v1/32px.svg\" alt=\"BigQuery logo\">\n",
    "      <br>Open in<br>BigQuery Studio\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/statmike/vertex-ai-mlops/main/MLOps/Pipelines/Vertex%20AI%20Pipelines%20-%20Control.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://www.gstatic.com/images/branding/gcpiconscolors/vertexai/v1/32px.svg\" alt=\"Vertex AI logo\">\n",
    "      <br>Open in<br>Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td colspan=\"5\" style=\"text-align: right\">\n",
    "    <b>Share This On: </b> \n",
    "    <a href=\"https://www.linkedin.com/sharing/share-offsite/?url=https://github.com/statmike/vertex-ai-mlops/blob/main/MLOps/Pipelines/Vertex%2520AI%2520Pipelines%2520-%2520Control.ipynb\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"Linkedin Logo\" width=\"20px\"></a> \n",
    "    <a href=\"https://reddit.com/submit?url=https://github.com/statmike/vertex-ai-mlops/blob/main/MLOps/Pipelines/Vertex%2520AI%2520Pipelines%2520-%2520Control.ipynb\"><img src=\"https://redditinc.com/hubfs/Reddit%20Inc/Brand/Reddit_Logo.png\" alt=\"Reddit Logo\" width=\"20px\"></a> \n",
    "    <a href=\"https://bsky.app/intent/compose?text=https://github.com/statmike/vertex-ai-mlops/blob/main/MLOps/Pipelines/Vertex%2520AI%2520Pipelines%2520-%2520Control.ipynb\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"BlueSky Logo\" width=\"20px\"></a> \n",
    "    <a href=\"https://twitter.com/intent/tweet?url=https://github.com/statmike/vertex-ai-mlops/blob/main/MLOps/Pipelines/Vertex%2520AI%2520Pipelines%2520-%2520Control.ipynb\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/5/5a/X_icon_2.svg\" alt=\"X (Twitter) Logo\" width=\"20px\"></a> \n",
    "  </td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td colspan=\"5\" style=\"text-align: right\">\n",
    "    <b>Connect With Author On: </b> \n",
    "    <a href=\"https://www.linkedin.com/in/statmike\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"Linkedin Logo\" width=\"20px\"></a>\n",
    "    <a href=\"https://www.github.com/statmike\"><img src=\"https://www.svgrepo.com/download/217753/github.svg\" alt=\"GitHub Logo\" width=\"20px\"></a> \n",
    "    <a href=\"https://www.youtube.com/@statmike-channel\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/f/fd/YouTube_full-color_icon_%282024%29.svg\" alt=\"YouTube Logo\" width=\"20px\"></a>\n",
    "    <a href=\"https://bsky.app/profile/statmike.bsky.social\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"BlueSky Logo\" width=\"20px\"></a> \n",
    "    <a href=\"https://x.com/statmike\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/5/5a/X_icon_2.svg\" alt=\"X (Twitter) Logo\" width=\"20px\"></a>\n",
    "  </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5746c105-167c-4c63-92d2-1e6b3821bc22",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "This is part of a [series of notebook based workflows](./readme.md) that teach all the ways to use pipelines within Vertex AI. The suggested order and description/reason is:\n",
    "\n",
    "|Link To Section|Notebook Workflow|Description|\n",
    "|---|---|---|\n",
    "||[Vertex AI Pipelines - Start Here](./Vertex%20AI%20Pipelines%20-%20Start%20Here.ipynb)|What are pipelines? Start here to go from code to pipeline and see it in action.|\n",
    "||[Vertex AI Pipelines - Introduction](./Vertex%20AI%20Pipelines%20-%20Introduction.ipynb)|Introduction to pipelines with the console and Vertex AI SDK|\n",
    "||[Vertex AI Pipelines - Components](./Vertex%20AI%20Pipelines%20-%20Components.ipynb)|An introduction to all the ways to create pipeline components from your code|\n",
    "||[Vertex AI Pipelines - IO](./Vertex%20AI%20Pipelines%20-%20IO.ipynb)|An overview of all the type of inputs and outputs for pipeline components|\n",
    "|_**This Notebook**_|[Vertex AI Pipelines - Control](./Vertex%20AI%20Pipelines%20-%20Control.ipynb)|An overview of controlling the flow of exectution for pipelines|\n",
    "||[Vertex AI Pipelines - Secret Manager](./Vertex%20AI%20Pipelines%20-%20Secret%20Manager.ipynb)|How to pass sensitive information to pipelines and components|\n",
    "||[Vertex AI Pipelines - GCS Read and Write](./Vertex%20AI%20Pipelines%20-%20GCS%20Read%20and%20Write.ipynb)|How to read/write to GCS from components, including container components.|\n",
    "||[Vertex AI Pipelines - Scheduling](./Vertex%20AI%20Pipelines%20-%20Scheduling.ipynb)|How to schedule pipeline execution|\n",
    "||[Vertex AI Pipelines - Notifications](./Vertex%20AI%20Pipelines%20-%20Notifications.ipynb)|How to send email notification of pipeline status.|\n",
    "||[Vertex AI Pipelines - Management](./Vertex%20AI%20Pipelines%20-%20Management.ipynb)|Managing, Reusing, and Storing pipelines and components|\n",
    "||[Vertex AI Pipelines - Testing](./Vertex%20AI%20Pipelines%20-%20Testing.ipynb)|Strategies for testing components and pipeliens locally and remotely to aide development.|\n",
    "||[Vertex AI Pipelines - Managing Pipeline Jobs](./Vertex%20AI%20Pipelines%20-%20Managing%20Pipeline%20Jobs.ipynb)|Manage runs of pipelines in an environment: list, check status, filtered list, cancel and delete jobs.|\n",
    "\n",
    "\n",
    "To discover these notebooks as part of an introduction to MLOps orchestration [start here](./readme.md).  To read more about MLOps also check out [the parent folder](../readme.md).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e4bfa2-f871-4a91-84a0-c1e4630e4436",
   "metadata": {},
   "source": [
    "# Vertex AI Pipelines - Control \n",
    "\n",
    "[Vertex AI Pipelines](https://cloud.google.com/vertex-ai/docs/pipelines/introduction) is a serverless  runner for Kubeflow Pipelines [(KFP)](https://www.kubeflow.org/docs/components/pipelines/v2/introduction/) and the [TensorFlow Extended (TFX)](https://www.tensorflow.org/tfx/guide/understanding_tfx_pipelines) framework.\n",
    "\n",
    "Components are used to runs the steps of a pipelines.  A pipeline task runs the component with inputs and results in the components outputs.  The components execute code on compute with a container image.\n",
    "\n",
    "This notebook will focus on controlling the flow of task execution within a pipeline:\n",
    "- **Ordering**: DAG and Explicit ordering\n",
    "- **Conditional Execution**: if, elif (else if), and else\n",
    "    - **Collecting**: Conditional results\n",
    "- **Looping**: And Parallelism\n",
    "    - **Collecting**: Looped Results\n",
    "- **Exit Handling:** with and without task failures\n",
    "- **Error Handling** continue execution even after task failures\n",
    "\n",
    "**References:**\n",
    "- [Kubeflow Pipelines Control Flow](https://www.kubeflow.org/docs/components/pipelines/v2/pipelines/control-flow/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412d7790-dbbf-4d9d-9291-d09d0d826778",
   "metadata": {
    "id": "od_UkDpvRmgD",
    "tags": []
   },
   "source": [
    "---\n",
    "## Colab Setup\n",
    "\n",
    "To run this notebook in Colab run the cells in this section.  Otherwise, skip this section.\n",
    "\n",
    "This cell will authenticate to GCP (follow prompts in the popup)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e767408-69f7-45b3-b6e5-da105c4b2519",
   "metadata": {
    "executionInfo": {
     "elapsed": 195,
     "status": "ok",
     "timestamp": 1683726184843,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "8UO9FnqyKBlF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'statmike-mlops-349915' # replace with project ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e75c429-7a0e-48d7-aa78-64d82a73a864",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68869,
     "status": "ok",
     "timestamp": 1683726253709,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "N98-KK7LRkjm",
    "outputId": "09ec5008-0def-4e1a-c349-c598ee752f78",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not a Colab Environment\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    !gcloud config set project {PROJECT_ID}\n",
    "    print('Colab authorized to GCP')\n",
    "except Exception:\n",
    "    print('Not a Colab Environment')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5249b0-69ab-470f-8c02-5d277cefe1fa",
   "metadata": {},
   "source": [
    "---\n",
    "## Installs\n",
    "\n",
    "The list `packages` contains tuples of package import names and install names.  If the import name is not found then the install name is used to install quitely for the current user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c58f135-2b70-4814-b8e2-4ef3ca37fab5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tuples of (import name, install name, min_version)\n",
    "packages = [\n",
    "    ('google.cloud.aiplatform', 'google-cloud-aiplatform'),\n",
    "    ('kfp', 'kfp')\n",
    "]\n",
    "\n",
    "import importlib\n",
    "install = False\n",
    "for package in packages:\n",
    "    if not importlib.util.find_spec(package[0]):\n",
    "        print(f'installing package {package[1]}')\n",
    "        install = True\n",
    "        !pip install {package[1]} -U -q --user\n",
    "    elif len(package) == 3:\n",
    "        if importlib.metadata.version(package[0]) < package[2]:\n",
    "            print(f'updating package {package[1]}')\n",
    "            install = True\n",
    "            !pip install {package[1]} -U -q --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d1fb44-5f69-40a7-b627-0374c6db6eb4",
   "metadata": {},
   "source": [
    "### API Enablement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e1f5860-3efc-4632-b4c0-ba5b262dec12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gcloud services enable aiplatform.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9e5ca2-6d31-4b73-8db2-ac75b7670be4",
   "metadata": {},
   "source": [
    "### Restart Kernel (If Installs Occured)\n",
    "\n",
    "After a kernel restart the code submission can start with the next cell after this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecee10aa-99b0-4daa-8fb2-38e5646af9ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if install:\n",
    "    import IPython\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)\n",
    "    IPython.display.display(IPython.display.Markdown(\"\"\"<div class=\\\"alert alert-block alert-warning\\\">\n",
    "        <b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. The previous cells do not need to be run again⚠️</b>\n",
    "        </div>\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe566058-b390-484e-980b-d03640d02e77",
   "metadata": {
    "id": "appt8-yVRtJ1"
   },
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d7364b-699b-4c26-a617-0dbbd9e4c51d",
   "metadata": {
    "id": "63mx2EozRxFP"
   },
   "source": [
    "Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3553bc6-67f5-44bb-a16c-9f43cee51546",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 2124,
     "status": "ok",
     "timestamp": 1683726390544,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "xzcoXjM5Rky5",
    "outputId": "b3bdcbc1-70d5-472e-aea2-42c74a42efde",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'statmike-mlops-349915'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ce46c83-6305-4210-adb9-674047137832",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1683726390712,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "IxWrFtqYMfku",
    "tags": []
   },
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "SERIES = 'mlops'\n",
    "EXPERIMENT = 'pipeline-control'\n",
    "\n",
    "# gcs bucket\n",
    "GCS_BUCKET = PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd21676-844f-441f-9dc6-db15dddf9ed2",
   "metadata": {
    "id": "LuajVwCiO6Yg"
   },
   "source": [
    "Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86cf0800-eb89-4c49-b20e-e752698f501a",
   "metadata": {
    "executionInfo": {
     "elapsed": 17761,
     "status": "ok",
     "timestamp": 1683726409304,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "LVC7zzSLRk2C",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, time, importlib\n",
    "from typing import NamedTuple\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "import kfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31fe26b3-488b-4e9d-9988-e53cacb5bcc2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.1'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfp.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6ebda6a-597f-4117-a730-014e6622b275",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.78.0'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aiplatform.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c3b756-c6b3-4c0c-9dfb-19a9f2e08388",
   "metadata": {
    "id": "EyAVFG9TO9H-"
   },
   "source": [
    "Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b9f0e32-9d71-40ed-bd02-cf8fdfd04863",
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1683726409306,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "L0RPE13LOZce",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vertex ai clients\n",
    "aiplatform.init(project = PROJECT_ID, location = REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e59e086-017e-42c8-a19d-67c6eac8687d",
   "metadata": {},
   "source": [
    "parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d59e937-5c05-4fc2-9e25-b96937dbd2c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DIR = f\"temp/{SERIES}-{EXPERIMENT}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d1eb622-626e-433a-9021-51655e893db0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1026793852137-compute@developer.gserviceaccount.com'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SERVICE_ACCOUNT = !gcloud config list --format='value(core.account)' \n",
    "SERVICE_ACCOUNT = SERVICE_ACCOUNT[0]\n",
    "SERVICE_ACCOUNT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8a42dc-aa9d-4cc9-824c-a708079a7ad5",
   "metadata": {},
   "source": [
    "environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18bb246b-2641-4d56-a3c2-40b355197590",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(DIR):\n",
    "    os.makedirs(DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd167d8-e15d-46d7-9852-da95c687c390",
   "metadata": {},
   "source": [
    "---\n",
    "## Example Components\n",
    "\n",
    "Components that:\n",
    "- generate coin flips with `flip_coin`\n",
    "    - by default it returns flip of a single coin as 'H' or 'T'\n",
    "    - optional input parameter of `num_coins` can be set to number of coins to retrive a string of flips, like 2 => 'HT'\n",
    "- generate dice rolls with `roll_dice`\n",
    "    - by default it returns the face number [1, 6] from a single die roll\n",
    "    - optionn input parameter of `num_dice` an be set to number of dice to retrieve a sum of rolls, like 2 => [2, 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95cd7aaa-9c63-4ccd-bdb2-84b1fa39acfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.component(base_image = 'python:3.10')\n",
    "def flip_coins(num_coins: int = 1) -> str:\n",
    "    import random\n",
    "    flipmap = ['T', 'H']\n",
    "    flips = [flipmap[random.randint(0, 1)] for n in range(num_coins)]\n",
    "    return ''.join(flips)\n",
    "\n",
    "@kfp.dsl.component(base_image = 'python:3.10')\n",
    "def roll_dice(num_dice: int = 1) -> int:\n",
    "    import random\n",
    "    result = sum([random.randint(1,6) for n in range(num_dice)])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980d79fb-e6ae-4fda-8111-847cbbb90010",
   "metadata": {},
   "source": [
    "---\n",
    "## Function To Run Pipeline\n",
    "\n",
    "A helper function that will compile a KFP pipeline, create a Vertex AI Pipeline job, submit and wait on the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0c27612-72fa-49f5-a7b5-ab15abfa9318",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pipeline_runner(pipeline_func, pipeline_name):\n",
    "    \n",
    "    # compile the pipeline\n",
    "    kfp.compiler.Compiler().compile(\n",
    "        pipeline_func = pipeline_func,\n",
    "        package_path = f'{DIR}/{pipeline_name}.yaml'\n",
    "    )\n",
    "    \n",
    "    # create pipeline job\n",
    "    pipeline_job = aiplatform.PipelineJob(\n",
    "        display_name = f\"{pipeline_name}\",\n",
    "        template_path = f\"{DIR}/{pipeline_name}.yaml\",\n",
    "        pipeline_root = f'gs://{GCS_BUCKET}/{SERIES}/{EXPERIMENT}/pipeline_root',\n",
    "    )\n",
    "    \n",
    "    # submit pipeline job\n",
    "    response = pipeline_job.submit(\n",
    "        service_account = SERVICE_ACCOUNT\n",
    "    )\n",
    "    \n",
    "    # wait on pipeline job\n",
    "    pipeline_job.wait()\n",
    "    \n",
    "    # return pipeline job\n",
    "    return pipeline_job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c6b8d7-d74a-4e97-a9aa-f59a42e46046",
   "metadata": {},
   "source": [
    "---\n",
    "## Ordering Tasks: DAG\n",
    "\n",
    "The outputs of components are used as inputs to other components forcing an order of operations - a [DAG (directed acyclic graph)](https://en.wikipedia.org/wiki/Directed_acyclic_graph).  All of the `task_1*` tasks run at the same time as they have no dependencies.  Then, each of the `task_2*` tasks run after their corresponding `task_1*` task completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f553f6ec-24b8-4b48-9191-d400dc78108c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mlops-pipeline-control-order-dag'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_name = f\"{SERIES}-{EXPERIMENT}-order-dag\"\n",
    "pipeline_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "390a21cf-bc2c-4238-9e6b-6f95fda883b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(name = pipeline_name)\n",
    "def order_pipeline_dag():\n",
    "    \n",
    "    task_1a = roll_dice()\n",
    "    task_1b = roll_dice(num_dice = 2)\n",
    "    task_1c = roll_dice(num_dice = 3)\n",
    "    \n",
    "    task_2a = flip_coins(num_coins = task_1a.output)\n",
    "    task_2b = flip_coins(num_coins = task_1b.output)\n",
    "    task_2c = flip_coins(num_coins = task_1c.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2fdcef04-91ea-4a6f-b870-58854a821a18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-20250310170504\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-20250310170504')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-control-order-dag-20250310170504?project=1026793852137\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-20250310170504 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-20250310170504 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-20250310170504 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-20250310170504 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-20250310170504\n"
     ]
    }
   ],
   "source": [
    "pipeline_job = pipeline_runner(order_pipeline_dag, pipeline_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "072e238a-7a2e-4d57-b264-d1b76b97bf90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dashboard can be viewed here:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-control-order-dag-20250310170504?project=1026793852137\n"
     ]
    }
   ],
   "source": [
    "print(f'The Dashboard can be viewed here:\\n{pipeline_job._dashboard_uri()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea72913a-643e-476f-8b14-41f0bd043bb8",
   "metadata": {},
   "source": [
    "<p><center>\n",
    "    <img alt=\"Order DAG\" src=\"../resources/images/screenshots/pipelines/control/order-dag.png\" width=\"90%\">\n",
    "</center><p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f6f58f-f9c3-47e9-b71d-124bf96e1a32",
   "metadata": {},
   "source": [
    "---\n",
    "## Ordering Tasks: DAG + Explicit Dependency\n",
    "\n",
    "The outputs of components are used as inputs to other components forcing an order of operations. \n",
    "\n",
    "The `task_1*` component do not have any input dependencies and by default run at the same time - as seen above.  Using the `.after()` method - [reference](https://kubeflow-pipelines.readthedocs.io/en/latest/source/dsl.html#kfp.dsl.PipelineTask.after) - allows for explicit dependency on another task.  The pipeline below uses `.after()` to force the order of the `task_1a`, then `task_1b`, then `task_1c`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98e18c9c-398c-4198-9aa9-82e9fa747080",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mlops-pipeline-control-order-dag-explicit'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_name = f\"{SERIES}-{EXPERIMENT}-order-dag-explicit\"\n",
    "pipeline_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "248585be-df52-437e-93af-98aa98055cf4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(name = pipeline_name)\n",
    "def order_pipeline_dag_explicit():\n",
    "\n",
    "    task_1a = roll_dice()\n",
    "    task_1b = roll_dice(num_dice = 2).after(task_1a)\n",
    "    task_1c = roll_dice(num_dice = 3).after(task_1b)\n",
    "    \n",
    "    task_2a = flip_coins(num_coins = task_1a.output)\n",
    "    task_2b = flip_coins(num_coins = task_1b.output)\n",
    "    task_2c = flip_coins(num_coins = task_1c.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92d9552c-8334-4464-81ec-87d755727d79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-explicit-20250310170855\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-explicit-20250310170855')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-control-order-dag-explicit-20250310170855?project=1026793852137\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-explicit-20250310170855 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-explicit-20250310170855 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-explicit-20250310170855 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-explicit-20250310170855 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-explicit-20250310170855\n"
     ]
    }
   ],
   "source": [
    "pipeline_job = pipeline_runner(order_pipeline_dag_explicit, pipeline_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5aeb13c2-e176-48e4-9591-2894db4c3890",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dashboard can be viewed here:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-control-order-dag-explicit-20250310170855?project=1026793852137\n"
     ]
    }
   ],
   "source": [
    "print(f'The Dashboard can be viewed here:\\n{pipeline_job._dashboard_uri()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db14f569-eef5-407f-b547-08c1b6081916",
   "metadata": {},
   "source": [
    "<p><center>\n",
    "    <img alt=\"Order DAG - Explicit\" src=\"../resources/images/screenshots/pipelines/control/order-dag-explicit.png\" width=\"90%\">\n",
    "</center><p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfede210-2358-4fa4-8547-cef3c720b432",
   "metadata": {},
   "source": [
    "---\n",
    "## Conditional Execution\n",
    "\n",
    "Sometimes, the execution of a component depends on an output value from another component.  Rather than need to build the logic into a component, there are `dsl` methods for evaluating task outputs:\n",
    "- `kfp.dsl.If`\n",
    "- `kfp.dsl.Elif`\n",
    "- `kfp.dsl.Else`\n",
    "\n",
    "[Reference](https://www.kubeflow.org/docs/components/pipelines/v2/pipelines/control-flow/#conditions-dslif-dslelif-dslelse)\n",
    "\n",
    "\n",
    "In the example pipeline below the same three task that convert numbers to letter are used.  Then new tasks are used to flip a coin and roll a single die. If the coin is heads, the result of die is used to conditionally convert one of the three letters back to a number.  If the coin is tails then all three letters are converted back to numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c874851-fdb2-4d8c-ae00-28e838db954d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mlops-pipeline-control-order-dag-condition'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_name = f\"{SERIES}-{EXPERIMENT}-order-dag-condition\"\n",
    "pipeline_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb110727-4e4b-4d42-9f47-114c653daded",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(name = pipeline_name)\n",
    "def order_pipeline_dag_condition():\n",
    "\n",
    "    task_1a = roll_dice()\n",
    "    task_1b = roll_dice(num_dice = 2)\n",
    "    task_1c = roll_dice(num_dice = 3)\n",
    "    task_1d = roll_dice(num_dice = 4)\n",
    "\n",
    "    coin = flip_coins() \n",
    "    with kfp.dsl.If(coin.output == \"H\", name = 'Flip: Heads (H)'):\n",
    "        \n",
    "        die = roll_dice()\n",
    "        with kfp.dsl.If(die.output <= 2, name = 'Roll: 1, 2'):\n",
    "            task_2a = flip_coins(num_coins = task_1a.output)\n",
    "        with kfp.dsl.Elif(die.output <= 4, name = 'Roll: 3, 4'):\n",
    "            task_2b = flip_coins(num_coins = task_1b.output)\n",
    "        with kfp.dsl.Else(name = 'Roll: 5, 6'):\n",
    "            task_2c = flip_coins(num_coins = task_1c.output)\n",
    "\n",
    "    with kfp.dsl.Elif(coin.output == \"T\", name = 'Flip: Tails (T)'):\n",
    "        task_2d = flip_coins(num_coins = task_1d.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c5e9653d-093c-4bdc-bb08-2184e1fac1a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-condition-20250310171317\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-condition-20250310171317')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-control-order-dag-condition-20250310171317?project=1026793852137\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-condition-20250310171317 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-condition-20250310171317 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-condition-20250310171317 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-condition-20250310171317 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-condition-20250310171317\n"
     ]
    }
   ],
   "source": [
    "pipeline_job = pipeline_runner(order_pipeline_dag_condition, pipeline_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e57788eb-352e-4a69-abc7-7a1f1e709049",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dashboard can be viewed here:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-control-order-dag-condition-20250310171317?project=1026793852137\n"
     ]
    }
   ],
   "source": [
    "print(f'The Dashboard can be viewed here:\\n{pipeline_job._dashboard_uri()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798edb0a-6bda-47f9-8d96-62e8850eb607",
   "metadata": {},
   "source": [
    "<p><center>\n",
    "    <img alt=\"Order DAG - Conditions\" src=\"../resources/images/screenshots/pipelines/control/order-dag-condition.png\" width=\"90%\">\n",
    "</center><p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e291219-b9ce-4357-aa99-2afd98e04f88",
   "metadata": {},
   "source": [
    "---\n",
    "### Conditional Execution: Collecting Tasks\n",
    "\n",
    "In the previous section, conditional exeuction with `kfp.dsl.If()`, `kfp.dsl.Elif()`, `kfp.dsl.Else()` was used.  If a downstream task needs to use the result of any tasks that ends up executing then it needs to monitor all the possibilities.  This is where\n",
    "`kfp.dsl.OneOf()` comes in handy. [Reference](https://www.kubeflow.org/docs/components/pipelines/v2/pipelines/control-flow/#dsloneof)\n",
    "\n",
    "The following pipeline repeats the flow from above and adds the `kfp.dsl.OneOf()` to collect all the conditional tasks: `task_2*`.  A new component is created that will take as input this collected result and calculate the frequency of outcomes 'H' and 'T'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e49b082f-44f0-4097-aad1-e86909eebbae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.component(base_image = 'python:3.10')\n",
    "def coin_freq(flips: str) -> dict:\n",
    "    result = dict(\n",
    "        H = flips.count('H'),\n",
    "        T = flips.count('T')\n",
    "    )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "84f8ad06-da5d-4060-a534-c1d702f196ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mlops-pipeline-control-order-dag-condition-collect'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_name = f\"{SERIES}-{EXPERIMENT}-order-dag-condition-collect\"\n",
    "pipeline_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4ba4e08f-d0b0-4a0e-934d-c4d4911ec391",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(name = pipeline_name)\n",
    "def order_pipeline_dag_condition_collect():\n",
    "\n",
    "    task_1a = roll_dice()\n",
    "    task_1b = roll_dice(num_dice = 2)\n",
    "    task_1c = roll_dice(num_dice = 3)\n",
    "    task_1d = roll_dice(num_dice = 4)\n",
    "\n",
    "    coin = flip_coins() \n",
    "    with kfp.dsl.If(coin.output == \"H\", name = 'Flip: Heads (H)'):\n",
    "        \n",
    "        die = roll_dice()\n",
    "        with kfp.dsl.If(die.output <= 2, name = 'Roll: 1, 2'):\n",
    "            task_2a = flip_coins(num_coins = task_1a.output)\n",
    "        with kfp.dsl.Elif(die.output <= 4, name = 'Roll: 3, 4'):\n",
    "            task_2b = flip_coins(num_coins = task_1b.output)\n",
    "        with kfp.dsl.Else(name = 'Roll: 5, 6'):\n",
    "            task_2c = flip_coins(num_coins = task_1c.output)\n",
    "\n",
    "        oneof = kfp.dsl.OneOf(task_2a.output, task_2b.output, task_2c.output)\n",
    "        coin_freq(flips = oneof)\n",
    "            \n",
    "    with kfp.dsl.Elif(coin.output == \"T\", name = 'Flip: Tails (T)'):\n",
    "        task_2d = flip_coins(num_coins = task_1d.output)\n",
    "        coin_freq(flips = task_2d.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fe4e4aec-b0ea-4a7c-92ef-c83a9b7c384c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-condition-collect-20250310171505\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-condition-collect-20250310171505')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-control-order-dag-condition-collect-20250310171505?project=1026793852137\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-condition-collect-20250310171505 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-condition-collect-20250310171505 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-condition-collect-20250310171505 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-condition-collect-20250310171505 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-condition-collect-20250310171505\n"
     ]
    }
   ],
   "source": [
    "pipeline_job = pipeline_runner(order_pipeline_dag_condition_collect, pipeline_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4f3f62a6-c494-4824-a929-f14ac2b24e4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dashboard can be viewed here:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-control-order-dag-condition-collect-20250310171505?project=1026793852137\n"
     ]
    }
   ],
   "source": [
    "print(f'The Dashboard can be viewed here:\\n{pipeline_job._dashboard_uri()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314f8fcb-06f6-4565-9ff2-1cf7fc4365a1",
   "metadata": {},
   "source": [
    "<p><center>\n",
    "    <img alt=\"Order DAG - Condition - Collect\" src=\"../resources/images/screenshots/pipelines/control/order-dag-condition-collect.png\" width=\"90%\">\n",
    "</center><p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f1c34e-6ce7-429e-b333-4b735fb9cb37",
   "metadata": {},
   "source": [
    "---\n",
    "## Looping - And Parallelism\n",
    "\n",
    "With KFP the same task can be repeated, or looped, for multiple input values.  This is done with `kfp.dsl.ParallelFor`.  With a list of values to iterate over this will run the task for each item in the list.  An item can also be a dictionary making it possible to provide multiple input parameters for each iteration.  As the name implies, the iterations are actually conducted in parallel.  The level of parallelism is set to maximum by default but can also be directly controlled with the `parallelism` parameter. [Reference](https://www.kubeflow.org/docs/components/pipelines/v2/pipelines/control-flow/)\n",
    "\n",
    "The example below conducts a `kfp.dsl.ParallelFor()` loop over a list of integers [1, 10].  For each value the `roll_dice` component is runs as a task with the integer used as the input number of dice to roll and sum.  This creates 10 tasks, each with a different number of dice to roll and sum.  The `parallelism = 5` setting is used to show how it will limit the number of simoultaneous tasks executions to 5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3d7d13a5-064f-4718-b3d7-f3bc5feb9051",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mlops-pipeline-control-order-dag-looping'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_name = f\"{SERIES}-{EXPERIMENT}-order-dag-looping\"\n",
    "pipeline_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5441e15f-b95a-4d4d-95dc-40536cf3ff6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(name = pipeline_name)\n",
    "def order_pipeline_dag_looping():\n",
    "    \n",
    "    with kfp.dsl.ParallelFor(\n",
    "        items = list(range(1, 11)),\n",
    "        parallelism = 5,\n",
    "        name = 'Loop of 10, 5 at a time'\n",
    "    ) as num_dice:\n",
    "        roll_dice(num_dice = num_dice).set_display_name(f'Sum of Die')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3839de10-b2ba-4438-848d-0c13adeed588",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-looping-20250310171735\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-looping-20250310171735')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-control-order-dag-looping-20250310171735?project=1026793852137\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-looping-20250310171735 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-looping-20250310171735 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-looping-20250310171735 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-looping-20250310171735\n"
     ]
    }
   ],
   "source": [
    "pipeline_job = pipeline_runner(order_pipeline_dag_looping, pipeline_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8b70e3a9-45db-4f3e-b385-232d95c3955d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dashboard can be viewed here:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-control-order-dag-looping-20250310171735?project=1026793852137\n"
     ]
    }
   ],
   "source": [
    "print(f'The Dashboard can be viewed here:\\n{pipeline_job._dashboard_uri()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3850558-50fa-4772-b0f4-770ff221549b",
   "metadata": {},
   "source": [
    "<p><center>\n",
    "    <img alt=\"Order DAG - Looping (running)\" src=\"../resources/images/screenshots/pipelines/control/order-dag-looping1.png\" width=\"45%\">\n",
    "    &nbsp;\n",
    "    &nbsp;\n",
    "    &nbsp;\n",
    "    &nbsp;\n",
    "    &nbsp;\n",
    "    &nbsp;\n",
    "    <img alt=\"Order DAG - Looping (done)\" src=\"../resources/images/screenshots/pipelines/control/order-dag-looping2.png\" width=\"45%\">\n",
    "</center><p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fde032-492a-48f1-b07a-eedf645ed426",
   "metadata": {},
   "source": [
    "---\n",
    "### Looping: Collecting Tasks\n",
    "\n",
    "In the previous section, looping with `kfp.dsl.ParallelFor()` was used.  If a downstream task needs to use the results of each loop iteration then it is necessary to wait and collect the results.  This is where\n",
    "`kfp.dsl.Collected()` comes in handy. [Reference](https://www.kubeflow.org/docs/components/pipelines/v2/pipelines/control-flow/#dslcollected)\n",
    "\n",
    "\n",
    "The pipeline is updated to add a new component, `sum_number()`, which will take the results of `kfp.dsl.Collected` as an input.  In this case, the collection is the output of each `roll_dice` tasks which is a list of numbers that each represent the sum of the dice rolled in the individual iterations task.  Now, the sum of all these `roll_dice` task outputs is created by the new `sum_numbers` component based task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8aeee680-f738-4696-98d3-6a44e4fc2640",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.component(base_image = 'python:3.10')\n",
    "def sum_numbers(numbers: list) -> int:\n",
    "    result = sum(numbers)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e82a7666-2c97-4073-9873-c77f753fe53f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mlops-pipeline-control-order-dag-looping-collect'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_name = f\"{SERIES}-{EXPERIMENT}-order-dag-looping-collect\"\n",
    "pipeline_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dca64e31-8023-412e-ba70-f052d018a7f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(name = pipeline_name)\n",
    "def order_pipeline_dag_looping_collect():\n",
    "    \n",
    "    with kfp.dsl.ParallelFor(\n",
    "        items = list(range(1, 11)),\n",
    "        parallelism = 5,\n",
    "        name = 'Loop of 10, 5 at a time'\n",
    "    ) as num_dice:\n",
    "        sum_roll = roll_dice(num_dice = num_dice).set_display_name(f'Sum of Die')\n",
    "        \n",
    "    sum_numbers(numbers = kfp.dsl.Collected(sum_roll.output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "917768a7-ba8a-4975-8146-e07174f6e7b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-looping-collect-20250310171852\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-looping-collect-20250310171852')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-control-order-dag-looping-collect-20250310171852?project=1026793852137\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-looping-collect-20250310171852 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-looping-collect-20250310171852 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-looping-collect-20250310171852 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-looping-collect-20250310171852 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-looping-collect-20250310171852\n"
     ]
    }
   ],
   "source": [
    "pipeline_job = pipeline_runner(order_pipeline_dag_looping_collect, pipeline_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3e7adc01-deb0-4159-91c8-1c9559c1ce20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dashboard can be viewed here:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-control-order-dag-looping-collect-20250310171852?project=1026793852137\n"
     ]
    }
   ],
   "source": [
    "print(f'The Dashboard can be viewed here:\\n{pipeline_job._dashboard_uri()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c3e747-8167-4f02-a012-8d1eb32e606e",
   "metadata": {},
   "source": [
    "<p><center>\n",
    "    <img alt=\"Order DAG - Looping - Collect\" src=\"../resources/images/screenshots/pipelines/control/order-dag-looping-collect.png\" width=\"90%\">\n",
    "</center><p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fca924-b675-412c-826b-e9dbc9cca559",
   "metadata": {},
   "source": [
    "---\n",
    "## Pipelines As Components (Pipelines Inside of Pipelines)\n",
    "\n",
    "A pipeline is made up of components.  It is also possible to use one pipelines as a component in another pipeline. In other words, [pipelines as components](https://www.kubeflow.org/docs/components/pipelines/v2/pipelines/pipeline-basics/#pipelines-as-components)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2af5517b-9791-4dff-b8da-dc6fa95ab661",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mlops-pipeline-control-order-dag-pipeascomp1'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_name = f\"{SERIES}-{EXPERIMENT}-order-dag-pipeascomp1\"\n",
    "pipeline_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a81b7d1c-7e79-47c7-91e2-b265f7bc5cc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(name = pipeline_name)\n",
    "def order_pipeline_dag_pipeaspipe1():   \n",
    "    task_1a = roll_dice()\n",
    "    task_1b = roll_dice(num_dice = 2).after(task_1a)\n",
    "    task_1c = roll_dice(num_dice = 3).after(task_1b)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9d4c98cf-1fe0-4358-9df3-1cadfbaed7f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mlops-pipeline-control-order-dag-pipeascomp2'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_name = f\"{SERIES}-{EXPERIMENT}-order-dag-pipeascomp2\"\n",
    "pipeline_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6ce9b84f-f096-4d58-a3ec-514f1e38d89f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(name = pipeline_name)\n",
    "def order_pipeline_dag_pipeaspipe2(): \n",
    "    pipe1 = order_pipeline_dag_pipeaspipe1()\n",
    "    task_2a = flip_coins(num_coins = 10) .after(pipe1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "64ecaeca-8f61-4a0f-9e3b-58b4b5c465b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-pipeascomp2-20250310172045\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-pipeascomp2-20250310172045')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-control-order-dag-pipeascomp2-20250310172045?project=1026793852137\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-pipeascomp2-20250310172045 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-pipeascomp2-20250310172045 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-pipeascomp2-20250310172045 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-pipeascomp2-20250310172045 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-pipeascomp2-20250310172045\n"
     ]
    }
   ],
   "source": [
    "pipeline_job = pipeline_runner(order_pipeline_dag_pipeaspipe2, pipeline_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "baff0159-9d1a-4ab7-9dd8-71b85891dd24",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dashboard can be viewed here:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-control-order-dag-pipeascomp2-20250310172045?project=1026793852137\n"
     ]
    }
   ],
   "source": [
    "print(f'The Dashboard can be viewed here:\\n{pipeline_job._dashboard_uri()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c7271f-8095-48b3-97cd-204be808703e",
   "metadata": {},
   "source": [
    "<p><center>\n",
    "    <img alt=\"Order DAG - Exit Handle\" src=\"../resources/images/screenshots/pipelines/control/order-dag-pipe-of-pipe.png\" width=\"90%\">\n",
    "</center><p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe9d5ba-41c2-45ed-a945-e0226136b887",
   "metadata": {},
   "source": [
    "---\n",
    "## Exit Handling\n",
    "\n",
    "When a tasks or group of task needs to be followed by specific actions the `kfp.dsl.ExistHandler` will help.  This allows setting a specific tasks as an exit task so that after that tasks finishes (or fails) additional task will run. [Reference](https://www.kubeflow.org/docs/components/pipelines/v2/pipelines/control-flow/#exit-handling-dslexithandler)\n",
    "\n",
    "\n",
    "The pipeline below runs three task with the `roll_dice` component.  The `kfp.dsl.ExitHandler` runs task 'task_2a' after 'task_1c' is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d6ce0e3e-62eb-45fd-89e0-1c7e6aa97b62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mlops-pipeline-control-order-dag-exithandle'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_name = f\"{SERIES}-{EXPERIMENT}-order-dag-exithandle\"\n",
    "pipeline_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b70e5f9b-c930-4bee-8d4b-5a0220bd17f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(name = pipeline_name)\n",
    "def order_pipeline_dag_exithandle():\n",
    " \n",
    "    task_2a = flip_coins(num_coins = 10)\n",
    "    \n",
    "    with kfp.dsl.ExitHandler(exit_task = task_2a, name = 'After Dice Roll Tasks, flip coins'):   \n",
    "        task_1a = roll_dice()\n",
    "        task_1b = roll_dice(num_dice = 2).after(task_1a)\n",
    "        task_1c = roll_dice(num_dice = 3).after(task_1b)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4cff54b8-d677-4964-96d8-84eefb0ff483",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-exithandle-20250310172522\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-exithandle-20250310172522')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-control-order-dag-exithandle-20250310172522?project=1026793852137\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-exithandle-20250310172522 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-exithandle-20250310172522 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-exithandle-20250310172522 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-exithandle-20250310172522 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-exithandle-20250310172522\n"
     ]
    }
   ],
   "source": [
    "pipeline_job = pipeline_runner(order_pipeline_dag_exithandle, pipeline_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "72751e1e-c363-4bea-bb0b-5957cbc097ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dashboard can be viewed here:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-control-order-dag-exithandle-20250310172522?project=1026793852137\n"
     ]
    }
   ],
   "source": [
    "print(f'The Dashboard can be viewed here:\\n{pipeline_job._dashboard_uri()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caab73d3-bbfd-45d4-83d3-3e28aa4dec71",
   "metadata": {},
   "source": [
    "<p><center>\n",
    "    <img alt=\"Order DAG - Exit Handle\" src=\"../resources/images/screenshots/pipelines/control/order-dag-exithandle.png\" width=\"90%\">\n",
    "</center><p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7eabe2-65d5-4176-8bef-ddf9bdb39e64",
   "metadata": {},
   "source": [
    "## Exit Handling: With Failures\n",
    "\n",
    "A type of exit is an error.  The following pipeline alters the pipeline above by adding a component that forces an error.  This shows that the `kfp.dsl.ExitHandler` still executes its `exit_task` after the failure.\n",
    "\n",
    "**Notice**: The pipeline does fail!  But the `exit_task` still completes after the failure.  The downstream task from the failure does not commence though.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2b4b1933-373f-4e8b-9448-f8dab8f4f38a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.component(base_image = 'python:3.10')\n",
    "def force_fail():\n",
    "    import sys\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d3e6173d-64c3-4717-9000-7a45642228fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mlops-pipeline-control-order-dag-exithandle-failure'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_name = f\"{SERIES}-{EXPERIMENT}-order-dag-exithandle-failure\"\n",
    "pipeline_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "880655c2-bf44-4222-a331-30d3bd1a5ce0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(name = pipeline_name)\n",
    "def order_pipeline_dag_exithandle_failure():\n",
    " \n",
    "    task_2a = flip_coins(num_coins = 10)\n",
    "    \n",
    "    with kfp.dsl.ExitHandler(exit_task = task_2a, name = 'After Dice Roll Tasks, flip coins'):   \n",
    "        task_1a = roll_dice()\n",
    "        task_1b = roll_dice(num_dice = 2).after(task_1a)\n",
    "        task_fail = force_fail().after(task_1b)\n",
    "        task_1c = roll_dice(num_dice = 3).after(task_fail)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8d228b3c-27cf-4930-b7f4-34ce1a022f89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-exithandle-failure-20250310173123\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-exithandle-failure-20250310173123')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-control-order-dag-exithandle-failure-20250310173123?project=1026793852137\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-exithandle-failure-20250310173123 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-exithandle-failure-20250310173123 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-exithandle-failure-20250310173123 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-exithandle-failure-20250310173123 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "An error occured: Job failed with:\n",
      "code: 9\n",
      "message: \"  The DAG failed because some tasks failed. The failed tasks are: [exit-handler-1].; Job (project_id = statmike-mlops-349915, job_id = 2055884571240562688) is failed due to the above error.; Failed to handle the job: {project_number = 1026793852137, job_id = 2055884571240562688}\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    pipeline_job = pipeline_runner(order_pipeline_dag_exithandle_failure, pipeline_name)\n",
    "except Exception as e:\n",
    "    print(f\"An error occured: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e00ecab9-159f-4f42-89fb-c1b98e15ea69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dashboard can be viewed here:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-control-order-dag-exithandle-20250310172522?project=1026793852137\n"
     ]
    }
   ],
   "source": [
    "print(f'The Dashboard can be viewed here:\\n{pipeline_job._dashboard_uri()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce67c9b-ebe8-493c-b0c6-a44f3f0e9655",
   "metadata": {},
   "source": [
    "**Notice**: The pipeline does fail!  But the `exit_task` still completes after the failure.  The downstream task from the failure does not commence though.  \n",
    "\n",
    "<p><center>\n",
    "    <img alt=\"Order DAG - Exit Handle\" src=\"../resources/images/screenshots/pipelines/control/order-dag-exithandle-failure.png\" width=\"90%\">\n",
    "</center><p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc18659-9da0-411d-8a10-10baeb5bdc97",
   "metadata": {},
   "source": [
    "---\n",
    "## Exit Handling: Error Handling\n",
    "\n",
    "The example above shows how the `kfp.dsl.ExitHandler` can continue with an `exit_task` even after a failure.  There are times where tasks still can be run even when an upstream task failed.  Like the 'task_1c' in that prior pipeline which has no inputs from the failed task, it just happens to be run after the task.  For this, the `.ignore_upstream_failure()` task method is a great solution. [Reference](https://www.kubeflow.org/docs/components/pipelines/v2/pipelines/control-flow/#ignore-upstream-failure)\n",
    "\n",
    "The prior pipeline is updated with the `.ignotre_upstream_failure()` method added to 'task_1c'.\n",
    "\n",
    "**Notice**: As before, the pipeline fails and `exit_task` still completes after the failure.  This time, the downstream task from the failure does continue and complete successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "badba070-f74e-4212-8a6b-1bd0a99abf39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mlops-pipeline-control-order-dag-errorhandle'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_name = f\"{SERIES}-{EXPERIMENT}-order-dag-errorhandle\"\n",
    "pipeline_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dddd6dd5-c43e-4f2a-8aa4-5e2923c6e5a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(name = pipeline_name)\n",
    "def order_pipeline_dag_errorhandle():\n",
    " \n",
    "    task_2a = flip_coins(num_coins = 10)\n",
    "    \n",
    "    with kfp.dsl.ExitHandler(exit_task = task_2a, name = 'After Dice Roll Tasks, flip coins'):   \n",
    "        task_1a = roll_dice()\n",
    "        task_1b = roll_dice(num_dice = 2).after(task_1a)\n",
    "        task_fail = force_fail().after(task_1b)\n",
    "        task_1c = roll_dice(num_dice = 3).after(task_fail).ignore_upstream_failure()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9159506a-7e63-48db-ab26-830ff132f34b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-errorhandle-20250310173452\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-errorhandle-20250310173452')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-control-order-dag-errorhandle-20250310173452?project=1026793852137\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-errorhandle-20250310173452 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-errorhandle-20250310173452 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-errorhandle-20250310173452 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-errorhandle-20250310173452 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-errorhandle-20250310173452 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "An error occured: Job failed with:\n",
      "code: 9\n",
      "message: \"  The DAG failed because some tasks failed. The failed tasks are: [exit-handler-1].; Job (project_id = statmike-mlops-349915, job_id = 5809648054793404416) is failed due to the above error.; Failed to handle the job: {project_number = 1026793852137, job_id = 5809648054793404416}\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    pipeline_job = pipeline_runner(order_pipeline_dag_errorhandle, pipeline_name)\n",
    "except Exception as e:\n",
    "    print(f\"An error occured: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8f9a4a38-a8ea-40e0-a53c-b0ba6eeb5bd0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dashboard can be viewed here:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-control-order-dag-exithandle-20250310172522?project=1026793852137\n"
     ]
    }
   ],
   "source": [
    "print(f'The Dashboard can be viewed here:\\n{pipeline_job._dashboard_uri()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8663c602-3ea6-4d37-b50f-e48c870de637",
   "metadata": {},
   "source": [
    "**Notice**: As before, the pipeline fails and `exit_task` still completes after the failure.  This time, the downstream task from the failure does continue and complete successfully.\n",
    "<p><center>\n",
    "    <img alt=\"Order DAG - Exit Handle\" src=\"../resources/images/screenshots/pipelines/control/order-dag-errorhandle.png\" width=\"90%\">\n",
    "</center><p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f854bd-16c1-492b-a8aa-e93f28dae508",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m128",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m128"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
