{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55cefd84",
   "metadata": {},
   "source": [
    "![tracker](https://us-central1-vertex-ai-mlops-369716.cloudfunctions.net/pixel-tracking?path=statmike%2Fvertex-ai-mlops%2F02+-+Vertex+AI+AutoML&file=02Tools+-+AutoML+Cloud+Logging.ipynb)\n",
    "<!--- header table --->\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/statmike/vertex-ai-mlops/blob/main/02%20-%20Vertex%20AI%20AutoML/02Tools%20-%20AutoML%20Cloud%20Logging.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\">\n",
    "      <br>Run in<br>Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https%3A%2F%2Fraw.githubusercontent.com%2Fstatmike%2Fvertex-ai-mlops%2Fmain%2F02%2520-%2520Vertex%2520AI%2520AutoML%2F02Tools%2520-%2520AutoML%2520Cloud%2520Logging.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\">\n",
    "      <br>Run in<br>Colab Enterprise\n",
    "    </a>\n",
    "  </td>      \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/statmike/vertex-ai-mlops/blob/main/02%20-%20Vertex%20AI%20AutoML/02Tools%20-%20AutoML%20Cloud%20Logging.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      <br>View on<br>GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/statmike/vertex-ai-mlops/main/02%20-%20Vertex%20AI%20AutoML/02Tools%20-%20AutoML%20Cloud%20Logging.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      <br>Open in<br>Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "50b2cdfa-3be9-4515-ad67-f484560512e6",
   "metadata": {},
   "source": [
    "# 02 Tools - AutoML Cloud Logging\n",
    "\n",
    "## WORK IN PROGRESS\n",
    "\n",
    "Use the Vertex AI Python Client parse through the AutoML Tuning and Model Ensemble logs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ea76885",
   "metadata": {},
   "source": [
    "### View Model Architeture in Cloud Logging\n",
    "\n",
    "\n",
    "This [link](https://cloud.google.com/vertex-ai/docs/tabular-data/classification-regression/logging#before_you_begin) provides information on how to use Cloud Logging to view details about a Vertex AI model.\n",
    "\n",
    "**Note**: By Default, logs are deleted after ***30 days***.\n",
    "\n",
    "**Prerequisites:**\n",
    "-  02b - Vertex AI - AutoML with clients (code)\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ca10ed5b",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "46f205a7",
   "metadata": {},
   "source": [
    "inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e41511-69cc-4048-b892-1767cfef090a",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64169f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "DATANAME = 'fraud'\n",
    "NOTEBOOK = '02b'\n",
    "\n",
    "# Resources\n",
    "DEPLOY_COMPUTE = 'n1-standard-4'\n",
    "\n",
    "# Model Training\n",
    "VAR_TARGET = 'Class'\n",
    "VAR_OMIT = 'transaction_id' # add more variables to the string with space delimiters\n",
    "\n",
    "# BigQuery destination \n",
    "BQ_PROJECT = PROJECT_ID\n",
    "BQ_DATASET = '02tools_automl_cloud_logging'\n",
    "BQ_TABLE_TUNING_LOGS = 'tuning-logs'\n",
    "BQ_TABLE_MODEL_LOGS = 'model-logs'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dbca2d69",
   "metadata": {},
   "source": [
    "packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73dcfa8-96a5-4e73-8340-65a9bbe26e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "from datetime import datetime\n",
    "from google.cloud import bigquery\n",
    "from google.protobuf import json_format\n",
    "from google.protobuf.struct_pb2 import Value\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import google.cloud.logging_v2 as logging\n",
    "import pandas_gbq as pd_gbq\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c8cd40cb",
   "metadata": {},
   "source": [
    "clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c06271-049a-4b08-9346-e4220ddf731f",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
    "bq = bigquery.Client()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9872da39",
   "metadata": {},
   "source": [
    "parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5a42b2-9b08-4a25-952a-aab3086b432d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list_filter = f\"labels.notebook=\\\"{NOTEBOOK}\\\"\"\n",
    "model_list_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4f0aa0-5bb2-4c0e-adba-77efc2c30df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = aiplatform.Model.list(filter=str(model_list_filter))\n",
    "create = [m.create_time for m in model_list] \n",
    "create.index(max(create))\n",
    "model_run_date_time = model_list[0].create_time\n",
    "model_create_time = model_list[0].create_time\n",
    "model_run_ts = datetime.strptime(str(model_create_time),\"%Y-%m-%d %H:%M:%S.%f%z\")\n",
    "model_run_ts = model_run_ts.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "model_run_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c119824-e89e-401d-8d52-2ad1f2f02f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import google.cloud.logging_v2 as logging\n",
    "# # import pandas as pd\n",
    "# # import json\n",
    "# # import matplotlib.pylab as plt\n",
    "# def get_logs(log_level):\n",
    "#     logging_client = logging.Client()\n",
    "#     hp_list = []\n",
    "#     FILTER = log_filter\n",
    "#     entries = logging_client.list_entries(filter_=FILTER)\n",
    "#     for ind, entry in enumerate(entries):\n",
    "#         if type(entry.payload) != dict:\n",
    "#             continue\n",
    "#         parse_log = entry.to_api_repr()\n",
    "#         if model_log_filter in parse_log[\"logName\"]:\n",
    "#             if log_level == \"tuning\":\n",
    "#                 for hp in parse_log[\"jsonPayload\"][\"modelStructure\"][\"modelParameters\"]:\n",
    "#                     # print(hp[\"hyperparameters\"])\n",
    "#                     hp_dict = hp[\"hyperparameters\"]\n",
    "#                     hp_dict[\"training_objective_point\"] = parse_log['jsonPayload']['trainingObjectivePoint']['value']\n",
    "#                     hp_list.append(hp_dict)\n",
    "#             elif log_level == \"model\":\n",
    "#                 for hp in parse_log[\"jsonPayload\"][\"modelParameters\"]:\n",
    "#                     hp_dict = hp[\"hyperparameters\"]\n",
    "#                     hp_list.append(hp_dict)\n",
    "#             df = pd.DataFrame(hp_list)\n",
    "#     return df\n",
    "\n",
    "# display(get_logs(log_level))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f5d1f604",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6723e456",
   "metadata": {},
   "source": [
    "### Parsing AutoML logs using Cloud Logging API\n",
    "\n",
    "This [link](https://cloud.google.com/python/docs/reference/logging/latest/index.html) contains the details about using the **python client** for cloud logging.\n",
    "\n",
    "There are two log levels in AutoML:\n",
    "- Tuning\n",
    "- Model\n",
    "\n",
    "To start with, we will retrieve the tuning logs by setting the **log level** as `tuning` in the parameter list below:\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e6fa23cf",
   "metadata": {},
   "source": [
    "parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89a1473",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_level = \"tuning\"\n",
    "model_log_filter = f\"projects/{PROJECT_ID}/logs/automl.googleapis.com%2F{log_level}\"\n",
    "model_log_filter\n",
    "log_filter = f\"timestamp > \\\"{model_run_ts}\\\" resource.type=\\\"cloudml_job\\\"\"\n",
    "model_log_filter\n",
    "log_filter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7c9a0222",
   "metadata": {},
   "source": [
    "Function to fetch tuning logs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a308f5-6f18-49fe-9446-29bdb6074581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tuning_logs(log_level):\n",
    "    logging_client = logging.Client()\n",
    "    hp_list = []\n",
    "    FILTER = log_filter\n",
    "    entries = logging_client.list_entries(filter_=FILTER)\n",
    "    for ind, entry in enumerate(entries):\n",
    "        if type(entry.payload) != dict:\n",
    "            continue\n",
    "        parse_log = entry.to_api_repr()\n",
    "        if model_log_filter in parse_log[\"logName\"]:\n",
    "            for hp in parse_log[\"jsonPayload\"][\"modelStructure\"][\"modelParameters\"]:\n",
    "                hp_dict = hp[\"hyperparameters\"]\n",
    "                hp_list.append(hp_dict)\n",
    "            tuning_log_df = pd.DataFrame(hp_list)\n",
    "    return tuning_log_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e3529f-1fa5-4d72-84fc-5154b3fd95ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_log_df = get_tuning_logs(log_level)\n",
    "tuning_log_df = tuning_log_df.applymap(str)\n",
    "# tuning_log_df.to_gbq(destination_table=\"automl_log.tuning_logs\")\n",
    "# pd_gbq.to_gbq(tuning_log_df,\"automl_log.tuning_logs_str\",project_id=PROJECT_ID)\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "  display(tuning_log_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2ae50dc1",
   "metadata": {},
   "source": [
    "Next step is to add **training objective point** to the tuning logs. Please refer the [link](https://cloud.google.com/vertex-ai/docs/tabular-data/classification-regression/logging#before_you_begin) to learn more about training objective point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96a42b5-5218-4d18-9966-5eb4ac2148a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tuning_logs_with_obj(log_level):\n",
    "    logging_client = logging.Client()\n",
    "    hp_list = []\n",
    "    FILTER = log_filter\n",
    "    entries = logging_client.list_entries(filter_=FILTER)\n",
    "    for ind, entry in enumerate(entries):\n",
    "        if type(entry.payload) != dict:\n",
    "            continue\n",
    "        parse_log = entry.to_api_repr()\n",
    "        if model_log_filter in parse_log[\"logName\"]:\n",
    "            for hp in parse_log[\"jsonPayload\"][\"modelStructure\"][\"modelParameters\"]:\n",
    "                # print(hp[\"hyperparameters\"])\n",
    "                hp_dict = hp[\"hyperparameters\"]\n",
    "                hp_dict[\"training_objective_point\"] = parse_log['jsonPayload']['trainingObjectivePoint']['value']\n",
    "                hp_list.append(hp_dict)\n",
    "            df = pd.DataFrame(hp_list)\n",
    "    return df\n",
    "\n",
    "tuning_with_obj_log_df = get_tuning_logs_with_obj(log_level)\n",
    "# pd_gbq.to_gbq(tuning_with_obj_log_df,\"automl_log.tuning_with_obj_logs\",project_id=PROJECT_ID)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a9815713",
   "metadata": {},
   "source": [
    "For retrieving the model ensemble logs, update the **log_level** to `model` in the parameter list below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9e7813-bfb9-40a9-ad23-b7ba835e0bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_level = \"model\"\n",
    "model_log_filter = \"projects/\" + PROJECT_ID + \"/logs/automl.googleapis.com%2F\" + log_level\n",
    "model_log_filter\n",
    "log_filter = \"timestamp > \\\"\" + model_run_ts + \"\\\" resource.type=\\\"cloudml_job\\\"\"\n",
    "model_log_filter\n",
    "log_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a734f75f-cd5b-40cb-9a71-b9f761192717",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_logs(log_level):\n",
    "    logging_client = logging.Client()\n",
    "    hp_list = []\n",
    "    FILTER = log_filter\n",
    "    entries = logging_client.list_entries(filter_=FILTER)\n",
    "    for ind, entry in enumerate(entries):\n",
    "        if type(entry.payload) != dict:\n",
    "            continue\n",
    "        parse_log = entry.to_api_repr()\n",
    "        if model_log_filter in parse_log[\"logName\"]:\n",
    "            for hp in parse_log[\"jsonPayload\"][\"modelParameters\"]:\n",
    "                hp_dict = hp[\"hyperparameters\"]\n",
    "                hp_list.append(hp_dict)\n",
    "            model_log_df = pd.DataFrame(hp_list)\n",
    "    return model_log_df\n",
    "\n",
    "# display(get_model_logs(log_level))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e21f2fa-c2cc-4628-ae00-61fc5129ab80",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_log_df = get_model_logs(log_level)\n",
    "model_log_df = model_log_df.applymap(str)\n",
    "# pd_gbq.to_gbq(model_log_df,\"automl_log.model_logs\",project_id=PROJECT_ID)\n",
    "# display(model_log_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "69b73c5f",
   "metadata": {},
   "source": [
    "Joining **Tuning** and **Model** logs to display the common training parmeters present in model ensemble logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db30d8e-43c9-4f90-b04e-c6865aceb107",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cd = pd.merge(tuning_log_df, model_log_df, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460f8c40-42c5-4696-a60c-a1412b695184",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    display(df_cd)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6f3c6eda",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ef7108ea-1b51-422c-b015-716154089458",
   "metadata": {},
   "source": [
    "## Loading logs into BigQuery for analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ace5762e",
   "metadata": {},
   "source": [
    "List BigQuery datasets in the project. Check for dataset name `02tools_automl_cloud_logging`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6496d30",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/Library/Frameworks/Python.framework/Versions/3.9/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Library/Frameworks/Python.framework/Versions/3.9/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "datasets = list(bq.list_datasets())\n",
    "for d in datasets:\n",
    "    print(d.dataset_id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4cc9566c",
   "metadata": {},
   "source": [
    "Create the dataset if missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d52920",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = bigquery.Dataset(f\"{BQ_PROJECT}.{BQ_DATASET}\")\n",
    "ds.location = REGION\n",
    "ds = bq.create_dataset(dataset = ds, exists_ok = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9cdd21a8",
   "metadata": {},
   "source": [
    "Validating the newly created BigQuery dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d08320",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = list(bigquery.list_datasets())\n",
    "for d in datasets:\n",
    "    print(d.dataset_id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13cad525",
   "metadata": {},
   "source": [
    "Loading Tuning Logs to BigQuery Table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43722c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_gbq.to_gbq(tuning_log_df,f\"{BQ_DATASET}.{BQ_TABLE_TUNING_LOGS}\",project_id=PROJECT_ID)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "381e6176",
   "metadata": {},
   "source": [
    "Loading Model Logs to BigQuery Table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89d6ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_gbq.to_gbq(model_log_df,f\"{BQ_DATASET}.{BQ_TABLE_MODEL_LOGS}\",project_id=PROJECT_ID)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e36e5f7",
   "metadata": {},
   "source": [
    "Retrieve the matching rows from tuning and model tables in BigQuery:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4689a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/Library/Frameworks/Python.framework/Versions/3.9/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Library/Frameworks/Python.framework/Versions/3.9/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "SELECT * \n",
    "FROM \n",
    "`{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE_TUNING_LOGS}`\n",
    "INNER JOIN\n",
    "`{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE_MODEL_LOGS}`\n",
    "using \n",
    "(enable_numerical_embeddings ,\n",
    "enable_embedding_l2 ,\n",
    "dropout,\n",
    "enable_batch_norm,\n",
    "enable_l1,\n",
    "enable_embedding_l1,\n",
    "num_hidden_layers,\n",
    "normalized_numerical,\n",
    "skip_connections_type,\n",
    "num_cross_layers,\n",
    "enable_l2,\n",
    "model_type,\n",
    "enable_layer_norm ,\n",
    "hidden_layer_size ,\n",
    "max_tree_depth ,\n",
    "num_trees ,\n",
    "l2 ,\n",
    "tree_complexity ,\n",
    "l1);\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2d7226df",
   "metadata": {},
   "source": [
    "Displaying the common training parameters using BigQuery:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8162c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = bq.query(query = query).to_dataframe()\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "07d2b79d",
   "metadata": {},
   "source": [
    "---\n",
    "### Reusable function to retrieve AutoML tuning and model logs\n",
    "Adding the function for reference purpose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9707c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logs(log_level):\n",
    "    logging_client = logging.Client()\n",
    "    hp_list = []\n",
    "    FILTER = log_filter\n",
    "    entries = logging_client.list_entries(filter_=FILTER)\n",
    "    for ind, entry in enumerate(entries):\n",
    "        if type(entry.payload) != dict:\n",
    "            continue\n",
    "        parse_log = entry.to_api_repr()\n",
    "        if model_log_filter in parse_log[\"logName\"]:\n",
    "            if log_level == \"tuning\":\n",
    "                for hp in parse_log[\"jsonPayload\"][\"modelStructure\"][\"modelParameters\"]:\n",
    "                    # print(hp[\"hyperparameters\"])\n",
    "                    hp_dict = hp[\"hyperparameters\"]\n",
    "                    hp_dict[\"training_objective_point\"] = parse_log['jsonPayload']['trainingObjectivePoint']['value']\n",
    "                    hp_list.append(hp_dict)\n",
    "            elif log_level == \"model\":\n",
    "                for hp in parse_log[\"jsonPayload\"][\"modelParameters\"]:\n",
    "                    hp_dict = hp[\"hyperparameters\"]\n",
    "                    hp_list.append(hp_dict)\n",
    "            df = pd.DataFrame(hp_list)\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-3.m100",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m100"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "7812ea015bdcee6f23a998adcdd2ef97c151c0c241b7b7070987d9313e41299d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
