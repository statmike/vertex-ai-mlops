{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45721903",
   "metadata": {},
   "source": [
    "![ga4](https://www.google-analytics.com/collect?v=2&tid=G-6VDTYWLKX6&cid=1&en=page_view&sid=1&dl=statmike%2Fvertex-ai-mlops%2F04+-+scikit-learn&dt=04e+-+Vertex+AI+Custom+Model+-+scikit-learn+-+Training+Pipeline+With+Python+Source+Distribution.ipynb)\n",
    "\n",
    "# 04e - Vertex AI > Training > Training Pipelines - With Python Source Distribution\n",
    "\n",
    "**04 Series Overview**\n",
    "\n",
    "Where a model gets trained is where it consumes computing resources.  With Vertex AI, you have choices for configuring the computing resources available at training.  This notebook is an example of an execution environment.  When it was set up there were choices for machine type and accelerators (GPUs).  \n",
    "\n",
    "In the [04 - Vertex AI Custom Model - scikit-learn - in Notebook](./04%20-%20Vertex%20AI%20Custom%20Model%20-%20scikit-learn%20-%20in%20Notebook.ipynb) notebook, the model training happened directly in the notebook.  The model was then imported to Vertex AI and deployed to an endpoint for online predictions. \n",
    "\n",
    "In this `04a-04i` series of demonstrations, the same model is trained using managed computing resources in Vertex AI Training as managed jobs.  These jobs will be demonstrated as:\n",
    "\n",
    "-  Custom Job that trains and saves (to GCS) a model from a python script (`04a`), python source distribution (`04b`), and custom container (`04c`)\n",
    "-  Training Pipeline that trains and registers a model from a python script (`04d`), python source distribution (`04e`), and custom container (`04f`)\n",
    "-  Hyperparameter Tuning Jobs from a python script (`04g`), python source distribution (`04h`), and custom container (`04i`)\n",
    "\n",
    "**This Notebook (`04e`): An extension of `04b` as a Training Pipeline that saves the model to Vertex AI > Model Registry** \n",
    "\n",
    "This notebook trains the same scikit-learn Keras model from [04 - Vertex AI Custom Model - scikit-learn - in Notebook](./04%20-%20Vertex%20AI%20Custom%20Model%20-%20scikit-learn%20-%20in%20Notebook.ipynb) by first modifying and saving the training code to a Python script as shown in [04 - Vertex AI Custom Model - scikit-learn - Notebook to Script](./04%20-%20Vertex%20AI%20Custom%20Model%20-%20scikit-learn%20-%20Notebook%20to%20Script.ipynb).  \n",
    "\n",
    "A Python source distribution is built containing the script.  For more guidance on this process visit the tip notebook [Python Packages](../Tips/Python%20Packages.ipynb).  The source distribution is then used as an input for a Vertex AI > Training > Training Pipeline that is also assigned compute resources and a [pre-built container for custom training](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers) for executing the training in a managed service.  While this example fits nicely in a single script, larger examples will benefit from the flexibility offered by source distributions and this notebook gives an example of making the shift.\n",
    "\n",
    "Compared to the Custom Job in `04b` the primary considerations for this Training Pipeline are:\n",
    "- the final model is registered to Vertex AI > Model Registry\n",
    "- the training pipeline triggers a similar custom job in Vertex AI > Training\n",
    "\n",
    "This job is launched using the Vertex AI client library:\n",
    "- [Python Cloud Client Libraries](https://cloud.google.com/python/docs/reference)\n",
    "    - [google-cloud-aiplatform](https://cloud.google.com/python/docs/reference/aiplatform/latest)\n",
    "        - [`aiplatform` package](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform)\n",
    "            - [`aiplatform.CustomPythonPackageTrainingJob()`](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.CustomPythonPackageTrainingJob)\n",
    "            - and run with the method [`.run()`](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.CustomPythonPackageTrainingJob#google_cloud_aiplatform_CustomPythonPackageTrainingJob_run)\n",
    "\n",
    "**Vertex AI Training**\n",
    "\n",
    "In Vertex AI Training you can run your training code as a job where you specify the compute resources to use. For tips on preparing code, running training jobs, and workflows for building custom containers with software and training code combined please visit these [tips notebooks](../Tips/readme.md) in this repository:\n",
    "- [Python Packages](../Tips/Python%20Packages.ipynb)\n",
    "- [Python Custom Containers](../Tips/Python%20Custom%20Containers.ipynb)\n",
    "- [Python Training](../Tips/Python%20Training.ipynb)\n",
    "\n",
    "<p align=\"center\" width=\"100%\">\n",
    "    <img src=\"../architectures/overview/training.png\" width=\"45%\">\n",
    "    &nbsp; &nbsp; &nbsp; &nbsp;\n",
    "    <img src=\"../architectures/overview/training2.png\" width=\"45%\">\n",
    "</p>\n",
    "\n",
    "**Prerequisites:**\n",
    "-  [01 - BigQuery - Table Data Source](../01%20-%20Data%20Sources/01%20-%20BigQuery%20-%20Table%20Data%20Source.ipynb)\n",
    "-  Understanding:\n",
    "    -  Model overview in [04 - Vertex AI Custom Model - scikit-learn - in Notebook](./04%20-%20Vertex%20AI%20Custom%20Model%20-%20scikit-learn%20-%20in%20Notebook.ipynb)\n",
    "    -  Convert notebook code to Python Script in [04 - Vertex AI Custom Model - scikit-learn - Notebook to Script](./04%20-%20Vertex%20AI%20Custom%20Model%20-%20scikit-learn%20-%20Notebook%20to%20Script.ipynb)\n",
    "\n",
    "**Resources:**\n",
    "-  [sklearn](https://scikit-learn.org/stable/)\n",
    "\n",
    "-  [Python Client For Google BigQuery](https://googleapis.dev/python/bigquery/latest/index.html)\n",
    "-  [Python Client for Vertex AI](https://googleapis.dev/python/aiplatform/latest/aiplatform.html)\n",
    "-  [Create a Python source distribution](https://cloud.google.com/vertex-ai/docs/training/create-python-pre-built-container) for a Vertex AI custom training job\n",
    "-  Containers for training (Pre-Built)\n",
    "   -  [Overview](https://cloud.google.com/vertex-ai/docs/training/create-python-pre-built-container)\n",
    "   -  [List](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers)\n",
    "\n",
    "**Conceptual Flow & Workflow**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img alt=\"Conceptual Flow\" src=\"../architectures/slides/05e_arch.png\" width=\"45%\">\n",
    "&nbsp; &nbsp; &nbsp; &nbsp;\n",
    "  <img alt=\"Workflow\" src=\"../architectures/slides/05e_console.png\" width=\"45%\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b7e917",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a217791-643a-4ce7-9c0a-ca95613e55ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Package Installs (if needed)\n",
    "\n",
    "The cells below check to see if the required Python libraries are installed.  If any are not it will print a message to do the install with the associated pip command to use.  These installs must be completed before continuing this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66585204-878e-4122-8dbf-0de17f7adede",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import build\n",
    "except ImportError:\n",
    "    print('You need to pip install build')\n",
    "    !pip install build -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901d9863-05a4-46c6-89b8-9168333dc16a",
   "metadata": {},
   "source": [
    "### Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752b96a1",
   "metadata": {},
   "source": [
    "inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f0ed1ad-c3b2-413a-b788-b2275a027c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mg-ce-demos'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30ec57de",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "EXPERIMENT = '04e'\n",
    "SERIES = '04'\n",
    "\n",
    "# source data\n",
    "BQ_PROJECT = PROJECT_ID\n",
    "BQ_DATASET = 'fraud'\n",
    "BQ_TABLE = 'fraud_prepped'\n",
    "\n",
    "# Resources\n",
    "DEPLOY_IMAGE = 'us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.0-23:latest'\n",
    "TRAIN_IMAGE = 'us-docker.pkg.dev/vertex-ai/training/scikit-learn-cpu.0-23:latest'\n",
    "TRAIN_COMPUTE = 'n1-standard-4'\n",
    "DEPLOY_COMPUTE = 'n1-standard-4'\n",
    "\n",
    "# Model Training\n",
    "VAR_TARGET = 'Class'\n",
    "VAR_OMIT = 'transaction_id-splits' + '-' + VAR_TARGET # add more variables to the string with space delimiters\n",
    "SOLVER = 'newton-cg'\n",
    "PENALTY = 'l2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f91c78a",
   "metadata": {},
   "source": [
    "packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87c170ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "from datetime import datetime\n",
    "import pkg_resources\n",
    "from IPython.display import Markdown as md\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "from google.protobuf import json_format\n",
    "from google.protobuf.struct_pb2 import Value\n",
    "import json\n",
    "import os, shutil\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca571c8",
   "metadata": {},
   "source": [
    "clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66beb723",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
    "gcs = storage.Client()\n",
    "bq = bigquery.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9f6a3a",
   "metadata": {},
   "source": [
    "parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2486e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "BUCKET = PROJECT_ID\n",
    "URI = f\"gs://{BUCKET}/{SERIES}/{EXPERIMENT}\"\n",
    "DIR = f\"temp/{EXPERIMENT}\"\n",
    "BLOB = f\"{SERIES}/{EXPERIMENT}/models/{TIMESTAMP}/model/model.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af97de35-454a-404f-bce3-604efdae8809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mg-ce-demos-main@mg-ce-demos.iam.gserviceaccount.com'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SERVICE_ACCOUNT = !gcloud config list --format='value(core.account)' \n",
    "SERVICE_ACCOUNT = SERVICE_ACCOUNT[0]\n",
    "SERVICE_ACCOUNT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed97d733-830b-4973-a46a-e1e3cfcea350",
   "metadata": {},
   "source": [
    "List the service accounts current roles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1616750d-5bad-4314-836f-a3f20fd1eea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROLE\n",
      "roles/aiplatform.admin\n",
      "roles/bigquery.admin\n",
      "roles/editor\n",
      "roles/storage.objectAdmin\n"
     ]
    }
   ],
   "source": [
    "!gcloud projects get-iam-policy $PROJECT_ID --filter=\"bindings.members:$SERVICE_ACCOUNT\" --format='table(bindings.role)' --flatten=\"bindings[].members\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abdfbd8-36d6-400f-a34d-e84688634c0d",
   "metadata": {},
   "source": [
    ">Note: If the resulting list is missing [roles/storage.objectAdmin](https://cloud.google.com/storage/docs/access-control/iam-roles) then [revisit the setup notebook](../00%20-%20Setup/00%20-%20Environment%20Setup.ipynb#permissions) and add this permission to the service account with the provided instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b465ba",
   "metadata": {},
   "source": [
    "environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "371f830d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf {DIR}\n",
    "!mkdir -p {DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed92d527-e55e-4b9c-aa62-71839d882fb8",
   "metadata": {},
   "source": [
    "Experiment Tracking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "505895a9-be45-48a1-9e03-08c75fd292c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAMEWORK = 'sklearn'\n",
    "TASK = 'classification'\n",
    "MODEL_TYPE = 'logistric-regression'\n",
    "EXPERIMENT_NAME = f'experiment-{SERIES}-{EXPERIMENT}-{FRAMEWORK}-{TASK}-{MODEL_TYPE}'\n",
    "RUN_NAME = f'run-{TIMESTAMP}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730374eb-13fb-4e4f-a81b-5e7c92f85ba7",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Get Vertex AI Experiments Tensorboard Instance Name\n",
    "[Vertex AI Experiments](https://cloud.google.com/vertex-ai/docs/experiments/tensorboard-overview) has managed [Tensorboard](https://www.scikit-learn.org/tensorboard) instances that you can track Tensorboard Experiments (a training run or hyperparameter tuning sweep).  \n",
    "\n",
    "The training job will show up as an experiment for the Tensorboard instance and have the same name as the training job ID.\n",
    "\n",
    "This code checks to see if a Tensorboard Instance has been created in the project, retrieves it if so, creates it otherwise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98492615-c9ef-4e3d-ad7d-e63256e69548",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = aiplatform.Tensorboard.list(filter=f\"labels.series={SERIES}\")\n",
    "if tb:\n",
    "    tb = tb[0]\n",
    "else: \n",
    "    tb = aiplatform.Tensorboard.create(display_name = SERIES, labels = {'series' : f'{SERIES}'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9593c67-525b-4767-adc9-ccb80a5f2ac8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/633472233130/locations/us-central1/tensorboards/4577495604850065408'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb.resource_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb07b125-3f32-43a8-a14a-908a4e1ad2e3",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup Vertex AI Experiments\n",
    "\n",
    "The code in this section initializes the experiment and starts a run that represents this notebook.  Throughout the notebook sections for model training and evaluation information will be logged to the experiment using:\n",
    "- [.log_params](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform#google_cloud_aiplatform_log_params)\n",
    "- [.log_metrics](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform#google_cloud_aiplatform_log_metrics)\n",
    "- [.log_time_series_metrics](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform#google_cloud_aiplatform_log_time_series_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "218ba499-a4b4-4872-8716-008be2c8f96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(experiment = EXPERIMENT_NAME, experiment_tensorboard = tb.resource_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2517acf",
   "metadata": {},
   "source": [
    "---\n",
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37f9d45-1926-4abe-b8e5-53b7d842cc5f",
   "metadata": {},
   "source": [
    "### Python File for Training\n",
    "\n",
    "This notebook trains the same scikit-learn Keras model from [04 - Vertex AI Custom Model - scikit-learn - in Notebook](./04%20-%20Vertex%20AI%20Custom%20Model%20-%20scikit-learn%20-%20in%20Notebook.ipynb) by first modifying and saving the training code to a python script as shown in [04 - Vertex AI Custom Model - scikit-learn - Notebook to Script](./04%20-%20Vertex%20AI%20Custom%20Model%20-%20scikit-learn%20-%20Notebook%20to%20Script.ipynb) which stores the script in [`./code/train.py`](./code/train.py).\n",
    "\n",
    "**Review the script:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b59ef69-fb65-4f4a-ad00-d0ea4e1572d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "\n",
       "\n",
       "# package import\n",
       "import sklearn\n",
       "from sklearn.preprocessing import StandardScaler\n",
       "from sklearn.linear_model import LogisticRegression\n",
       "from sklearn.pipeline import Pipeline\n",
       "from sklearn import metrics\n",
       "\n",
       "import pickle\n",
       "import pandas as pd \n",
       "import numpy as np \n",
       "\n",
       "from google.cloud import bigquery\n",
       "from google.cloud import aiplatform\n",
       "from google.cloud import storage\n",
       "import argparse\n",
       "import os\n",
       "import sys\n",
       "\n",
       "# import argument to local variables\n",
       "parser = argparse.ArgumentParser()\n",
       "# the passed param, dest: a name for the param, default: if absent fetch this param from the OS, type: type to convert to, help: description of argument\n",
       "parser.add_argument('--penalty', dest = 'penalty', default = 'l2', type = str, help = 'Penalty term')\n",
       "parser.add_argument('--solver', dest = 'solver', default = 'newton-cg', type = str, help = 'Logistic regression solver')\n",
       "parser.add_argument('--var_target', dest = 'var_target', type=str)\n",
       "parser.add_argument('--var_omit', dest = 'var_omit', type=str)\n",
       "parser.add_argument('--project_id', dest = 'project_id', type=str)\n",
       "parser.add_argument('--bq_project', dest = 'bq_project', type=str)\n",
       "parser.add_argument('--bq_dataset', dest = 'bq_dataset', type=str)\n",
       "parser.add_argument('--bq_table', dest = 'bq_table', type=str)\n",
       "parser.add_argument('--region', dest = 'region', type=str)\n",
       "parser.add_argument('--experiment', dest = 'experiment', type=str)\n",
       "parser.add_argument('--series', dest = 'series', type=str)\n",
       "parser.add_argument('--experiment_name', dest = 'experiment_name', type=str)\n",
       "parser.add_argument('--run_name', dest = 'run_name', type=str)\n",
       "parser.add_argument('--bucket', dest = 'bucket', type=str)\n",
       "parser.add_argument('--uri', dest = 'uri', type=str)\n",
       "parser.add_argument('--blob', dest = 'blob', type=str)\n",
       "parser.add_argument('--timestamp', dest = 'timestamp', type=str)\n",
       "args = parser.parse_args()\n",
       "\n",
       "# Model Training\n",
       "VAR_TARGET = str(args.var_target)\n",
       "VAR_OMIT = str(args.var_omit).split('-')\n",
       "\n",
       "# clients\n",
       "bq = bigquery.Client(project = args.project_id)\n",
       "aiplatform.init(project = args.project_id, location = args.region)\n",
       "\n",
       "# Vertex AI Experiment\n",
       "expRun = aiplatform.ExperimentRun.create(run_name = args.run_name, experiment = args.experiment_name)\n",
       "expRun.log_params({'experiment': args.experiment, 'series': args.series, 'project_id': args.project_id})\n",
       "\n",
       "# get schema from bigquery source\n",
       "query = f\"SELECT * FROM {args.bq_project}.{args.bq_dataset}.INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '{args.bq_table}'\"\n",
       "schema = bq.query(query).to_dataframe()\n",
       "\n",
       "# get number of classes from bigquery source\n",
       "nclasses = bq.query(query = f'SELECT DISTINCT {VAR_TARGET} FROM {args.bq_project}.{args.bq_dataset}.{args.bq_table} WHERE {VAR_TARGET} is not null').to_dataframe()\n",
       "nclasses = nclasses.shape[0]\n",
       "expRun.log_params({'data_source': f'bq://{args.bq_project}.{args.bq_dataset}.{args.bq_table}', 'nclasses': nclasses, 'var_split': 'splits', 'var_target': VAR_TARGET})\n",
       "\n",
       "train_query = f\"SELECT * FROM {args.bq_project}.{args.bq_dataset}.{args.bq_table} WHERE splits = 'TRAIN'\"\n",
       "train = bq.query(train_query).to_dataframe()\n",
       "X_train = train.loc[:, ~train.columns.isin(VAR_OMIT)]\n",
       "y_train = train[VAR_TARGET].astype('int')\n",
       "\n",
       "val_query = f\"SELECT * FROM {args.bq_project}.{args.bq_dataset}.{args.bq_table} WHERE splits = 'VALIDATE'\"\n",
       "val = bq.query(val_query).to_dataframe()\n",
       "X_val = val.loc[:, ~val.columns.isin(VAR_OMIT)]\n",
       "y_val = val[VAR_TARGET].astype('int')\n",
       "\n",
       "test_query = f\"SELECT * FROM {args.bq_project}.{args.bq_dataset}.{args.bq_table} WHERE splits = 'TEST'\"\n",
       "test = bq.query(test_query).to_dataframe()\n",
       "X_test = test.loc[:, ~test.columns.isin(VAR_OMIT)]\n",
       "y_test = test[VAR_TARGET].astype('int')\n",
       "\n",
       "# Logistic Regression\n",
       "# instantiate the model \n",
       "logistic = LogisticRegression(solver=args.solver, penalty=args.penalty)\n",
       "\n",
       "# Define a Standard Scaler to normalize inputs\n",
       "scaler = StandardScaler()\n",
       "\n",
       "expRun.log_params({'solver': args.solver, 'penalty': args.penalty})\n",
       "\n",
       "# define pipeline\n",
       "pipe = Pipeline(steps=[(\"scaler\", scaler), (\"logistic\", logistic)])\n",
       "\n",
       "# define grid search model\n",
       "model = pipe.fit(X_train, y_train)\n",
       "\n",
       "# test evaluations:\n",
       "y_pred = model.predict(X_test)\n",
       "test_acc = metrics.accuracy_score(y_test, y_pred) \n",
       "test_prec = metrics.precision_score(y_test, y_pred)\n",
       "test_rec = metrics.recall_score(y_test, y_pred)\n",
       "test_rocauc = metrics.roc_auc_score(y_test, y_pred)\n",
       "expRun.log_metrics({'test_accuracy': test_acc, 'test_precision': test_prec, 'test_recall': test_rec, 'test_roc_auc': test_rocauc})\n",
       "\n",
       "# val evaluations:\n",
       "y_pred_val = model.predict(X_val)\n",
       "val_acc = metrics.accuracy_score(y_val, y_pred_val) \n",
       "val_prec = metrics.precision_score(y_val, y_pred_val)\n",
       "val_rec = metrics.recall_score(y_val, y_pred_val)\n",
       "val_rocauc = metrics.roc_auc_score(y_val, y_pred_val)\n",
       "expRun.log_metrics({'validation_accuracy': val_acc, 'validation_precision': val_prec, 'validation_recall': val_rec, 'validation_roc_auc': val_rocauc})\n",
       "\n",
       "# training evaluations:\n",
       "y_pred_training = model.predict(X_train)\n",
       "training_acc = metrics.accuracy_score(y_train, y_pred_training) \n",
       "training_prec = metrics.precision_score(y_train, y_pred_training)\n",
       "training_rec = metrics.recall_score(y_train, y_pred_training)\n",
       "training_rocauc = metrics.roc_auc_score(y_train, y_pred_training)\n",
       "expRun.log_metrics({'training_accuracy': training_acc, 'training_precision':training_prec, 'training_recall': training_rec, 'training_roc_auc': training_rocauc})\n",
       "\n",
       "# output the model save files\n",
       "with open('model.pkl','wb') as f:\n",
       "    pickle.dump(model,f)\n",
       "    \n",
       "# Upload the model to GCS\n",
       "bucket = storage.Client().bucket(args.bucket)\n",
       "blob = bucket.blob(args.blob)\n",
       "blob.upload_from_filename('model.pkl')\n",
       "\n",
       "expRun.log_params({'model.save': f'{args.uri}/models/{args.timestamp}/model'})\n",
       "expRun.end_run()\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCRIPT_PATH = './code/train.py'\n",
    "\n",
    "with open(SCRIPT_PATH, 'r') as file:\n",
    "    data = file.read()\n",
    "md(f\"```python\\n\\n{data}\\n```\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc76034-3171-4d2d-82ac-be9b77b7fefc",
   "metadata": {},
   "source": [
    "### Construct Python Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1db8322e-b654-4788-9fe9-69f44e976486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'temp/04e'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a1fe610-d832-4aa1-88c8-f36a31de5024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a2ad71-43e7-4219-b8ef-4ab771b1a5ed",
   "metadata": {},
   "source": [
    "#### Create the folder structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b69fb3f7-45f3-4df0-ad5d-853a930ddc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(DIR + f'/src/{EXPERIMENT}_trainer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e73669e3-76aa-4213-9ce9-fc85531c51a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp/04e\n",
      "temp/04e/src\n",
      "temp/04e/src/04e_trainer\n"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk(DIR):\n",
    "    print(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3aded1-a7a2-4477-8673-2315c54cbf27",
   "metadata": {},
   "source": [
    "#### Add files to directory\n",
    "Copy the `./code/train.py` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9081c6cf-1140-47af-9448-01ce0fb076b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.copyfile(SCRIPT_PATH, f'{DIR}/src/{EXPERIMENT}_trainer/train.py')\n",
    "with open(f'{DIR}/src/{EXPERIMENT}_trainer/__init__.py', 'w') as file: pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15c5b5a-5b88-4835-b5ee-1f9cf8d65dc2",
   "metadata": {},
   "source": [
    "create `setup.py` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e925ec81-f329-46c3-99dd-e2bcc84e67d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing temp/04e/src/setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {DIR}/src/setup.py\n",
    "from setuptools import setup\n",
    "from setuptools import find_packages\n",
    "\n",
    "REQUIRED_PACKAGES = ['google-cloud-aiplatform', 'protobuf',  'db-dtypes>=1.0.0', 'google-auth>=2.6.0', 'google-cloud-bigquery>=3.0.1']\n",
    "\n",
    "setup(\n",
    "    name = '04e_trainer',\n",
    "    version = '0.1',\n",
    "    install_requires = REQUIRED_PACKAGES, \n",
    "    packages = find_packages(),\n",
    "    include_package_data = True,\n",
    "    description='Training Package'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf53f83d-df07-4cb0-8c94-e9136f4d8d10",
   "metadata": {},
   "source": [
    "add `__init__.py` file to the trainer modules folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54260a38-1ad9-4185-9336-0bfb1824dcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!touch {DIR}/src/{EXPERIMENT}_trainer/__init__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa211dee-2d69-497a-85d4-d3ddb2c7fd37",
   "metadata": {},
   "source": [
    "list directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f0dc96a-71d7-468a-9776-2127b5c2fb2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp/04e/src/setup.py\n",
      "temp/04e/src/04e_trainer/__init__.py\n",
      "temp/04e/src/04e_trainer/train.py\n"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk(DIR):\n",
    "    for f in files:\n",
    "        print(os.path.join(root, f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46a340a-55ff-4dd3-9f2a-265619412358",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Build the Python distribution archives:\n",
    "\n",
    "The build process creates both a `.tar.gz` source distribution and a `.whl` built distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "208a4571-06d9-4113-afee-01686cd08e83",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mikegoodman/Documents/developer/git_repos/vertex-ai-mlops/04 - scikit-learn/temp/04e\n",
      "a src\n",
      "a src/04e_trainer\n",
      "a src/setup.py\n",
      "a src/04e_trainer/__init__.py\n",
      "a src/04e_trainer/train.py\n",
      "/Users/mikegoodman/Documents/developer/git_repos/vertex-ai-mlops/04 - scikit-learn/temp\n",
      "/Users/mikegoodman/Documents/developer/git_repos/vertex-ai-mlops/04 - scikit-learn\n"
     ]
    }
   ],
   "source": [
    "%cd {DIR}\n",
    "\n",
    "!rm -f src.tar src.tar.gz\n",
    "!tar cvf src.tar src\n",
    "!gzip src.tar\n",
    "\n",
    "%cd ..\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e62b32-a8e2-4ccd-a37e-53eabb04402f",
   "metadata": {},
   "source": [
    "list directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57b490b5-9fe6-4682-b474-b6e967ed5567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp/04e/src.tar.gz\n",
      "temp/04e/src/setup.py\n",
      "temp/04e/src/04e_trainer/__init__.py\n",
      "temp/04e/src/04e_trainer/train.py\n"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk(DIR):\n",
    "    for f in files:\n",
    "        print(os.path.join(root, f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db6a8ea-9d65-43fa-ae6c-a71a75fb234f",
   "metadata": {},
   "source": [
    "#### Copy to GCS\n",
    "\n",
    "Here the folder structure for DIR will be copied to the GCS Bucket used across this project.  This section uses skills that are discussed in more detail in the [Python Client for GCS](../Tips/Python%20Client%20for%20GCS.ipynb) notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313205cf-4d3d-4c8f-8c1f-561d760a6c1a",
   "metadata": {},
   "source": [
    "List buckets in project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c85dde48-64f3-404b-aea8-afe82ee61179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Bucket: artifacts.mg-ce-demos.appspot.com>,\n",
       " <Bucket: cloud-ai-platform-585d7202-46a7-4364-961f-f1aed4f943a3>,\n",
       " <Bucket: dataflow-staging-us-central1-633472233130>,\n",
       " <Bucket: dataprep-staging-0b868edb-9e2e-49a0-9c95-1eb997f327be>,\n",
       " <Bucket: gcf-sources-633472233130-us-central1>,\n",
       " <Bucket: mg-ce-demos>,\n",
       " <Bucket: mg-ce-demos-aip-20220314182836>,\n",
       " <Bucket: mg-ce-demos-bucket>,\n",
       " <Bucket: mg-ce-demos-l300>,\n",
       " <Bucket: mg-ce-demos-vertex-staging-us-central1>,\n",
       " <Bucket: mg-ce-demos_cloudbuild>,\n",
       " <Bucket: mg-ce-demosaip-20220314191437>,\n",
       " <Bucket: us.artifacts.mg-ce-demos.appspot.com>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(gcs.list_buckets())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53357214-1a47-4b1a-acfa-354ddf7c6f84",
   "metadata": {},
   "source": [
    "Get the bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5da58857-96e5-4e00-801e-e85a5aa33e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = gcs.lookup_bucket(PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32927b3f-f428-4ed8-aaf7-1c643004a91f",
   "metadata": {},
   "source": [
    "copy files to GCS bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "26dda773-8c06-4822-8e5d-85feccde27c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://temp/04e/src.tar.gz [Content-Type=application/x-tar]...\n",
      "/ [1 files][  2.3 KiB/  2.3 KiB]                                                \n",
      "Operation completed over 1 objects/2.3 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp {DIR}/src.tar.gz {URI}/{TIMESTAMP}/src.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3b6c4dd7-ee00-40ee-9f00-d2c4ef30b962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the bucket directly here:\n",
      "https://console.cloud.google.com/storage/browser/mg-ce-demos/04/04e;tab=objects&project=mg-ce-demos\n"
     ]
    }
   ],
   "source": [
    "print(f\"View the bucket directly here:\\nhttps://console.cloud.google.com/storage/browser/{PROJECT_ID}/{SERIES}/{EXPERIMENT};tab=objects&project={PROJECT_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bb5496-8fbe-440d-a71e-e6302c8dbfc2",
   "metadata": {},
   "source": [
    "list files in bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3a8d4a87-9489-49d4-a90b-13b8002854f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/04e/20230131095534/src.tar.gz\n"
     ]
    }
   ],
   "source": [
    "for blob in list(bucket.list_blobs(prefix = f'{SERIES}/{EXPERIMENT}/')):\n",
    "    print(blob.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d5e363-bd93-478c-95aa-ae87e042918e",
   "metadata": {},
   "source": [
    "get a list of source distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "08321796-9baf-4bbb-99aa-f0ca04b5c121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gs://mg-ce-demos/04/04e/20230131095534/src.tar.gz']\n",
      "['gs://mg-ce-demos/04/04e/20230131095534/src.tar.gz']\n"
     ]
    }
   ],
   "source": [
    "SOURCE_LIST = [f'gs://{PROJECT_ID}/{blob.name}' for blob in list(bucket.list_blobs(prefix = f'{SERIES}/{EXPERIMENT}/')) if blob.name[-7:] == '.tar.gz']\n",
    "print(SOURCE_LIST)\n",
    "SOURCE = [SOURCE_LIST[-1]]\n",
    "print(SOURCE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d30ca0",
   "metadata": {},
   "source": [
    "### Setup Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6a7c3d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "CMDARGS = [\n",
    "    \"--penalty=\" + PENALTY,\n",
    "    \"--solver=\" + SOLVER,\n",
    "    \"--var_target=\" + VAR_TARGET,\n",
    "    \"--var_omit=\" + VAR_OMIT,\n",
    "    \"--project_id=\" + PROJECT_ID,\n",
    "    \"--bq_project=\" + BQ_PROJECT,\n",
    "    \"--bq_dataset=\" + BQ_DATASET,\n",
    "    \"--bq_table=\" + BQ_TABLE,\n",
    "    \"--region=\" + REGION,\n",
    "    \"--experiment=\" + EXPERIMENT,\n",
    "    \"--series=\" + SERIES,\n",
    "    \"--experiment_name=\" + EXPERIMENT_NAME,\n",
    "    \"--run_name=\" + RUN_NAME,\n",
    "    \"--bucket=\" + BUCKET,\n",
    "    \"--uri=\" + URI,\n",
    "    \"--blob=\" + BLOB,\n",
    "    \"--timestamp=\" + TIMESTAMP\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e2f6a707",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingJob = aiplatform.CustomPythonPackageTrainingJob(\n",
    "    display_name = f'{SERIES}_{EXPERIMENT}_{TIMESTAMP}',\n",
    "    python_package_gcs_uri = SOURCE,\n",
    "    python_module_name = f\"{EXPERIMENT}_trainer.train\",\n",
    "    container_uri = TRAIN_IMAGE,\n",
    "    model_serving_container_image_uri = DEPLOY_IMAGE,\n",
    "    staging_bucket = f\"{URI}/models/{TIMESTAMP}\",\n",
    "    labels = {'series' : f'{SERIES}', 'experiment' : f'{EXPERIMENT}', 'experiment_name' : f'{EXPERIMENT_NAME}', 'run_name' : f'{RUN_NAME}'}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16d5166",
   "metadata": {},
   "source": [
    "### Run Training Job AND Upload The Model\n",
    "The training job will automatically upload the model to the Vertex AI Model Registy and return the link to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ed9b1dd5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a new model, creating in model registry\n",
      "Training Output directory:\n",
      "gs://mg-ce-demos/04/04e/models/20230131095534 \n",
      "View Training:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/6689410189130465280?project=633472233130\n",
      "View backing custom job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/1668081322565828608?project=633472233130\n",
      "CustomPythonPackageTrainingJob projects/633472233130/locations/us-central1/trainingPipelines/6689410189130465280 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "CustomPythonPackageTrainingJob projects/633472233130/locations/us-central1/trainingPipelines/6689410189130465280 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "CustomPythonPackageTrainingJob projects/633472233130/locations/us-central1/trainingPipelines/6689410189130465280 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "CustomPythonPackageTrainingJob projects/633472233130/locations/us-central1/trainingPipelines/6689410189130465280 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "CustomPythonPackageTrainingJob projects/633472233130/locations/us-central1/trainingPipelines/6689410189130465280 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "CustomPythonPackageTrainingJob run completed. Resource name: projects/633472233130/locations/us-central1/trainingPipelines/6689410189130465280\n",
      "Model available at projects/633472233130/locations/us-central1/models/model_04_04e\n"
     ]
    }
   ],
   "source": [
    "modelmatch = aiplatform.Model.list(filter = f'display_name={SERIES}_{EXPERIMENT} AND labels.series={SERIES} AND labels.experiment={EXPERIMENT}')\n",
    "\n",
    "upload_model = True\n",
    "if modelmatch:\n",
    "    print(\"Model Already in Registry:\")\n",
    "    if RUN_NAME in modelmatch[0].version_aliases:\n",
    "        print(\"This version already loaded, no action taken.\")\n",
    "        upload_model = False\n",
    "        model = aiplatform.Model(model_name = modelmatch[0].resource_name)\n",
    "    else:\n",
    "        print('Loading model as new default version.')\n",
    "        parent_model = modelmatch[0].resource_name\n",
    "else:\n",
    "    print('This is a new model, creating in model registry')\n",
    "    parent_model = ''\n",
    "    \n",
    "if upload_model:\n",
    "    model = trainingJob.run(\n",
    "        model_display_name = f'{SERIES}_{EXPERIMENT}',\n",
    "        model_labels = {'series' : f'{SERIES}', 'experiment' : f'{EXPERIMENT}', 'experiment_name' : f'{EXPERIMENT_NAME}', 'run_name' : f'{RUN_NAME}'},\n",
    "        model_id = f'model_{SERIES}_{EXPERIMENT}',\n",
    "        parent_model = parent_model,\n",
    "        is_default_version = True,\n",
    "        model_version_aliases = [RUN_NAME],\n",
    "        model_version_description = RUN_NAME,\n",
    "        base_output_dir = f\"{URI}/models/{TIMESTAMP}\",\n",
    "        service_account = SERVICE_ACCOUNT,\n",
    "        args = CMDARGS,\n",
    "        replica_count = 1,\n",
    "        machine_type = TRAIN_COMPUTE,\n",
    "        accelerator_count = 0,\n",
    "        #tensorboard = tb.resource_name\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bd4c1f-2013-4968-9f2b-b07a9dc10c01",
   "metadata": {},
   "source": [
    "Get the backing Custom Job for the Training Pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "47f7697b-c2f3-4f2c-9e3b-3db869a03c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "clientPL = aiplatform.gapic.PipelineServiceClient(client_options = {'api_endpoint': f'{REGION}-aiplatform.googleapis.com'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b7fd024b-f7e1-4805-8a10-7aa6b827b9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.protobuf.json_format import MessageToDict\n",
    "\n",
    "backingCustomJob = MessageToDict(clientPL.get_training_pipeline(name = trainingJob.resource_name)._pb)['trainingTaskMetadata']['backingCustomJob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1757724f-095f-41e5-aa80-d4f11ac31568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('projects/633472233130/locations/us-central1/customJobs/1668081322565828608',\n",
       " '04_04e_20230131095534-custom-job')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customJob = aiplatform.CustomJob.get(backingCustomJob)\n",
    "customJob.resource_name, customJob.display_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff0daa0-93db-48fc-b3d3-75075c02484d",
   "metadata": {},
   "source": [
    "Create hyperlinks to job and tensorboard here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "50b0944f-73f4-456b-905c-c5a80b51806b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review the Training Pipeline here:\n",
      "https://console.cloud.google.com/vertex-ai/training/training-pipelines?project=mg-ce-demos\n",
      "Review the Custom Job here:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/training/1668081322565828608/cpu?cloudshell=false&project=mg-ce-demos\n",
      "Review the model in the Vertex AI Model Registry:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/models/model_04_04e?project=mg-ce-demos\n"
     ]
    }
   ],
   "source": [
    "job_link = f\"https://console.cloud.google.com/vertex-ai/locations/{REGION}/training/{customJob.resource_name.split('/')[-1]}/cpu?cloudshell=false&project={PROJECT_ID}\"\n",
    "#board_link = f\"https://{REGION}.tensorboard.googleusercontent.com/experiment/{tb.resource_name.replace('/', '+')}+experiments+{customJob.name.split('/')[-1]}\"\n",
    "\n",
    "print(f'Review the Training Pipeline here:\\nhttps://console.cloud.google.com/vertex-ai/training/training-pipelines?project={PROJECT_ID}')\n",
    "print(f'Review the Custom Job here:\\n{job_link}')\n",
    "#print(f'Review the TensorBoard From the Job here:\\n{board_link}')\n",
    "print(f'Review the model in the Vertex AI Model Registry:\\nhttps://console.cloud.google.com/vertex-ai/locations/{REGION}/models/{model.name}?project={PROJECT_ID}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc02a2b6",
   "metadata": {},
   "source": [
    "---\n",
    "## Serving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c27ed6-ff52-47a7-8e34-3fb1aaa5e235",
   "metadata": {},
   "source": [
    "### Vertex AI Experiment Update and Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d35467ee-5ea5-4423-ac21-ba0881598166",
   "metadata": {},
   "outputs": [],
   "source": [
    "expRun = aiplatform.ExperimentRun(run_name = RUN_NAME, experiment = EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9d947289-5c62-4feb-9d0a-8429c742b6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "expRun.log_params({\n",
    "    'model.uri': model.uri,\n",
    "    'model.display_name': model.display_name,\n",
    "    'model.name': model.name,\n",
    "    'model.resource_name': model.resource_name,\n",
    "    'model.version_id': model.version_id,\n",
    "    'model.versioned_resource_name': model.versioned_resource_name,\n",
    "    'trainingPipelines.display_name': trainingJob.display_name,\n",
    "    'trainingPipelines.resource_name': trainingJob.resource_name,\n",
    "    'customJobs.display_name': customJob.display_name,\n",
    "    'customJobs.resource_name': customJob.resource_name,\n",
    "    'customJobs.link': job_link,\n",
    "    #'customJobs.tensorboard': board_link\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da31e5a0-1570-4714-82c3-3fb0c833db3f",
   "metadata": {},
   "source": [
    "Complete the experiment run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f4134d53-cea2-42da-a4d6-b6c71e835b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "expRun.update_state(state = aiplatform.gapic.Execution.State.COMPLETE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d17ccfe-5942-4dcb-b06a-d2ba8c270d2c",
   "metadata": {},
   "source": [
    "Retrieve the experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "57b4e1d3-9836-4aac-9286-c0a07d4ccdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = aiplatform.Experiment(experiment_name = EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "65d603e1-b034-4469-a245-de9ab1334d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>run_name</th>\n",
       "      <th>run_type</th>\n",
       "      <th>state</th>\n",
       "      <th>param.model.version_id</th>\n",
       "      <th>param.customJobs.link</th>\n",
       "      <th>param.model.save</th>\n",
       "      <th>param.model.display_name</th>\n",
       "      <th>param.var_split</th>\n",
       "      <th>param.model.versioned_resource_name</th>\n",
       "      <th>...</th>\n",
       "      <th>metric.test_precision</th>\n",
       "      <th>metric.training_roc_auc</th>\n",
       "      <th>metric.test_recall</th>\n",
       "      <th>metric.training_recall</th>\n",
       "      <th>metric.validation_accuracy</th>\n",
       "      <th>metric.validation_roc_auc</th>\n",
       "      <th>metric.validation_recall</th>\n",
       "      <th>metric.training_accuracy</th>\n",
       "      <th>metric.training_precision</th>\n",
       "      <th>metric.test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>experiment-04-04e-sklearn-classification-logis...</td>\n",
       "      <td>run-20230131095534</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>1</td>\n",
       "      <td>https://console.cloud.google.com/vertex-ai/loc...</td>\n",
       "      <td>gs://mg-ce-demos/04/04e/models/20230131095534/...</td>\n",
       "      <td>04_04e</td>\n",
       "      <td>splits</td>\n",
       "      <td>projects/633472233130/locations/us-central1/mo...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.809018</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.618182</td>\n",
       "      <td>0.999016</td>\n",
       "      <td>0.774422</td>\n",
       "      <td>0.54902</td>\n",
       "      <td>0.99921</td>\n",
       "      <td>0.878229</td>\n",
       "      <td>0.803501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     experiment_name            run_name  \\\n",
       "0  experiment-04-04e-sklearn-classification-logis...  run-20230131095534   \n",
       "\n",
       "               run_type     state param.model.version_id  \\\n",
       "0  system.ExperimentRun  COMPLETE                      1   \n",
       "\n",
       "                               param.customJobs.link  \\\n",
       "0  https://console.cloud.google.com/vertex-ai/loc...   \n",
       "\n",
       "                                    param.model.save param.model.display_name  \\\n",
       "0  gs://mg-ce-demos/04/04e/models/20230131095534/...                   04_04e   \n",
       "\n",
       "  param.var_split                param.model.versioned_resource_name  ...  \\\n",
       "0          splits  projects/633472233130/locations/us-central1/mo...  ...   \n",
       "\n",
       "  metric.test_precision metric.training_roc_auc metric.test_recall  \\\n",
       "0              0.894737                0.809018           0.607143   \n",
       "\n",
       "  metric.training_recall metric.validation_accuracy metric.validation_roc_auc  \\\n",
       "0               0.618182                   0.999016                  0.774422   \n",
       "\n",
       "  metric.validation_recall metric.training_accuracy metric.training_precision  \\\n",
       "0                  0.54902                  0.99921                  0.878229   \n",
       "\n",
       "  metric.test_roc_auc  \n",
       "0            0.803501  \n",
       "\n",
       "[1 rows x 37 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.get_data_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203610f1-fc41-4e06-b4b7-666ee1eccd92",
   "metadata": {},
   "source": [
    "Review the Experiments TensorBoard to compare runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3ce18389-8484-4d5d-a30e-c4841eb52e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f\"The Experiment TensorBoard Link:\\nhttps://{REGION}.tensorboard.googleusercontent.com/experiment/{tb.resource_name.replace('/', '+')}+experiments+{exp.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "37b9fded-da22-4c24-8d8c-54fefb07e1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#expRun.get_time_series_data_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126bfdad-d07d-4d9d-99e5-66b738696c11",
   "metadata": {},
   "source": [
    "### Compare This Run Using Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98f07dd-8a84-43b1-bd6f-f9ee29ca97d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "Get a list of all experiments in this project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bb42949a-a4ab-4ef0-b163-ce89d2b58c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = aiplatform.Experiment.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9328219-b085-436d-8be8-f68412acc45f",
   "metadata": {},
   "source": [
    "Remove experiments not in the SERIES:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d9fd9424-3b50-4921-868e-e08eb6e2c033",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [e for e in experiments if e.name.split('-')[0:2] == ['experiment', SERIES]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80593d05-e6e5-465d-ab7e-4467f45dadae",
   "metadata": {},
   "source": [
    "Combine the runs from all experiments in SERIES into a single dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "eb7352f4-d50a-43c1-a342-a15ba06b1ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment-04-04e-sklearn-classification-logistric-regression\n",
      "experiment-04-04d-sklearn-classification-logistric-regression\n",
      "experiment-04-04-sklearn-classification-logistic-regression\n",
      "experiment-04-04c-sklearn-classification-logistric-regression\n",
      "experiment-04-04b-sklearn-classification-logistric-regression\n",
      "experiment-04-04a-sklearn-classification-logistric-regression\n",
      "experiment-04-04-sklearn-classification-sklearn-logistic-regression\n",
      "experiment-04-04-tf-classification-sklearn-logistic-regression\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for experiment in experiments:\n",
    "        results.append(experiment.get_data_frame())\n",
    "        print(experiment.name)\n",
    "results = pd.concat(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1d6415-e38a-4f67-a333-66d944d4c571",
   "metadata": {},
   "source": [
    "Create ranks for models within experiment and across the entire SERIES:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7cd876a4-7984-4687-b42b-c829952c2ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>run_name</th>\n",
       "      <th>param.model.display_name</th>\n",
       "      <th>param.model.version_id</th>\n",
       "      <th>metric.test_roc_auc</th>\n",
       "      <th>series_rank</th>\n",
       "      <th>experiment_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>experiment-04-04-sklearn-classification-logist...</td>\n",
       "      <td>run-20221102155936</td>\n",
       "      <td>04_04</td>\n",
       "      <td>2</td>\n",
       "      <td>0.803501</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>experiment-04-04-sklearn-classification-logist...</td>\n",
       "      <td>run-20221104083407</td>\n",
       "      <td>04_04</td>\n",
       "      <td>3</td>\n",
       "      <td>0.803501</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>experiment-04-04-sklearn-classification-logist...</td>\n",
       "      <td>run-20221104090606</td>\n",
       "      <td>04_04</td>\n",
       "      <td>4</td>\n",
       "      <td>0.803501</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>experiment-04-04-sklearn-classification-logist...</td>\n",
       "      <td>run-20221107104554</td>\n",
       "      <td>04_04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.803501</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>experiment-04-04-sklearn-classification-logist...</td>\n",
       "      <td>run-20221108143538</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>experiment-04-04c-sklearn-classification-logis...</td>\n",
       "      <td>run-20221206105306</td>\n",
       "      <td>04_04c</td>\n",
       "      <td>3</td>\n",
       "      <td>0.803501</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>experiment-04-04c-sklearn-classification-logis...</td>\n",
       "      <td>run-20221220083637</td>\n",
       "      <td>04_04c</td>\n",
       "      <td>4</td>\n",
       "      <td>0.803501</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>experiment-04-04c-sklearn-classification-logis...</td>\n",
       "      <td>run-20230125100727</td>\n",
       "      <td>04_04c</td>\n",
       "      <td>5</td>\n",
       "      <td>0.803501</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>experiment-04-04d-sklearn-classification-logis...</td>\n",
       "      <td>run-20230131091335</td>\n",
       "      <td>04_04d</td>\n",
       "      <td>1</td>\n",
       "      <td>0.803501</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>experiment-04-04e-sklearn-classification-logis...</td>\n",
       "      <td>run-20230131095534</td>\n",
       "      <td>04_04e</td>\n",
       "      <td>1</td>\n",
       "      <td>0.803501</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      experiment_name            run_name  \\\n",
       "29  experiment-04-04-sklearn-classification-logist...  run-20221102155936   \n",
       "28  experiment-04-04-sklearn-classification-logist...  run-20221104083407   \n",
       "27  experiment-04-04-sklearn-classification-logist...  run-20221104090606   \n",
       "26  experiment-04-04-sklearn-classification-logist...  run-20221107104554   \n",
       "25  experiment-04-04-sklearn-classification-logist...  run-20221108143538   \n",
       "..                                                ...                 ...   \n",
       "32  experiment-04-04c-sklearn-classification-logis...  run-20221206105306   \n",
       "31  experiment-04-04c-sklearn-classification-logis...  run-20221220083637   \n",
       "30  experiment-04-04c-sklearn-classification-logis...  run-20230125100727   \n",
       "1   experiment-04-04d-sklearn-classification-logis...  run-20230131091335   \n",
       "0   experiment-04-04e-sklearn-classification-logis...  run-20230131095534   \n",
       "\n",
       "   param.model.display_name param.model.version_id  metric.test_roc_auc  \\\n",
       "29                    04_04                      2             0.803501   \n",
       "28                    04_04                      3             0.803501   \n",
       "27                    04_04                      4             0.803501   \n",
       "26                    04_04                      5             0.803501   \n",
       "25                      NaN                    NaN                  NaN   \n",
       "..                      ...                    ...                  ...   \n",
       "32                   04_04c                      3             0.803501   \n",
       "31                   04_04c                      4             0.803501   \n",
       "30                   04_04c                      5             0.803501   \n",
       "1                    04_04d                      1             0.803501   \n",
       "0                    04_04e                      1             0.803501   \n",
       "\n",
       "    series_rank  experiment_rank  \n",
       "29          1.0              1.0  \n",
       "28          1.0              1.0  \n",
       "27          1.0              1.0  \n",
       "26          1.0              1.0  \n",
       "25          NaN              NaN  \n",
       "..          ...              ...  \n",
       "32          1.0              1.0  \n",
       "31          1.0              1.0  \n",
       "30          1.0              1.0  \n",
       "1           1.0              1.0  \n",
       "0           1.0              1.0  \n",
       "\n",
       "[76 rows x 7 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ranker(metric = 'metric.test_roc_auc'):\n",
    "    ranks = results[['experiment_name', 'run_name', 'param.model.display_name', 'param.model.version_id', metric]].copy().reset_index(drop = True)\n",
    "    ranks['series_rank'] = ranks[metric].rank(method = 'dense', ascending = False)\n",
    "    ranks['experiment_rank'] = ranks.groupby('experiment_name')[metric].rank(method = 'dense', ascending = False)\n",
    "    return ranks.sort_values(by = ['experiment_name', 'run_name'])\n",
    "    \n",
    "ranks = ranker('metric.test_roc_auc')\n",
    "ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dae6903c-1986-47f8-b1e7-f05777ca6fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>run_name</th>\n",
       "      <th>param.model.display_name</th>\n",
       "      <th>param.model.version_id</th>\n",
       "      <th>metric.test_roc_auc</th>\n",
       "      <th>series_rank</th>\n",
       "      <th>experiment_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>experiment-04-04e-sklearn-classification-logis...</td>\n",
       "      <td>run-20230131095534</td>\n",
       "      <td>04_04e</td>\n",
       "      <td>1</td>\n",
       "      <td>0.803501</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     experiment_name            run_name  \\\n",
       "0  experiment-04-04e-sklearn-classification-logis...  run-20230131095534   \n",
       "\n",
       "  param.model.display_name param.model.version_id  metric.test_roc_auc  \\\n",
       "0                   04_04e                      1             0.803501   \n",
       "\n",
       "   series_rank  experiment_rank  \n",
       "0          1.0              1.0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_rank = ranks.loc[(ranks['param.model.display_name'] == model.display_name) & (ranks['param.model.version_id'] == model.version_id)]\n",
    "current_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1e45ccb7-8f93-4c12-9b7d-666fd8fa238c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current model is ranked 1.0 within this experiment and 1.0 across this series.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The current model is ranked {current_rank['experiment_rank'].iloc[0]} within this experiment and {current_rank['series_rank'].iloc[0]} across this series.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c33a3c-a8ce-4548-8249-3e4fd29d0ba7",
   "metadata": {},
   "source": [
    "### Create/Retrieve The Endpoint For This Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2cc28d98-b525-4385-9b95-489bf574f967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Exists: projects/633472233130/locations/us-central1/endpoints/1476393427452035072\n",
      "Review the Endpoint in the Console:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/endpoints/1476393427452035072?project=mg-ce-demos\n"
     ]
    }
   ],
   "source": [
    "endpoints = aiplatform.Endpoint.list(filter = f\"labels.series={SERIES}\")\n",
    "if endpoints:\n",
    "    endpoint = endpoints[0]\n",
    "    print(f\"Endpoint Exists: {endpoints[0].resource_name}\")\n",
    "else:\n",
    "    endpoint = aiplatform.Endpoint.create(\n",
    "        display_name = f\"{SERIES}\",\n",
    "        labels = {'series' : f\"{SERIES}\"}    \n",
    "    )\n",
    "    print(f\"Endpoint Created: {endpoint.resource_name}\")\n",
    "    \n",
    "print(f'Review the Endpoint in the Console:\\nhttps://console.cloud.google.com/vertex-ai/locations/{REGION}/endpoints/{endpoint.name}?project={PROJECT_ID}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0a538bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'04'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint.display_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0a0029bd-9744-4449-91f0-56ef7ca5e535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'950149570212397056': 100}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint.traffic_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "85d06eba-82dc-4d50-8405-800d756e3584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[id: \"950149570212397056\"\n",
       " model: \"projects/633472233130/locations/us-central1/models/model_04_04d\"\n",
       " display_name: \"04_04d\"\n",
       " create_time {\n",
       "   seconds: 1675175537\n",
       "   nanos: 209224000\n",
       " }\n",
       " dedicated_resources {\n",
       "   machine_spec {\n",
       "     machine_type: \"n1-standard-4\"\n",
       "   }\n",
       "   min_replica_count: 1\n",
       "   max_replica_count: 1\n",
       " }\n",
       " model_version_id: \"1\"]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployed_models = endpoint.list_models()\n",
    "deployed_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed5350c-bb04-4b36-8afa-5b91e0baf6f3",
   "metadata": {},
   "source": [
    "### Should This Model Be Deployed?\n",
    "Is it better than the model already deployed on the endpoint?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5db9b246-2b03-4313-b620-5fc8029280b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current model is ranked better (1.0) than a currently deployed model (1.0).\n"
     ]
    }
   ],
   "source": [
    "deploy = False\n",
    "if deployed_models:\n",
    "    for deployed_model in deployed_models:\n",
    "        deployed_rank = ranks.loc[(ranks['param.model.display_name'] == deployed_model.display_name) & (ranks['param.model.version_id'] == deployed_model.model_version_id)]['series_rank'].iloc[0]\n",
    "        model_rank = current_rank['series_rank'].iloc[0]\n",
    "        if deployed_model.display_name == model.display_name and deployed_model.model_version_id == model.version_id:\n",
    "            print(f'The current model/version is already deployed.')\n",
    "            break\n",
    "        elif model_rank <= deployed_rank:\n",
    "            deploy = True\n",
    "            print(f'The current model is ranked better ({model_rank}) than a currently deployed model ({deployed_rank}).')\n",
    "            break\n",
    "    if deploy == False: print(f'The current model is ranked worse ({model_rank}) than a currently deployed model ({deployed_rank})')\n",
    "else: \n",
    "    deploy = True\n",
    "    print('No models currently deployed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81269f1c-16ad-4428-aa14-d2bbfa553227",
   "metadata": {},
   "source": [
    "### Deploy Model To Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2aa50205-0f93-423e-a622-4659f81e8674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying model with 100% of traffic...\n",
      "Deploying Model projects/633472233130/locations/us-central1/models/model_04_04e to Endpoint : projects/633472233130/locations/us-central1/endpoints/1476393427452035072\n",
      "Deploy Endpoint model backing LRO: projects/633472233130/locations/us-central1/endpoints/1476393427452035072/operations/4042241043662372864\n",
      "Endpoint model deployed. Resource name: projects/633472233130/locations/us-central1/endpoints/1476393427452035072\n"
     ]
    }
   ],
   "source": [
    "if deploy:\n",
    "    print(f'Deploying model with 100% of traffic...')\n",
    "    endpoint.deploy(\n",
    "        model = model,\n",
    "        deployed_model_display_name = model.display_name,\n",
    "        traffic_percentage = 100,\n",
    "        machine_type = DEPLOY_COMPUTE,\n",
    "        min_replica_count = 1,\n",
    "        max_replica_count = 1\n",
    "    )\n",
    "else: print(f'Not deploying - current model is worse ({model_rank}) than the currently deployed model ({deployed_rank})') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56b7e5a-4556-4e40-8450-a2e1eedee0f2",
   "metadata": {},
   "source": [
    "### Remove Deployed Models without Traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6945f51a-0c06-4760-bbfe-f2b9d1e7d38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 04_04e with version 1 has traffic = 100\n",
      "Undeploying Endpoint model: projects/633472233130/locations/us-central1/endpoints/1476393427452035072\n",
      "Undeploy Endpoint model backing LRO: projects/633472233130/locations/us-central1/endpoints/1476393427452035072/operations/4870903375098544128\n",
      "Endpoint model undeployed. Resource name: projects/633472233130/locations/us-central1/endpoints/1476393427452035072\n",
      "Undeploying 04_04d with version 1 because it has no traffic.\n"
     ]
    }
   ],
   "source": [
    "for deployed_model in endpoint.list_models():\n",
    "    if deployed_model.id in endpoint.traffic_split:\n",
    "        print(f\"Model {deployed_model.display_name} with version {deployed_model.model_version_id} has traffic = {endpoint.traffic_split[deployed_model.id]}\")\n",
    "    else:\n",
    "        endpoint.undeploy(deployed_model_id = deployed_model.id)\n",
    "        print(f\"Undeploying {deployed_model.display_name} with version {deployed_model.model_version_id} because it has no traffic.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d90c6900-de81-4fcd-af0b-ba6b3925724d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'146257036726763520': 100}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint.traffic_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "14cbf4a3-9e32-4158-a9ee-0cfca92e8574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[id: \"146257036726763520\"\n",
       " model: \"projects/633472233130/locations/us-central1/models/model_04_04e\"\n",
       " display_name: \"04_04e\"\n",
       " create_time {\n",
       "   seconds: 1675178176\n",
       "   nanos: 990976000\n",
       " }\n",
       " dedicated_resources {\n",
       "   machine_spec {\n",
       "     machine_type: \"n1-standard-4\"\n",
       "   }\n",
       "   min_replica_count: 1\n",
       "   max_replica_count: 1\n",
       " }\n",
       " model_version_id: \"1\"]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint.list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4568c3cc-863f-48d6-808d-36e9c32471bb",
   "metadata": {},
   "source": [
    "---\n",
    "## Prediction\n",
    "\n",
    "See many more details on requesting predictions in the [04Tools - Prediction](./04Tools%20-%20Prediction.ipynb) notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8538a303-b8ac-4966-af80-0020477605c1",
   "metadata": {},
   "source": [
    "### Prepare a record for prediction: instance and parameters lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "55c3919f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query = f\"SELECT * FROM {BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE} WHERE splits = 'TEST'\"\n",
    "test = bq.query(test_query).to_dataframe()\n",
    "X_test = test.loc[:, ~test.columns.isin(VAR_OMIT.split('-'))]\n",
    "y_test = test[VAR_TARGET]\n",
    "\n",
    "instances = [X_test.to_dict(orient='split')['data'][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce406c3d",
   "metadata": {},
   "source": [
    "### Get Predictions: Python Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "310c36d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(predictions=[0.0], deployed_model_id='146257036726763520', model_version_id='1', model_resource_name='projects/633472233130/locations/us-central1/models/model_04_04e', explanations=None)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = endpoint.predict(instances=instances)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1577b05f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e015da78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(prediction.predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adfb305",
   "metadata": {},
   "source": [
    "### Get Predictions: REST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8404930e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{DIR}/request.json','w') as file:\n",
    "    file.write(json.dumps({\"instances\": instances}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f512483f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"predictions\": [\n",
      "    0\n",
      "  ],\n",
      "  \"deployedModelId\": \"146257036726763520\",\n",
      "  \"model\": \"projects/633472233130/locations/us-central1/models/model_04_04e\",\n",
      "  \"modelDisplayName\": \"04_04e\",\n",
      "  \"modelVersionId\": \"1\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!curl -X POST \\\n",
    "-H \"Authorization: Bearer \"$(gcloud auth application-default print-access-token) \\\n",
    "-H \"Content-Type: application/json; charset=utf-8\" \\\n",
    "-d @{DIR}/request.json \\\n",
    "https://{REGION}-aiplatform.googleapis.com/v1/{endpoint.resource_name}:predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e780e01b",
   "metadata": {},
   "source": [
    "### Get Predictions: gcloud (CLI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2fef4aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-prediction-aiplatform.googleapis.com/]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "!gcloud beta ai endpoints predict {endpoint.name.rsplit('/',1)[-1]} --region={REGION} --json-request={DIR}/request.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc0f5a8",
   "metadata": {},
   "source": [
    "---\n",
    "## Remove Resources\n",
    "see notebook \"99 - Cleanup\""
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-3.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m94"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
