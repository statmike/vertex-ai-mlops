{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e538e68",
   "metadata": {},
   "source": [
    "![tracker](https://us-central1-vertex-ai-mlops-369716.cloudfunctions.net/pixel-tracking?path=statmike%2Fvertex-ai-mlops%2FDev&file=Work+For+05+-+Prediction+-+Triton+Server.ipynb)\n",
    "<!--- header table --->\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/statmike/vertex-ai-mlops/blob/main/Dev/Work%20For%2005%20-%20Prediction%20-%20Triton%20Server.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\">\n",
    "      <br>Run in<br>Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https%3A%2F%2Fraw.githubusercontent.com%2Fstatmike%2Fvertex-ai-mlops%2Fmain%2FDev%2FWork%2520For%252005%2520-%2520Prediction%2520-%2520Triton%2520Server.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\">\n",
    "      <br>Run in<br>Colab Enterprise\n",
    "    </a>\n",
    "  </td>      \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/statmike/vertex-ai-mlops/blob/main/Dev/Work%20For%2005%20-%20Prediction%20-%20Triton%20Server.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      <br>View on<br>GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/statmike/vertex-ai-mlops/main/Dev/Work%20For%2005%20-%20Prediction%20-%20Triton%20Server.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      <br>Open in<br>Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acb07d2-562a-4a5b-bb3f-2ec56b06b889",
   "metadata": {},
   "source": [
    "# WORK FOR: 05 Prediction - TRITON SERVER\n",
    "\n",
    "Working on Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "ef105296-46b5-4725-b9ae-817fb982848a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'statmike-mlops-349915'"
      ]
     },
     "execution_count": 621,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUCKET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137c047f-3edc-406a-b4d8-c6dad1735da9",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "### Ensemble: Pipeline Instances To All Models And Versions\n",
    "\n",
    "Triton Server has a model abstraction that can be specified with `platform: ensemble` in a `config.pbtxt` file.  This can be added to a model repository like any other model:\n",
    "\n",
    "```\n",
    "    <model-repository-path>/\n",
    "        <model-name>/\n",
    "            [config.pbtxt]\n",
    "            [<output-labels-file> ...]\n",
    "            <version>/\n",
    "                <model-definition-file>\n",
    "            <version>/\n",
    "                <model-definition-file>\n",
    "            ...\n",
    "        <model-name>/\n",
    "            [config.pbtxt]\n",
    "            [<output-labels-file> ...]\n",
    "            <version>/\n",
    "                <model-definition-file>\n",
    "            <version>/\n",
    "                <model-definition-file>\n",
    "        <ensemble-name>/\n",
    "            [config.pbtxt]\n",
    "            <version>/\n",
    "                empty\n",
    "            ...\n",
    "        ...\n",
    "```\n",
    "\n",
    "The ensemble model specification is primarily made up of `ensemble_scheduling` which is a series of steps that map inputs > outputs > inputs ...\n",
    "\n",
    "Reference [Ensemble Models](https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/user_guide/architecture.html?highlight=ensemble#ensemble-models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e580c7-ed43-46cd-b853-8d335af96ad6",
   "metadata": {},
   "source": [
    "List of input feature names to use for constructing the ensemble.  For this model all the input features have the same shape `[1, 1]` and data type `FP32`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "04fbd0ff-7f7f-4d74-b3a1-c1424a733697",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9350f8f2-d2cd-4fd5-920d-7d2167b72e36",
   "metadata": {},
   "source": [
    "Start the `config.pbtxt` construction with a string representing the header:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "58d5a6ad-63d8-4be6-a1ac-830bf2642ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"ensemble\"\n",
      "platform: \"ensemble\"\n",
      "max_batch_size: 4\n"
     ]
    }
   ],
   "source": [
    "ensemble_all = f\"\"\"name: \"ensemble\"\n",
    "platform: \"ensemble\"\n",
    "max_batch_size: 4\"\"\"\n",
    "\n",
    "print(ensemble_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d5cff0-bbfb-4080-86a1-499be4bbf870",
   "metadata": {},
   "source": [
    "Add the `input` specification for the ensemble using the feature names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "id": "2907aeb1-316f-4ff3-a049-92f04711ea2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"ensemble\"\n",
      "platform: \"ensemble\"\n",
      "max_batch_size: 4\n",
      "input [\n",
      "    {\n",
      "        name: \"Time\"\n",
      "        data_type: TYPE_FP32\n",
      "        dims: [ 1 ]\n",
      "    },\n",
      "    \n",
      "\n",
      "\n",
      "<2219 characters hidden>\n",
      "\n",
      "\n",
      " e: \"V28\"\n",
      "        data_type: TYPE_FP32\n",
      "        dims: [ 1 ]\n",
      "    },\n",
      "    {\n",
      "        name: \"Amount\"\n",
      "        data_type: TYPE_FP32\n",
      "        dims: [ 1 ]\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "for n, name in enumerate(feature_names):\n",
    "    if n == 0:\n",
    "        ensemble_all += \"\\ninput [\"\n",
    "    else:\n",
    "        ensemble_all += \",\"\n",
    "    ensemble_all += f\"\"\"\n",
    "    {{\n",
    "        name: \"{name}\"\n",
    "        data_type: TYPE_FP32\n",
    "        dims: [ 1 ]\n",
    "    }}\"\"\"\n",
    "    if n == len(feature_names) - 1:\n",
    "        ensemble_all += \"\\n]\"\n",
    "\n",
    "print(ensemble_all[0:150], f'\\n\\n\\n<{len(ensemble_all)-300} characters hidden>\\n\\n\\n', ensemble_all[-150:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dfc091-2087-4434-962e-bdc12fc5dabc",
   "metadata": {},
   "source": [
    "Add the `output` specification for the ensemble using the model names and versions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "id": "28d4e449-7b4e-4b24-ab77-28804595ab61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"ensemble\"\n",
      "platform: \"ensemble\"\n",
      "max_batch_size: 4\n",
      "input [\n",
      "    {\n",
      "        name: \"Time\"\n",
      "        data_type: TYPE_FP32\n",
      "        dims: [ 1 ]\n",
      "    },\n",
      "    \n",
      "\n",
      "\n",
      "<2328 characters hidden>\n",
      "\n",
      "\n",
      " pe: TYPE_FP32\n",
      "        dims: [ 1 ]\n",
      "    }\n",
      "]\n",
      "output [\n",
      "    {\n",
      "        name: \"logistic_for_05_05_2\"\n",
      "        data_type: TYPE_FP32\n",
      "        dims: [ 2 ]\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "for m, model in enumerate(models_artifacts[0:1]):\n",
    "    if m == 0:\n",
    "        ensemble_all += \"\\noutput [\"\n",
    "    \n",
    "    for v, version in enumerate(model[1][0:1]):\n",
    "        ensemble_all += f\"\"\"\n",
    "    {{\n",
    "        name: \"logistic_for_{model[0].display_name}_{version[0]}\"\n",
    "        data_type: TYPE_FP32\n",
    "        dims: [ 2 ]\n",
    "    }}\"\"\"\n",
    "    \n",
    "    if m == len(models_artifacts[0:1]) - 1:\n",
    "        ensemble_all += \"\\n]\"\n",
    "\n",
    "print(ensemble_all[0:150], f'\\n\\n\\n<{len(ensemble_all)-300} characters hidden>\\n\\n\\n', ensemble_all[-150:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13321131-a7d8-4aae-b047-d0178d3e1e64",
   "metadata": {},
   "source": [
    "Build the `ensemble_scheduling` specification.  This is very large due to the number of models and input parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "id": "dfcff7ba-807f-45a6-9443-bbb3f48f9259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ensemble_scheduling {\n",
      "    step [\n",
      "        {\n",
      "            model_name: \"05_05\"\n",
      "            model_version: 2\n",
      "            input_map {\n",
      "                key: \"Time\"\n",
      "                value: \"Time\"\n",
      "            }\n",
      "            input_map {\n",
      "                key: \"V1\"\n",
      "                value: \"V1\"\n",
      "            }\n",
      "        \n",
      "\n",
      "\n",
      "<2449 characters hidden>\n",
      "\n",
      "\n",
      "             key: \"V28\"\n",
      "                value: \"V28\"\n",
      "            }\n",
      "            input_map {\n",
      "                key: \"Amount\"\n",
      "                value: \"Amount\"\n",
      "            }\n",
      "            output_map {\n",
      "                key: \"logistic\"\n",
      "                value: \"logistic_for_05_05_2\"\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "for m, model in enumerate(models_artifacts[0:1]):\n",
    "    if m == 0:\n",
    "        ensemble_scheduling = \"\"\"\n",
    "ensemble_scheduling {\n",
    "    step [\"\"\"\n",
    "    \n",
    "    for v, version in enumerate(model[1][0:1]):\n",
    "        if m > 0 or v > 0:\n",
    "            ensemble_scheduling += \"\"#\",\"\n",
    "        \n",
    "        for n, name in enumerate(feature_names):\n",
    "            if n == 0:\n",
    "                input_map = \"\"\n",
    "            #else:\n",
    "            #    input_map += \",\"\n",
    "            input_map += f\"\"\"\n",
    "            input_map {{\n",
    "                key: \"{name}\"\n",
    "                value: \"{name}\"\n",
    "            }}\"\"\"\n",
    "        \n",
    "        ensemble_scheduling += f\"\"\"\n",
    "        {{\n",
    "            model_name: \"{model[0].display_name}\"\n",
    "            model_version: {version[0]}{input_map}\n",
    "            output_map {{\n",
    "                key: \"logistic\"\n",
    "                value: \"logistic_for_{model[0].display_name}_{version[0]}\"\n",
    "            }}\n",
    "        }}\"\"\"\n",
    "        \n",
    "        \n",
    "    if m == len(models_artifacts[0:1]) - 1:\n",
    "        ensemble_scheduling += \"\"\"\n",
    "    ]\n",
    "}\"\"\"\n",
    "        \n",
    "print(ensemble_scheduling[0:300], f'\\n\\n\\n<{len(ensemble_scheduling)-600} characters hidden>\\n\\n\\n', ensemble_scheduling[-300:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2497394e-88b3-4592-b0a7-d9050344284e",
   "metadata": {},
   "source": [
    "Add the `ensemble_scheduling` specification to the overall ensemble specification in `ensemble_all`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "25077944-58aa-41d4-9cd8-14801c9f36b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_all = ensemble_all + ensemble_scheduling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9e6cd4-0f71-4ae9-babe-47327e4b049b",
   "metadata": {},
   "source": [
    "Add the ensemble model to the model repository in GCS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "id": "1f797947-6d1b-4f79-9355-7105a1c044db",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = gcs.lookup_bucket(BUCKET)\n",
    "blob = bucket.blob(f'{SERIES}/{EXPERIMENT}/model_repo/ensemble/config.pbtxt')\n",
    "blob.upload_from_string(ensemble_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b5bf01-cd9a-45af-abdb-d640aa840c42",
   "metadata": {},
   "source": [
    "Review the `config.pbtxt` in the browser with the following link:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "id": "5711f84d-ea52-4661-abe8-dcf968086e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://storage.cloud.google.com/statmike-mlops-349915/05/triton/model_repo/ensemble/config.pbtxt\n"
     ]
    }
   ],
   "source": [
    "print(f'https://storage.cloud.google.com/{BUCKET}/{SERIES}/{EXPERIMENT}/model_repo/ensemble/config.pbtxt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b4a10d-2ed6-4cff-bf6d-5a886a8d6306",
   "metadata": {},
   "source": [
    "**NOTES ON TRITON MODEL REPOSITORY FOR ENSEMBLE**\n",
    "\n",
    "All models in the TRITON model repository need version folders. But what about ensemble models? While nothing is required in the version folder, it still seems to be required. Since the souce of the model repository is a GCS URI registered in Vertex AI Model Registry, and object storage does not have the concept of \"folders\", you find this error:\n",
    "\n",
    ">E0822 00:28:44.857235 1 model_repository_manager.cc:546] failed to load model 'ensemble_all': at least one version must be available under the version policy of model 'ensemble_all'\n",
    "\n",
    "To solve this, the following cells create an empty text file named `empty.txt` and copy it to the `/1/empty.txt` location of the ensemble model in the model registry folder of GCS.\n",
    "\n",
    "Check out [this related GitHub issue](https://github.com/triton-inference-server/server/issues/3623) for confirmation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "id": "d23fec99-804b-4f93-a6df-9407246a8472",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = bucket.blob(f'{SERIES}/{EXPERIMENT}/model_repo/ensemble/1/empty.txt')\n",
    "blob.upload_from_string('# just an empty file to help force the creation of a version folder: /1/empty.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7ea6f4-bc02-42d5-831c-fcc0d2011fe6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-12.m110",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-12:m110"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
