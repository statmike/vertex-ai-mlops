{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6ad0372",
   "metadata": {},
   "source": [
    "![tracker](https://us-central1-vertex-ai-mlops-369716.cloudfunctions.net/pixel-tracking?path=statmike%2Fvertex-ai-mlops%2FApplied+ML%2FAI+Agents%2Fconcept-bq%2Fagent_convo_api%2Fdeploy&file=deploy-vertex-ai-agent-engine.ipynb)\n",
    "<!--- header table --->\n",
    "<table align=\"left\">\n",
    "<tr>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/statmike/vertex-ai-mlops/blob/main/Applied%20ML/AI%20Agents/concept-bq/agent_convo_api/deploy/deploy-vertex-ai-agent-engine.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://www.svgrepo.com/download/217753/github.svg\" alt=\"GitHub logo\">\n",
    "      <br>View on<br>GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/statmike/vertex-ai-mlops/blob/main/Applied%20ML/AI%20Agents/concept-bq/agent_convo_api/deploy/deploy-vertex-ai-agent-engine.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://www.gstatic.com/pantheon/images/bigquery/welcome_page/colab-logo.svg\" alt=\"Google Colaboratory logo\">\n",
    "      <br>Run in<br>Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https%3A%2F%2Fraw.githubusercontent.com%2Fstatmike%2Fvertex-ai-mlops%2Fmain%2FApplied%2520ML%2FAI%2520Agents%2Fconcept-bq%2Fagent_convo_api%2Fdeploy%2Fdeploy-vertex-ai-agent-engine.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\">\n",
    "      <br>Run in<br>Colab Enterprise\n",
    "    </a>\n",
    "  </td>      \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/bigquery/import?url=https://github.com/statmike/vertex-ai-mlops/blob/main/Applied%20ML/AI%20Agents/concept-bq/agent_convo_api/deploy/deploy-vertex-ai-agent-engine.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://www.gstatic.com/images/branding/gcpiconscolors/bigquery/v1/32px.svg\" alt=\"BigQuery logo\">\n",
    "      <br>Open in<br>BigQuery Studio\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/statmike/vertex-ai-mlops/main/Applied%20ML/AI%20Agents/concept-bq/agent_convo_api/deploy/deploy-vertex-ai-agent-engine.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://www.gstatic.com/images/branding/gcpiconscolors/vertexai/v1/32px.svg\" alt=\"Vertex AI logo\">\n",
    "      <br>Open in<br>Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td colspan=\"5\" style=\"text-align: right\">\n",
    "    <b>Share This On: </b> \n",
    "    <a href=\"https://www.linkedin.com/sharing/share-offsite/?url=https://github.com/statmike/vertex-ai-mlops/blob/main/Applied%2520ML/AI%2520Agents/concept-bq/agent_convo_api/deploy/deploy-vertex-ai-agent-engine.ipynb\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"Linkedin Logo\" width=\"20px\"></a> \n",
    "    <a href=\"https://reddit.com/submit?url=https://github.com/statmike/vertex-ai-mlops/blob/main/Applied%2520ML/AI%2520Agents/concept-bq/agent_convo_api/deploy/deploy-vertex-ai-agent-engine.ipynb\"><img src=\"https://redditinc.com/hubfs/Reddit%20Inc/Brand/Reddit_Logo.png\" alt=\"Reddit Logo\" width=\"20px\"></a> \n",
    "    <a href=\"https://bsky.app/intent/compose?text=https://github.com/statmike/vertex-ai-mlops/blob/main/Applied%2520ML/AI%2520Agents/concept-bq/agent_convo_api/deploy/deploy-vertex-ai-agent-engine.ipynb\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"BlueSky Logo\" width=\"20px\"></a> \n",
    "    <a href=\"https://twitter.com/intent/tweet?url=https://github.com/statmike/vertex-ai-mlops/blob/main/Applied%2520ML/AI%2520Agents/concept-bq/agent_convo_api/deploy/deploy-vertex-ai-agent-engine.ipynb\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/5/5a/X_icon_2.svg\" alt=\"X (Twitter) Logo\" width=\"20px\"></a> \n",
    "  </td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td colspan=\"5\" style=\"text-align: right\">\n",
    "    <b>Connect With Author On: </b> \n",
    "    <a href=\"https://www.linkedin.com/in/statmike\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"Linkedin Logo\" width=\"20px\"></a>\n",
    "    <a href=\"https://www.github.com/statmike\"><img src=\"https://www.svgrepo.com/download/217753/github.svg\" alt=\"GitHub Logo\" width=\"20px\"></a> \n",
    "    <a href=\"https://www.youtube.com/@statmike-channel\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/f/fd/YouTube_full-color_icon_%282024%29.svg\" alt=\"YouTube Logo\" width=\"20px\"></a>\n",
    "    <a href=\"https://bsky.app/profile/statmike.bsky.social\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"BlueSky Logo\" width=\"20px\"></a> \n",
    "    <a href=\"https://x.com/statmike\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/5/5a/X_icon_2.svg\" alt=\"X (Twitter) Logo\" width=\"20px\"></a>\n",
    "  </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy Agent To Vertex AI Agent Engine\n",
    "\n",
    "After building and testing an agent built with ADK the next step is deployment for use in production workflows and applications. This notebook workflow shows the steps for deploying the agent on [Vertex AI Agent Engine](https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/overview). This service includes:\n",
    "- [Development](https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/develop/adk) tooling to test the agent locally first\n",
    "- [Deployment](https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/deploy) tooling to create the agent instance on Vertex AI Agent Engine\n",
    "- [Agent Use](https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/use/adk) SDK directly within the Vetex AI SDK\n",
    "- [Mangagement](https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/manage/overview) services for access control, tracing, logging, and monitoring of deployed agents\n",
    "- and services like [Agent Evaluation](https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/evaluate) and more!\n",
    "\n",
    "While Vertex AI Agent Engine is a service for many agent building frameworks (ADK, LangChain, LangGraph, AG2, LlamaIndex, Custom, ...) it is also directly integrated with Google ADK, the framework used in this project. [ADK Deployment](https://google.github.io/adk-docs/deploy/) options include [Vertex AI Agent Engine](https://google.github.io/adk-docs/deploy/agent-engine/) as well as [Cloud Run](https://google.github.io/adk-docs/deploy/cloud-run/) and [custom infrastructure](https://google.github.io/adk-docs/deploy/gke/) deployments.\n",
    "\n",
    "**Notes:**\n",
    "- This notebook is designed to be run from the `agent_name/deploy/` folder\n",
    "- It automatically discovers the agent from `../agent.py`\n",
    "- Project configuration is read from `../../.env` (main folder)\n",
    "- Deployment metadata is stored in `./deployment.json` (this folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import dotenv\n",
    "\n",
    "import vertexai\n",
    "from vertexai import agent_engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Google Cloud Project Information\n",
      "==================================================\n",
      "PROJECT_ID     = statmike-mlops-349915\n",
      "PROJECT_NUMBER = 1026793852137\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = subprocess.run(['gcloud', 'config', 'get-value', 'project'], capture_output=True, text=True, check=True).stdout.strip()\n",
    "PROJECT_NUMBER = subprocess.run(['gcloud', 'projects', 'describe', PROJECT_ID, '--format=value(projectNumber)'], capture_output=True, text=True, check=True).stdout.strip()\n",
    "\n",
    "print(f\"\\n{'='*50}\\nGoogle Cloud Project Information\\n{'='*50}\\nPROJECT_ID     = {PROJECT_ID}\\nPROJECT_NUMBER = {PROJECT_NUMBER}\\n{'='*50}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto-Configure Paths\n",
    "\n",
    "This notebook automatically detects its location and configures paths accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploy folder: /usr/local/google/home/statmike/Git/vertex-ai-mlops/Applied ML/AI Agents/concept-bq/agent_convo_api/deploy\n",
      "Agent folder: /usr/local/google/home/statmike/Git/vertex-ai-mlops/Applied ML/AI Agents/concept-bq/agent_convo_api\n",
      "Project root: /usr/local/google/home/statmike/Git/vertex-ai-mlops/Applied ML/AI Agents/concept-bq\n",
      "Agent name: agent_convo_api\n"
     ]
    }
   ],
   "source": [
    "# Get current directory (should be agent_name/deploy/)\n",
    "deploy_folder = Path.cwd()\n",
    "agent_folder = deploy_folder.parent\n",
    "project_root = agent_folder.parent\n",
    "\n",
    "# Extract agent name from folder structure\n",
    "agent_name = agent_folder.name\n",
    "\n",
    "print(f\"Deploy folder: {deploy_folder}\")\n",
    "print(f\"Agent folder: {agent_folder}\")\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Agent name: {agent_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Configuration\n",
    "\n",
    "Load project-wide configuration from the main `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project: statmike-mlops-349915\n",
      "Location: us-central1\n",
      "Storage Bucket: gs://statmike-mlops-349915\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from project root\n",
    "env_path = project_root / '.env'\n",
    "dotenv.load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "# Display loaded configuration\n",
    "print(f\"Project: {os.getenv('GOOGLE_CLOUD_PROJECT')}\")\n",
    "print(f\"Location: {os.getenv('GOOGLE_CLOUD_LOCATION')}\")\n",
    "print(f\"Storage Bucket: {os.getenv('GOOGLE_CLOUD_STORAGE_BUCKET')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertexai.init(\n",
    "    project=os.getenv('GOOGLE_CLOUD_PROJECT'),\n",
    "    location=os.getenv('GOOGLE_CLOUD_LOCATION'),\n",
    "    staging_bucket=os.getenv('GOOGLE_CLOUD_STORAGE_BUCKET')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suppress Warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', message='.*EXPERIMENTAL.*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Agent\n",
    "\n",
    "Import the `root_agent` from the parent directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent Name: agent_convo_api\n",
      "Agent Description: An agent that can answer questions about BigQuery data using the Conversational Analytics API.\n",
      "Agent Model: gemini-2.5-flash\n"
     ]
    }
   ],
   "source": [
    "# Add parent directory to path to import agent module\n",
    "sys.path.insert(0, str(agent_folder.parent))\n",
    "\n",
    "# Import the agent dynamically\n",
    "agent_module = __import__(f\"{agent_name}.agent\", fromlist=['root_agent'])\n",
    "root_agent = agent_module.root_agent\n",
    "\n",
    "# Display agent info\n",
    "print(f\"Agent Name: {root_agent.name}\")\n",
    "print(f\"Agent Description: {root_agent.description}\")\n",
    "print(f\"Agent Model: {root_agent.model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure GCS Path for Staging\n",
    "\n",
    "Define where agent artifacts will be staged in GCS.\n",
    "\n",
    "The path automatically mirrors the repository structure starting from \"Applied ML\", converted to lowercase with spaces replaced by hyphens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCS staging path: applied-ml/ai-agents/concept-bq/agent_convo_api/staging\n"
     ]
    }
   ],
   "source": [
    "# Build GCS staging path mirroring repository structure from \"Applied ML\" level\n",
    "# Convert to lowercase and replace spaces with hyphens\n",
    "gcs_base = str(project_root).split('Applied ML/')[-1].lower().replace(' ', '-')\n",
    "agent_gcs_path = f\"applied-ml/{gcs_base}/{agent_name}/staging\"\n",
    "\n",
    "print(f\"GCS staging path: {agent_gcs_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Local Testing: Prepare Agent for Vertex AI Agent Engine\n",
    "\n",
    "Before deploying the ADK agent to Vertex AI Agent Engine it can first be tested locally with the SDK.\n",
    "\n",
    "[SDK Link for `agent_engines.AdkApp`](https://github.com/googleapis/python-aiplatform/blob/main/vertexai/agent_engines/templates/adk.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = agent_engines.AdkApp(\n",
    "    agent=root_agent,\n",
    "    enable_tracing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Query\n",
    "\n",
    "**Customize this query to test your specific agent's capabilities.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parts': [{'text': \"I am a specialized AI assistant that can answer questions about data in Google BigQuery. I can find relevant datasets and tables, analyze their schemas, and then use a conversational tool to answer your questions, display data in tables, or even generate charts. Just tell me what you're looking for!\"}], 'role': 'model'}\n"
     ]
    }
   ],
   "source": [
    "async for event in app.async_stream_query(\n",
    "    user_id='test_user',\n",
    "    message=\"What can you do?\"\n",
    "):\n",
    "    print(event.get('content'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Up Test Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 session(s)\n",
      "Deleted session: c5b01bd7-e7b2-495e-a9ba-4a49769fde7f\n"
     ]
    }
   ],
   "source": [
    "# List sessions\n",
    "list_sessions = await app.async_list_sessions(user_id='test_user')\n",
    "print(f\"Found {len(list_sessions.sessions)} session(s)\")\n",
    "\n",
    "# Delete all test sessions\n",
    "for session in list_sessions.sessions:\n",
    "    await app.async_delete_session(user_id='test_user', session_id=session.id)\n",
    "    print(f\"Deleted session: {session.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Deploy To Vertex AI Agent Engine\n",
    "\n",
    "Now that the ADK Agent has been tested locally it can be deployed to Vertex AI Agent Engine.\n",
    "\n",
    "[SDK for `agent_engines.get | create | list | delete | update`](https://github.com/googleapis/python-aiplatform/blob/main/vertexai/agent_engines/__init__.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Deployment Metadata\n",
    "\n",
    "Check if this agent has been deployed previously by reading `deployment.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current deployment resource ID: projects/statmike-mlops-349915/locations/us-central1/reasoningEngines/6919838002059411456\n"
     ]
    }
   ],
   "source": [
    "deployment_file = deploy_folder / 'deployment.json'\n",
    "\n",
    "# Load existing deployment metadata if it exists\n",
    "if deployment_file.exists():\n",
    "    with open(deployment_file, 'r') as f:\n",
    "        deployment_metadata = json.load(f)\n",
    "    current_deployment = deployment_metadata.get('resource_id', '')\n",
    "else:\n",
    "    deployment_metadata = {}\n",
    "    current_deployment = ''\n",
    "\n",
    "print(f\"Current deployment resource ID: {current_deployment or 'None'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect Existing Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing deployment: projects/statmike-mlops-349915/locations/us-central1/reasoningEngines/6919838002059411456\n"
     ]
    }
   ],
   "source": [
    "remote_app = None\n",
    "\n",
    "if current_deployment:\n",
    "    try:\n",
    "        remote_app = agent_engines.get(resource_name=current_deployment)\n",
    "        print(f\"Found existing deployment: {remote_app.resource_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not retrieve deployment: {e}\")\n",
    "        print(\"Will create new deployment\")\n",
    "else:\n",
    "    print(\"No previous deployment found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<vertexai.agent_engines._agent_engines.AgentEngine object at 0x7f6d4d722120> \n",
       "resource name: projects/statmike-mlops-349915/locations/us-central1/reasoningEngines/6919838002059411456"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remote_app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create A Deployment\n",
    "\n",
    "If a prior deployment was not found, create a new deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not remote_app:\n",
    "    print(\"Creating new deployment...\")\n",
    "    \n",
    "    # Change to project_root directory for deployment so relative paths work\n",
    "    import os as _os\n",
    "    original_cwd = _os.getcwd()\n",
    "    _os.chdir(str(project_root))\n",
    "    \n",
    "    try:\n",
    "        remote_app = agent_engines.create(\n",
    "            agent_engine=root_agent,\n",
    "            requirements=\"requirements.txt\",  # Relative path from project_root\n",
    "            extra_packages=[agent_name],  # Relative path - just the folder name!\n",
    "            gcs_dir_name=agent_gcs_path,\n",
    "            display_name=root_agent.name,\n",
    "            description=root_agent.description,\n",
    "        )\n",
    "        print(f\"✓ Deployment created: {remote_app.resource_name}\")\n",
    "    finally:\n",
    "        # Always restore original directory\n",
    "        _os.chdir(original_cwd)\n",
    "else:\n",
    "    print(\"Retrieved existing deployment, use update instead of create.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/statmike-mlops-349915/locations/us-central1/reasoningEngines/6919838002059411456'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remote_app.resource_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Deployment Metadata\n",
    "\n",
    "Write the deployment information to `deployment.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Deployment metadata saved to /usr/local/google/home/statmike/Git/vertex-ai-mlops/Applied ML/AI Agents/concept-bq/agent_convo_api/deploy/deployment.json\n",
      "{\n",
      "  \"resource_id\": \"projects/statmike-mlops-349915/locations/us-central1/reasoningEngines/6919838002059411456\",\n",
      "  \"deployed_at\": \"2025-10-19T00:24:24.622473\",\n",
      "  \"display_name\": \"agent_convo_api\",\n",
      "  \"description\": \"An agent that can answer questions about BigQuery data using the Conversational Analytics API.\",\n",
      "  \"gemini_enterprise_agent_id\": \"projects/1026793852137/locations/global/collections/default_collection/engines/enterprise-search-17381091_1738109128316/assistants/default_assistant/agents/18337555184602126877\",\n",
      "  \"registered_at\": \"2025-10-15T16:55:46.862102849Z\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Update deployment metadata\n",
    "deployment_metadata.update({\n",
    "    \"resource_id\": remote_app.resource_name,\n",
    "    \"deployed_at\": datetime.now().isoformat(),\n",
    "    \"display_name\": root_agent.name,\n",
    "    \"description\": root_agent.description\n",
    "})\n",
    "\n",
    "# Write to file\n",
    "with open(deployment_file, 'w') as f:\n",
    "    json.dump(deployment_metadata, f, indent=2)\n",
    "\n",
    "print(f\"✓ Deployment metadata saved to {deployment_file}\")\n",
    "print(json.dumps(deployment_metadata, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Existing Deployment\n",
    "\n",
    "To update an existing deployment with code changes, use this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run to update the deployment\n",
    "# if remote_app:\n",
    "#     print(\"Updating deployment...\")\n",
    "#     \n",
    "#     # Change to project_root directory for deployment so relative paths work\n",
    "#     import os as _os\n",
    "#     original_cwd = _os.getcwd()\n",
    "#     _os.chdir(str(project_root))\n",
    "#     \n",
    "#     try:\n",
    "#         update_app = agent_engines.update(\n",
    "#             resource_name=remote_app.resource_name,\n",
    "#             agent_engine=root_agent,\n",
    "#             requirements=\"requirements.txt\",  # Relative path from project_root\n",
    "#             extra_packages=[agent_name],  # Relative path - just the folder name!\n",
    "#         )\n",
    "#         print(f\"✓ Deployment updated: {update_app.resource_name}\")\n",
    "#         \n",
    "#         # Update metadata\n",
    "#         deployment_metadata[\"last_updated_at\"] = datetime.now().isoformat()\n",
    "#         with open(deployment_file, 'w') as f:\n",
    "#             json.dump(deployment_metadata, f, indent=2)\n",
    "#         print(\"✓ Metadata updated\")\n",
    "#     finally:\n",
    "#         # Always restore original directory\n",
    "#         _os.chdir(original_cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Remote Deployment\n",
    "\n",
    "Create a session and test the deployed agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'async_get_session',\n",
       "  'api_mode': 'async',\n",
       "  'description': 'Get a session for the given user.\\n\\nArgs:\\n    user_id (str):\\n        Required. The ID of the user.\\n    session_id (str):\\n        Required. The ID of the session.\\n    **kwargs (dict[str, Any]):\\n        Optional. Additional keyword arguments to pass to the\\n        session service.\\n\\nReturns:\\n    Session: The session instance (if any). It returns None if the\\n    session is not found.\\n\\nRaises:\\n    RuntimeError: If the session is not found.\\n',\n",
       "  'parameters': {'required': ['user_id', 'session_id'],\n",
       "   'type': 'object',\n",
       "   'properties': {'session_id': {'type': 'string'},\n",
       "    'user_id': {'type': 'string'}}}},\n",
       " {'name': 'async_list_sessions',\n",
       "  'api_mode': 'async',\n",
       "  'description': 'List sessions for the given user.\\n\\nArgs:\\n    user_id (str):\\n        Required. The ID of the user.\\n    **kwargs (dict[str, Any]):\\n        Optional. Additional keyword arguments to pass to the\\n        session service.\\n\\nReturns:\\n    ListSessionsResponse: The list of sessions.\\n',\n",
       "  'parameters': {'required': ['user_id'],\n",
       "   'type': 'object',\n",
       "   'properties': {'user_id': {'type': 'string'}}}},\n",
       " {'name': 'async_create_session',\n",
       "  'api_mode': 'async',\n",
       "  'description': 'Creates a new session.\\n\\nArgs:\\n    user_id (str):\\n        Required. The ID of the user.\\n    session_id (str):\\n        Optional. The ID of the session. If not provided, an ID\\n        will be be generated for the session.\\n    state (dict[str, Any]):\\n        Optional. The initial state of the session.\\n    **kwargs (dict[str, Any]):\\n        Optional. Additional keyword arguments to pass to the\\n        session service.\\n\\nReturns:\\n    Session: The newly created session instance.\\n',\n",
       "  'parameters': {'required': ['user_id'],\n",
       "   'type': 'object',\n",
       "   'properties': {'state': {'type': 'object', 'nullable': True},\n",
       "    'session_id': {'type': 'string', 'nullable': True},\n",
       "    'user_id': {'type': 'string'}}}},\n",
       " {'name': 'async_delete_session',\n",
       "  'api_mode': 'async',\n",
       "  'description': 'Deletes a session for the given user.\\n\\nArgs:\\n    user_id (str):\\n        Required. The ID of the user.\\n    session_id (str):\\n        Required. The ID of the session.\\n    **kwargs (dict[str, Any]):\\n        Optional. Additional keyword arguments to pass to the\\n        session service.\\n',\n",
       "  'parameters': {'required': ['user_id', 'session_id'],\n",
       "   'type': 'object',\n",
       "   'properties': {'session_id': {'type': 'string'},\n",
       "    'user_id': {'type': 'string'}}}},\n",
       " {'name': 'async_add_session_to_memory',\n",
       "  'api_mode': 'async',\n",
       "  'description': 'Generates memories.\\n\\nArgs:\\n    session (Dict[str, Any]):\\n        Required. The session to use for generating memories. It should\\n        be a dictionary representing an ADK Session object, e.g.\\n        session.model_dump(mode=\"json\").\\n',\n",
       "  'parameters': {'required': ['session'],\n",
       "   'type': 'object',\n",
       "   'properties': {'session': {'type': 'object',\n",
       "     'additionalProperties': True}}}},\n",
       " {'name': 'async_search_memory',\n",
       "  'api_mode': 'async',\n",
       "  'description': 'Searches memories for the given user.\\n\\nArgs:\\n    user_id: The id of the user.\\n    query: The query to match the memories on.\\n\\nReturns:\\n    A SearchMemoryResponse containing the matching memories.\\n',\n",
       "  'parameters': {'required': ['user_id', 'query'],\n",
       "   'type': 'object',\n",
       "   'properties': {'query': {'type': 'string'},\n",
       "    'user_id': {'type': 'string'}}}},\n",
       " {'name': 'async_stream_query',\n",
       "  'api_mode': 'async_stream',\n",
       "  'description': 'Streams responses asynchronously from the ADK application.\\n\\nArgs:\\n    message (str):\\n        Required. The message to stream responses for.\\n    user_id (str):\\n        Required. The ID of the user.\\n    session_id (str):\\n        Optional. The ID of the session. If not provided, a new\\n        session will be created for the user.\\n    run_config (Optional[Dict[str, Any]]):\\n        Optional. The run config to use for the query. If you want to\\n        pass in a `run_config` pydantic object, you can pass in a dict\\n        representing it as `run_config.model_dump(mode=\"json\")`.\\n    **kwargs (dict[str, Any]):\\n        Optional. Additional keyword arguments to pass to the\\n        runner.\\n\\nYields:\\n    Event dictionaries asynchronously.\\n',\n",
       "  'parameters': {'required': ['message', 'user_id'],\n",
       "   'type': 'object',\n",
       "   'properties': {'message': {'anyOf': [{'type': 'string'},\n",
       "      {'type': 'object', 'additionalProperties': True}]},\n",
       "    'session_id': {'type': 'string', 'nullable': True},\n",
       "    'run_config': {'type': 'object', 'nullable': True},\n",
       "    'user_id': {'type': 'string'}}}},\n",
       " {'name': 'streaming_agent_run_with_events',\n",
       "  'api_mode': 'async_stream',\n",
       "  'description': 'Streams responses asynchronously from the ADK application.\\n\\nIn general, you should use `async_stream_query` instead, as it has a\\nmore structured API and works with the respective ADK services that\\nyou have defined for the AdkApp. This method is primarily meant for\\ninvocation from AgentSpace.\\n\\nArgs:\\n    request_json (str):\\n        Required. The request to stream responses for.\\n',\n",
       "  'parameters': {'required': ['request_json'],\n",
       "   'type': 'object',\n",
       "   'properties': {'request_json': {'type': 'string'}}}}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remote_app.operation_schemas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created session: 4251072867673833472\n"
     ]
    }
   ],
   "source": [
    "remote_session = await remote_app.async_create_session(user_id='test_user')\n",
    "print(f\"Created session: {remote_session['id']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active sessions: 1\n"
     ]
    }
   ],
   "source": [
    "list_sessions = await remote_app.async_list_sessions(user_id='test_user')\n",
    "print(f\"Active sessions: {len(list_sessions['sessions'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Test session deleted\n"
     ]
    }
   ],
   "source": [
    "# Clean up test session\n",
    "await remote_app.async_delete_session(user_id='test_user', session_id=remote_session['id'])\n",
    "print(\"✓ Test session deleted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Manage Deployed App Permissions\n",
    "\n",
    "The deployed agent runs with a service account that may need additional IAM permissions.\n",
    "\n",
    "**Common permissions needed:**\n",
    "- BigQuery: `roles/bigquery.jobUser`, `roles/bigquery.dataViewer`\n",
    "- Conversational Analytics API: `roles/geminidataanalytics.dataAgentStatelessUser`, `roles/cloudaicompanion.user`\n",
    "- Storage: Already included via `roles/aiplatform.reasoningEngineServiceAgent`\n",
    "\n",
    "**Note:** Customize the permissions based on your agent's specific requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Number: 1026793852137\n",
      "Service Account: service-1026793852137@gcp-sa-aiplatform-re.iam.gserviceaccount.com\n"
     ]
    }
   ],
   "source": [
    "service_account_id = f\"service-{PROJECT_NUMBER}@gcp-sa-aiplatform-re.iam.gserviceaccount.com\"\n",
    "\n",
    "print(f\"Project Number: {PROJECT_NUMBER}\")\n",
    "print(f\"Service Account: {service_account_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROLE\n",
      "roles/aiplatform.reasoningEngineServiceAgent\n",
      "roles/bigquery.dataViewer\n",
      "roles/bigquery.jobUser\n",
      "roles/cloudaicompanion.user\n",
      "roles/dlp.user\n",
      "roles/documentai.apiUser\n",
      "roles/geminidataanalytics.dataAgentStatelessUser\n"
     ]
    }
   ],
   "source": [
    "# View current permissions\n",
    "!gcloud projects get-iam-policy {project_number} --flatten=\"bindings\" --format=\"table(bindings.role)\" --filter=\"bindings.members:'{service_account_id}'\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Required Permissions\n",
    "\n",
    "Uncomment and run the cells below to grant permissions as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Grant BigQuery permissions\n",
    "# !gcloud projects add-iam-policy-binding {project_number} --member=\"serviceAccount:{service_account_id}\" --role=\"roles/bigquery.jobUser\"\n",
    "# !gcloud projects add-iam-policy-binding {project_number} --member=\"serviceAccount:{service_account_id}\" --role=\"roles/bigquery.dataViewer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Grant Conversational Analytics API permissions\n",
    "# !gcloud projects add-iam-policy-binding {project_number} --member=\"serviceAccount:{service_account_id}\" --role=\"roles/geminidataanalytics.dataAgentStatelessUser\"\n",
    "# !gcloud projects add-iam-policy-binding {project_number} --member=\"serviceAccount:{service_account_id}\" --role=\"roles/cloudaicompanion.user\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Delete Deployed Agent\n",
    "\n",
    "Use this to remove the deployment from Vertex AI Agent Engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_app = False\n",
    "\n",
    "if delete_app and remote_app:\n",
    "    print(\"Deleting deployment...\")\n",
    "    task = agent_engines.delete(\n",
    "        resource_name=remote_app.resource_name,\n",
    "        force=True\n",
    "    )\n",
    "    print(\"✓ Deployment deleted\")\n",
    "    \n",
    "    # Clear deployment metadata\n",
    "    deployment_metadata = {\n",
    "        \"resource_id\": \"\",\n",
    "        \"deployed_at\": \"\",\n",
    "        \"display_name\": \"\",\n",
    "        \"description\": \"\"\n",
    "    }\n",
    "    with open(deployment_file, 'w') as f:\n",
    "        json.dump(deployment_metadata, f, indent=2)\n",
    "    print(\"✓ Deployment metadata cleared\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Next Steps\n",
    "\n",
    "After deploying your agent:\n",
    "1. Use the deployed agent with [use-vertex-ai-agent-engine.ipynb](./use-vertex-ai-agent-engine.ipynb)\n",
    "2. Register with Gemini Enterprise using [register-adk-on-agent-engine-with-gemini-enterprise.ipynb](./register-adk-on-agent-engine-with-gemini-enterprise.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (concept-bq)",
   "language": "python",
   "name": "concept-bq"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
