{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd75ca02",
   "metadata": {},
   "source": [
    "![tracker](https://us-central1-vertex-ai-mlops-369716.cloudfunctions.net/pixel-tracking?path=statmike%2Fvertex-ai-mlops%2FApplied+GenAI%2FEvaluation&file=Evaluation+For+GenAI.ipynb)\n",
    "<!--- header table --->\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/statmike/vertex-ai-mlops/blob/main/Applied%20GenAI/Evaluation/Evaluation%20For%20GenAI.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\">\n",
    "      <br>Run in<br>Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https%3A%2F%2Fraw.githubusercontent.com%2Fstatmike%2Fvertex-ai-mlops%2Fmain%2FApplied%2520GenAI%2FEvaluation%2FEvaluation%2520For%2520GenAI.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\">\n",
    "      <br>Run in<br>Colab Enterprise\n",
    "    </a>\n",
    "  </td>      \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/statmike/vertex-ai-mlops/blob/main/Applied%20GenAI/Evaluation/Evaluation%20For%20GenAI.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      <br>View on<br>GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/statmike/vertex-ai-mlops/main/Applied%20GenAI/Evaluation/Evaluation%20For%20GenAI.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      <br>Open in<br>Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27af7448-af9d-4490-999c-7bedab5be6bb",
   "metadata": {},
   "source": [
    "# Evaluation For GenAI\n",
    "\n",
    "In machine learning, evaluation involves computing the predicted outcome and comparing it to the known actual outcome. With generative AI, all responses are predicted values. How do we assess these for their accuracy in designated tasks such as summarization, question answering, code writing, generating dialogue, and other, even custom, tasks? That is the goal of this workflow!\n",
    "\n",
    "In machine learning, the comparison of predicted values to actual known values comes down to a metric that is computed and then used to judge the ability of the model. This could be a confusion matrix, accuracy score, F1 score, precision, and more for a classification model. It could be MAE, RMSE, MSE, and others for a regression model. But what about text?\n",
    "\n",
    "To [evaluate generative AI responses](https://cloud.google.com/vertex-ai/generative-ai/docs/models/evaluation-overview), we first need to decide what we are comparing them to:\n",
    "\n",
    "- **Compare to another response: Model-Based Pairwise** - compare two responses and pick the better one\n",
    "    - Use a model as a judge to compare responses based on a metric\n",
    "    - Compare two models, two versions of a model, two different system instructions, ...\n",
    "- **Compare to criteria: Model-Based Pointwise** - judge a response against an evaluation criteria\n",
    "    - Use a model as a judge to evaluate responses for a metric on a rating scale\n",
    "- **Ground truth reference: Computation-based** metrics used to compute metrics that directly compare text\n",
    "    - Similarity using **Lexicon-based metrics** like Exact Match, BLEU, and ROUGE\n",
    "    - Classification metrics like F1-score, Accuracy on aggregated responses\n",
    "    - Embedding-based comparison like the distance between results in an embedding space\n",
    "\n",
    "The following workflow shows how to use evaluations to optimize prompts by rewriting system instructions automatically:\n",
    "\n",
    "- [Optimize Prompts Using Evaluation Metrics](./Optimize%20Prompts%20Using%20Evaluation%20Metrics.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8649b101-b698-482c-aaae-6c772589f030",
   "metadata": {
    "id": "od_UkDpvRmgD",
    "tags": []
   },
   "source": [
    "---\n",
    "## Colab Setup\n",
    "\n",
    "To run this notebook in Colab run the cells in this section.  Otherwise, skip this section.\n",
    "\n",
    "This cell will authenticate to GCP (follow prompts in the popup)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1686cc18-266a-4c03-8f23-6032c869ff52",
   "metadata": {
    "executionInfo": {
     "elapsed": 195,
     "status": "ok",
     "timestamp": 1683726184843,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "8UO9FnqyKBlF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'statmike-mlops-349915' # replace with project ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e93bfe9-2519-4e68-a44b-c7e0f36c0a23",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68869,
     "status": "ok",
     "timestamp": 1683726253709,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "N98-KK7LRkjm",
    "outputId": "09ec5008-0def-4e1a-c349-c598ee752f78",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not a Colab Environment\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    !gcloud config set project {PROJECT_ID}\n",
    "    print('Colab authorized to GCP')\n",
    "except Exception:\n",
    "    print('Not a Colab Environment')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436eb3ea-ad07-40c3-b4a8-cb625ba02740",
   "metadata": {},
   "source": [
    "---\n",
    "## Installs\n",
    "\n",
    "The list `packages` contains tuples of package import names and install names.  If the import name is not found then the install name is used to install quitely for the current user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d62ebb20-480c-4072-bd05-03e64b87d74c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tuples of (import name, install name, min_version)\n",
    "packages = [\n",
    "    ('google.cloud.aiplatform', 'google-cloud-aiplatform', '1.78.0'),\n",
    "    ('pandas', 'pandas')\n",
    "]\n",
    "\n",
    "import importlib\n",
    "install = False\n",
    "for package in packages:\n",
    "    if not importlib.util.find_spec(package[0]):\n",
    "        print(f'installing package {package[1]}')\n",
    "        install = True\n",
    "        !pip install {package[1]} -U -q --user\n",
    "    elif len(package) == 3:\n",
    "        if importlib.metadata.version(package[0]) < package[2]:\n",
    "            print(f'updating package {package[1]}')\n",
    "            install = True\n",
    "            !pip install {package[1]} -U -q --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fbce7f-26f6-4f5e-8839-c883cf6aecf3",
   "metadata": {},
   "source": [
    "### API Enablement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0f8036a-2907-48b7-a0be-0b39c9fc014d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gcloud services enable aiplatform.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0a7a7b-95d0-4bb9-8470-8890ee9adb11",
   "metadata": {},
   "source": [
    "### Restart Kernel (If Installs Occured)\n",
    "\n",
    "After a kernel restart the code submission can start with the next cell after this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d87c013-0d98-48c3-aa0a-aa1edb3ddaae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if install:\n",
    "    import IPython\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)\n",
    "    IPython.display.display(IPython.display.Markdown(\"\"\"<div class=\\\"alert alert-block alert-warning\\\">\n",
    "        <b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. The previous cells do not need to be run again⚠️</b>\n",
    "        </div>\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77851cb0-a405-4da0-82b5-964983149d34",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6001fe44-a8e5-4640-93d7-4c7486657af3",
   "metadata": {},
   "source": [
    "inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "116fc887-7a01-4d53-a972-f88baf31de9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'statmike-mlops-349915'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bc05e75-0cfa-45ae-8fd2-c88a4f84c733",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "SERIES = 'applied-genai'\n",
    "EXPERIMENT = 'evaluation'\n",
    "\n",
    "BUCKET = PROJECT_ID # change to Bucket name if not the same as the Project ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6d16bc-6120-4e90-8e02-b9ae1c34998b",
   "metadata": {},
   "source": [
    "packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "afbbf5dc-098f-4ff1-9720-2c23dc16608c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# package imports\n",
    "from IPython.display import Markdown\n",
    "import pandas as pd\n",
    "\n",
    "# vertex ai imports\n",
    "from google.cloud import aiplatform\n",
    "import vertexai\n",
    "import vertexai.generative_models # for Gemini Models\n",
    "import vertexai.evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9390d25e-6b1e-41bc-8400-e5f3d499ccf5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.78.0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aiplatform.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbebc60-f306-4680-95c4-3cb364c4d7da",
   "metadata": {},
   "source": [
    "clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76b77198-dd34-42d1-bf5c-592e63bb0508",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vertexai.init(project = PROJECT_ID, location = REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee85d809-2f4b-4268-96ec-073b4d6c9bde",
   "metadata": {},
   "source": [
    "---\n",
    "## Gemini Models\n",
    "\n",
    "Select one (or more) of the [supported Gemini models](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#supported-models) and read more about the characteristics of each [here](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-models).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964d9431-bdd7-4459-94a9-27712dbedc85",
   "metadata": {},
   "source": [
    "### Setup Model\n",
    "\n",
    "Here these models are selected:\n",
    "- [Gemini 1.5 Flash model with version 002](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-1.5-flash)\n",
    "- [Gemini 1.5 Pro model with version 002](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-1.5-pro)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fed593f9-ac8b-4424-8ca7-14bb8c3ca3e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gemini_flash = vertexai.generative_models.GenerativeModel(\"gemini-1.5-flash-002\")\n",
    "gemini_pro = vertexai.generative_models.GenerativeModel(\"gemini-1.5-pro-002\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdcbcce-44d3-4f02-96a6-848a5de77f3c",
   "metadata": {},
   "source": [
    "### Prompt With Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "721dc734-16b8-41f4-898c-5d3c339cfc86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Plastic colored dreams,\n",
       "Clicking, building, towers rise,\n",
       "Worlds born piece by piece. \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(gemini_flash.generate_content('Write a creative Haiku about Lego bricks.').text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a86e767b-121a-4e1c-b064-944722746795",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Colorful plastic\n",
       "Clicking together they build\n",
       "Worlds in small hands bloom\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(gemini_pro.generate_content('Write a creative Haiku about Lego bricks.').text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d213b3-397a-4fed-ac94-9b10079ea86c",
   "metadata": {},
   "source": [
    "### Multiple Responses For Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e99abbd6-241a-4295-9ef5-dfc69848bc9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "- Small blocks, endless worlds,\n",
       "Dragons built from colored dreams,\n",
       "Mind's eye takes the flight. \n",
       "- Small blocks, endless worlds,\n",
       "Ships sail, dragons take flight,\n",
       "Dreams click into place.\n",
       "- Small brick, endless worlds,\n",
       "Ships sail, dragons take flight now,\n",
       "Mind's eye builds the dream. \n",
       "- Small blocks, worlds unfold,\n",
       "Pirate ships or castles rise,\n",
       "Dreams click into place. \n",
       "- Small blocks, endless worlds,\n",
       "Dragons built from tiny squares,\n",
       "Dreams take plastic form. \n",
       "- Small brick, endless worlds,\n",
       "Ships and castles rise and fall,\n",
       "Dreams take plastic form.\n",
       "- Small blocks, worlds unfold,\n",
       "Pirate ship or dragon's lair,\n",
       "Mind's eye takes the lead. \n",
       "- Small brick, boundless dream,\n",
       "Worlds rise from clicking plastic,\n",
       "Mind's eye takes the lead. \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flash_responses = gemini.generate_content(\n",
    "    contents = 'Write a creative Haiku about Lego bricks ability to foster imagination.',\n",
    "    generation_config = vertexai.generative_models.GenerationConfig(\n",
    "        candidate_count = 8,\n",
    "        temperature = 2.0\n",
    "    )\n",
    ")\n",
    "Markdown(''.join(['- ' + r.text for r in flash_responses.candidates]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40da5f9a-d85a-4f62-a133-6619eef4dc8a",
   "metadata": {},
   "source": [
    "# Evaluation Workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84666d0f-4ae1-4a85-8858-5b8416d4bbd5",
   "metadata": {},
   "source": [
    "## Workflow 1: Pointwise Evaluation With Multiple Prebuilt Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86ccb9a-9e9c-4903-ad8c-0e6cf884347e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d7198155-45f6-42a3-bedf-d1ae6b280ae7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_dataset = pd.DataFrame(\n",
    "    dict(\n",
    "        prompt = ['Write a Haiku about Lego bricks.'] * len(flash_responses.candidates),\n",
    "        responses = [r.text for r in flash_responses.candidates]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5aca4112-afcd-421d-9e02-a7dd06dd7ba8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pointwise_task = vertexai.evaluation.EvalTask(\n",
    "    dataset = eval_dataset,\n",
    "    metrics = [\n",
    "        vertexai.evaluation.MetricPromptTemplateExamples.Pointwise.FLUENCY,\n",
    "        vertexai.evaluation.MetricPromptTemplateExamples.Pointwise.COHERENCE,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6f00339e-2d4c-4d00-a32c-c539959eb628",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating a total of 8 responses from Gemini model gemini-1.5-pro-002.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00,  9.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 8 responses are successfully generated from Gemini model gemini-1.5-pro-002.\n",
      "Multithreaded Batch Inference took: 0.8736460581421852 seconds.\n",
      "Computing metrics with a total of 16 Vertex Gen AI Evaluation Service API requests.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 16/16 [00:19<00:00,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 16 metric requests are successfully computed.\n",
      "Evaluation Took:19.36790792644024 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
       "    <style>\n",
       "      .view-vertex-resource,\n",
       "      .view-vertex-resource:hover,\n",
       "      .view-vertex-resource:visited {\n",
       "        position: relative;\n",
       "        display: inline-flex;\n",
       "        flex-direction: row;\n",
       "        height: 32px;\n",
       "        padding: 0 12px;\n",
       "          margin: 4px 18px;\n",
       "        gap: 4px;\n",
       "        border-radius: 4px;\n",
       "\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "        background-color: rgb(255, 255, 255);\n",
       "        color: rgb(51, 103, 214);\n",
       "\n",
       "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
       "        font-size: 13px;\n",
       "        font-weight: 500;\n",
       "        text-transform: uppercase;\n",
       "        text-decoration: none !important;\n",
       "\n",
       "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
       "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active {\n",
       "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
       "        position: absolute;\n",
       "        top: 0;\n",
       "        bottom: 0;\n",
       "        left: 0;\n",
       "        right: 0;\n",
       "        border-radius: 4px;\n",
       "        pointer-events: none;\n",
       "\n",
       "        content: '';\n",
       "        background-color: rgb(51, 103, 214);\n",
       "        opacity: 0.12;\n",
       "      }\n",
       "      .view-vertex-icon {\n",
       "        font-size: 18px;\n",
       "      }\n",
       "    </style>\n",
       "  \n",
       "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-0c6a3454-cd9b-47b1-9bf6-54b2eb8fd65d\" href=\"#view-view-vertex-resource-0c6a3454-cd9b-47b1-9bf6-54b2eb8fd65d\">\n",
       "          <span class=\"material-icons view-vertex-icon\">bar_chart</span>\n",
       "          <span>View evaluation results</span>\n",
       "        </a>\n",
       "        \n",
       "        <script>\n",
       "          (function () {\n",
       "            const link = document.getElementById('view-vertex-resource-0c6a3454-cd9b-47b1-9bf6-54b2eb8fd65d');\n",
       "            link.addEventListener('click', (e) => {\n",
       "              if (window.google?.colab?.openUrl) {\n",
       "                window.google.colab.openUrl('https://cloud.google.com/vertex-ai/generative-ai/docs/models/view-evaluation');\n",
       "              } else {\n",
       "                window.open('https://cloud.google.com/vertex-ai/generative-ai/docs/models/view-evaluation', '_blank');\n",
       "              }\n",
       "              e.stopPropagation();\n",
       "              e.preventDefault();\n",
       "            });\n",
       "          })();\n",
       "        </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pointwise_result = pointwise_task.evaluate(\n",
    "    model = gemini_pro\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6190e3de-f6c2-4c47-8e75-c42cd1721712",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'row_count': 8,\n",
       " 'fluency/mean': 5.0,\n",
       " 'fluency/std': 0.0,\n",
       " 'coherence/mean': 5.0,\n",
       " 'coherence/std': 0.0}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pointwise_result.summary_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ac8eb9ab-0eb7-41e4-b8b5-1b670bbaab31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>responses</th>\n",
       "      <th>response</th>\n",
       "      <th>fluency/explanation</th>\n",
       "      <th>fluency/score</th>\n",
       "      <th>coherence/explanation</th>\n",
       "      <th>coherence/score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Write a Haiku about Lego bricks.</td>\n",
       "      <td>Small blocks, endless worlds,\\nDragons built f...</td>\n",
       "      <td>Colorful plastic\\nClick together, worlds are b...</td>\n",
       "      <td>STEP 1: Assess grammar correctness: The respon...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>STEP 1: The purpose is to write a Haiku about ...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Write a Haiku about Lego bricks.</td>\n",
       "      <td>Small blocks, endless worlds,\\nShips sail, dra...</td>\n",
       "      <td>Colorful plastic\\nClick together, worlds are b...</td>\n",
       "      <td>STEP 1: Assess grammar correctness: The respon...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>STEP 1: The purpose of the prompt is to genera...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Write a Haiku about Lego bricks.</td>\n",
       "      <td>Small brick, endless worlds,\\nShips sail, drag...</td>\n",
       "      <td>Colorful plastic\\nClick together, worlds are b...</td>\n",
       "      <td>STEP 1: Assess grammar correctness: The respon...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The AI response provides a haiku that is topic...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Write a Haiku about Lego bricks.</td>\n",
       "      <td>Small blocks, worlds unfold,\\nPirate ships or ...</td>\n",
       "      <td>Colorful plastic\\nClick together, worlds we bu...</td>\n",
       "      <td>STEP 1: Assess grammar correctness: The respon...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>STEP 1: The purpose is to write a Haiku about ...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Write a Haiku about Lego bricks.</td>\n",
       "      <td>Small blocks, endless worlds,\\nDragons built f...</td>\n",
       "      <td>Colorful plastic\\nClick together, worlds we bu...</td>\n",
       "      <td>STEP 1: Assess grammar correctness: The respon...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>STEP 1: The purpose of the prompt is to genera...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Write a Haiku about Lego bricks.</td>\n",
       "      <td>Small brick, endless worlds,\\nShips and castle...</td>\n",
       "      <td>Colorful plastic\\nClick together, worlds we bu...</td>\n",
       "      <td>STEP 1: Assess grammar correctness: The respon...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>STEP 1: The purpose is to write a Haiku about ...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Write a Haiku about Lego bricks.</td>\n",
       "      <td>Small blocks, worlds unfold,\\nPirate ship or d...</td>\n",
       "      <td>Colorful bright bricks\\nClick together, worlds...</td>\n",
       "      <td>STEP 1: Assess grammar correctness: The respon...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>STEP 1: The purpose of the prompt is to genera...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Write a Haiku about Lego bricks.</td>\n",
       "      <td>Small brick, boundless dream,\\nWorlds rise fro...</td>\n",
       "      <td>Colorful plastic\\nClick together, worlds we bu...</td>\n",
       "      <td>STEP 1: Assess grammar correctness: The respon...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>STEP 1: The purpose is to write a Haiku about ...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             prompt  \\\n",
       "0  Write a Haiku about Lego bricks.   \n",
       "1  Write a Haiku about Lego bricks.   \n",
       "2  Write a Haiku about Lego bricks.   \n",
       "3  Write a Haiku about Lego bricks.   \n",
       "4  Write a Haiku about Lego bricks.   \n",
       "5  Write a Haiku about Lego bricks.   \n",
       "6  Write a Haiku about Lego bricks.   \n",
       "7  Write a Haiku about Lego bricks.   \n",
       "\n",
       "                                           responses  \\\n",
       "0  Small blocks, endless worlds,\\nDragons built f...   \n",
       "1  Small blocks, endless worlds,\\nShips sail, dra...   \n",
       "2  Small brick, endless worlds,\\nShips sail, drag...   \n",
       "3  Small blocks, worlds unfold,\\nPirate ships or ...   \n",
       "4  Small blocks, endless worlds,\\nDragons built f...   \n",
       "5  Small brick, endless worlds,\\nShips and castle...   \n",
       "6  Small blocks, worlds unfold,\\nPirate ship or d...   \n",
       "7  Small brick, boundless dream,\\nWorlds rise fro...   \n",
       "\n",
       "                                            response  \\\n",
       "0  Colorful plastic\\nClick together, worlds are b...   \n",
       "1  Colorful plastic\\nClick together, worlds are b...   \n",
       "2  Colorful plastic\\nClick together, worlds are b...   \n",
       "3  Colorful plastic\\nClick together, worlds we bu...   \n",
       "4  Colorful plastic\\nClick together, worlds we bu...   \n",
       "5  Colorful plastic\\nClick together, worlds we bu...   \n",
       "6  Colorful bright bricks\\nClick together, worlds...   \n",
       "7  Colorful plastic\\nClick together, worlds we bu...   \n",
       "\n",
       "                                 fluency/explanation  fluency/score  \\\n",
       "0  STEP 1: Assess grammar correctness: The respon...            5.0   \n",
       "1  STEP 1: Assess grammar correctness: The respon...            5.0   \n",
       "2  STEP 1: Assess grammar correctness: The respon...            5.0   \n",
       "3  STEP 1: Assess grammar correctness: The respon...            5.0   \n",
       "4  STEP 1: Assess grammar correctness: The respon...            5.0   \n",
       "5  STEP 1: Assess grammar correctness: The respon...            5.0   \n",
       "6  STEP 1: Assess grammar correctness: The respon...            5.0   \n",
       "7  STEP 1: Assess grammar correctness: The respon...            5.0   \n",
       "\n",
       "                               coherence/explanation  coherence/score  \n",
       "0  STEP 1: The purpose is to write a Haiku about ...              5.0  \n",
       "1  STEP 1: The purpose of the prompt is to genera...              5.0  \n",
       "2  The AI response provides a haiku that is topic...              5.0  \n",
       "3  STEP 1: The purpose is to write a Haiku about ...              5.0  \n",
       "4  STEP 1: The purpose of the prompt is to genera...              5.0  \n",
       "5  STEP 1: The purpose is to write a Haiku about ...              5.0  \n",
       "6  STEP 1: The purpose of the prompt is to genera...              5.0  \n",
       "7  STEP 1: The purpose is to write a Haiku about ...              5.0  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pointwise_result.metrics_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08bf169-8b1b-474e-b979-9ff6e57ee895",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f535d7b-fbfc-4d4e-be33-2ce0565f6c26",
   "metadata": {},
   "source": [
    "## Workflow 2: Pointwise Evaluation With Custom Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b05d4fb-f718-4653-911f-c43e2aa6b31f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0fc35eec-f55f-401c-a155-b0c9842430d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The `input_variables` parameter is empty. Only the `response` column is used for computing this model-based metric.\n"
     ]
    }
   ],
   "source": [
    "haiku_quality = vertexai.evaluation.PointwiseMetric(\n",
    "    metric = 'custom_text_quality',\n",
    "    metric_prompt_template = vertexai.evaluation.PointwiseMetricPromptTemplate(\n",
    "        criteria = dict(\n",
    "            haiku_rules = 'Has three lines.  First and third line has five syllables.  Second line has seven syllables.',\n",
    "            imagination = 'The content fosters a spirit of imagination.',\n",
    "            fun_out_loud = 'The text sounds fun to read and even easy to memorize based on its meter when spoken.'\n",
    "        ),\n",
    "        rating_rubric = dict([\n",
    "            (3, 'The response is exceptional at all criteria'),\n",
    "            (2, 'The response is exceptional at two criteria'),\n",
    "            (1, 'The response is exceptional at one criteria.'),\n",
    "            (0, 'The response adhears to all critera'),\n",
    "            (-1, 'The response fails to adhear to one or more criteria')\n",
    "        ])\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a2332688-c7c6-4879-b10e-e6c219c530c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_dataset = pd.DataFrame(\n",
    "    dict(\n",
    "        response = [r.text for r in flash_responses.candidates]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f358b76a-3c3b-41fb-ae04-d101c8f1f5a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_task = vertexai.evaluation.EvalTask(\n",
    "    dataset = eval_dataset,\n",
    "    metrics = [haiku_quality]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "92059ad6-554f-4e9c-acef-af1062b18423",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metrics with a total of 8 Vertex Gen AI Evaluation Service API requests.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:11<00:00,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 8 metric requests are successfully computed.\n",
      "Evaluation Took:11.713130806572735 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
       "    <style>\n",
       "      .view-vertex-resource,\n",
       "      .view-vertex-resource:hover,\n",
       "      .view-vertex-resource:visited {\n",
       "        position: relative;\n",
       "        display: inline-flex;\n",
       "        flex-direction: row;\n",
       "        height: 32px;\n",
       "        padding: 0 12px;\n",
       "          margin: 4px 18px;\n",
       "        gap: 4px;\n",
       "        border-radius: 4px;\n",
       "\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "        background-color: rgb(255, 255, 255);\n",
       "        color: rgb(51, 103, 214);\n",
       "\n",
       "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
       "        font-size: 13px;\n",
       "        font-weight: 500;\n",
       "        text-transform: uppercase;\n",
       "        text-decoration: none !important;\n",
       "\n",
       "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
       "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active {\n",
       "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
       "        position: absolute;\n",
       "        top: 0;\n",
       "        bottom: 0;\n",
       "        left: 0;\n",
       "        right: 0;\n",
       "        border-radius: 4px;\n",
       "        pointer-events: none;\n",
       "\n",
       "        content: '';\n",
       "        background-color: rgb(51, 103, 214);\n",
       "        opacity: 0.12;\n",
       "      }\n",
       "      .view-vertex-icon {\n",
       "        font-size: 18px;\n",
       "      }\n",
       "    </style>\n",
       "  \n",
       "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-5ec583d9-5f07-4f85-9d7d-99fc9b6bf511\" href=\"#view-view-vertex-resource-5ec583d9-5f07-4f85-9d7d-99fc9b6bf511\">\n",
       "          <span class=\"material-icons view-vertex-icon\">bar_chart</span>\n",
       "          <span>View evaluation results</span>\n",
       "        </a>\n",
       "        \n",
       "        <script>\n",
       "          (function () {\n",
       "            const link = document.getElementById('view-vertex-resource-5ec583d9-5f07-4f85-9d7d-99fc9b6bf511');\n",
       "            link.addEventListener('click', (e) => {\n",
       "              if (window.google?.colab?.openUrl) {\n",
       "                window.google.colab.openUrl('https://cloud.google.com/vertex-ai/generative-ai/docs/models/view-evaluation');\n",
       "              } else {\n",
       "                window.open('https://cloud.google.com/vertex-ai/generative-ai/docs/models/view-evaluation', '_blank');\n",
       "              }\n",
       "              e.stopPropagation();\n",
       "              e.preventDefault();\n",
       "            });\n",
       "          })();\n",
       "        </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_results  = eval_task.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bb53e308-02b1-40c7-aa2b-88de5b0669c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_results.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "abf5d12c-5347-4775-be81-a6a6d0d4bc03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'row_count': 8,\n",
       " 'custom_text_quality/mean': 1.6875,\n",
       " 'custom_text_quality/std': 0.45806269065645216}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_results.summary_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4f3a75a1-023d-46a8-aa54-501eb8e58fed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "      <th>custom_text_quality/explanation</th>\n",
       "      <th>custom_text_quality/score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Small blocks, endless worlds,\\nDragons built f...</td>\n",
       "      <td>fun_out_loud: The text has a sing-songy meter ...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Small blocks, endless worlds,\\nShips sail, dra...</td>\n",
       "      <td>fun_out_loud: The response is fun to read out ...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Small brick, endless worlds,\\nShips sail, drag...</td>\n",
       "      <td>fun_out_loud: The cadence is acceptable and ea...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Small blocks, worlds unfold,\\nPirate ships or ...</td>\n",
       "      <td>fun_out_loud: The response is fun to read out ...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Small blocks, endless worlds,\\nDragons built f...</td>\n",
       "      <td>fun_out_loud: The response is written in a met...</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Small brick, endless worlds,\\nShips and castle...</td>\n",
       "      <td>fun_out_loud: The response's meter is not bad....</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Small blocks, worlds unfold,\\nPirate ship or d...</td>\n",
       "      <td>fun_out_loud: The response is somewhat sing-so...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Small brick, boundless dream,\\nWorlds rise fro...</td>\n",
       "      <td>fun_out_loud: The response provides a poem wit...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            response  \\\n",
       "0  Small blocks, endless worlds,\\nDragons built f...   \n",
       "1  Small blocks, endless worlds,\\nShips sail, dra...   \n",
       "2  Small brick, endless worlds,\\nShips sail, drag...   \n",
       "3  Small blocks, worlds unfold,\\nPirate ships or ...   \n",
       "4  Small blocks, endless worlds,\\nDragons built f...   \n",
       "5  Small brick, endless worlds,\\nShips and castle...   \n",
       "6  Small blocks, worlds unfold,\\nPirate ship or d...   \n",
       "7  Small brick, boundless dream,\\nWorlds rise fro...   \n",
       "\n",
       "                     custom_text_quality/explanation  \\\n",
       "0  fun_out_loud: The text has a sing-songy meter ...   \n",
       "1  fun_out_loud: The response is fun to read out ...   \n",
       "2  fun_out_loud: The cadence is acceptable and ea...   \n",
       "3  fun_out_loud: The response is fun to read out ...   \n",
       "4  fun_out_loud: The response is written in a met...   \n",
       "5  fun_out_loud: The response's meter is not bad....   \n",
       "6  fun_out_loud: The response is somewhat sing-so...   \n",
       "7  fun_out_loud: The response provides a poem wit...   \n",
       "\n",
       "   custom_text_quality/score  \n",
       "0                        2.0  \n",
       "1                        2.0  \n",
       "2                        1.0  \n",
       "3                        2.0  \n",
       "4                        1.5  \n",
       "5                        2.0  \n",
       "6                        1.0  \n",
       "7                        2.0  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_results.metrics_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9eab923-dbb4-41ef-a783-ac546b33e7e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81ccaf8a-e86d-4ae4-a3d3-85cf244ba82d",
   "metadata": {},
   "source": [
    "## Workflow 3: Listing Available Model-Based Metrics\n",
    "\n",
    "**References:**\n",
    "- [Metric prompt templates for model-based evaluation](https://cloud.google.com/vertex-ai/generative-ai/docs/models/metrics-templates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0d184a-ea6f-4eee-bc79-766042805f3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d5b93b24-234e-4bcd-8521-d21a15126d9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__module__', '__doc__', 'FLUENCY', 'COHERENCE', 'SAFETY', 'GROUNDEDNESS', 'INSTRUCTION_FOLLOWING', 'VERBOSITY', 'TEXT_QUALITY', 'SUMMARIZATION_QUALITY', 'QUESTION_ANSWERING_QUALITY', 'MULTI_TURN_CHAT_QUALITY', 'MULTI_TURN_SAFETY_QUALITY', '__dict__', '__weakref__'])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vertexai.evaluation.MetricPromptTemplateExamples.Pairwise.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "66d682fe-057f-4d32-9a17-cecab82f60a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__module__', '__doc__', 'FLUENCY', 'COHERENCE', 'SAFETY', 'GROUNDEDNESS', 'INSTRUCTION_FOLLOWING', 'VERBOSITY', 'TEXT_QUALITY', 'SUMMARIZATION_QUALITY', 'QUESTION_ANSWERING_QUALITY', 'MULTI_TURN_CHAT_QUALITY', 'MULTI_TURN_SAFETY_QUALITY', '__dict__', '__weakref__'])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vertexai.evaluation.MetricPromptTemplateExamples.Pointwise.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3375a631-a76d-4eea-bad2-2f8405d78468",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
       "    <style>\n",
       "      .view-vertex-resource,\n",
       "      .view-vertex-resource:hover,\n",
       "      .view-vertex-resource:visited {\n",
       "        position: relative;\n",
       "        display: inline-flex;\n",
       "        flex-direction: row;\n",
       "        height: 32px;\n",
       "        padding: 0 12px;\n",
       "          margin: 4px 18px;\n",
       "        gap: 4px;\n",
       "        border-radius: 4px;\n",
       "\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "        background-color: rgb(255, 255, 255);\n",
       "        color: rgb(51, 103, 214);\n",
       "\n",
       "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
       "        font-size: 13px;\n",
       "        font-weight: 500;\n",
       "        text-transform: uppercase;\n",
       "        text-decoration: none !important;\n",
       "\n",
       "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
       "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active {\n",
       "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
       "        position: absolute;\n",
       "        top: 0;\n",
       "        bottom: 0;\n",
       "        left: 0;\n",
       "        right: 0;\n",
       "        border-radius: 4px;\n",
       "        pointer-events: none;\n",
       "\n",
       "        content: '';\n",
       "        background-color: rgb(51, 103, 214);\n",
       "        opacity: 0.12;\n",
       "      }\n",
       "      .view-vertex-icon {\n",
       "        font-size: 18px;\n",
       "      }\n",
       "    </style>\n",
       "  \n",
       "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-075a001f-af4d-4294-96eb-8122854f22f9\" href=\"#view-view-vertex-resource-075a001f-af4d-4294-96eb-8122854f22f9\">\n",
       "          <span class=\"material-icons view-vertex-icon\">list</span>\n",
       "          <span>Browse pre-built metrics</span>\n",
       "        </a>\n",
       "        \n",
       "        <script>\n",
       "          (function () {\n",
       "            const link = document.getElementById('view-vertex-resource-075a001f-af4d-4294-96eb-8122854f22f9');\n",
       "            link.addEventListener('click', (e) => {\n",
       "              if (window.google?.colab?.openUrl) {\n",
       "                window.google.colab.openUrl('https://cloud.google.com/vertex-ai/generative-ai/docs/models/metrics-templates');\n",
       "              } else {\n",
       "                window.open('https://cloud.google.com/vertex-ai/generative-ai/docs/models/metrics-templates', '_blank');\n",
       "              }\n",
       "              e.stopPropagation();\n",
       "              e.preventDefault();\n",
       "            });\n",
       "          })();\n",
       "        </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['coherence',\n",
       " 'fluency',\n",
       " 'safety',\n",
       " 'groundedness',\n",
       " 'instruction_following',\n",
       " 'verbosity',\n",
       " 'text_quality',\n",
       " 'summarization_quality',\n",
       " 'question_answering_quality',\n",
       " 'multi_turn_chat_quality',\n",
       " 'multi_turn_safety',\n",
       " 'pairwise_coherence',\n",
       " 'pairwise_fluency',\n",
       " 'pairwise_safety',\n",
       " 'pairwise_groundedness',\n",
       " 'pairwise_instruction_following',\n",
       " 'pairwise_verbosity',\n",
       " 'pairwise_text_quality',\n",
       " 'pairwise_summarization_quality',\n",
       " 'pairwise_question_answering_quality',\n",
       " 'pairwise_multi_turn_chat_quality',\n",
       " 'pairwise_multi_turn_safety']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vertexai.evaluation.MetricPromptTemplateExamples.list_example_metric_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0b15bed8-c179-405e-b1e6-03a7b26a5767",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Instruction\n",
      "You are an expert evaluator. Your task is to evaluate the quality of the responses generated by two AI models. We will provide you with the user input and a pair of AI-generated responses (Response A and Response B). You should first read the user input carefully for analyzing the task, and then evaluate the quality of the responses based on the Criteria provided in the Evaluation section below.\n",
      "You will first judge responses individually, following the Rating Rubric and Evaluation Steps. Then you will give step-by-step explanations for your judgment, compare the results to declare the winner based on the Rating Rubric and Evaluation Steps.\n",
      "\n",
      "# Evaluation\n",
      "## Metric Definition\n",
      "You will be assessing the Text Quality of each model's response, which measures how effectively the text conveys clear, accurate, and engaging information that directly addresses the user's prompt, considering factors like fluency, coherence, relevance, and conciseness.\n",
      "\n",
      "## Criteria\n",
      "Coherence: The response presents ideas in a logical and organized manner, with clear transitions and a consistent focus, making it easy to follow and understand.\n",
      "Fluency: The text flows smoothly and naturally, adhering to grammatical rules and using appropriate vocabulary.\n",
      "Instruction following: The response demonstrates a clear understanding of the task instructions, satisfying all of the instruction's requirements.\n",
      "Groundedness: The response contains information included only in the context. The response does not reference any outside information.\n",
      "Verbosity: The response is appropriately concise, providing sufficient detail without using complex language to thoroughly address the prompt without being overly wordy or excessively brief.\n",
      "\n",
      "## Rating Rubric\n",
      "\"A\": Response A demonstrates significantly better Text Quality than Response B as per criteria, excelling in aspects such as coherence, fluency, instruction following, groundedness, and verbosity.\n",
      "\"SAME\": Response A and Response B demonstrate comparable Text Quality as per criteria, with no significant differences in aspects such as coherence, fluency, instruction following, groundedness, and verbosity.\n",
      "\"B\": Response B demonstrates significantly better Text Quality than Response A as per criteria, excelling in aspects such as coherence, fluency, instruction following, groundedness, and verbosity.\n",
      "\n",
      "\n",
      "## Evaluation Steps\n",
      "STEP 1: Analyze Response A based on all the Criteria provided, including Coherence, Fluency, Instruction following, Groundedness, and Verbosity. Provide assessment according to each criterion.\n",
      "STEP 2: Analyze Response B based on all the Criteria provided, including Coherence, Fluency, Instruction following, Groundedness, and Verbosity. Provide assessment according to each criterion.\n",
      "STEP 3: Compare the overall performance of Response A and Response B based on your analyses and assessment of each criterion.\n",
      "STEP 4: Output your preference of \"A\", \"SAME\" or \"B\" to the pairwise_choice field according to the Rating Rubric.\n",
      "STEP 5: Output your assessment reasoning in the explanation field, justifying your choice by highlighting the specific strengths and weaknesses of each response in terms of Text Quality.\n",
      "\n",
      "\n",
      "# User Inputs and AI-generated Responses\n",
      "## User Inputs\n",
      "### Prompt\n",
      "{prompt}\n",
      "\n",
      "# AI-generated Responses\n",
      "\n",
      "### Response A\n",
      "{baseline_model_response}\n",
      "\n",
      "### Response B\n",
      "{response}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(vertexai.evaluation.MetricPromptTemplateExamples.get_prompt_template('pairwise_text_quality'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636d8fda-3f8a-4db8-89e4-11be9fedfa31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0cc144aa-f036-47a8-8071-f284b4757576",
   "metadata": {},
   "source": [
    "## Workflow 4: Pairwise Evaluation With Modified Pre-Built Metric\n",
    "\n",
    "Compare multiple models and have the evaluation service make the model generation calls for the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c9f50c-43b8-4586-a1d3-87d3efb92f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8687d701-2ca7-4aa2-a10c-97d5c6256d56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating a total of 1 responses from Gemini model gemini-1.5-pro-002.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 1 responses are successfully generated from Gemini model gemini-1.5-pro-002.\n",
      "Multithreaded Batch Inference took: 0.7885037232190371 seconds.\n",
      "Generating a total of 1 responses from Gemini model gemini-1.5-flash-002.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 1 responses are successfully generated from Gemini model gemini-1.5-flash-002.\n",
      "Multithreaded Batch Inference took: 0.3570019705221057 seconds.\n",
      "Computing metrics with a total of 1 Vertex Gen AI Evaluation Service API requests.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 1 metric requests are successfully computed.\n",
      "Evaluation Took:2.183914008550346 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
       "    <style>\n",
       "      .view-vertex-resource,\n",
       "      .view-vertex-resource:hover,\n",
       "      .view-vertex-resource:visited {\n",
       "        position: relative;\n",
       "        display: inline-flex;\n",
       "        flex-direction: row;\n",
       "        height: 32px;\n",
       "        padding: 0 12px;\n",
       "          margin: 4px 18px;\n",
       "        gap: 4px;\n",
       "        border-radius: 4px;\n",
       "\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "        background-color: rgb(255, 255, 255);\n",
       "        color: rgb(51, 103, 214);\n",
       "\n",
       "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
       "        font-size: 13px;\n",
       "        font-weight: 500;\n",
       "        text-transform: uppercase;\n",
       "        text-decoration: none !important;\n",
       "\n",
       "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
       "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active {\n",
       "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
       "        position: absolute;\n",
       "        top: 0;\n",
       "        bottom: 0;\n",
       "        left: 0;\n",
       "        right: 0;\n",
       "        border-radius: 4px;\n",
       "        pointer-events: none;\n",
       "\n",
       "        content: '';\n",
       "        background-color: rgb(51, 103, 214);\n",
       "        opacity: 0.12;\n",
       "      }\n",
       "      .view-vertex-icon {\n",
       "        font-size: 18px;\n",
       "      }\n",
       "    </style>\n",
       "  \n",
       "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-d76036c2-7f0e-46ca-96a3-a743158a8796\" href=\"#view-view-vertex-resource-d76036c2-7f0e-46ca-96a3-a743158a8796\">\n",
       "          <span class=\"material-icons view-vertex-icon\">bar_chart</span>\n",
       "          <span>View evaluation results</span>\n",
       "        </a>\n",
       "        \n",
       "        <script>\n",
       "          (function () {\n",
       "            const link = document.getElementById('view-vertex-resource-d76036c2-7f0e-46ca-96a3-a743158a8796');\n",
       "            link.addEventListener('click', (e) => {\n",
       "              if (window.google?.colab?.openUrl) {\n",
       "                window.google.colab.openUrl('https://cloud.google.com/vertex-ai/generative-ai/docs/models/view-evaluation');\n",
       "              } else {\n",
       "                window.open('https://cloud.google.com/vertex-ai/generative-ai/docs/models/view-evaluation', '_blank');\n",
       "              }\n",
       "              e.stopPropagation();\n",
       "              e.preventDefault();\n",
       "            });\n",
       "          })();\n",
       "        </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pairwise_quality = vertexai.evaluation.PairwiseMetric(\n",
    "    metric = 'my_text_quality',\n",
    "    metric_prompt_template = vertexai.evaluation.MetricPromptTemplateExamples.get_prompt_template('pairwise_text_quality'),\n",
    "    baseline_model = gemini_flash\n",
    ")\n",
    "eval_dataset = pd.DataFrame(dict(prompt = ['Write a Haiku about Lego bricks.']))\n",
    "pairwise_task = vertexai.evaluation.EvalTask(\n",
    "    dataset = eval_dataset,\n",
    "    metrics = [pairwise_quality],\n",
    ")\n",
    "pairwise_result = pairwise_task.evaluate(\n",
    "    model = gemini_pro\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c3e18952-c701-4ff9-8e0b-9e71eab651db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>baseline_model_response</th>\n",
       "      <th>my_text_quality/explanation</th>\n",
       "      <th>my_text_quality/pairwise_choice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Write a Haiku about Lego bricks.</td>\n",
       "      <td>Colorful plastic\\nClick together, worlds are b...</td>\n",
       "      <td>Colorful plastic,\\nEndless worlds in tiny bric...</td>\n",
       "      <td>Both responses fulfill the prompt but BASELINE...</td>\n",
       "      <td>BASELINE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             prompt  \\\n",
       "0  Write a Haiku about Lego bricks.   \n",
       "\n",
       "                                            response  \\\n",
       "0  Colorful plastic\\nClick together, worlds are b...   \n",
       "\n",
       "                             baseline_model_response  \\\n",
       "0  Colorful plastic,\\nEndless worlds in tiny bric...   \n",
       "\n",
       "                         my_text_quality/explanation  \\\n",
       "0  Both responses fulfill the prompt but BASELINE...   \n",
       "\n",
       "  my_text_quality/pairwise_choice  \n",
       "0                        BASELINE  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairwise_result.metrics_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7e617a-18fb-4069-97f4-a7b14742085b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b93efbd-2374-4588-8f1c-c9cae269deba",
   "metadata": {},
   "source": [
    "## Workflow 5: Evaluation with Multiple Computation-Based Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6888550-fe74-47c9-a059-2f99f5e61ddf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "78ea958e-837a-455c-816f-3d856c031d6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_dataset = pd.DataFrame(\n",
    "    dict(\n",
    "        reference = ['Plastic colored dreams, Clicking, building, towers rise, Worlds born piece by piece.'] * 8,\n",
    "        response = [r.text for r in flash_responses.candidates]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c4dfb43c-c468-46c7-a59a-86fb156c19ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_task = vertexai.evaluation.EvalTask(\n",
    "    dataset = eval_dataset,\n",
    "    metrics = ['bleu', 'exact_match', 'rouge']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "52867053-adaf-459e-8ecc-26c2d2984213",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metrics with a total of 24 Vertex Gen AI Evaluation Service API requests.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:23<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 24 metric requests are successfully computed.\n",
      "Evaluation Took:23.085264557041228 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
       "    <style>\n",
       "      .view-vertex-resource,\n",
       "      .view-vertex-resource:hover,\n",
       "      .view-vertex-resource:visited {\n",
       "        position: relative;\n",
       "        display: inline-flex;\n",
       "        flex-direction: row;\n",
       "        height: 32px;\n",
       "        padding: 0 12px;\n",
       "          margin: 4px 18px;\n",
       "        gap: 4px;\n",
       "        border-radius: 4px;\n",
       "\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "        background-color: rgb(255, 255, 255);\n",
       "        color: rgb(51, 103, 214);\n",
       "\n",
       "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
       "        font-size: 13px;\n",
       "        font-weight: 500;\n",
       "        text-transform: uppercase;\n",
       "        text-decoration: none !important;\n",
       "\n",
       "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
       "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active {\n",
       "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
       "        position: absolute;\n",
       "        top: 0;\n",
       "        bottom: 0;\n",
       "        left: 0;\n",
       "        right: 0;\n",
       "        border-radius: 4px;\n",
       "        pointer-events: none;\n",
       "\n",
       "        content: '';\n",
       "        background-color: rgb(51, 103, 214);\n",
       "        opacity: 0.12;\n",
       "      }\n",
       "      .view-vertex-icon {\n",
       "        font-size: 18px;\n",
       "      }\n",
       "    </style>\n",
       "  \n",
       "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-7f5d8ab1-250a-478b-9739-e8c03f132ae3\" href=\"#view-view-vertex-resource-7f5d8ab1-250a-478b-9739-e8c03f132ae3\">\n",
       "          <span class=\"material-icons view-vertex-icon\">bar_chart</span>\n",
       "          <span>View evaluation results</span>\n",
       "        </a>\n",
       "        \n",
       "        <script>\n",
       "          (function () {\n",
       "            const link = document.getElementById('view-vertex-resource-7f5d8ab1-250a-478b-9739-e8c03f132ae3');\n",
       "            link.addEventListener('click', (e) => {\n",
       "              if (window.google?.colab?.openUrl) {\n",
       "                window.google.colab.openUrl('https://cloud.google.com/vertex-ai/generative-ai/docs/models/view-evaluation');\n",
       "              } else {\n",
       "                window.open('https://cloud.google.com/vertex-ai/generative-ai/docs/models/view-evaluation', '_blank');\n",
       "              }\n",
       "              e.stopPropagation();\n",
       "              e.preventDefault();\n",
       "            });\n",
       "          })();\n",
       "        </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_result = eval_task.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8c27062f-2661-42bf-9c31-c87089ccd6a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'row_count': 8,\n",
       " 'bleu/mean': 0.042436428375,\n",
       " 'bleu/std': 0.020690220151082194,\n",
       " 'exact_match/mean': 0.0,\n",
       " 'exact_match/std': 0.0,\n",
       " 'rouge/mean': 0.15374033437499998,\n",
       " 'rouge/std': 0.07371710453463654}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_result.summary_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5d48d78d-c8c0-439f-8860-6c41daab7375",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>response</th>\n",
       "      <th>bleu/score</th>\n",
       "      <th>exact_match/score</th>\n",
       "      <th>rouge/score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Plastic colored dreams, Clicking, building, to...</td>\n",
       "      <td>Small blocks, endless worlds,\\nDragons built f...</td>\n",
       "      <td>0.084754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Plastic colored dreams, Clicking, building, to...</td>\n",
       "      <td>Small blocks, endless worlds,\\nShips sail, dra...</td>\n",
       "      <td>0.032115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Plastic colored dreams, Clicking, building, to...</td>\n",
       "      <td>Small brick, endless worlds,\\nShips sail, drag...</td>\n",
       "      <td>0.025828</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Plastic colored dreams, Clicking, building, to...</td>\n",
       "      <td>Small blocks, worlds unfold,\\nPirate ships or ...</td>\n",
       "      <td>0.057514</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Plastic colored dreams, Clicking, building, to...</td>\n",
       "      <td>Small blocks, endless worlds,\\nDragons built f...</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Plastic colored dreams, Clicking, building, to...</td>\n",
       "      <td>Small brick, endless worlds,\\nShips and castle...</td>\n",
       "      <td>0.032115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.230769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Plastic colored dreams, Clicking, building, to...</td>\n",
       "      <td>Small blocks, worlds unfold,\\nPirate ship or d...</td>\n",
       "      <td>0.024427</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Plastic colored dreams, Clicking, building, to...</td>\n",
       "      <td>Small brick, boundless dream,\\nWorlds rise fro...</td>\n",
       "      <td>0.050395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.074074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           reference  \\\n",
       "0  Plastic colored dreams, Clicking, building, to...   \n",
       "1  Plastic colored dreams, Clicking, building, to...   \n",
       "2  Plastic colored dreams, Clicking, building, to...   \n",
       "3  Plastic colored dreams, Clicking, building, to...   \n",
       "4  Plastic colored dreams, Clicking, building, to...   \n",
       "5  Plastic colored dreams, Clicking, building, to...   \n",
       "6  Plastic colored dreams, Clicking, building, to...   \n",
       "7  Plastic colored dreams, Clicking, building, to...   \n",
       "\n",
       "                                            response  bleu/score  \\\n",
       "0  Small blocks, endless worlds,\\nDragons built f...    0.084754   \n",
       "1  Small blocks, endless worlds,\\nShips sail, dra...    0.032115   \n",
       "2  Small brick, endless worlds,\\nShips sail, drag...    0.025828   \n",
       "3  Small blocks, worlds unfold,\\nPirate ships or ...    0.057514   \n",
       "4  Small blocks, endless worlds,\\nDragons built f...    0.032342   \n",
       "5  Small brick, endless worlds,\\nShips and castle...    0.032115   \n",
       "6  Small blocks, worlds unfold,\\nPirate ship or d...    0.024427   \n",
       "7  Small brick, boundless dream,\\nWorlds rise fro...    0.050395   \n",
       "\n",
       "   exact_match/score  rouge/score  \n",
       "0                0.0     0.222222  \n",
       "1                0.0     0.160000  \n",
       "2                0.0     0.071429  \n",
       "3                0.0     0.240000  \n",
       "4                0.0     0.160000  \n",
       "5                0.0     0.230769  \n",
       "6                0.0     0.071429  \n",
       "7                0.0     0.074074  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_result.metrics_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856722a5-aa51-46b7-ae88-29ab713fa277",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
