{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b052034b",
   "metadata": {},
   "source": [
    "![tracker](https://us-central1-vertex-ai-mlops-369716.cloudfunctions.net/pixel-tracking?path=statmike%2Fvertex-ai-mlops%2FApplied+GenAI%2FEvaluation&file=Optimize+Prompts+Using+Evaluation+Metrics.ipynb)\n",
    "<!--- header table --->\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/statmike/vertex-ai-mlops/blob/main/Applied%20GenAI/Evaluation/Optimize%20Prompts%20Using%20Evaluation%20Metrics.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\">\n",
    "      <br>Run in<br>Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https%3A%2F%2Fraw.githubusercontent.com%2Fstatmike%2Fvertex-ai-mlops%2Fmain%2FApplied%2520GenAI%2FEvaluation%2FOptimize%2520Prompts%2520Using%2520Evaluation%2520Metrics.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\">\n",
    "      <br>Run in<br>Colab Enterprise\n",
    "    </a>\n",
    "  </td>      \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/statmike/vertex-ai-mlops/blob/main/Applied%20GenAI/Evaluation/Optimize%20Prompts%20Using%20Evaluation%20Metrics.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      <br>View on<br>GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/statmike/vertex-ai-mlops/main/Applied%20GenAI/Evaluation/Optimize%20Prompts%20Using%20Evaluation%20Metrics.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      <br>Open in<br>Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d79870-678f-4fd2-8b3f-d0685103c9db",
   "metadata": {},
   "source": [
    "# Optimize Prompts Using Evaluation Metrics\n",
    "\n",
    "Prompt optimization rewrites system instructions to optimize the performance of a set of prompts on one or more evaluation metrics.\n",
    "\n",
    "First, it is helpful to understand the Vertex AI GenAI evaluation service as covered in this workflow: [Evaluation For GenAI](./Evaluation%20For%20GenAI.ipynb). Evaluation is the comparison of a model's output to a baseline or ground truth using a metric to quantify the performance. Vertex AI offers pointwise metrics, pairwise metrics, and computed metrics for GenAI evaluation. These same evaluations can be used as the optimization goal for prompt optimization - the focus of this workflow.\n",
    "\n",
    "The Vertex AI Prompt Optimization service is a tool that optimizes system instructions for a set of prompts. It offers modes for optimizing the system instructions with and without the inclusion of demonstrations, also known as multi-shot prompting. The content of this workflow is summarized here with direct links to official documentation:\n",
    "\n",
    "- Documentation Link: [Optimize Prompts](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/prompt-optimizer)\n",
    "- This service provides code: [GitHub Link to .py file](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/prompts/prompt_optimizer/vapo_lib.py)\n",
    "    - And [example notebooks](https://github.com/GoogleCloudPlatform/generative-ai/tree/main/gemini/prompts/prompt_optimizer)\n",
    "- The user uses the code to initialize a prompt optimization job, which runs as a Vertex AI Custom Training Job\n",
    "- The inputs are:\n",
    "    - The current **System Instructions** - [Documentation Link](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/prompt-optimizer#template-si)\n",
    "    - The **Prompt Template** for the sample prompts - [Documentation Link](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/prompt-optimizer#template-si)\n",
    "        - If you have ground truth responses, or responses from a known good model, then the template can include a `{target}` variable that maps to the `target` values in the input file\n",
    "        - If you don't have these responses, you can provide the `source_model` parameter in the configuration, and the optimization job will use the model to generate responses for comparison.\n",
    "    - A **file of input data** for each sample prompt to be used with the prompt template - [Documentation Link](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/prompt-optimizer#prepare-sample-prompts)\n",
    "        - Either a JSONL file or a CSV stored in a GCS bucket\n",
    "    - **Configuration parameters** for the job - [Documentation Link](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/prompt-optimizer#configuration)\n",
    "        - Which metrics to use, including custom metrics\n",
    "        - Which target and source LLM to use\n",
    "        - Many more optional parameters\n",
    "- The outputs are:\n",
    "    - Optimized System Instructions\n",
    "    - Results for each evaluation step taken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c2de9e-09fb-47a0-bbac-352b31b7dd29",
   "metadata": {
    "id": "od_UkDpvRmgD",
    "tags": []
   },
   "source": [
    "---\n",
    "## Colab Setup\n",
    "\n",
    "To run this notebook in Colab run the cells in this section.  Otherwise, skip this section.\n",
    "\n",
    "This cell will authenticate to GCP (follow prompts in the popup)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69b929cf-bfd4-4046-bca9-549b1a9a2c99",
   "metadata": {
    "executionInfo": {
     "elapsed": 195,
     "status": "ok",
     "timestamp": 1683726184843,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "8UO9FnqyKBlF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'statmike-mlops-349915' # replace with project ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eddec88e-5ed0-4cc6-af40-9fd0c37be7e2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68869,
     "status": "ok",
     "timestamp": 1683726253709,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "N98-KK7LRkjm",
    "outputId": "09ec5008-0def-4e1a-c349-c598ee752f78",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not a Colab Environment\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    !gcloud config set project {PROJECT_ID}\n",
    "    print('Colab authorized to GCP')\n",
    "except Exception:\n",
    "    print('Not a Colab Environment')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7887c228-1e53-4601-97bf-6958f6805838",
   "metadata": {},
   "source": [
    "---\n",
    "## Installs\n",
    "\n",
    "The list `packages` contains tuples of package import names and install names.  If the import name is not found then the install name is used to install quitely for the current user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc155657-fed5-4b08-92a3-ee40fe992246",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tuples of (import name, install name, min_version)\n",
    "packages = [\n",
    "    ('google.cloud.aiplatform', 'google-cloud-aiplatform', '1.78.0'),\n",
    "    ('google.cloud.storage', 'google-cloud-storage'),\n",
    "    ('pandas', 'pandas')\n",
    "]\n",
    "\n",
    "import importlib\n",
    "install = False\n",
    "for package in packages:\n",
    "    if not importlib.util.find_spec(package[0]):\n",
    "        print(f'installing package {package[1]}')\n",
    "        install = True\n",
    "        !pip install {package[1]} -U -q --user\n",
    "    elif len(package) == 3:\n",
    "        if importlib.metadata.version(package[0]) < package[2]:\n",
    "            print(f'updating package {package[1]}')\n",
    "            install = True\n",
    "            !pip install {package[1]} -U -q --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c718e7-8fab-4c2d-bb8f-458ce8fa06bf",
   "metadata": {},
   "source": [
    "### API Enablement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61e13ed9-b569-432c-88ec-9cd3a276b082",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gcloud services enable aiplatform.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53de01be-c07a-4a05-8643-7b18deefe236",
   "metadata": {},
   "source": [
    "### Restart Kernel (If Installs Occured)\n",
    "\n",
    "After a kernel restart the code submission can start with the next cell after this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e4c7c96-e263-45ba-bb2e-c59290f5b8cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if install:\n",
    "    import IPython\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)\n",
    "    IPython.display.display(IPython.display.Markdown(\"\"\"<div class=\\\"alert alert-block alert-warning\\\">\n",
    "        <b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. The previous cells do not need to be run again⚠️</b>\n",
    "        </div>\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e48e4b-7bdf-4a72-b7ea-cbeb997f248f",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb350cfd-b8eb-4dd0-95ad-919710d8d752",
   "metadata": {},
   "source": [
    "inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c3e3fbc-aba1-4929-9eb1-2e363648db10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'statmike-mlops-349915'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbb2ebcc-2f90-4dfd-9d1c-c1df79a3713c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "SERIES = 'applied-genai'\n",
    "EXPERIMENT = 'prompt-optimization'\n",
    "\n",
    "BUCKET = PROJECT_ID # change to Bucket name if not the same as the Project ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f53604d-523b-41d7-b458-e77cf6cbb854",
   "metadata": {},
   "source": [
    "packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60ce1a12-aa36-4c82-ba29-bac7a2cac6a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Python standard library imports:\n",
    "import json, io, requests, sys, types, datetime, time\n",
    "\n",
    "# package imports\n",
    "from IPython.display import Markdown, HTML, display\n",
    "\n",
    "# vertex ai imports\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import storage\n",
    "import vertexai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cbf9029-51a5-4895-8306-9c3ae092145b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.78.0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aiplatform.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a66d53-8014-45eb-93b7-34869b959ba5",
   "metadata": {},
   "source": [
    "clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3de3fc66-5c7b-47df-a864-539d663b57ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vertexai.init(project = PROJECT_ID, location = REGION)\n",
    "gcs = storage.Client(project = PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1936d63-a30c-4408-9e3b-2acbff56c444",
   "metadata": {},
   "source": [
    "---\n",
    "## Optimize Prompts: Prepare Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b4ddae-3921-433d-83e9-218f540a480a",
   "metadata": {},
   "source": [
    "### Load The Code\n",
    "\n",
    "The code is on [GitHub](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/prompts/prompt_optimizer/vapo_lib.py) as a `.py` file that is loaded in this session as a module with name `prompt_opt` by the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e2e3041-81b5-423a-8229-6ac01531283c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 23:54:44.195123: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1738194884.222224 3337070 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1738194884.230083 3337070 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-29 23:54:44.257623: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "module_name = 'vapo_lib'\n",
    "url = 'https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/prompts/prompt_optimizer/vapo_lib.py'\n",
    "response = requests.get(url)\n",
    "vapo_lib = types.ModuleType(module_name)\n",
    "vapo_lib.__file__ = f'<remote>/{module_name}.py'\n",
    "sys.modules[module_name] = vapo_lib\n",
    "exec(response.text, vapo_lib.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e55328f-01c0-403e-9239-1a2aed786a2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import vapo_lib as prompt_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f7cbfe-2399-4814-8d22-049380d4834a",
   "metadata": {},
   "source": [
    "### Define Inputs\n",
    "\n",
    "Define the current version of the system instruction and the template used for the prompt samples.\n",
    "\n",
    "> **Details About Prompt Templates**\n",
    ">\n",
    "> A prompt template contains the structure of the prompt with the parts that change replaced by variables in the format `{variable_name}`.  The variable names cannot contain spaces.\n",
    ">\n",
    "> If a prompt contains multimodal content then the variable should be followed with the `MIME_TYPE` like this: `{image_variable} @@@image/jpeg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce5f6416-ce67-4628-ad59-3868460ba0b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SYSTEM_INSTRUCTIONS = \"Write poems.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce11699a-de62-4797-9e02-5bbf1743cfb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = \"Write a {type} about {topic}.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5547fff8-7845-438c-9da1-12db6b641612",
   "metadata": {},
   "source": [
    "### Prepare Data For Prompts\n",
    "\n",
    "The prompt templates variables are read from a data struture provided as either a CSV or JSONL stored in a GCS bucket.  Here the data is first prepared as a list of dictionaries where each dictionary contains the key:value pairs for an instance of the prompt.\n",
    "\n",
    "> **Details About Multimodal Content**\n",
    ">\n",
    "> If the prompt template includes multimodal content then the variable should get values that are the GCS location of the content to load.  Example: `{\"image_variable\": \"gs://bucket_name/path/to/file/filename.extension\"}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d029fc9-a120-435d-9fc7-da8527ab59ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_parameters = [\n",
    "    dict(type = 'Haiku', topic = 'Lego'),\n",
    "    dict(type = 'Sonnet', topic = 'Lego'),\n",
    "    dict(type = 'Limerick', topic = 'Lego'),\n",
    "    dict(type = 'Acrostic', topic = 'Lego'),\n",
    "    dict(type = 'Ode', topic = 'Lego')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3941880-4af5-4709-99f6-09dfd8fa2b9b",
   "metadata": {},
   "source": [
    "### Store Prompt Data In GCS\n",
    "\n",
    "This example converts the list of dictionaries to JSON lines and stores it directly in a GCS bucket as `prompt_parameters.jsonl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94c7106e-5c63-431c-956e-b06240ed5a0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bucket = gcs.bucket(BUCKET)\n",
    "blob = bucket.blob(f'{SERIES}/{EXPERIMENT}/prompt_parameters.jsonl')\n",
    "with io.StringIO() as jsonl_file:\n",
    "    for item in prompt_parameters:\n",
    "        json.dump(item, jsonl_file)\n",
    "        jsonl_file.write('\\n')\n",
    "    blob.upload_from_string(jsonl_file.getvalue(), content_type = 'application/jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7cb64f-19c9-48c3-86c8-e23d37fb5d69",
   "metadata": {
    "tags": []
   },
   "source": [
    "Review the contents here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8edddd72-9720-41f3-8781-21824e4d00a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"type\": \"Haiku\", \"topic\": \"Lego\"}\n",
      "{\"type\": \"Sonnet\", \"topic\": \"Lego\"}\n",
      "{\"type\": \"Limerick\", \"topic\": \"Lego\"}\n",
      "{\"type\": \"Acrostic\", \"topic\": \"Lego\"}\n",
      "{\"type\": \"Ode\", \"topic\": \"Lego\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(blob.download_as_string().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cd1468-7e5d-43dd-a08b-6f63d55a268f",
   "metadata": {},
   "source": [
    "### Define Inputs Parameters And Validate Data\n",
    "\n",
    "The code contains methods for determining the required structure of the inputs and the completness of the inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd185b9f-c496-4aae-8af6-1f43cc289b6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SOURCE_MODEL = \"gemini-1.5-flash-001\" # or provide ground truth\n",
    "TARGET_MODEL = \"gemini-1.5-flash-002\" # the model for which the optimized system instructions are created for\n",
    "EVAL_METRICS = ['coherence', 'fluency'] # https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/prompt-optimizer#supported-evaluation-metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7e651ac-a58d-4121-8057-bb5c3864f3f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_opt.is_run_target_required(\n",
    "    eval_metric_types = EVAL_METRICS,\n",
    "    source_model = SOURCE_MODEL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d63e6a2-f60c-4e05-9ed4-127458824f1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_opt.validate_prompt_and_data(\n",
    "    template = '\\n'.join([SYSTEM_INSTRUCTIONS, PROMPT_TEMPLATE]),\n",
    "    dataset_path = f'gs://{bucket.name}/{blob.name}',\n",
    "    placeholder_to_content = '{}',\n",
    "    label_enforced = prompt_opt.is_run_target_required(\n",
    "        eval_metric_types = EVAL_METRICS,\n",
    "        source_model = SOURCE_MODEL\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23051ef6-cde8-479c-b1b3-28a2b8e0031d",
   "metadata": {},
   "source": [
    "---\n",
    "## Optimize Prompts: System Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2367cb-5797-49c6-b563-39ca7d4d1939",
   "metadata": {},
   "source": [
    "### Set Optimization Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80be3d57-5856-4866-993f-b31a463ae971",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIMIZATION_MODE = \"instruction\" # choices are instuction, demonstration, instruction_and_demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fedf305-dd6b-4695-b19e-2aefac4696c8",
   "metadata": {},
   "source": [
    "### Run Optimization Job On Vertex AI Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2b84469-a0e8-4717-867c-ce9107d3d282",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Job display name: lego_lyrics_2025-01-29T23:55:21\n",
      "Creating CustomJob\n",
      "CustomJob created. Resource name: projects/1026793852137/locations/us-central1/customJobs/1425355712598376448\n",
      "To use this CustomJob in another session:\n",
      "custom_job = aiplatform.CustomJob.get('projects/1026793852137/locations/us-central1/customJobs/1425355712598376448')\n",
      "View Custom Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/1425355712598376448?project=1026793852137\n"
     ]
    }
   ],
   "source": [
    "job_name = 'lego_lyrics_' + datetime.datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "vertex_job = prompt_opt.run_apd(\n",
    "    config = dict(\n",
    "        project = PROJECT_ID,\n",
    "        system_instruction = SYSTEM_INSTRUCTIONS,\n",
    "        prompt_template = PROMPT_TEMPLATE,\n",
    "        target_model = TARGET_MODEL,\n",
    "        target_model_location = REGION, \n",
    "        eval_metrics_types = EVAL_METRICS,\n",
    "        eval_metrics_weights = [.5, .5],\n",
    "        aggregation_type = 'weighted_sum',\n",
    "        source_model = SOURCE_MODEL,\n",
    "        optimization_mode = OPTIMIZATION_MODE,\n",
    "        input_data_path = f'gs://{bucket.name}/{blob.name}',\n",
    "        output_path = f'gs://{bucket.name}/{SERIES}/{EXPERIMENT}/{job_name}'\n",
    "    ),\n",
    "    bucket_uri = f'gs://{bucket.name}/{SERIES}/{EXPERIMENT}/{job_name}',\n",
    "    display_name = job_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3c412c-907a-43a1-9552-cac8582d8e01",
   "metadata": {},
   "source": [
    "Check out the Vertex AI Training Job with the link in the output above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5bae3bb4-98d9-4710-984b-f6331d38cbaf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1425355712598376448',\n",
       " 'lego_lyrics_2025-01-29T23:55:21',\n",
       " 'projects/1026793852137/locations/us-central1/customJobs/1425355712598376448')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vertex_job.name, vertex_job.display_name, vertex_job.resource_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b0f1349b-f06c-467a-a5fb-1bb42f4c5896",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job state: JOB_STATE_PENDING, checking again in 30 seconds...\n",
      "Job state: JOB_STATE_PENDING, checking again in 30 seconds...\n",
      "Job state: JOB_STATE_PENDING, checking again in 30 seconds...\n",
      "Job state: JOB_STATE_PENDING, checking again in 30 seconds...\n",
      "Job state: JOB_STATE_PENDING, checking again in 30 seconds...\n",
      "Job state: JOB_STATE_PENDING, checking again in 30 seconds...\n",
      "Job state: JOB_STATE_RUNNING, checking again in 30 seconds...\n",
      "Job state: JOB_STATE_RUNNING, checking again in 30 seconds...\n",
      "Job state: JOB_STATE_RUNNING, checking again in 30 seconds...\n",
      "Job state: JOB_STATE_RUNNING, checking again in 30 seconds...\n",
      "Job state: JOB_STATE_RUNNING, checking again in 30 seconds...\n",
      "Job state: JOB_STATE_RUNNING, checking again in 30 seconds...\n",
      "Job state: JOB_STATE_RUNNING, checking again in 30 seconds...\n",
      "Job state: JOB_STATE_RUNNING, checking again in 30 seconds...\n",
      "Job state: JOB_STATE_RUNNING, checking again in 30 seconds...\n",
      "Job state: JOB_STATE_RUNNING, checking again in 30 seconds...\n",
      "Job state: JOB_STATE_RUNNING, checking again in 30 seconds...\n",
      "Job state: JOB_STATE_RUNNING, checking again in 30 seconds...\n",
      "Job state: JOB_STATE_RUNNING, checking again in 30 seconds...\n",
      "Job state: JOB_STATE_RUNNING, checking again in 30 seconds...\n",
      "Job state: JOB_STATE_RUNNING, checking again in 30 seconds...\n",
      "Job state: JOB_STATE_RUNNING, checking again in 30 seconds...\n",
      "Job state: JOB_STATE_RUNNING, checking again in 30 seconds...\n",
      "Job state: JOB_STATE_RUNNING, checking again in 30 seconds...\n",
      "Job state: JOB_STATE_RUNNING, checking again in 30 seconds...\n",
      "Job state: JOB_STATE_RUNNING, checking again in 30 seconds...\n",
      "Job state: JOB_STATE_RUNNING, checking again in 30 seconds...\n",
      "Job state: JOB_STATE_RUNNING, checking again in 30 seconds...\n",
      "Job state: JOB_STATE_RUNNING, checking again in 30 seconds...\n",
      "Job state: JOB_STATE_RUNNING, checking again in 30 seconds...\n"
     ]
    }
   ],
   "source": [
    "while vertex_job.state == aiplatform.gapic.JobState.JOB_STATE_PENDING or vertex_job.state == aiplatform.gapic.JobState.JOB_STATE_RUNNING:\n",
    "    print(f\"Job state: {vertex_job.state.name}, checking again in 30 seconds...\")\n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "02cfd7b8-a65d-45cf-b3f1-134ce12fd3b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'JOB_STATE_SUCCEEDED'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vertex_job.state.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5c596a08-3660-492e-a081-1bf2292ddf82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The job ran for 15 minutes and 16 seconds\n"
     ]
    }
   ],
   "source": [
    "minutes, seconds = divmod((vertex_job.end_time - vertex_job.start_time).total_seconds(), 60)\n",
    "print(f'The job ran for {int(minutes)} minutes and {int(seconds)} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fe72cc-6db1-4ecc-b75f-aebc506d0d0f",
   "metadata": {},
   "source": [
    "### Review The Optimized Result: System Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1533379c-3ae9-4fd9-8319-1bcbce5e5c62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'step': 5,\n",
       " 'metrics': {'coherence/mean': 4.8,\n",
       "  'fluency/mean': 4.8,\n",
       "  'composite_metric/mean': 4.8},\n",
       " 'prompt': 'Write a poem of the specified TYPE and TOPIC.  Adhere to the rules and conventions of the given poem TYPE.  The poem should be creative, use vivid imagery, and have a strong rhythm if applicable to the TYPE. Do not generate poems in other formats.\\n\\nTYPE: Ode\\n\\nTOPIC: Lego\\n\\nSpecifically, focus on the elevated and lyrical nature of an ode, praising the qualities of Lego.  Consider its versatility, the joy it brings, and the creativity it inspires.'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = json.loads(\n",
    "    bucket.blob(f'{SERIES}/{EXPERIMENT}/{job_name}/instruction/optimized_results.json').download_as_string()\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "34f068ab-08ea-445b-abd8-6357c0824edf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Write a poem of the specified TYPE and TOPIC.  Adhere to the rules and conventions of the given poem TYPE.  The poem should be creative, use vivid imagery, and have a strong rhythm if applicable to the TYPE. Do not generate poems in other formats.\n",
       "\n",
       "TYPE: Ode\n",
       "\n",
       "TOPIC: Lego\n",
       "\n",
       "Specifically, focus on the elevated and lyrical nature of an ode, praising the qualities of Lego.  Consider its versatility, the joy it brings, and the creativity it inspires."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(result['prompt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fafdc1e-9472-47ea-add5-dbe24e517d66",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Review The Evaluation Process: Step-By-Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "df3ce2f6-a92b-4e37-a13f-c9f72032a523",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_ui = prompt_opt.ResultsUI(path = f'gs://{bucket.name}/{SERIES}/{EXPERIMENT}/{job_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c6de0fe5-79fe-47a0-8cd0-16881c6a8828",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  .scrollable {\n",
       "    width: 100%;\n",
       "    height: 80px;\n",
       "    overflow-y: auto;\n",
       "    overflow-x: hidden;  /* Hide horizontal scrollbar */\n",
       "  }\n",
       "  tr:nth-child(odd) {\n",
       "    background: var(--colab-highlighted-surface-color);\n",
       "  }\n",
       "  tr:nth-child(even) {\n",
       "    background-color: var(--colab-primary-surface-color);\n",
       "  }\n",
       "  th {\n",
       "    background-color: var(--colab-highlighted-surface-color);\n",
       "  }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2e0628233bf4c1e9c9ee6500a54855e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Select Run:'), Dropdown(layout=Layout(width='200px'), options=('gs://statmike-mlop…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_df_html = \"\"\"\n",
    "<style>\n",
    "  .scrollable {\n",
    "    width: 100%;\n",
    "    height: 80px;\n",
    "    overflow-y: auto;\n",
    "    overflow-x: hidden;  /* Hide horizontal scrollbar */\n",
    "  }\n",
    "  tr:nth-child(odd) {\n",
    "    background: var(--colab-highlighted-surface-color);\n",
    "  }\n",
    "  tr:nth-child(even) {\n",
    "    background-color: var(--colab-primary-surface-color);\n",
    "  }\n",
    "  th {\n",
    "    background-color: var(--colab-highlighted-surface-color);\n",
    "  }\n",
    "</style>\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(results_df_html))\n",
    "display(results_ui.get_container())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c808a535-7151-49ce-9269-fc6774c49085",
   "metadata": {},
   "source": [
    "---\n",
    "## Optimize Prompts: System Instructions Multi-Shot Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209e1bc8-3d0e-4074-85bb-debc70536275",
   "metadata": {},
   "source": [
    "### Set Optimization Mode\n",
    "\n",
    "Use `instruction_and_demo` to optimize the system instructions and include examples, called demonstration, for multi-shot prompting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f374e1dd-7c47-410d-a30a-1cd3135f8730",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "OPTIMIZATION_MODE = \"instruction_and_demo\" # choices are instuction, demonstration, instruction_and_demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecb645d-7f8b-49c6-a4f8-7c324535c644",
   "metadata": {},
   "source": [
    "### Run Optimization Job On Vertex AI Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0c7d9938-d782-4e21-b143-4d8e9e58f483",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Job display name: lego_lyrics_2025-01-30T12:32:02\n",
      "Creating CustomJob\n",
      "CustomJob created. Resource name: projects/1026793852137/locations/us-central1/customJobs/521134942101438464\n",
      "To use this CustomJob in another session:\n",
      "custom_job = aiplatform.CustomJob.get('projects/1026793852137/locations/us-central1/customJobs/521134942101438464')\n",
      "View Custom Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/521134942101438464?project=1026793852137\n"
     ]
    }
   ],
   "source": [
    "job_name = 'lego_lyrics_' + datetime.datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "vertex_job = prompt_opt.run_apd(\n",
    "    config = dict(\n",
    "        project = PROJECT_ID,\n",
    "        system_instruction = SYSTEM_INSTRUCTIONS,\n",
    "        prompt_template = PROMPT_TEMPLATE,\n",
    "        target_model = TARGET_MODEL,\n",
    "        target_model_location = REGION, \n",
    "        eval_metrics_types = EVAL_METRICS,\n",
    "        eval_metrics_weights = [.5, .5],\n",
    "        aggregation_type = 'weighted_sum',\n",
    "        source_model = SOURCE_MODEL,\n",
    "        optimization_mode = OPTIMIZATION_MODE,\n",
    "        input_data_path = f'gs://{bucket.name}/{blob.name}',\n",
    "        output_path = f'gs://{bucket.name}/{SERIES}/{EXPERIMENT}/{job_name}'\n",
    "    ),\n",
    "    bucket_uri = f'gs://{bucket.name}/{SERIES}/{EXPERIMENT}/{job_name}',\n",
    "    display_name = job_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a61e57e-492e-4682-8ba4-c639c8945e58",
   "metadata": {},
   "source": [
    "Check out the Vertex AI Training Job with the link in the output above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0bddef0e-7ccf-4d46-b979-a3ef303ccd21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('521134942101438464',\n",
       " 'lego_lyrics_2025-01-30T12:32:02',\n",
       " 'projects/1026793852137/locations/us-central1/customJobs/521134942101438464')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vertex_job.name, vertex_job.display_name, vertex_job.resource_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1a1d8817-a93d-4406-854a-0891c5ac002f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "while vertex_job.state == aiplatform.gapic.JobState.JOB_STATE_PENDING or vertex_job.state == aiplatform.gapic.JobState.JOB_STATE_RUNNING:\n",
    "    print(f\"Job state: {vertex_job.state.name}, checking again in 30 seconds...\")\n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bd08f94b-920f-42c6-8edf-ac995539747d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'JOB_STATE_SUCCEEDED'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vertex_job.state.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6dd3c587-0bd6-4403-92ce-0c3035846187",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The job ran for 15 minutes and 16 seconds\n"
     ]
    }
   ],
   "source": [
    "minutes, seconds = divmod((vertex_job.end_time - vertex_job.start_time).total_seconds(), 60)\n",
    "print(f'The job ran for {int(minutes)} minutes and {int(seconds)} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398d9898-9e68-45ac-99c5-e824b0d18292",
   "metadata": {},
   "source": [
    "### Review The Optimized Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f6589c-1ed5-4d54-8fa9-a2ccc23428c9",
   "metadata": {},
   "source": [
    "#### System Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1b161de7-8c1f-4a97-a2f1-059134f47964",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'step': 2,\n",
       " 'metrics': {'coherence/mean': 4.8,\n",
       "  'fluency/mean': 5.0,\n",
       "  'composite_metric/mean': 4.9},\n",
       " 'prompt': 'Write a poem with the following specifications:\\n\\nTYPE: [Specify the type of poem, e.g., Acrostic, Haiku, Limerick, Sonnet, Free Verse, etc.]\\n\\nTOPIC: [Specify the topic of the poem, e.g., Lego, Nature, Love, Loss, etc.]\\n\\nSTYLE: [Specify the desired style, e.g., descriptive, narrative, lyrical, humorous, etc.]\\n\\nTONE: [Specify the desired tone or mood, e.g., joyful, melancholic, reflective, whimsical, etc.]\\n\\nAUDIENCE: [Specify the intended audience for the poem, e.g., children, adults, a specific person, etc.]\\n\\nLENGTH: [Specify the desired length, e.g., a specific number of lines, stanzas, or words, or a general range like \"short\" or \"long\".]\\n\\nPURPOSE: [Specify the purpose or message of the poem, e.g., to express a feeling, tell a story, celebrate an event, etc.]\\n\\nIMAGERY/METAPHORS: [Encourage the use of vivid imagery and metaphors related to the topic.  For example, if the topic is \"Lego,\" suggest metaphors related to building, creation, imagination, or the specific characteristics of Lego bricks.]\\n\\nConsider these additional instructions for crafting your poem:\\n\\n* Use strong verbs and evocative language to create vivid imagery.\\n* Pay attention to the rhythm and flow of the poem.\\n* Ensure the poem has a clear structure and progression.\\n* If applicable, adhere to the specific rules and structure of the chosen poem type (e.g., syllable count for Haiku, rhyming scheme for a Sonnet).\\n\\n\\nIf exemplers/demonstrations are provided in the context, please follow them as guidelines for style, tone, and structure while still adhering to the above specifications.'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = json.loads(\n",
    "    bucket.blob(f'{SERIES}/{EXPERIMENT}/{job_name}/instruction/optimized_results.json').download_as_string()\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5a3b8a6c-b0c8-47ff-aa10-5d370f4b3b98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Write a poem with the following specifications:\n",
       "\n",
       "TYPE: [Specify the type of poem, e.g., Acrostic, Haiku, Limerick, Sonnet, Free Verse, etc.]\n",
       "\n",
       "TOPIC: [Specify the topic of the poem, e.g., Lego, Nature, Love, Loss, etc.]\n",
       "\n",
       "STYLE: [Specify the desired style, e.g., descriptive, narrative, lyrical, humorous, etc.]\n",
       "\n",
       "TONE: [Specify the desired tone or mood, e.g., joyful, melancholic, reflective, whimsical, etc.]\n",
       "\n",
       "AUDIENCE: [Specify the intended audience for the poem, e.g., children, adults, a specific person, etc.]\n",
       "\n",
       "LENGTH: [Specify the desired length, e.g., a specific number of lines, stanzas, or words, or a general range like \"short\" or \"long\".]\n",
       "\n",
       "PURPOSE: [Specify the purpose or message of the poem, e.g., to express a feeling, tell a story, celebrate an event, etc.]\n",
       "\n",
       "IMAGERY/METAPHORS: [Encourage the use of vivid imagery and metaphors related to the topic.  For example, if the topic is \"Lego,\" suggest metaphors related to building, creation, imagination, or the specific characteristics of Lego bricks.]\n",
       "\n",
       "Consider these additional instructions for crafting your poem:\n",
       "\n",
       "* Use strong verbs and evocative language to create vivid imagery.\n",
       "* Pay attention to the rhythm and flow of the poem.\n",
       "* Ensure the poem has a clear structure and progression.\n",
       "* If applicable, adhere to the specific rules and structure of the chosen poem type (e.g., syllable count for Haiku, rhyming scheme for a Sonnet).\n",
       "\n",
       "\n",
       "If exemplers/demonstrations are provided in the context, please follow them as guidelines for style, tone, and structure while still adhering to the above specifications."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(result['prompt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4905e7b-efd0-42e8-865e-5339eed4295b",
   "metadata": {},
   "source": [
    "#### System Instruction With Examples (Demonstration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "095dbcd2-5bd5-4126-bed2-ec3a15491823",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'step': 6,\n",
       " 'metrics': {'coherence/mean': 5.0,\n",
       "  'fluency/mean': 5.0,\n",
       "  'composite_metric/mean': 5.0},\n",
       " 'prompt': 'Write a poem with the following specifications:\\n\\nTYPE: [Specify the type of poem, e.g., Acrostic, Haiku, Limerick, Sonnet, Free Verse, etc.]\\n\\nTOPIC: [Specify the topic of the poem, e.g., Lego, Nature, Love, Loss, etc.]\\n\\nSTYLE: [Specify the desired style, e.g., descriptive, narrative, lyrical, humorous, etc.]\\n\\nTONE: [Specify the desired tone or mood, e.g., joyful, melancholic, reflective, whimsical, etc.]\\n\\nAUDIENCE: [Specify the intended audience for the poem, e.g., children, adults, a specific person, etc.]\\n\\nLENGTH: [Specify the desired length, e.g., a specific number of lines, stanzas, or words, or a general range like \"short\" or \"long\".]\\n\\nPURPOSE: [Specify the purpose or message of the poem, e.g., to express a feeling, tell a story, celebrate an event, etc.]\\n\\nIMAGERY/METAPHORS: [Encourage the use of vivid imagery and metaphors related to the topic.  For example, if the topic is \"Lego,\" suggest metaphors related to building, creation, imagination, or the specific characteristics of Lego bricks.]\\n\\nConsider these additional instructions for crafting your poem:\\n\\n* Use strong verbs and evocative language to create vivid imagery.\\n* Pay attention to the rhythm and flow of the poem.\\n* Ensure the poem has a clear structure and progression.\\n* If applicable, adhere to the specific rules and structure of the chosen poem type (e.g., syllable count for Haiku, rhyming scheme for a Sonnet).\\n\\n\\nIf exemplers/demonstrations are provided in the context, please follow them as guidelines for style, tone, and structure while still adhering to the above specifications.\\nWrite a Sonnet about Lego.\\n\\nThe response is: From plastic bricks, a world of dreams takes flight,\\nA castle grand, a spaceship sleek and bold,\\nWith tiny hands, we build, our stories told,\\nIn vibrant hues, a tapestry of light.\\nNo need for glue, or hammer, or for might,\\nJust snap and click, a structure to behold,\\nA dragon fierce, a pirate ship of old,\\nEach piece a part, a symphony of sight.\\nFrom simple squares, to intricate designs,\\nA boundless realm, where imagination thrives,\\nA child\\'s delight, a grown-up\\'s fondest wish,\\nTo build and create, where nothing ever dies.\\nSo let us play, with these enduring toys,\\nAnd find in Lego, endless, joyful joys. \\n\\n==\\n\\n\\nWrite a Acrostic about Lego.\\n\\nThe response is: **L**ittle bricks of plastic,\\n**E**ndlessly creative,\\n**G**rowing worlds with each piece,\\n**O**utstanding imagination. \\n\\n==\\n\\n\\nWrite a Limerick about Lego.\\n\\nThe response is: There once was a builder named Sue,\\nWhose Lego creations were true.\\nFrom castles to ships,\\nWith colorful clips,\\nShe built them all, just for you. \\n'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_demonstration = json.loads(\n",
    "    bucket.blob(f'{SERIES}/{EXPERIMENT}/{job_name}/demonstration/optimized_results.json').download_as_string()\n",
    ")\n",
    "result_demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d27949f0-f65a-4b76-ac0d-e37f34ecab6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Write a poem with the following specifications:\n",
       "\n",
       "TYPE: [Specify the type of poem, e.g., Acrostic, Haiku, Limerick, Sonnet, Free Verse, etc.]\n",
       "\n",
       "TOPIC: [Specify the topic of the poem, e.g., Lego, Nature, Love, Loss, etc.]\n",
       "\n",
       "STYLE: [Specify the desired style, e.g., descriptive, narrative, lyrical, humorous, etc.]\n",
       "\n",
       "TONE: [Specify the desired tone or mood, e.g., joyful, melancholic, reflective, whimsical, etc.]\n",
       "\n",
       "AUDIENCE: [Specify the intended audience for the poem, e.g., children, adults, a specific person, etc.]\n",
       "\n",
       "LENGTH: [Specify the desired length, e.g., a specific number of lines, stanzas, or words, or a general range like \"short\" or \"long\".]\n",
       "\n",
       "PURPOSE: [Specify the purpose or message of the poem, e.g., to express a feeling, tell a story, celebrate an event, etc.]\n",
       "\n",
       "IMAGERY/METAPHORS: [Encourage the use of vivid imagery and metaphors related to the topic.  For example, if the topic is \"Lego,\" suggest metaphors related to building, creation, imagination, or the specific characteristics of Lego bricks.]\n",
       "\n",
       "Consider these additional instructions for crafting your poem:\n",
       "\n",
       "* Use strong verbs and evocative language to create vivid imagery.\n",
       "* Pay attention to the rhythm and flow of the poem.\n",
       "* Ensure the poem has a clear structure and progression.\n",
       "* If applicable, adhere to the specific rules and structure of the chosen poem type (e.g., syllable count for Haiku, rhyming scheme for a Sonnet).\n",
       "\n",
       "\n",
       "If exemplers/demonstrations are provided in the context, please follow them as guidelines for style, tone, and structure while still adhering to the above specifications.\n",
       "Write a Sonnet about Lego.\n",
       "\n",
       "The response is: From plastic bricks, a world of dreams takes flight,\n",
       "A castle grand, a spaceship sleek and bold,\n",
       "With tiny hands, we build, our stories told,\n",
       "In vibrant hues, a tapestry of light.\n",
       "No need for glue, or hammer, or for might,\n",
       "Just snap and click, a structure to behold,\n",
       "A dragon fierce, a pirate ship of old,\n",
       "Each piece a part, a symphony of sight.\n",
       "From simple squares, to intricate designs,\n",
       "A boundless realm, where imagination thrives,\n",
       "A child's delight, a grown-up's fondest wish,\n",
       "To build and create, where nothing ever dies.\n",
       "So let us play, with these enduring toys,\n",
       "And find in Lego, endless, joyful joys. \n",
       "\n",
       "==\n",
       "\n",
       "\n",
       "Write a Acrostic about Lego.\n",
       "\n",
       "The response is: **L**ittle bricks of plastic,\n",
       "**E**ndlessly creative,\n",
       "**G**rowing worlds with each piece,\n",
       "**O**utstanding imagination. \n",
       "\n",
       "==\n",
       "\n",
       "\n",
       "Write a Limerick about Lego.\n",
       "\n",
       "The response is: There once was a builder named Sue,\n",
       "Whose Lego creations were true.\n",
       "From castles to ships,\n",
       "With colorful clips,\n",
       "She built them all, just for you. \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(result_demonstration['prompt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725d94b6-184a-4093-ac09-a2f3e9630d29",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Review The Evaluation Process: Step-By-Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b984e5a0-687f-445f-ae52-1313cc585bb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_ui = prompt_opt.ResultsUI(path = f'gs://{bucket.name}/{SERIES}/{EXPERIMENT}/{job_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "42802063-7d41-45df-a9a7-e3d0e837bc71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  .scrollable {\n",
       "    width: 100%;\n",
       "    height: 80px;\n",
       "    overflow-y: auto;\n",
       "    overflow-x: hidden;  /* Hide horizontal scrollbar */\n",
       "  }\n",
       "  tr:nth-child(odd) {\n",
       "    background: var(--colab-highlighted-surface-color);\n",
       "  }\n",
       "  tr:nth-child(even) {\n",
       "    background-color: var(--colab-primary-surface-color);\n",
       "  }\n",
       "  th {\n",
       "    background-color: var(--colab-highlighted-surface-color);\n",
       "  }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18f9bb3215c24d5495506e53bad591a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Select Run:'), Dropdown(layout=Layout(width='200px'), options=('gs://statmike-mlop…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_df_html = \"\"\"\n",
    "<style>\n",
    "  .scrollable {\n",
    "    width: 100%;\n",
    "    height: 80px;\n",
    "    overflow-y: auto;\n",
    "    overflow-x: hidden;  /* Hide horizontal scrollbar */\n",
    "  }\n",
    "  tr:nth-child(odd) {\n",
    "    background: var(--colab-highlighted-surface-color);\n",
    "  }\n",
    "  tr:nth-child(even) {\n",
    "    background-color: var(--colab-primary-surface-color);\n",
    "  }\n",
    "  th {\n",
    "    background-color: var(--colab-highlighted-surface-color);\n",
    "  }\n",
    "</style>\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(results_df_html))\n",
    "display(results_ui.get_container())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4534a86-860f-4831-8899-dddff6957679",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
