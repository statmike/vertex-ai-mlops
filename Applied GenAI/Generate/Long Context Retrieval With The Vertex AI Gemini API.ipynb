{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e37b4076",
   "metadata": {},
   "source": [
    "![tracker](https://us-central1-vertex-ai-mlops-369716.cloudfunctions.net/pixel-tracking?path=statmike%2Fvertex-ai-mlops%2FApplied+GenAI%2FGenerate&file=Long+Context+Retrieval+With+The+Vertex+AI+Gemini+API.ipynb)\n",
    "<!--- header table --->\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/statmike/vertex-ai-mlops/blob/main/Applied%20GenAI/Generate/Long%20Context%20Retrieval%20With%20The%20Vertex%20AI%20Gemini%20API.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\">\n",
    "      <br>Run in<br>Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https%3A%2F%2Fraw.githubusercontent.com%2Fstatmike%2Fvertex-ai-mlops%2Fmain%2FApplied%2520GenAI%2FGenerate%2FLong%2520Context%2520Retrieval%2520With%2520The%2520Vertex%2520AI%2520Gemini%2520API.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\">\n",
    "      <br>Run in<br>Colab Enterprise\n",
    "    </a>\n",
    "  </td>      \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/statmike/vertex-ai-mlops/blob/main/Applied%20GenAI/Generate/Long%20Context%20Retrieval%20With%20The%20Vertex%20AI%20Gemini%20API.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      <br>View on<br>GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/statmike/vertex-ai-mlops/main/Applied%20GenAI/Generate/Long%20Context%20Retrieval%20With%20The%20Vertex%20AI%20Gemini%20API.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      <br>Open in<br>Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f1a5be-feee-4a70-a927-8abfbd4cc98c",
   "metadata": {},
   "source": [
    "# Long Context Retrieval With The Vertex AI Gemini API\n",
    "\n",
    "**Retrieval - the task of retrieving information as context for an LLM**, like the Gemini family on Vertex AI. Retrieval augmented generation (RAG) is the task of retrieving relevant context and then providing it along with the prompt to the LLM. \n",
    "\n",
    "[Long context](https://cloud.google.com/vertex-ai/generative-ai/docs/long-context) is a way of providing full-length sources to the LLM, which can then perform its own retrieval.  Gemini 1.5 Flash (1M) and Gemini 1.5 Pro (2M) have incredible input context windows (1M and 2M tokens respectively) and have shown [near-perfect retrieval of > 99%](https://storage.googleapis.com/deepmind-media/gemini/gemini_v1_5_report.pdf).\n",
    "\n",
    "For a complete overview of the Gemini API, check out the companion workflow [Vertex AI Gemini API](./Vertex%20AI%20Gemini%20API.ipynb).\n",
    "\n",
    "**Use Case Exploration**\n",
    "\n",
    "Buying a home usually involves borrowing money from a lending institution, typically through a mortgage secured by the home's value. But how do these institutions manage the risks associated with such large loans, and how are lending standards established?\n",
    "\n",
    "In the United States, two government-sponsored enterprises (GSEs) play a vital role in the housing market:\n",
    "- Federal National Mortgage Association ([Fannie Mae](https://www.fanniemae.com/))\n",
    "- Federal Home Loan Mortgage Corporation ([Freddie Mac](https://www.freddiemac.com/))\n",
    "\n",
    "These GSEs purchase mortgages from lenders, enabling those lenders to offer more loans. This process also allows Fannie Mae and Freddie Mac to set standards for mortgages, ensuring they are responsible and borrowers are more likely to repay them. This system makes homeownership more affordable and stabilizes the housing market by maintaining a steady flow of liquidity for lenders and keeping interest rates controlled.\n",
    "\n",
    "However, navigating the complexities of these GSEs and their extensive servicing guides can be challenging. What if you could directly query these guides and get precise answers without needing to design a complex RAG architecture?\n",
    "\n",
    "This workflow leverages the long context capabilities of Vertex AI Gemini models and the efficiency of context caching to provide low-latency and cost-effective access to these comprehensive documents. Explore the implementation below!\n",
    "\n",
    "**References**\n",
    "- [Retrieval Augmented Generation or Long-Context LLMs? A Comprehensive Study and Hybrid Approach](https://arxiv.org/pdf/2407.16833)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ece663-3016-4501-aa23-8a88c530067f",
   "metadata": {
    "id": "od_UkDpvRmgD",
    "tags": []
   },
   "source": [
    "---\n",
    "## Colab Setup\n",
    "\n",
    "To run this notebook in Colab run the cells in this section.  Otherwise, skip this section.\n",
    "\n",
    "This cell will authenticate to GCP (follow prompts in the popup)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c40dc09-e248-402d-a350-5de4f2c00f49",
   "metadata": {
    "executionInfo": {
     "elapsed": 195,
     "status": "ok",
     "timestamp": 1683726184843,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "8UO9FnqyKBlF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'statmike-mlops-349915' # replace with project ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15d1d8ef-591c-4f22-8e3b-95d1ea01485e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68869,
     "status": "ok",
     "timestamp": 1683726253709,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "N98-KK7LRkjm",
    "outputId": "09ec5008-0def-4e1a-c349-c598ee752f78",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not a Colab Environment\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    !gcloud config set project {PROJECT_ID}\n",
    "    print('Colab authorized to GCP')\n",
    "except Exception:\n",
    "    print('Not a Colab Environment')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d751709b-5c77-4a9d-8db7-59a1e31a57f5",
   "metadata": {},
   "source": [
    "---\n",
    "## Installs\n",
    "\n",
    "The list `packages` contains tuples of package import names and install names.  If the import name is not found then the install name is used to install quitely for the current user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bfb1c54-be62-4842-9134-63296ccf5461",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tuples of (import name, install name, min_version)\n",
    "packages = [\n",
    "    ('google.cloud.aiplatform', 'google-cloud-aiplatform', '1.69.0'),\n",
    "    ('google.cloud.storage', 'google-cloud-storage'),\n",
    "    ('fitz', 'pymupdf'),\n",
    "    ('requests', 'requests')\n",
    "]\n",
    "\n",
    "import importlib\n",
    "install = False\n",
    "for package in packages:\n",
    "    if not importlib.util.find_spec(package[0]):\n",
    "        print(f'installing package {package[1]}')\n",
    "        install = True\n",
    "        !pip install {package[1]} -U -q --user\n",
    "    elif len(package) == 3:\n",
    "        if importlib.metadata.version(package[0]) < package[2]:\n",
    "            print(f'updating package {package[1]}')\n",
    "            install = True\n",
    "            !pip install {package[1]} -U -q --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767959a6-0f26-426c-b8d5-ee2d9aebba9b",
   "metadata": {},
   "source": [
    "### API Enablement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c6dca7d-8e41-41a3-bcf8-778a94a139b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "To take a quick anonymous survey, run:\n",
      "  $ gcloud survey\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!gcloud services enable aiplatform.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e79a0d-00f1-4f24-b7c6-654afc2a01dd",
   "metadata": {},
   "source": [
    "### Restart Kernel (If Installs Occured)\n",
    "\n",
    "After a kernel restart the code submission can start with the next cell after this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e226fcb9-6300-44ff-be3f-969b4e5ff8ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if install:\n",
    "    import IPython\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)\n",
    "    IPython.display.display(IPython.display.Markdown(\"\"\"<div class=\\\"alert alert-block alert-warning\\\">\n",
    "        <b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. The previous cells do not need to be run again⚠️</b>\n",
    "        </div>\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1615f583-88f8-4d42-b1e4-f5c328fd6470",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc2c040-7f2d-4bc8-af61-e37e9742bbb1",
   "metadata": {},
   "source": [
    "inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad7450a4-b673-43c6-8073-09254f159e82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'statmike-mlops-349915'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5230593b-33a8-4b59-afd4-8ffb4e319715",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "SERIES = 'applied-genai'\n",
    "EXPERIMENT = 'long-context'\n",
    "\n",
    "GCS_BUCKET = PROJECT_ID # change to Bucket name if not the same as the Project ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cfe0fe-2965-474a-be2b-d2b6ec610390",
   "metadata": {},
   "source": [
    "packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efcba1ba-2e39-40b9-8464-5851121c62ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Python standard library imports:\n",
    "import os, io, base64, json, datetime\n",
    "\n",
    "# package imports\n",
    "from IPython.display import Markdown\n",
    "import IPython.display\n",
    "import fitz #pymupdf\n",
    "import requests\n",
    "\n",
    "# vertex ai imports\n",
    "from google.cloud import aiplatform\n",
    "import vertexai\n",
    "import vertexai.generative_models # for Gemini Models\n",
    "\n",
    "# preview imports for vertex ai api:\n",
    "from vertexai.preview import caching\n",
    "import vertexai.preview.generative_models\n",
    "import vertexai.preview.batch_prediction\n",
    "\n",
    "# google cloud imports\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81cc0fdc-2b00-4cb9-b789-9543f51bc988",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.71.0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aiplatform.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12939dcc-9376-424f-bd8a-db25e14bc4ef",
   "metadata": {},
   "source": [
    "clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bb530fa-7633-46ec-ae22-2e4a5e81e99c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vertexai.init(project = PROJECT_ID, location = REGION)\n",
    "gcs = storage.Client(project = PROJECT_ID)\n",
    "bucket = gcs.bucket(GCS_BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d99693-f3d8-48d1-80f5-619d01301353",
   "metadata": {},
   "source": [
    "---\n",
    "## Gemini Models\n",
    "\n",
    "Select one of the [supported Gemini models](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#supported-models) and read more about the characteristics of each [here](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-models).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fff7672-a1e8-4844-a1b1-4daffef1441e",
   "metadata": {},
   "source": [
    "### Setup Model\n",
    "\n",
    "Here the [Gemini 1.5 Flash model with version 002](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-1.5-flash) is selected. It has these characteristics (to name a few):\n",
    "- Max Input Tokens: 1,048,576\n",
    "- Max Output Tokens: 8,192\n",
    "- Max image:\n",
    "    - raw size 20MB\n",
    "    - base64 encoded size 7MB\n",
    "    - number per prompt 3000\n",
    "- Max video:\n",
    "    - length 1 hour\n",
    "    - number per prompt 10\n",
    "- Max audio:\n",
    "    - length 8.4 hours\n",
    "    - number per prompt 1\n",
    "- Max PDF:\n",
    "    - size 30 MB\n",
    "- 102 [Languages](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#languages-gemini) for understanding and responding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2afb7060-ab49-44f4-a6d2-bab2805f61ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gemini = vertexai.generative_models.GenerativeModel(\"gemini-1.5-pro-002\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b078403-3e54-4d1d-81d5-d6bd18ec5abc",
   "metadata": {},
   "source": [
    "### **Prompt With Text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "135842da-0f68-420e-85c6-f1824ce126a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Getting a mortgage involves several steps and requires careful planning. Here's a general overview of the process:\n",
       "\n",
       "**1. Check your credit score and report:**\n",
       "\n",
       "* **Obtain your credit report:** You're entitled to a free credit report annually from each of the three major credit bureaus (Equifax, Experian, and TransUnion) through AnnualCreditReport.com.  Review it for errors and address any issues that could negatively impact your score.\n",
       "* **Understand your credit score:** Your credit score is a crucial factor in mortgage approval and interest rates. Higher scores typically qualify you for better terms.  Aim for a score of 620 or higher, although some lenders may accept lower scores with compensating factors.\n",
       "\n",
       "**2. Determine how much you can afford:**\n",
       "\n",
       "* **Use online mortgage calculators:** These tools can help you estimate your monthly payments based on various loan amounts, interest rates, and loan terms.\n",
       "* **Consider your debt-to-income ratio (DTI):** Lenders use DTI to assess your ability to repay the loan.  A DTI of 43% or lower is generally preferred, but some lenders may accept higher ratios. Calculate your DTI by dividing your total monthly debt payments by your gross monthly income.\n",
       "* **Factor in additional costs:** Remember to account for property taxes, homeowners insurance, private mortgage insurance (PMI if your down payment is less than 20%), closing costs, and potential moving expenses.\n",
       "\n",
       "**3. Get pre-approved for a mortgage:**\n",
       "\n",
       "* **Shop around with multiple lenders:** Compare interest rates, fees, and loan terms from different lenders, including banks, credit unions, and online mortgage companies.\n",
       "* **Provide necessary documentation:** Lenders will require documentation such as pay stubs, tax returns, bank statements, and employment history.\n",
       "* **Receive a pre-approval letter:** This letter indicates how much the lender is willing to loan you and strengthens your position when making an offer on a home.\n",
       "\n",
       "**4. Shop for a home:**\n",
       "\n",
       "* **Work with a real estate agent:** A qualified agent can help you find properties that meet your needs and budget.\n",
       "* **Make an offer:** Once you've found a home you like, submit a written offer to the seller.\n",
       "* **Negotiate the terms:** Be prepared to negotiate the price, closing date, and other contingencies.\n",
       "\n",
       "**5. Finalize the mortgage:**\n",
       "\n",
       "* **Complete the loan application:** Provide the lender with all required documentation.\n",
       "* **Get a home appraisal:** The lender will order an appraisal to determine the fair market value of the property.\n",
       "* **Review the closing disclosure:** This document outlines the final loan terms, including closing costs.\n",
       "* **Close on the loan:** Sign the final paperwork and pay closing costs.\n",
       "\n",
       "**Tips for a smooth mortgage process:**\n",
       "\n",
       "* **Save for a down payment:** A larger down payment can lead to lower interest rates and eliminate the need for PMI.\n",
       "* **Pay down debt:** Reducing your debt can improve your DTI and credit score.\n",
       "* **Avoid making major financial changes:** Don't open new credit accounts, change jobs, or make large purchases during the mortgage process.\n",
       "* **Be organized and responsive:** Keep all your financial documents readily available and respond to lender requests promptly.\n",
       "* **Ask questions:** Don't hesitate to ask your lender or real estate agent if you have any questions or concerns.\n",
       "\n",
       "\n",
       "Getting a mortgage can be complex, but by following these steps and being prepared, you can navigate the process successfully. Remember to shop around and compare offers from multiple lenders to ensure you're getting the best possible terms.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = gemini.generate_content('How do I get a mortgage?')\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07512b1-9f6e-49db-85c2-92839f425c48",
   "metadata": {},
   "source": [
    "### Retrieve Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "772a322c-83fb-443b-b380-497ea8cdf69f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "freddie_url = 'https://guide.freddiemac.com/ci/okcsFattach/get/1002095_2'\n",
    "fannie_url = 'https://singlefamily.fanniemae.com/media/39861/display'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17702779-2554-4d3f-9659-b011d2cd2cc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "freddie_retrieve = requests.get(freddie_url).content\n",
    "fannie_retrieve = requests.get(fannie_url).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff1a3a84-0a5f-4e7b-8358-f1bd182f321f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "freddie_doc = fitz.open(stream = freddie_retrieve, filetype = 'pdf')\n",
    "fannie_doc = fitz.open(stream = fannie_retrieve, filetype = 'pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6f7312d-0b84-4f9b-9ac0-999def72b056",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2588, 1180)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freddie_doc.page_count, fannie_doc.page_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284e36d1-86d3-4949-98b5-141ee3f17458",
   "metadata": {},
   "source": [
    "### Split Documents\n",
    "\n",
    "The models have constraints on the size of individual files.  Here we want to split the PDFs into parts of no more than 1000 pages and verify that they are under 30MB in size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f6f89fc-cfd4-48d6-91d4-b8ef277e5cf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def doc_parts(doc):\n",
    "    start_page = 0\n",
    "    max_pages = 1000\n",
    "    n_pages = doc.page_count\n",
    "    \n",
    "    doc_list = []\n",
    "    while start_page < n_pages:\n",
    "        end_page = min(start_page + max_pages - 1, n_pages)\n",
    "        new_doc = fitz.open()\n",
    "        new_doc.insert_pdf(doc, from_page = start_page, to_page = end_page)\n",
    "        doc_list.append(new_doc)\n",
    "        start_page = end_page + 1\n",
    "    \n",
    "    print(f\"The document has {n_pages} pages and has been split into parts with page counts: {[p.page_count for p in doc_list]}\")\n",
    "    \n",
    "    return doc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4fe05d7-f1f0-4551-b828-9f2cc9682d69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The document has 2588 pages and has been split into parts with page counts: [1000, 1000, 588]\n"
     ]
    }
   ],
   "source": [
    "freddie_parts = doc_parts(freddie_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa5e201b-c6cf-48ee-971c-68d15e99209d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The document has 1180 pages and has been split into parts with page counts: [1000, 180]\n"
     ]
    }
   ],
   "source": [
    "fannie_parts = doc_parts(fannie_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9173f3-84b9-49a8-9e35-cdab9ec2392a",
   "metadata": {},
   "source": [
    "### Save Documents To GCS Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7b6151e-502f-4c3b-93a5-1055d0041317",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def doc_to_gcs(document, name):\n",
    "    buffer = io.BytesIO()\n",
    "    document.save(buffer)\n",
    "    buffer.seek(0) # reset the position to the beginning\n",
    "    blob = bucket.blob(f\"{SERIES}/{EXPERIMENT}/{name}.pdf\")\n",
    "    blob.upload_from_file(buffer, content_type = 'application/pdf')\n",
    "    print(f\"The file 'gs://{bucket.name}/{blob.name}' is {(blob.size / (1024*1024)):.2f} MB\")\n",
    "    return blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b16bf53-7bba-42f6-996c-6fd692d79f08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file 'gs://statmike-mlops-349915/applied-genai/long-context/freddie_full.pdf' is 14.60 MB\n"
     ]
    }
   ],
   "source": [
    "freddie_blob = doc_to_gcs(freddie_doc, 'freddie_full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a011c149-c35a-43f7-8222-c64da5b94094",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file 'gs://statmike-mlops-349915/applied-genai/long-context/fannie_full.pdf' is 4.55 MB\n"
     ]
    }
   ],
   "source": [
    "fannie_blob = doc_to_gcs(fannie_doc, 'fannie_full')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76619b4-68a5-4435-9ce4-2b643a6a3c36",
   "metadata": {},
   "source": [
    "### Save Document Parts To GCS Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8788323e-4065-4d79-a9e3-fb413b128572",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file 'gs://statmike-mlops-349915/applied-genai/long-context/freddie_part_0.pdf' is 4.79 MB\n",
      "The file 'gs://statmike-mlops-349915/applied-genai/long-context/freddie_part_1.pdf' is 5.21 MB\n",
      "The file 'gs://statmike-mlops-349915/applied-genai/long-context/freddie_part_2.pdf' is 4.28 MB\n"
     ]
    }
   ],
   "source": [
    "freddie_blobs = [doc_to_gcs(doc, f'freddie_part_{d}') for d, doc in enumerate(freddie_parts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d71dbfc-e3fd-4825-8e6d-28a3dd14122a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file 'gs://statmike-mlops-349915/applied-genai/long-context/fannie_part_0.pdf' is 3.49 MB\n",
      "The file 'gs://statmike-mlops-349915/applied-genai/long-context/fannie_part_1.pdf' is 0.61 MB\n"
     ]
    }
   ],
   "source": [
    "fannie_blobs = [doc_to_gcs(doc, f'fannie_part_{d}') for d, doc in enumerate(fannie_parts)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391eaf3f-e5b9-483a-92b5-222c900084d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Gemini Multimodal Context Parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d28f3aff-74cb-443a-bfdf-be277df993ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "freddie_contexts = [\n",
    "    vertexai.generative_models.Part.from_uri(\n",
    "        uri = f\"gs://{bucket.name}/{b.name}\",\n",
    "        mime_type = b.content_type\n",
    "    ) for b in freddie_blobs\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe02d334-d63d-4ef4-812d-4974fcdb6418",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fannie_contexts = [\n",
    "    vertexai.generative_models.Part.from_uri(\n",
    "        uri = f\"gs://{bucket.name}/{b.name}\",\n",
    "        mime_type = b.content_type\n",
    "    ) for b in fannie_blobs\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b79fc3-70bf-4241-aa89-55433461bd5c",
   "metadata": {},
   "source": [
    "---\n",
    "## Multimodal Prompts With Long Context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e488f245-5c54-4dc6-80cf-1b054fddc5cc",
   "metadata": {},
   "source": [
    "### Generate Responses With Gemini Multimodal Prompts - Long Context In Prompt\n",
    "\n",
    "Use the Gemini Flash 1.5 model separately for each of the three prompt example: specific to Fannie Mae, Freddie Mac, and then a combined and comparative answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6dbbe534-76a6-49ba-a820-4a853fde8277",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = 'Does a lender have to perform servicing functions directly?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a3b34ab8-fb9d-4bdb-8704-d8208a23c629",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Lenders are not required to perform servicing functions directly. They can contract with a third-party servicing company. However, in some situations, they might find it advantageous to maintain that role in-house, especially if the loan requires special handling, such as in cases of loss mitigation."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freddie_response = gemini.generate_content(['The Freddie Mac documents:'] + freddie_contexts + [prompt])\n",
    "Markdown(freddie_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1ba2360f-df59-423f-ab0f-a2b2229cd102",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "No. Lenders may outsource some or all of their servicing functions, but they are still fully responsible to Fannie Mae for those functions. This includes the use of a subservicer or service bureau. If a lender uses a subservicer, then both the lender (as the \"master servicer\") and the subservicer must be Fannie Mae-approved servicers in good standing and able to perform the duties associated with a master servicer/subservicer arrangement.\n",
       "\n",
       "Additionally, a lender may use a document custodian to hold and manage certain loan documents on behalf of Fannie Mae and the lender. Fannie Mae has approved a list of document custodians and lenders are required to choose from this list."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fannie_response = gemini.generate_content(['The Fannie Mae documents:'] + fannie_contexts + [prompt])\n",
    "Markdown(fannie_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "97d78476-6c40-430a-b380-d82d93314127",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Freddie Mac's Perspective**\n",
       "\n",
       "Freddie Mac allows lenders to transfer their servicing responsibilities to another Freddie Mac-approved servicer through a variety of methods, including Concurrent Transfer of Servicing, Subsequent Transfer of Servicing, and Intra-Servicer Portfolio Moves.  Freddie Mac monitors both the transferor and transferee servicer for compliance and has the right to rescind or deny servicing transfers in certain situations.\n",
       "\n",
       "\n",
       "**Fannie Mae's Perspective**\n",
       "\n",
       "Fannie Mae requires a lender to transfer the servicing rights to another Fannie Mae-approved servicer if it cannot or does not intend to service the loans itself.  Concurrent Transfers of Servicing occur when a lender sells loans to Fannie Mae. Subsequent Transfers of Servicing occur after Fannie Mae has purchased or securitized a loan.  Similar to Freddie Mac, Fannie Mae may monitor and assess the transferor and transferee servicers.\n",
       "\n",
       "**Comparison**\n",
       "\n",
       "Both GSEs require that loans be serviced by an approved servicer, allowing lenders to transfer these responsibilities if needed.  They both monitor the process for compliance and retain the right to step in under certain circumstances.  The specific processes and requirements for transferring servicing may vary slightly between the two GSEs.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemini_gse = vertexai.generative_models.GenerativeModel(\n",
    "    model_name = \"gemini-1.5-pro-002\",\n",
    "    system_instruction = 'You are incredibly knowledgable about GSEs (Freddie Mac and Fannie Mae) who purchase mortgages from lenders.  You answer questions about the selling process from the point of view of each GSE and then you compare/contrast each of them relative to the users question.'\n",
    ")\n",
    "combined_response = gemini_gse.generate_content(['The Freddie Mac documents:'] + freddie_contexts + ['The Fannie Mae documents:'] + fannie_contexts + [prompt])\n",
    "Markdown(combined_response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6ff3c7-8afa-4170-b5d9-a3365c45c69d",
   "metadata": {},
   "source": [
    "---\n",
    "## Multimodal Prompts With Context Cache For Long Context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbd04e8-4ab4-4efb-ab6e-f343dea87cc8",
   "metadata": {},
   "source": [
    "### Create Context Cache(s)\n",
    "\n",
    "Rather than sending the document (parts) along with each call to the Gemini API, it can be helpful to first load the documents as a context cache.  This makes subsequent call to the API faster and possibly cheaper as the documents are charged at a caching rate (size and time used) rather than a token/character rate.  \n",
    "\n",
    "For more information on [Context Caching](https://cloud.google.com/vertex-ai/generative-ai/docs/context-cache/context-cache-overview) check out the companion workflow: [Vertex AI Gemini API](./Vertex%20AI%20Gemini%20API.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4ca7614a-e77a-4219-9dc9-641dd78608cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "freddie_cache = vertexai.preview.caching.CachedContent.create(\n",
    "    model_name = 'gemini-1.5-flash-002',\n",
    "    contents = freddie_contexts,\n",
    "    ttl = datetime.timedelta(minutes = 30),\n",
    "    display_name = 'freddie-cache'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "633f42fe-bdf6-46ff-ad1b-2cffd8345573",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fannie_cache = vertexai.preview.caching.CachedContent.create(\n",
    "    model_name = 'gemini-1.5-flash-002',\n",
    "    contents = fannie_contexts,\n",
    "    ttl = datetime.timedelta(minutes = 30),\n",
    "    display_name = 'fannie-cache'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e82c5a47-5c60-41d2-b572-eef18e845477",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_cache = vertexai.preview.caching.CachedContent.create(\n",
    "    model_name = 'gemini-1.5-flash-002',\n",
    "    contents = ['The Freddie Mac documents:'] + freddie_contexts + ['The Fannie Mae documents:'] + fannie_contexts,\n",
    "    system_instruction = 'You are incredibly knowledgable about GSEs (Freddie Mac and Fannie Mae) who purchase mortgages from lenders.  You answer questions about the selling process from the point of view of each GSE and then you compare/contrast each of them relative to the users question.',\n",
    "    ttl = datetime.timedelta(minutes = 30),\n",
    "    display_name = 'combined-cache'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc10e17-7c95-4ed4-ba84-aab9fb61573f",
   "metadata": {},
   "source": [
    "### Generate Responses With Gemini Multimodal Prompts - Using Cache\n",
    "\n",
    "Register the Gemini Flash 1.5 model separately for each of the three caches. Then prompt each to see answer specific to Fannie Mae, Freddie Mac, and then a combined and comparative answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0e314e7f-d007-4201-8492-8892fa6c0118",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = 'Does a lender have to perform servicing functions directly?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "59511f84-bf0e-4fd2-8c55-dfcd386ec6ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "freddie_model = vertexai.preview.generative_models.GenerativeModel.from_cached_content(cached_content = freddie_cache)\n",
    "fannie_model = vertexai.preview.generative_models.GenerativeModel.from_cached_content(cached_content = fannie_cache)\n",
    "combined_model = vertexai.preview.generative_models.GenerativeModel.from_cached_content(cached_content = combined_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "60835287-3719-448e-989e-79c15998fedf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "No, a lender does not have to perform servicing functions directly.  The Freddie Mac Single-Family Seller/Servicer Guide outlines situations where lenders may use a Servicer to perform those functions.  The guide also details the responsibilities and requirements for both the lender and the servicer in such arrangements.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freddie_response = freddie_model.generate_content(\n",
    "    contents = [prompt]\n",
    ")\n",
    "Markdown(freddie_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8efa74ae-aa7f-41ff-945c-53637bccfed3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "No.  A lender may use other organizations to perform some or all of its servicing functions.  Fannie Mae refers to these arrangements as \"subservicing\" arrangements.  A master servicer may use a subservicer, but the master servicer remains ultimately responsible for meeting Fannie Mae's requirements."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fannie_response = fannie_model.generate_content(\n",
    "    contents = [prompt]\n",
    ")\n",
    "Markdown(fannie_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "653e697c-fa47-44c4-8c86-8031bfe60c13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here's a comparison of Freddie Mac and Fannie Mae's perspectives on whether a lender must perform servicing functions directly, based on their Selling Guides:\n",
       "\n",
       "**Freddie Mac:**\n",
       "\n",
       "Freddie Mac's Selling Guide doesn't require lenders to perform servicing functions directly.  The Guide explicitly allows for servicing to be transferred to a third-party servicer.  There are extensive sections dedicated to Transfers of Servicing, outlining the requirements and responsibilities of both the transferring servicer and the transferee servicer.  The process involves obtaining Freddie Mac's approval and adhering to specific timelines and procedures.\n",
       "\n",
       "**Fannie Mae:**\n",
       "\n",
       "Similar to Freddie Mac, Fannie Mae's Selling Guide also permits servicing to be performed by a third party.  The Guide details requirements for transfers of servicing, including the need for Fannie Mae's approval and various documentation requirements.  There's a strong emphasis on ensuring the transferee servicer meets Fannie Mae's standards and can adequately service the mortgages.\n",
       "\n",
       "**Comparison:**\n",
       "\n",
       "Both Freddie Mac and Fannie Mae allow for third-party servicing. Their Selling Guides provide detailed processes and requirements for transferring servicing rights, emphasizing the need for approval and adherence to specified procedures.  There are no explicit requirements mandating that lenders service the loans themselves.  The differences in specific requirements between the two GSEs are primarily in their detailed processes and the specific forms and procedures.  Both strive to ensure the mortgages are serviced according to their standards, regardless of who performs the servicing.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_response = combined_model.generate_content(\n",
    "    contents = [prompt]\n",
    ")\n",
    "Markdown(combined_response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5463091-392f-4ece-8e93-08cf1d4a0c0f",
   "metadata": {},
   "source": [
    "### Check And Remove The Context Cache(s)\n",
    "\n",
    "Check the remaining time for each cache.  This time can be extended as needed with `.update()`.  In this case the caches are deleted to eliminate any further costs now that this workflow is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2cf54bd1-538b-4257-9f26-09314b694870",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def time_left(cache):\n",
    "    expire = cache.expire_time\n",
    "    now = datetime.datetime.now(tz=expire.tzinfo) \n",
    "    print(f\"Expiration Time: {expire.strftime('%B %d, %Y at %I:%M:%S %p')}\")\n",
    "    print(f\"   Current Time: {now.strftime('%B %d, %Y at %I:%M:%S %p')}\")\n",
    "    diff = (expire - now).total_seconds()\n",
    "    sign, diff = (1, abs(diff)) if diff >= 0 else (-1, abs(diff))\n",
    "    minutes = int(diff // 60)\n",
    "    seconds = int(diff % 60)\n",
    "    if minutes > 60:\n",
    "        hours = int(minutes // 60)\n",
    "        minutes = minutes - hours*60\n",
    "    else: hours = 0\n",
    "    if sign == 1:\n",
    "        print(f\"{hours:02d}:{minutes:02d}:{seconds:02d} until expiration\")\n",
    "    else:\n",
    "        print(f\"Expired {hours:02d}:{minutes:02d}:{seconds:02d} ago\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a4a00d76-b9b1-44cf-9b00-165c3103d7a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expiration Time: January 26, 2025 at 03:28:28 PM\n",
      "   Current Time: January 26, 2025 at 03:19:49 PM\n",
      "00:08:38 until expiration\n"
     ]
    }
   ],
   "source": [
    "time_left(freddie_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "34d6db5a-f93a-4ac2-bc77-57684c5049ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expiration Time: January 26, 2025 at 03:40:27 PM\n",
      "   Current Time: January 26, 2025 at 03:19:49 PM\n",
      "00:20:37 until expiration\n"
     ]
    }
   ],
   "source": [
    "time_left(fannie_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "475ff426-b4d6-489c-8b45-6ca286ab399d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expiration Time: January 26, 2025 at 03:41:57 PM\n",
      "   Current Time: January 26, 2025 at 03:19:49 PM\n",
      "00:22:07 until expiration\n"
     ]
    }
   ],
   "source": [
    "time_left(combined_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e859e36e-1386-4135-be32-7248f9d08c8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting CachedContent : projects/1026793852137/locations/us-central1/cachedContents/2358342490416742400\n"
     ]
    }
   ],
   "source": [
    "if len(freddie_cache.list()) > 0:\n",
    "    freddie_cache.refresh\n",
    "    freddie_cache.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "66efea90-0cb9-4fbb-bfda-46b8fb303a73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting CachedContent : projects/1026793852137/locations/us-central1/cachedContents/1596108253484285952\n"
     ]
    }
   ],
   "source": [
    "if len(fannie_cache.list()) > 0:\n",
    "    fannie_cache.refresh\n",
    "    fannie_cache.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "26ddfe33-e299-4198-b268-2d0b0c2c4b4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting CachedContent : projects/1026793852137/locations/us-central1/cachedContents/3511263995023589376\n"
     ]
    }
   ],
   "source": [
    "if len(combined_cache.list()) > 0:\n",
    "    combined_cache.refresh\n",
    "    combined_cache.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9366be6d-a910-43e9-b0e3-c96a59ed57ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
