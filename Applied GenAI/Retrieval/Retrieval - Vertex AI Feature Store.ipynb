{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94f43524",
   "metadata": {},
   "source": [
    "![tracker](https://us-central1-vertex-ai-mlops-369716.cloudfunctions.net/pixel-tracking?path=statmike%2Fvertex-ai-mlops%2FApplied+GenAI%2FRetrieval&file=Retrieval+-+Vertex+AI+Feature+Store.ipynb)\n",
    "<!--- header table --->\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/statmike/vertex-ai-mlops/blob/main/Applied%20GenAI/Retrieval/Retrieval%20-%20Vertex%20AI%20Feature%20Store.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\">\n",
    "      <br>Run in<br>Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https%3A%2F%2Fraw.githubusercontent.com%2Fstatmike%2Fvertex-ai-mlops%2Fmain%2FApplied%2520GenAI%2FRetrieval%2FRetrieval%2520-%2520Vertex%2520AI%2520Feature%2520Store.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\">\n",
    "      <br>Run in<br>Colab Enterprise\n",
    "    </a>\n",
    "  </td>      \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/statmike/vertex-ai-mlops/blob/main/Applied%20GenAI/Retrieval/Retrieval%20-%20Vertex%20AI%20Feature%20Store.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      <br>View on<br>GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/statmike/vertex-ai-mlops/main/Applied%20GenAI/Retrieval/Retrieval%20-%20Vertex%20AI%20Feature%20Store.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      <br>Open in<br>Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b0e8e6-d761-4540-9d09-8f0c4ce9a020",
   "metadata": {},
   "source": [
    "# Retrieval - Vertex AI Feature Store\n",
    "\n",
    "In prior workflows, a series of documents was [processed into chunks](../Chunking/readme.md), and for each chunk, [embeddings](../Embeddings/readme.md) were created:\n",
    "\n",
    "- Process: [Large Document Processing - Document AI Layout Parser](../Chunking/Large%20Document%20Processing%20-%20Document%20AI%20Layout%20Parser.ipynb)\n",
    "- Embed: [Vertex AI Text Embeddings API](../Embeddings/Vertex%20AI%20Text%20Embeddings%20API.ipynb)\n",
    "\n",
    "Retrieving chunks for a query involves calculating the embedding for the query and then using similarity metrics to find relevant chunks. A thorough review of similarity matching can be found in [The Math of Similarity](../Embeddings/The%20Math%20of%20Similarity.ipynb) - use dot product! As development moves from experiment to application, the process of storing and computing similarity is migrated to a [retrieval](./readme.md) system. This workflow is part of a [series of workflows exploring many retrieval systems](./readme.md).  \n",
    "\n",
    "A detailed [comparison of many retrieval systems](./readme.md#comparison-of-vector-database-solutions) can be found in the readme as well.\n",
    "\n",
    "---\n",
    "\n",
    "**Vertex AI Feature Store For Storage, Indexing, And Search**\n",
    "\n",
    "[Vertex AI Feature Store](https://cloud.google.com/vertex-ai/docs/featurestore/latest/overview) creates online feature views from BigQuery tables or views, either directly or through the feature registry, and synchronizes the source data in BigQuery with the online serving. The online stores provide a low-latency API for vector matching using either vectors or entity IDs as input. The response includes all features in the feature view, which can encompass the text and metadata for the match, as these can be included as features. Learn more about Vertex AI Feature Store in this repository's [MLOps](../../MLOps/readme.md) section, which includes a deep dive into [feature stores](../../MLOps/Feature%20Store/readme.md).\n",
    "\n",
    "---\n",
    "\n",
    "**Use Case Data**\n",
    "\n",
    "Buying a home usually involves borrowing money from a lending institution, typically through a mortgage secured by the home's value. But how do these institutions manage the risks associated with such large loans, and how are lending standards established?\n",
    "\n",
    "In the United States, two government-sponsored enterprises (GSEs) play a vital role in the housing market:\n",
    "\n",
    "- Federal National Mortgage Association ([Fannie Mae](https://www.fanniemae.com/))\n",
    "- Federal Home Loan Mortgage Corporation ([Freddie Mac](https://www.freddiemac.com/))\n",
    "\n",
    "These GSEs purchase mortgages from lenders, enabling those lenders to offer more loans. This process also allows Fannie Mae and Freddie Mac to set standards for mortgages, ensuring they are responsible and borrowers are more likely to repay them. This system makes homeownership more affordable and stabilizes the housing market by maintaining a steady flow of liquidity for lenders and keeping interest rates controlled.\n",
    "\n",
    "However, navigating the complexities of these GSEs and their extensive servicing guides can be challenging.\n",
    "\n",
    "**Approaches**\n",
    "\n",
    "[This series](../readme.md) covers many generative AI workflows. These documents are used directly as long context for Gemini in the workflow [Long Context Retrieval With The Vertex AI Gemini API](../Generate/Long%20Context%20Retrieval%20With%20The%20Vertex%20AI%20Gemini%20API.ipynb). The workflow below uses a [retrieval](./readme.md) approach with the already generated chunks and embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be889472-69b0-416c-9cf1-edc9706fa5c5",
   "metadata": {
    "id": "od_UkDpvRmgD"
   },
   "source": [
    "---\n",
    "## Colab Setup\n",
    "\n",
    "When running this notebook in [Colab](https://colab.google/) or [Colab Enterprise](https://cloud.google.com/colab/docs/introduction), this section will authenticate to GCP (follow prompts in the popup) and set the current project for the session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21f75ba8-df50-466e-a5ec-f2a6dd88eb26",
   "metadata": {
    "executionInfo": {
     "elapsed": 195,
     "status": "ok",
     "timestamp": 1683726184843,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "8UO9FnqyKBlF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'statmike-mlops-349915' # replace with project ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c325515-1ea0-45cc-82d3-a1bfb1c52155",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68869,
     "status": "ok",
     "timestamp": 1683726253709,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "N98-KK7LRkjm",
    "outputId": "09ec5008-0def-4e1a-c349-c598ee752f78",
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    !gcloud config set project {PROJECT_ID}\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055a4bd7-7b47-43ef-ba14-636c955e44e3",
   "metadata": {},
   "source": [
    "---\n",
    "## Installs and API Enablement\n",
    "\n",
    "The clients packages may need installing in this environment. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410502ee-6fe3-4624-a69a-960ad7105f10",
   "metadata": {},
   "source": [
    "### Installs (If Needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4dbdb83-3170-430c-b60d-3d686222a168",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tuples of (import name, install name, min_version)\n",
    "packages = [\n",
    "    ('google.cloud.aiplatform', 'google-cloud-aiplatform', '1.69.0'),\n",
    "    ('google.cloud.bigquery', 'google-cloud-bigquery')\n",
    "]\n",
    "\n",
    "import importlib\n",
    "install = False\n",
    "for package in packages:\n",
    "    if not importlib.util.find_spec(package[0]):\n",
    "        print(f'installing package {package[1]}')\n",
    "        install = True\n",
    "        !pip install {package[1]} -U -q --user\n",
    "    elif len(package) == 3:\n",
    "        if importlib.metadata.version(package[0]) < package[2]:\n",
    "            print(f'updating package {package[1]}')\n",
    "            install = True\n",
    "            !pip install {package[1]} -U -q --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25374857-7d37-4c84-8cbb-a3c2fc7bb065",
   "metadata": {},
   "source": [
    "### API Enablement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b7300a8-7e3a-4a08-95c0-91186237753f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gcloud services enable aiplatform.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157d09ba-9774-495f-8ced-3382bf75be8f",
   "metadata": {},
   "source": [
    "### Restart Kernel (If Installs Occured)\n",
    "\n",
    "After a kernel restart the code submission can start with the next cell after this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9864153-66c8-43e1-ae96-1179632ccf7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if install:\n",
    "    import IPython\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)\n",
    "    IPython.display.display(IPython.display.Markdown(\"\"\"<div class=\\\"alert alert-block alert-warning\\\">\n",
    "        <b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. The previous cells do not need to be run again⚠️</b>\n",
    "        </div>\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a1ab41-cb32-4398-86dc-d30effb88a36",
   "metadata": {
    "id": "appt8-yVRtJ1"
   },
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cebe11b-9ca1-4f3e-aa78-78640ff01ec8",
   "metadata": {
    "id": "63mx2EozRxFP"
   },
   "source": [
    "Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab2239cd-40ab-416d-bac0-0c6953d911b6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 2124,
     "status": "ok",
     "timestamp": 1683726390544,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "xzcoXjM5Rky5",
    "outputId": "b3bdcbc1-70d5-472e-aea2-42c74a42efde",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'statmike-mlops-349915'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8aa97f05-66e9-4276-b2e6-83b5a91ca50c",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1683726390712,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "IxWrFtqYMfku",
    "tags": []
   },
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "SERIES = 'applied-genai'\n",
    "EXPERIMENT = 'retrieval-vertex-feature-store'\n",
    "\n",
    "# make this the BigQuery Project / Dataset / Table prefix to store results\n",
    "BQ_PROJECT = PROJECT_ID\n",
    "BQ_DATASET = SERIES.replace('-', '_')\n",
    "BQ_TABLE = EXPERIMENT\n",
    "BQ_REGION = REGION[0:2]\n",
    "\n",
    "# Vertex AI Feature Store names:\n",
    "FS_NAME = PROJECT_ID.replace('-', '_')\n",
    "FV_NAME = f\"{SERIES}-{EXPERIMENT}\".replace('-', '_')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bbf65b-5d29-4a72-84ae-d977b9a743a6",
   "metadata": {
    "id": "LuajVwCiO6Yg"
   },
   "source": [
    "Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "559f6e60-a594-4789-893b-295a8381b670",
   "metadata": {
    "executionInfo": {
     "elapsed": 17761,
     "status": "ok",
     "timestamp": 1683726409304,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "LVC7zzSLRk2C",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, json, time, glob, datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Vertex AI\n",
    "from google.cloud import aiplatform\n",
    "import vertexai.language_models # for embeddings API\n",
    "import vertexai.generative_models # for Gemini Models\n",
    "from vertexai.resources.preview import feature_store\n",
    "\n",
    "# BigqQery\n",
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3fef31f-928f-45f2-a3f4-292ee242232c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.71.0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aiplatform.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5758c07e-f064-40fb-a0ef-de6cbde5cd0a",
   "metadata": {
    "id": "EyAVFG9TO9H-"
   },
   "source": [
    "Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b72f3bb-176b-4678-ba6b-df9b2de14997",
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1683726409306,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "L0RPE13LOZce",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Vertex AI clients\n",
    "vertexai.init(project = PROJECT_ID, location = REGION)\n",
    "\n",
    "# BigQuery client\n",
    "bq = bigquery.Client(project = PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8579282f-2723-4294-b72a-a65cc0831f44",
   "metadata": {},
   "source": [
    "---\n",
    "## Text & Embeddings For Examples\n",
    "\n",
    "This repository contains a [section for document processing (chunking)](../Chunking/readme.md) that includes an example of processing mulitple large pdfs (over 1000 pages) into chunks: [Large Document Processing - Document AI Layout Parser](../Chunking/Large%20Document%20Processing%20-%20Document%20AI%20Layout%20Parser.ipynb).  The chunks of text from that workflow are stored with this repository and loaded by another companion workflow that augments the chunks with text embeddings: [Vertex AI Text Embeddings API](../Embeddings/Vertex%20AI%20Text%20Embeddings%20API.ipynb).\n",
    "\n",
    "The following code will load the version of the chunks that includes text embeddings and prepare it for a local example of retrival augmented generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e12cbe2-3ca6-4656-9e73-c0db5c63bf50",
   "metadata": {},
   "source": [
    "### Get The Documents\n",
    "\n",
    "If you are working from a clone of this notebooks [repository](https://github.com/statmike/vertex-ai-mlops) then the documents are already present. The following cell checks for the documents folder and if it is missing gets it (`git clone`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f4e77ed-43f7-42be-9575-6a491c0d6cba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "local_dir = '../Embeddings/files/embeddings-api'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63ebe7c3-e72c-4394-91c3-d60c05bc0ce2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents Found in folder `../Embeddings/files/embeddings-api`\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(local_dir):\n",
    "    print('Retrieving documents...')\n",
    "    parent_dir = os.path.dirname(local_dir)\n",
    "    temp_dir = os.path.join(parent_dir, 'temp')\n",
    "    if not os.path.exists(temp_dir):\n",
    "        os.makedirs(temp_dir)\n",
    "    !git clone https://www.github.com/statmike/vertex-ai-mlops {temp_dir}/vertex-ai-mlops\n",
    "    shutil.copytree(f'{temp_dir}/vertex-ai-mlops/Applied GenAI/Embeddings/files/embeddings-api', local_dir)\n",
    "    shutil.rmtree(temp_dir)\n",
    "    print(f'Documents are now in folder `{local_dir}`')\n",
    "else:\n",
    "    print(f'Documents Found in folder `{local_dir}`')             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e68a84-9f88-4590-9ff1-e01c8a953ccf",
   "metadata": {},
   "source": [
    "### Load The Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58d04382-a74a-44ac-8824-3b46c86aa148",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0000.jsonl',\n",
       " '../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0001.jsonl',\n",
       " '../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0002.jsonl',\n",
       " '../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0003.jsonl',\n",
       " '../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0004.jsonl',\n",
       " '../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0005.jsonl',\n",
       " '../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0006.jsonl',\n",
       " '../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0007.jsonl',\n",
       " '../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0008.jsonl',\n",
       " '../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0009.jsonl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonl_files = glob.glob(f\"{local_dir}/large-files*.jsonl\")\n",
    "jsonl_files.sort()\n",
    "jsonl_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a54c6c96-6c28-49bb-80be-5d46797dfe77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9040"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = []\n",
    "for file in jsonl_files:\n",
    "    with open(file, 'r') as f:\n",
    "        chunks.extend([json.loads(line) for line in f])\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70115ec-6d60-41df-b7e6-9e2e5b463b1d",
   "metadata": {},
   "source": [
    "### Review A Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc20423e-e3d6-4e90-9e98-a5248508c82d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['instance', 'predictions', 'status'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1955ea39-4ffc-4d30-b653-a5a9911f2dab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fannie_part_0_c17'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0]['instance']['chunk_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3537982c-4a0e-456c-a652-19ea7507873b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Selling Guide Fannie Mae Single Family\n",
      "\n",
      "## Fannie Mae Copyright Notice\n",
      "\n",
      "### Fannie Mae Copyright Notice\n",
      "\n",
      "|-|\n",
      "| Section B3-4.2, Verification of Depository Assets 402 |\n",
      "| B3-4.2-01, Verification of Deposits and Assets (05/04/2022) 403 |\n",
      "| B3-4.2-02, Depository Accounts (12/14/2022) 405 |\n",
      "| B3-4.2-03, Individual Development Accounts (02/06/2019) 408 |\n",
      "| B3-4.2-04, Pooled Savings (Community Savings Funds) (04/01/2009) 411 |\n",
      "| B3-4.2-05, Foreign Assets (05/04/2022) 411 |\n",
      "| Section B3-4.3, Verification of Non-Depository Assets 412 |\n",
      "| B3-4.3-01, Stocks, Stock Options, Bonds, and Mutual Funds (06/30/2015) 412 |\n",
      "| B3-4.3-02, Trust Accounts (04/01/2009) 413 |\n",
      "| B3-4.3-03, Retirement Accounts (06/30/2015) 414 |\n",
      "| B3-4.3-04, Personal Gifts (09/06/2023) 415 |\n",
      "| B3-4.3-05, Gifts of Equity (10/07/2020) 418 |\n",
      "| B3-4.3-06, Grants and Lender Contributions (12/14/2022) 419 |\n",
      "| B3-4.3-07, Disaster Relief Grants or Loans (04/01/2009) 423 |\n",
      "| B3-4.3-08, Employer Assistance (09/29/2015) 423 |\n",
      "| B3-4.3-09, Earnest Money Deposit (05/04/2022) 425 |\n",
      "| B3-4.3-10, Anticipated Sales Proceeds (02/23/2016) B3-4.3-11, Trade Equity (12/16/2020) 426 428 |\n",
      "| B3-4.3-12, Rent-Related Credits (08/07/2024) 429 |\n",
      "| B3-4.3-13, Sweat Equity (04/15/2014) 430 |\n",
      "| B3-4.3-14, Bridge/Swing Loans (04/01/2009) 431 |\n",
      "| B3-4.3-15, Borrowed Funds Secured by an Asset (10/30/2009) 431 |\n",
      "|  |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(chunks[0]['instance']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49f06293-a439-436b-bc93-cd6cd3fb4aff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.031277116388082504,\n",
       " 0.03056905046105385,\n",
       " 0.010865348391234875,\n",
       " 0.0623614676296711,\n",
       " 0.03228681534528732,\n",
       " 0.05066155269742012,\n",
       " 0.046544693410396576,\n",
       " 0.05509665608406067,\n",
       " -0.014074751175940037,\n",
       " 0.008380400016903877]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0]['predictions'][0]['embeddings']['values'][0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f977358d-d9ea-4172-9eca-66079bb6087d",
   "metadata": {},
   "source": [
    "### Prepare Chunk Structure\n",
    "\n",
    "Make a list of dictionaries with information for each chunk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be9fa708-130c-4343-b179-dbde0b09a972",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "content_chunks = [\n",
    "    dict(\n",
    "        gse = chunk['instance']['gse'],\n",
    "        chunk_id = chunk['instance']['chunk_id'],\n",
    "        content = chunk['instance']['content'],\n",
    "        embedding = chunk['predictions'][0]['embeddings']['values']\n",
    "    ) for chunk in chunks\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6619605-7b10-444e-a131-db06e56a4be8",
   "metadata": {},
   "source": [
    "### Query Embedding\n",
    "\n",
    "Create a query, or prompt, and get the embedding for it:\n",
    "\n",
    "Connect to models for text embeddings. Learn more about the model API:\n",
    "- [Vertex AI Text Embeddings API](../Embeddings/Vertex%20AI%20Text%20Embeddings%20API.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3da5d30c-3dfb-42ba-a133-83dceb252787",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question = \"Does a lender have to perform servicing functions directly?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7992c26f-d058-4920-80a3-a157b88733e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedder = vertexai.language_models.TextEmbeddingModel.from_pretrained('text-embedding-004')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbe6fda7-9cea-49a2-9e2f-9222d50677af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.0005117303808219731,\n",
       " 0.009651427157223225,\n",
       " 0.01768726110458374,\n",
       " 0.014538003131747246,\n",
       " -0.01829824410378933,\n",
       " 0.027877431362867355,\n",
       " -0.021124685183167458,\n",
       " 0.008830446749925613,\n",
       " -0.02669006586074829,\n",
       " 0.06414774805307388]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_embedding = embedder.get_embeddings([question])[0].values\n",
    "question_embedding[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6ec209-b34a-4837-8c54-a991ad831764",
   "metadata": {},
   "source": [
    "---\n",
    "## Load To BigQuery - The Offline Store For Vertex AI Feature Store\n",
    "\n",
    "The offline store for [Vertex AI Feature Store](https://cloud.google.com/vertex-ai/docs/featurestore/latest/overview) is BigQuery.  This streamlines ML feature management prior to serving online with feature store.  We will first load the data to BigQuery.\n",
    "\n",
    "In this case the information to load to BigQuery is local.  It could be in GCS or other BigQuery sources.  You can also get embeddings for information within BigQuery using the [ML.GENERATE_EMBEDDING function](https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-generate-embedding) and even use the exact same model as was used for the data imported above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4498c73e-5f88-434a-9a6a-eb8cb263793b",
   "metadata": {},
   "source": [
    "### Create/Recall Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e447923e-9586-4635-929f-3f330eec1331",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = bigquery.Dataset(f\"{BQ_PROJECT}.{BQ_DATASET}\")\n",
    "dataset.location = BQ_REGION\n",
    "bq_dataset = bq.create_dataset(dataset, exists_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc2fe99-094b-4d94-8839-1ee9640f8d8b",
   "metadata": {},
   "source": [
    "### Load JSON TO BigQuery Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e561bb0-5060-49b2-93e9-c6d0d1f6c130",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bq_table = bq_dataset.table(BQ_TABLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "92744b85-75ab-4edb-8159-4d66caf45b92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "job_config = bigquery.LoadJobConfig(\n",
    "    source_format = bigquery.SourceFormat.NEWLINE_DELIMITED_JSON,\n",
    "    write_disposition = bigquery.WriteDisposition.WRITE_TRUNCATE,\n",
    "    autodetect = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "571b9ccf-542a-4abd-a398-d72222baf8a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoadJob<project=statmike-mlops-349915, location=US, id=51dbc28a-9236-40bf-abaf-8e8671d66c58>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_job = bq.load_table_from_json(\n",
    "    json_rows = content_chunks,\n",
    "    destination = bq_table,\n",
    "    job_config = job_config\n",
    ")\n",
    "load_job.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0bb75cd8-218e-46f9-876e-a4c6b86293fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>embedding</th>\n",
       "      <th>content</th>\n",
       "      <th>gse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>freddie_part_1_c275</td>\n",
       "      <td>[-0.010820388793945312, 0.03051573783159256, 0...</td>\n",
       "      <td># (g) Texas Equity Uniform Instruments and oth...</td>\n",
       "      <td>freddie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>freddie_part_6_c129</td>\n",
       "      <td>[0.033966064453125, 0.02275390923023224, 0.038...</td>\n",
       "      <td># 9209.5: Property valuation requirements for ...</td>\n",
       "      <td>freddie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>freddie_part_4_c91</td>\n",
       "      <td>[0.021045684814453125, 0.0005818947684019804, ...</td>\n",
       "      <td># 6302.16: Special delivery requirements for r...</td>\n",
       "      <td>freddie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>freddie_part_2_c479</td>\n",
       "      <td>[0.0327911376953125, -0.03755122050642967, -0....</td>\n",
       "      <td># 5401.1: Monthly housing expense-to-income ra...</td>\n",
       "      <td>freddie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>freddie_part_3_c576</td>\n",
       "      <td>[0.02548600733280182, 0.06772162765264511, -0....</td>\n",
       "      <td># 6201.14: Postsettlement adjustments for Mort...</td>\n",
       "      <td>freddie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              chunk_id                                          embedding  \\\n",
       "0  freddie_part_1_c275  [-0.010820388793945312, 0.03051573783159256, 0...   \n",
       "1  freddie_part_6_c129  [0.033966064453125, 0.02275390923023224, 0.038...   \n",
       "2   freddie_part_4_c91  [0.021045684814453125, 0.0005818947684019804, ...   \n",
       "3  freddie_part_2_c479  [0.0327911376953125, -0.03755122050642967, -0....   \n",
       "4  freddie_part_3_c576  [0.02548600733280182, 0.06772162765264511, -0....   \n",
       "\n",
       "                                             content      gse  \n",
       "0  # (g) Texas Equity Uniform Instruments and oth...  freddie  \n",
       "1  # 9209.5: Property valuation requirements for ...  freddie  \n",
       "2  # 6302.16: Special delivery requirements for r...  freddie  \n",
       "3  # 5401.1: Monthly housing expense-to-income ra...  freddie  \n",
       "4  # 6201.14: Postsettlement adjustments for Mort...  freddie  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bq.query(f\"SELECT * FROM `{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}` LIMIT 5\").to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6ade5f-cdcf-4394-b0db-74895d41ec2a",
   "metadata": {},
   "source": [
    "---\n",
    "## Retrieval With BigQuery\n",
    "\n",
    "BigQuery is a fully managed data warehouse where SQL queries run without the need to plan for storage or compute requirements.  Built into this solution is the  `VECTOR_SEARCH` function that can perform brute-force searches for neighboring embeddings and utilize an index for efficient search. BigQuery offers two built-in methods for [creating vector indexes](https://cloud.google.com/bigquery/docs/vector-index): the [Inverted File (IVF) index](https://cloud.google.com/bigquery/docs/vector-index#ivf-index) and the [TreeAH index](https://cloud.google.com/bigquery/docs/vector-index#tree-ah-index).\n",
    "\n",
    "Check out a companion workflow using BigQuery here: \n",
    "- [Retrieval - BigQuery Vector Indexing And Search](Retrieval%20-%20BigQuery%20Vector%20Indexing%20And%20Search.ipynb)\n",
    "\n",
    "This workflow continues with Vertex AI Feature Store as an online serving infrasturcture that syncs with BigQuery."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3745dc92-0000-418f-a914-3bd4fa49cf5b",
   "metadata": {},
   "source": [
    "---\n",
    "## Retrieval With Vertex AI Feature Store\n",
    "\n",
    "[Vertex AI Feature Store](https://cloud.google.com/vertex-ai/docs/featurestore/latest/overview) creates online feature views from BigQuery tables or views, either directly or through the feature registry, and synchronizes the source data in BigQuery with the online serving. The online stores provide a low-latency API for vector matching using either vectors or entity IDs as input. The response includes all features in the feature view, which can encompass the text and metadata for the match, as these can be included as features. Learn more about Vertex AI Feature Store in this repository's [MLOps](../../MLOps/readme.md) section, which includes a deep dive into [feature stores](../../MLOps/Feature%20Store/readme.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2c2639-eb73-46d6-8a11-5fcf0b5109ca",
   "metadata": {},
   "source": [
    "### Create/Retrieve Online Store\n",
    "\n",
    "The first step is to create a Vertex AI Feature Store.  There are two serving types to choose from when setting up a feature store: Bigtable and Optimized.  For this work the Optimized online serving is picked becasue it also [provides vector similarity search](https://cloud.google.com/vertex-ai/docs/featurestore/latest/embeddings-search) functionality that Bigtable serving does not.\n",
    ">**NOTE:** This can take around 10 minutes if creating a new feature store instance\n",
    "\n",
    "**Reference:**\n",
    "- [Create an Online Store Instance](https://cloud.google.com/vertex-ai/docs/featurestore/latest/create-onlinestore)\n",
    "- [Online Serving Types](https://cloud.google.com/vertex-ai/docs/featurestore/latest/online-serving-types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "04b19990-58f6-414b-b92c-6643b0c21cfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    online_store = feature_store.FeatureOnlineStore(name = FS_NAME)\n",
    "    print(f\"Found the feature store:\\n{online_store.resource_name}\")\n",
    "except Exception:\n",
    "    print(\"Create the feature store...\")\n",
    "    online_store = feature_store.FeatureOnlineStore.create_optimized_store(\n",
    "        name = FS_NAME\n",
    "    )\n",
    "    print(f\"Create the feature store:\\n{online_store.resource_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "894f724c-498c-4792-bd32-785b73958eee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/1026793852137/locations/us-central1/featureOnlineStores/statmike_mlops_349915'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "online_store.resource_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5f414304-5527-4b8e-9579-ed950613953d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'statmike_mlops_349915'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "online_store.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1c5327-a0b1-4773-b210-39e4b6faa3c6",
   "metadata": {},
   "source": [
    "### Create/Retrieve Feature View With Vector Index: From BigQuery Source\n",
    "\n",
    "There are two paths to [creating feature views](https://cloud.google.com/vertex-ai/docs/featurestore/latest/create-featureview) in feature store. The one used here is syncing a BigQuery table or view directly to the online store. The alternative involves using the feature registry which gives greater control of selecting features (columns) form multiple BigQuery source tables and views.  Learn more about Vertex AI Feature Store in this repository's [MLOps](../../MLOps/readme.md) section, which includes a deep dive into [feature stores](../../MLOps/Feature%20Store/readme.md).\n",
    "\n",
    "**Vector Index**\n",
    "\n",
    "The feature view specification includes the vector index specification.  This includes set the column name with the embedding and dimension of the embedding.  For the index you can set:\n",
    "- `algorithm_config` - can be `TreeAhConfig` or `BruteForceConfig`\n",
    "- `filter_columns` for any pre-filter columns\n",
    "- `crowding_column` for any column that may be used to specify limits by unique value for during queries\n",
    "- `distance_measure_type` to select Euclidean distance, Cosine Similarity, or Dot Product as the measurement method\n",
    "    - Use 3 for dot product here for these normalized embeddings and read more about why in [The Math of Similarity](../Embeddings/The%20Math%20of%20Similarity.ipynb)\n",
    "\n",
    "**Reference:**\n",
    "- [Create a feature view instance](https://cloud.google.com/vertex-ai/docs/featurestore/latest/create-featureview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bc38b24a-244a-42e2-a32d-52462fda1486",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    feature_view = feature_store.FeatureView(\n",
    "        name = FV_NAME,\n",
    "        feature_online_store_id = online_store.resource_name\n",
    "    )\n",
    "except Exception:\n",
    "    feature_view = online_store.create_feature_view(\n",
    "        name = FV_NAME,\n",
    "        source = feature_store.utils.FeatureViewBigQuerySource(\n",
    "            uri = f'bq://{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}',\n",
    "            entity_id_columns = ['chunk_id'] \n",
    "        ),\n",
    "        index_config = feature_store.utils.IndexConfig(\n",
    "            embedding_column = 'embedding',\n",
    "            dimensions = len(question_embedding),\n",
    "            algorithm_config = feature_store.utils.TreeAhConfig(\n",
    "                leaf_node_embedding_count = 250 # default is 1000\n",
    "            ), #TreeAHConfig is default, can override here with BruteForceConfig\n",
    "            filter_columns = ['gse'],\n",
    "            crowding_column = 'gse',\n",
    "            distance_measure_type = feature_store.utils.DistanceMeasureType(3) # 1=Euclidean/L2, 2=Cosine, 3=dot product\n",
    "        ),\n",
    "        sync_config = 'TZ=America/New_York 10 * * * *' # 10 minutes past the hour, every hour\n",
    "    )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4362dc78-21fe-4783-880a-ce7e97fdac08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'applied_genai_retrieval_vertex_feature_store'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_view.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d053cdc0-bdac-446f-8734-408ebe748f07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/1026793852137/locations/us-central1/featureOnlineStores/statmike_mlops_349915/featureViews/applied_genai_retrieval_vertex_feature_store'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_view.resource_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a11d2e-5360-4c78-bfe4-de9327f73686",
   "metadata": {},
   "source": [
    "### Managing Synchronization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90498d16-2994-4a13-8283-19199aa55ceb",
   "metadata": {},
   "source": [
    "Force a synchronization rather than wait for the next scheduled sync:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b9c5f121-7843-4b73-8a52-3a507730be4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "force_sync = feature_view.sync()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dd5d2b79-a216-4fd6-8336-9eda634858cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vertexai.resources.preview.feature_store.feature_view.FeatureView.FeatureViewSync"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(force_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f13b292a-e702-40ea-85f2-df65a5af8f35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'projects/1026793852137/locations/us-central1/featureOnlineStores/statmike_mlops_349915/featureViews/applied_genai_retrieval_vertex_feature_store/featureViewSyncs/895940494457044992',\n",
       " 'createTime': '2024-11-10T19:55:01.636814Z',\n",
       " 'runTime': {'startTime': '2024-11-10T19:55:01.636814Z'}}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "force_sync.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670907ee-0aba-4be5-8c75-82c384459cca",
   "metadata": {},
   "source": [
    "Get updated information about the sync job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2ca08d43-9b84-43f1-a3d2-169aa6837c5e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'projects/1026793852137/locations/us-central1/featureOnlineStores/statmike_mlops_349915/featureViews/applied_genai_retrieval_vertex_feature_store/featureViewSyncs/895940494457044992',\n",
       " 'createTime': '2024-11-10T19:55:01.636814Z',\n",
       " 'runTime': {'startTime': '2024-11-10T19:55:01.636814Z'}}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "force_sync = feature_view.get_sync(name = force_sync.name)\n",
    "force_sync.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f718f194-60f5-4d11-abb7-bdc005d0bf79",
   "metadata": {},
   "source": [
    "Wait on the sync job to complete and report timing and rows synced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4972f6de-d227-4960-b049-2b89200139cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waited 0 seconds, Update again in 30 seconds...\n",
      "Waited 30 seconds, Update again in 30 seconds...\n",
      "Waited 60 seconds, Update again in 30 seconds...\n",
      "Waited 90 seconds, Update again in 30 seconds...\n",
      "Waited 120 seconds, Update again in 30 seconds...\n",
      "Sync completed in 154.04748 seconds and synced 27120 rows.\n"
     ]
    }
   ],
   "source": [
    "waited = 0\n",
    "while True:\n",
    "    sync_status = feature_view.get_sync(name = force_sync.name).to_dict()\n",
    "    if 'endTime' in list(sync_status['runTime'].keys()):\n",
    "        seconds = (\n",
    "            datetime.datetime.fromisoformat(sync_status['runTime']['endTime'].replace('Z', '+00:00'))\n",
    "            -\n",
    "            datetime.datetime.fromisoformat(sync_status['runTime']['startTime'].replace('Z', '+00:00'))\n",
    "        ).total_seconds()\n",
    "        rows = sync_status['syncSummary']['rowSynced']\n",
    "        print(f\"Sync completed in {seconds} seconds and synced {rows} rows.\")\n",
    "        break\n",
    "    else:\n",
    "        print(f\"Waited {waited} seconds, Update again in 30 seconds...\")\n",
    "        time.sleep(30)\n",
    "        waited += 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defece5a-2c1c-4859-b80b-c7d6a238c2aa",
   "metadata": {},
   "source": [
    "Get a list of sync jobs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4cfcc27a-5257-434b-8390-74a0531a7ffa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_syncs = feature_view.list_syncs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24ffe54-1914-476a-81ec-3b9441fdbdc6",
   "metadata": {},
   "source": [
    "Print out the end time and rows synced for each job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c48e04-fe20-4e8b-9cc6-7634924129ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for sync in list_syncs:\n",
    "    s = feature_view.get_sync(name = sync.name).to_dict()\n",
    "    ended = datetime.datetime.fromisoformat(s['runTime']['endTime'].replace('Z', '+00:00')).strftime(\"%m/%d/%Y %H:%M:%S\")\n",
    "    rows = s['syncSummary']['rowSynced']\n",
    "    print(f\"Sync completed at {ended} and synced {rows} rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ed0c74-808b-41da-a395-b87bb0cd6835",
   "metadata": {},
   "source": [
    "### Retrieve: Features For Entity\n",
    "\n",
    "**NOTE:** The embedding is also retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "83cd89cc-ab07-4dde-a212-24ae10961538",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Public endpoint for the optimized online store statmike_mlops_349915 is 6457115130579648512.us-central1-1026793852137.featurestore.vertexai.goog\n"
     ]
    }
   ],
   "source": [
    "results = feature_view.read(key = ['fannie_part_0_c1']).to_dict()['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9a0d2a38-4b07-409b-ae9a-25936ddd2c69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'content', 'value': {'string_value': 'Fannie Mae'}},\n",
       " {'name': 'gse', 'value': {'string_value': 'fannie'}}]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for f, feature in enumerate(results):\n",
    "    if feature['name'] == 'embedding':\n",
    "        results.pop(f)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8d0ac7-bcba-4cea-a8aa-c9d9da37f48e",
   "metadata": {},
   "source": [
    "### Matches: For Entity\n",
    "\n",
    "Given an entity id value find the neighbors using the similarity search with embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "90cbb72a-1103-42e4-a0f8-c4efc391eea1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = feature_view.search(\n",
    "    entity_id = 'fannie_part_0_c40',\n",
    "    neighbor_count = 5,\n",
    "    return_full_entity = False,\n",
    "    #per_crowding_attribute_neighbor_count = 5,\n",
    "    #leaf_nodes_search_fraction = 0.25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bda0907f-4037-4819-bae4-0a120c102c64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SearchNearestEntitiesResponse(_response=nearest_neighbors {\n",
       "  neighbors {\n",
       "    entity_id: \"fannie_part_0_c39\"\n",
       "    distance: -0.90960991382598877\n",
       "  }\n",
       "  neighbors {\n",
       "    entity_id: \"fannie_part_0_c38\"\n",
       "    distance: -0.84551787376403809\n",
       "  }\n",
       "  neighbors {\n",
       "    entity_id: \"fannie_part_0_c5\"\n",
       "    distance: -0.804158091545105\n",
       "  }\n",
       "  neighbors {\n",
       "    entity_id: \"fannie_part_0_c37\"\n",
       "    distance: -0.79278743267059326\n",
       "  }\n",
       "  neighbors {\n",
       "    entity_id: \"fannie_part_0_c6\"\n",
       "    distance: -0.7925485372543335\n",
       "  }\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712daa1d-7669-4f14-a152-04f0a5f8145c",
   "metadata": {},
   "source": [
    "### Matches: For Entity Returning All Features\n",
    "\n",
    "Given an entity id value find the neighbors using the similarity search with embeddings and return all the features for the matches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "116ac3f3-5323-4a8e-a343-85bc9c952640",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = feature_view.search(\n",
    "    entity_id = 'fannie_part_0_c40',\n",
    "    neighbor_count = 2,\n",
    "    return_full_entity = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8226e33b-263c-4b10-9fac-d9415b1d0d2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'chunk_id': 'fannie_part_0_c39',\n",
       "  'content': '# Selling Guide Fannie Mae Single Family\\n\\n## Fannie Mae Copyright Notice\\n\\n### Fannie Mae Copyright Notice\\n\\nE-3-08, Acronyms and Glossary of Defined Terms: H (04/05/2023) 1129\\n| E-3-09, Acronyms and Glossary of Defined Terms: I (05/03/2023) 1131 |\\n| E-3-10, Acronyms and Glossary of Defined Terms: J (04/01/2009) 1134 |\\n| applicable terms. E-3-11, Acronyms and No 1134 Glossary of Defined Terms: K (12/14/2022) 1134 |\\n| applicable terms. E-3-12, Acronyms and Glossary of Defined Terms: L (09/04/2018) No 1134 1134 |\\n| and Glossary of Defined Terms: M (12/13/2023) E-3-13, Acronyms 1137 |\\n| E-3-14, Acronyms Terms: N (05/26/2015) Defined Glossary of and 1142 |\\n| Terms: O (11/10/2014) Defined Glossary of and Acronyms E-3-15, 1143 |\\n| E-3-16, Acronyms E-3-17, Acronyms Terms: P (02/07/2024) Glossary of Defined and 1144 and Glossary of Defined Terms: Q (04/01/2009) 1148 |\\n| No applicable terms. 1148 |\\n| Terms: R (02/07/2024) Glossary of Defined and E-3-18, Acronyms 1148 |\\n| Glossary of Defined Terms: S (02/07/2024) and E-3-19, Acronyms 1152 |\\n| E-3-20, Acronyms and Glossary of Defined Terms: T (02/07/2024) 1157 |\\n| E-3-21, Acronyms and Glossary of Defined Terms: U (05/01/2019) 1159 |\\n|  |\\n'},\n",
       " {'chunk_id': 'fannie_part_0_c38',\n",
       "  'content': '# Selling Guide Fannie Mae Single Family\\n\\n## Fannie Mae Copyright Notice\\n\\n### Fannie Mae Copyright Notice\\n| E-2-01, Required Custodial Documents (05/04/2022) 1071 |\\n| E-2-02, Suggested Format for Phase I Environmental Hazard Assessments (06/28/2011) 1074 |\\n| E-2-03, Revocable Trust Rider (Sample Language) (01/17/2013) 1086 |\\n| E-2-04, Signature Requirements for Mortgages to Inter Vivos Revocable Trusts (02/27/2018) 1087 |\\n| E-2-05, Servicing Marketplace - Mortgage Loan Servicing Purchase and Sale Agreement (12/15/2021) |\\n| 1091 |\\n| E-2-06, Correcting Errors in eNotes (12/13/2023) 1106 |\\n| E-2-07, Description of eNote Header, Footer, and eNote Clause (12/13/2023) 1107 |\\n| Chapter E-3, Acronyms and Glossary of Defined Terms 1109 |\\n| E-3-01, Acronyms and Glossary of Defined Terms: A (05/01/2024) 1109 |\\n| E-3-02, Acronyms and Glossary of Defined Terms: B (02/07/2024) 1113 |\\n| Acronyms and Glossary of Defined Terms: C (06/05/2024) E-3-03, 1114 |\\n| E-3-04, Acronyms and Glossary of Defined Terms: D (03/01/2023) 1120 |\\n| E-3-05, Acronyms and Glossary of Defined Terms: E (12/14/2022) 1122 |\\n| E-3-06, Acronyms and Glossary of Defined Terms: F (05/01/2024) 1124 |\\n| E-3-07, Acronyms and Glossary of Defined Terms: G (12/14/2022) 1128 |\\n|  |\\n'}]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches = []\n",
    "for result in results.to_dict()['neighbors']:\n",
    "    for feature in result['entity_key_values']['key_values']['features']:\n",
    "        if feature['name'] == 'content':\n",
    "            matches.append(dict(\n",
    "                chunk_id = result['entity_id'],\n",
    "                content = feature['value']['string_value']\n",
    "            ))\n",
    "matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da611b82-d247-4bf6-a381-2b8ecb3f86d8",
   "metadata": {},
   "source": [
    "### Matches: For Query Embedding\n",
    "\n",
    "Given a query embedding find the neighbors using the similarity search with embeddings and return all the feature for the matches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e37bd2af-13d1-49ec-be69-c64fbb08c4f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Does a lender have to perform servicing functions directly?'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "575e44b3-f173-44ed-a3c7-9b17c7bbfbe3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(question_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3602819b-7ea1-4cea-90a4-a5a108238611",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = feature_view.search(\n",
    "    embedding_value = question_embedding,\n",
    "    neighbor_count = 2,\n",
    "    return_full_entity = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f1c4a031-139c-437f-a2cd-3e5571a940ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'chunk_id': 'fannie_part_0_c352',\n",
       "  'content': '# A3-3-03, Other Servicing Arrangements (12/15/2015)\\n\\nIntroduction This topic provides an overview of other servicing arrangements, including: • Subservicing • General Requirements for Subservicing Arrangements • Pledge of Servicing Rights and Transfer of Interest in Servicing Income\\n\\n## Subservicing\\n\\nA lender may use other organizations to perform some or all of its servicing functions. Fannie Mae refers to these arrangements as “subservicing” arrangements, meaning that a servicer (the “subservicer”) other than the contractually responsible servicer (the “master” servicer) is performing the servicing functions. The following are not considered to be subservicing arrangements: • when a computer service bureau is used to perform accounting and reporting functions; • when the originating lender sells and assigns servicing to another lender, unless the originating lender continues to be the contractually responsible servicer.'},\n",
       " {'chunk_id': 'freddie_part_4_c509',\n",
       "  'content': \"# (1) Notice requirements\\n\\nThe notice must advise the Borrower of the following: 1. The date the new Servicing Agent or Master Servicer undertakes the performance of the Servicing obligations 2. The name and address of the Servicer undertaking the performance of the Servicing obligations 3. The names and telephone numbers of the contact persons or departments where the Borrowers' inquiries relating to the transfer should be directed. (If toll-free numbers are not available, the letter must indicate that collect calls will be accepted.) Such names and telephone numbers must be provided for the party previously performing the Servicing obligations as well as the new Servicing Agent or Master Servicer undertaking the performance of the Servicing obligations. 4. The date when the party previously performing the Servicing obligation will no longer collect the Borrowers' payments and when the new Servicing Agent or Master Servicer undertaking the performance of the Servicing obligations will begin to collect them 5. Procedures for maintenance of automatic draft payments, if applicable. Every effort must be made to continue, without interruption, electronic payments on the Borrower's Mortgage, to the extent permitted by applicable law.\"}]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches = []\n",
    "for result in results.to_dict()['neighbors']:\n",
    "    for feature in result['entity_key_values']['key_values']['features']:\n",
    "        if feature['name'] == 'content':\n",
    "            matches.append(dict(\n",
    "                chunk_id = result['entity_id'],\n",
    "                content = feature['value']['string_value']\n",
    "            ))\n",
    "matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac4708c-40a7-421e-a99c-a4dc29e1270a",
   "metadata": {},
   "source": [
    "### Matches: For Query Embedding - Expand Search Candidates\n",
    "\n",
    "Given a query embedding find the neighbors using the similarity search with embeddings and return all the feature for the matches.  Expand the search candidates by providing an override for `leaf_nodes_search_fraction`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6be77e63-b8ae-490f-8c02-12add02145ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = feature_view.search(\n",
    "    embedding_value = question_embedding,\n",
    "    neighbor_count = 2,\n",
    "    return_full_entity = True,\n",
    "    leaf_nodes_search_fraction = 0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1a305897-46ff-42ce-b210-778fe708df87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'chunk_id': 'fannie_part_0_c352',\n",
       "  'content': '# A3-3-03, Other Servicing Arrangements (12/15/2015)\\n\\nIntroduction This topic provides an overview of other servicing arrangements, including: • Subservicing • General Requirements for Subservicing Arrangements • Pledge of Servicing Rights and Transfer of Interest in Servicing Income\\n\\n## Subservicing\\n\\nA lender may use other organizations to perform some or all of its servicing functions. Fannie Mae refers to these arrangements as “subservicing” arrangements, meaning that a servicer (the “subservicer”) other than the contractually responsible servicer (the “master” servicer) is performing the servicing functions. The following are not considered to be subservicing arrangements: • when a computer service bureau is used to perform accounting and reporting functions; • when the originating lender sells and assigns servicing to another lender, unless the originating lender continues to be the contractually responsible servicer.'},\n",
       " {'chunk_id': 'freddie_part_4_c509',\n",
       "  'content': \"# (1) Notice requirements\\n\\nThe notice must advise the Borrower of the following: 1. The date the new Servicing Agent or Master Servicer undertakes the performance of the Servicing obligations 2. The name and address of the Servicer undertaking the performance of the Servicing obligations 3. The names and telephone numbers of the contact persons or departments where the Borrowers' inquiries relating to the transfer should be directed. (If toll-free numbers are not available, the letter must indicate that collect calls will be accepted.) Such names and telephone numbers must be provided for the party previously performing the Servicing obligations as well as the new Servicing Agent or Master Servicer undertaking the performance of the Servicing obligations. 4. The date when the party previously performing the Servicing obligation will no longer collect the Borrowers' payments and when the new Servicing Agent or Master Servicer undertaking the performance of the Servicing obligations will begin to collect them 5. Procedures for maintenance of automatic draft payments, if applicable. Every effort must be made to continue, without interruption, electronic payments on the Borrower's Mortgage, to the extent permitted by applicable law.\"}]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches = []\n",
    "for result in results.to_dict()['neighbors']:\n",
    "    for feature in result['entity_key_values']['key_values']['features']:\n",
    "        if feature['name'] == 'content':\n",
    "            matches.append(dict(\n",
    "                chunk_id = result['entity_id'],\n",
    "                content = feature['value']['string_value']\n",
    "            ))\n",
    "matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c19b98-1303-4b40-82c3-7eda8898c290",
   "metadata": {},
   "source": [
    "### Matches: For Query Embedding - Diversity of Responses\n",
    "\n",
    "Given a query embedding find the neighbors using the similarity search with embeddings and return all the feature for the matches.  Use the crowding attribute, gse, to request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0c3a406b-4846-45ec-9a5b-0e0d42dc12ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = feature_view.search(\n",
    "    embedding_value = question_embedding,\n",
    "    #neighbor_count = 4,\n",
    "    return_full_entity = True,\n",
    "    per_crowding_attribute_neighbor_count = 4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9a7e903c-0b28-4415-9367-efe4444ea5df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'chunk_id': 'fannie_part_0_c352'},\n",
       " {'chunk_id': 'freddie_part_4_c509'},\n",
       " {'chunk_id': 'freddie_part_4_c510'},\n",
       " {'chunk_id': 'fannie_part_0_c353'}]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches = []\n",
    "for result in results.to_dict()['neighbors']:\n",
    "    for feature in result['entity_key_values']['key_values']['features']:\n",
    "        if feature['name'] == 'content':\n",
    "            matches.append(dict(\n",
    "                chunk_id = result['entity_id'],\n",
    "                #content = feature['value']['string_value']\n",
    "            ))\n",
    "matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a315092-cdb9-4463-b769-5f7742a081d0",
   "metadata": {},
   "source": [
    "### Matches: For Query Embedding - Limit Search Area\n",
    "\n",
    "Given a query embedding find the neighbors using the similarity search with embeddings and return all the feature for the matches.  Use the attribute GSE to limit search to values with 'fannie':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6e671e83-95c3-4545-a103-f8cf443de24e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = feature_view.search(\n",
    "    embedding_value = question_embedding,\n",
    "    neighbor_count = 4,\n",
    "    return_full_entity = True,\n",
    "    string_filters = [aiplatform.gapic.NearestNeighborQuery.StringFilter(name = 'gse', allow_tokens = ['fannie'])]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "073bd65b-26bd-4cca-863b-ae2959ceb984",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'chunk_id': 'fannie_part_0_c352'},\n",
       " {'chunk_id': 'fannie_part_0_c353'},\n",
       " {'chunk_id': 'fannie_part_0_c326'},\n",
       " {'chunk_id': 'fannie_part_0_c92'}]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches = []\n",
    "for result in results.to_dict()['neighbors']:\n",
    "    for feature in result['entity_key_values']['key_values']['features']:\n",
    "        if feature['name'] == 'content':\n",
    "            matches.append(dict(\n",
    "                chunk_id = result['entity_id'],\n",
    "                #content = feature['value']['string_value']\n",
    "            ))\n",
    "matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b486fd2-4824-4ecb-a0ac-f2ee3bd226ab",
   "metadata": {},
   "source": [
    "---\n",
    "## Retrieval Augmented Generation (RAG)\n",
    "\n",
    "Build a simple retrieval augmented generation process that enhances a query by retrieving context.  This is done here by constructing three functions for the stages:\n",
    "- `retrieve` - a function that uses an embedding to search for matching context parts, pieces of texts\n",
    "    - this uses the system built earlier in this workflow!\n",
    "- `augment` - prepare chunks into a prompt\n",
    "- `generate` - make the llm request with the augmented prompt\n",
    "\n",
    "A final function is used to execute the workflow of rag:\n",
    "- `rag` - a function that receives the query an orchestrates the workflow through `retrieve` > `augment` > `generate`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6052c911-2d2c-4052-be17-393ab42117dc",
   "metadata": {},
   "source": [
    "### Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "458497c2-1142-4d5b-b298-5706fef5b7e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedder = vertexai.language_models.TextEmbeddingModel.from_pretrained('text-embedding-004')\n",
    "llm = vertexai.generative_models.GenerativeModel(\"gemini-1.5-flash-002\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9f6311-216b-4240-b69b-4809736ed3c6",
   "metadata": {},
   "source": [
    "### Retrieve Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "da56e1a4-7a94-435c-a5e3-835da329cf2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def retrieve_featurestore(query_embedding, n_matches = 5):\n",
    "    \n",
    "    results = feature_view.search(\n",
    "        embedding_value = question_embedding,\n",
    "        neighbor_count = n_matches,\n",
    "        return_full_entity = True\n",
    "    )\n",
    "    matches = []\n",
    "    for result in results.to_dict()['neighbors']:\n",
    "        for feature in result['entity_key_values']['key_values']['features']:\n",
    "            if feature['name'] == 'content':\n",
    "                matches.append(dict(\n",
    "                    chunk_id = result['entity_id'],\n",
    "                    content = feature['value']['string_value']\n",
    "                ))\n",
    "    \n",
    "    return matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b86d38d-b771-4790-94d4-77a6dda1ff28",
   "metadata": {},
   "source": [
    "### Augment Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "130f9878-afd2-456c-be8c-4202b9ee608c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def augment(matches):\n",
    "\n",
    "    prompt = ''\n",
    "    for m, match in enumerate(matches):\n",
    "        prompt += f\"Context {m+1}:\\n{match['content']}\\n\\n\"\n",
    "    prompt += f'Answer the following question using the provided contexts:\\n'\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730fdcc4-9f26-4a59-9f9c-f6d54bde8954",
   "metadata": {},
   "source": [
    "### Generate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "04c99c53-80d0-4eeb-a63d-5aa64e56fd01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate(prompt):\n",
    "\n",
    "    result = llm.generate_content(prompt)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca30788a-6518-4e2d-8ce2-3630dbb23182",
   "metadata": {},
   "source": [
    "### RAG Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8aa4673f-3d81-4d94-9f32-898c1aee02d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    \n",
    "    query_embedding = embedder.get_embeddings([query])[0].values\n",
    "    matches = retrieve_featurestore(query_embedding)\n",
    "    prompt = augment(matches) + query\n",
    "    result = generate(prompt)\n",
    "    \n",
    "    return result.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d6fb02-f6f2-4029-83d5-561cc47406f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Example In Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "31feda38-b22a-44ce-8694-3e24c96b0d06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Does a lender have to perform servicing functions directly?'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e2c3734d-1c90-433a-9876-76c589e0ad4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.  A lender may use other organizations to perform some or all of its servicing functions through a \"subservicing\" arrangement (Context 1).  However, the lender remains ultimately responsible, even if they use a subservicer (Context 4).  The specifics of these arrangements, including notice requirements to borrowers, are detailed in the provided texts.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(rag(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e3a168-3b86-4a14-b4e2-b2f6dea8ba85",
   "metadata": {},
   "source": [
    "---\n",
    "### Profiling Performance\n",
    "\n",
    "Profile the timing of each step in the RAG function for sequential calls. The environment choosen for this workflow is a minimal testing enviornment so load testing (simoultaneous requests) would not be helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8313ea84-8ed1-4757-bd80-4fdd81b8cfbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "profile = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "83b93f83-ae49-456a-a55a-5c98dd1311a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rag(query, profile = profile):\n",
    "    \n",
    "    timings = {}\n",
    "    start_time = time.time()\n",
    "    \n",
    "    \n",
    "    # 1. Get embeddings\n",
    "    embedding_start = time.time()\n",
    "    query_embedding = embedder.get_embeddings([query])[0].values\n",
    "    timings['embedding'] = time.time() - embedding_start\n",
    "\n",
    "    # 2. Retrieve from Bigtable\n",
    "    retrieval_start = time.time()\n",
    "    matches = retrieve_featurestore(query_embedding)\n",
    "    timings['retrieve_featurestore'] = time.time() - retrieval_start\n",
    "\n",
    "    # 3. Augment the prompt\n",
    "    augment_start = time.time()\n",
    "    prompt = augment(matches) + query\n",
    "    timings['augment'] = time.time() - augment_start\n",
    "\n",
    "    # 4. Generate text\n",
    "    generate_start = time.time()\n",
    "    result = generate(prompt)\n",
    "    timings['generate'] = time.time() - generate_start\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    timings['total'] = total_time\n",
    "    \n",
    "    profile.append(timings)\n",
    "    \n",
    "    return result.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "480efc2b-2ad8-4fd1-a330-1c6b1ebcc6cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No, a lender does not have to perform servicing functions directly.  Context 1 explicitly states that a lender \"may use other organizations to perform some or all of its servicing functions,\" referring to this as \"subservicing.\"  However, there are stipulations and requirements regarding these subservicing arrangements, as outlined in the provided texts.  The lender remains ultimately responsible, even when using a subservicer or master servicer.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(rag(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6bf60ccf-2fed-48cd-bd1d-707971e338b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'embedding': 0.1379692554473877,\n",
       "  'retrieve_featurestore': 0.18321871757507324,\n",
       "  'augment': 4.100799560546875e-05,\n",
       "  'generate': 0.8281786441802979,\n",
       "  'total': 1.1494147777557373}]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c06faf7d-0bdc-4747-b68c-058a1e8e8872",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    response = rag(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef2feb3-8bf5-4769-bc85-5a2ec8a7f0e3",
   "metadata": {},
   "source": [
    "### Report From Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "643efd60-fbe6-4630-9eea-6e57d713378d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_timings = {}\n",
    "for timings in profile:\n",
    "    for key, value in timings.items():\n",
    "        if key not in all_timings:\n",
    "            all_timings[key] = []\n",
    "        all_timings[key].append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "07648196-9281-4824-96f9-5b55b8224300",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for 'embedding':\n",
      "  Min: 0.0468 seconds\n",
      "  Max: 0.2955 seconds\n",
      "  Mean: 0.0589 seconds\n",
      "  Median: 0.0534 seconds\n",
      "  Std Dev: 0.0262 seconds\n",
      "  P95: 0.0751 seconds\n",
      "  P99: 0.1380 seconds\n",
      "\n",
      "Statistics for 'retrieve_featurestore':\n",
      "  Min: 0.0503 seconds\n",
      "  Max: 0.1832 seconds\n",
      "  Mean: 0.0810 seconds\n",
      "  Median: 0.0629 seconds\n",
      "  Std Dev: 0.0289 seconds\n",
      "  P95: 0.1226 seconds\n",
      "  P99: 0.1423 seconds\n",
      "\n",
      "Statistics for 'augment':\n",
      "  Min: 0.0000 seconds\n",
      "  Max: 0.0000 seconds\n",
      "  Mean: 0.0000 seconds\n",
      "  Median: 0.0000 seconds\n",
      "  Std Dev: 0.0000 seconds\n",
      "  P95: 0.0000 seconds\n",
      "  P99: 0.0000 seconds\n",
      "\n",
      "Statistics for 'generate':\n",
      "  Min: 0.5262 seconds\n",
      "  Max: 1.0575 seconds\n",
      "  Mean: 0.7240 seconds\n",
      "  Median: 0.6985 seconds\n",
      "  Std Dev: 0.1103 seconds\n",
      "  P95: 0.9799 seconds\n",
      "  P99: 1.0316 seconds\n",
      "\n",
      "Statistics for 'total':\n",
      "  Min: 0.6308 seconds\n",
      "  Max: 1.2209 seconds\n",
      "  Mean: 0.8639 seconds\n",
      "  Median: 0.8283 seconds\n",
      "  Std Dev: 0.1217 seconds\n",
      "  P95: 1.1393 seconds\n",
      "  P99: 1.2022 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, values in all_timings.items():\n",
    "    arr = np.array(values)\n",
    "    print(f\"Statistics for '{key}':\")\n",
    "    print(f\"  Min: {np.min(arr):.4f} seconds\")\n",
    "    print(f\"  Max: {np.max(arr):.4f} seconds\")\n",
    "    print(f\"  Mean: {np.mean(arr):.4f} seconds\")\n",
    "    print(f\"  Median: {np.median(arr):.4f} seconds\")\n",
    "    print(f\"  Std Dev: {np.std(arr):.4f} seconds\")\n",
    "    print(f\"  P95: {np.percentile(arr, 95):.4f} seconds\")\n",
    "    print(f\"  P99: {np.percentile(arr, 99):.4f} seconds\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599a7244-b746-4c83-ad50-1496ef55ef37",
   "metadata": {},
   "source": [
    "---\n",
    "## Remove Resources\n",
    "\n",
    "The resources created above in BigQuery and Feature Store will persist unless deleted.  The Feature Store service does have ongoing costs even if not used so it might be desirable to remove it here.  Uncomment lines in the following cell to remove resources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bf52b3-c7f0-41b0-ba4f-e28608910a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#online_store.delete(force = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f41dde8-ed2e-47f3-9ccc-32a65ab7c8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bq.delete_table(bq_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dc0cfe-a18b-4ae3-b1f9-19b3ee1e28a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
