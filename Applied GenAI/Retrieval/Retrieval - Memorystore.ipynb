{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e89180c9",
   "metadata": {},
   "source": [
    "![tracker](https://us-central1-vertex-ai-mlops-369716.cloudfunctions.net/pixel-tracking?path=statmike%2Fvertex-ai-mlops%2FApplied+GenAI%2FRetrieval&file=Retrieval+-+Memorystore.ipynb)\n",
    "<!--- header table --->\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/statmike/vertex-ai-mlops/blob/main/Applied%20GenAI/Retrieval/Retrieval%20-%20Memorystore.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\">\n",
    "      <br>Run in<br>Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https%3A%2F%2Fraw.githubusercontent.com%2Fstatmike%2Fvertex-ai-mlops%2Fmain%2FApplied%2520GenAI%2FRetrieval%2FRetrieval%2520-%2520Memorystore.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\">\n",
    "      <br>Run in<br>Colab Enterprise\n",
    "    </a>\n",
    "  </td>      \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/statmike/vertex-ai-mlops/blob/main/Applied%20GenAI/Retrieval/Retrieval%20-%20Memorystore.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      <br>View on<br>GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/statmike/vertex-ai-mlops/main/Applied%20GenAI/Retrieval/Retrieval%20-%20Memorystore.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      <br>Open in<br>Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b0e8e6-d761-4540-9d09-8f0c4ce9a020",
   "metadata": {},
   "source": [
    "# Retrieval - Memorystore (Redis)\n",
    "\n",
    "In prior workflows, a series of documents was [processed into chunks](../Chunking/readme.md), and for each chunk, [embeddings](../Embeddings/readme.md) were created:\n",
    "\n",
    "- Process: [Large Document Processing - Document AI Layout Parser](../Chunking/Large%20Document%20Processing%20-%20Document%20AI%20Layout%20Parser.ipynb)\n",
    "- Embed: [Vertex AI Text Embeddings API](../Embeddings/Vertex%20AI%20Text%20Embeddings%20API.ipynb)\n",
    "\n",
    "Retrieving chunks for a query involves calculating the embedding for the query and then using similarity metrics to find relevant chunks. A thorough review of similarity matching can be found in [The Math of Similarity](../Embeddings/The%20Math%20of%20Similarity.ipynb) - use dot product! As development moves from experiment to application, the process of storing and computing similarity is migrated to a [retrieval](./readme.md) system. This workflow is part of a [series of workflows exploring many retrieval systems](./readme.md).  \n",
    "\n",
    "A detailed [comparison of many retrieval systems](./readme.md#comparison-of-vector-database-solutions) can be found in the readme as well.\n",
    "\n",
    "---\n",
    "\n",
    "**Memorystore For Storage, Indexing, And Search**\n",
    "\n",
    "[Google Cloud Memorystore](https://cloud.google.com/memorystore) is a fully managed in-memory data store service that can be used to enhance the performance of applications by caching frequently accessed data. Memorystore offers several in-memory database options, including [Redis](https://cloud.google.com/memorystore/docs/redis), [Redis Cluster](https://cloud.google.com/memorystore/docs/cluster), [Memcached](https://cloud.google.com/memorystore/docs/memcached), and [Valkey](https://cloud.google.com/memorystore/docs/valkey/). Each option provides unique features and capabilities to suit different needs.\n",
    "\n",
    "This example uses [Redis](https://redis.io/docs/latest/), which is an open-source, in-memory data store that can be used as a database, cache, message broker, and streaming engine. In Redis, data is stored as key-value pairs. The key serves as an identifier to request or retrieve specific data. Redis offers a [variety of data types](https://redis.io/docs/latest/develop/data-types/) for values, including strings, lists, sets, hashes, and sorted sets. These data types provide flexibility in how you structure and organize your data. In addition to basic retrieval using keys, Redis offers querying capabilities across data elements, [including vector search](https://cloud.google.com/memorystore/docs/redis/about-vector-search) for efficient similarity matching.\n",
    "\n",
    "---\n",
    "\n",
    "**Use Case Data**\n",
    "\n",
    "Buying a home usually involves borrowing money from a lending institution, typically through a mortgage secured by the home's value. But how do these institutions manage the risks associated with such large loans, and how are lending standards established?\n",
    "\n",
    "In the United States, two government-sponsored enterprises (GSEs) play a vital role in the housing market:\n",
    "\n",
    "- Federal National Mortgage Association ([Fannie Mae](https://www.fanniemae.com/))\n",
    "- Federal Home Loan Mortgage Corporation ([Freddie Mac](https://www.freddiemac.com/))\n",
    "\n",
    "These GSEs purchase mortgages from lenders, enabling those lenders to offer more loans. This process also allows Fannie Mae and Freddie Mac to set standards for mortgages, ensuring they are responsible and borrowers are more likely to repay them. This system makes homeownership more affordable and stabilizes the housing market by maintaining a steady flow of liquidity for lenders and keeping interest rates controlled.\n",
    "\n",
    "However, navigating the complexities of these GSEs and their extensive servicing guides can be challenging.\n",
    "\n",
    "**Approaches**\n",
    "\n",
    "[This series](../readme.md) covers many generative AI workflows. These documents are used directly as long context for Gemini in the workflow [Long Context Retrieval With The Vertex AI Gemini API](../Generate/Long%20Context%20Retrieval%20With%20The%20Vertex%20AI%20Gemini%20API.ipynb). The workflow below uses a [retrieval](./readme.md) approach with the already generated chunks and embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be889472-69b0-416c-9cf1-edc9706fa5c5",
   "metadata": {
    "id": "od_UkDpvRmgD"
   },
   "source": [
    "---\n",
    "## Colab Setup\n",
    "\n",
    "When running this notebook in [Colab](https://colab.google/) or [Colab Enterprise](https://cloud.google.com/colab/docs/introduction), this section will authenticate to GCP (follow prompts in the popup) and set the current project for the session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21f75ba8-df50-466e-a5ec-f2a6dd88eb26",
   "metadata": {
    "executionInfo": {
     "elapsed": 195,
     "status": "ok",
     "timestamp": 1683726184843,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "8UO9FnqyKBlF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'statmike-mlops-349915' # replace with project ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c325515-1ea0-45cc-82d3-a1bfb1c52155",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68869,
     "status": "ok",
     "timestamp": 1683726253709,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "N98-KK7LRkjm",
    "outputId": "09ec5008-0def-4e1a-c349-c598ee752f78",
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    !gcloud config set project {PROJECT_ID}\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055a4bd7-7b47-43ef-ba14-636c955e44e3",
   "metadata": {},
   "source": [
    "---\n",
    "## Installs and API Enablement\n",
    "\n",
    "The clients packages may need installing in this environment. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410502ee-6fe3-4624-a69a-960ad7105f10",
   "metadata": {},
   "source": [
    "### Installs (If Needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4dbdb83-3170-430c-b60d-3d686222a168",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tuples of (import name, install name, min_version)\n",
    "packages = [\n",
    "    ('google.cloud.aiplatform', 'google-cloud-aiplatform', '1.69.0'),\n",
    "    ('google.cloud.redis', 'google-cloud-redis'),\n",
    "    ('redis', 'redis', '5.0.8')\n",
    "]\n",
    "\n",
    "import importlib\n",
    "install = False\n",
    "for package in packages:\n",
    "    if not importlib.util.find_spec(package[0]):\n",
    "        print(f'installing package {package[1]}')\n",
    "        install = True\n",
    "        !pip install {package[1]} -U -q --user\n",
    "    elif len(package) == 3:\n",
    "        if importlib.metadata.version(package[0]) < package[2]:\n",
    "            print(f'updating package {package[1]}')\n",
    "            install = True\n",
    "            !pip install {package[1]} -U -q --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25374857-7d37-4c84-8cbb-a3c2fc7bb065",
   "metadata": {},
   "source": [
    "### API Enablement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b7300a8-7e3a-4a08-95c0-91186237753f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gcloud services enable aiplatform.googleapis.com\n",
    "!gcloud services enable redis.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157d09ba-9774-495f-8ced-3382bf75be8f",
   "metadata": {},
   "source": [
    "### Restart Kernel (If Installs Occured)\n",
    "\n",
    "After a kernel restart the code submission can start with the next cell after this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9864153-66c8-43e1-ae96-1179632ccf7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if install:\n",
    "    import IPython\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)\n",
    "    IPython.display.display(IPython.display.Markdown(\"\"\"<div class=\\\"alert alert-block alert-warning\\\">\n",
    "        <b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. The previous cells do not need to be run again⚠️</b>\n",
    "        </div>\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a1ab41-cb32-4398-86dc-d30effb88a36",
   "metadata": {
    "id": "appt8-yVRtJ1"
   },
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cebe11b-9ca1-4f3e-aa78-78640ff01ec8",
   "metadata": {
    "id": "63mx2EozRxFP"
   },
   "source": [
    "Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab2239cd-40ab-416d-bac0-0c6953d911b6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 2124,
     "status": "ok",
     "timestamp": 1683726390544,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "xzcoXjM5Rky5",
    "outputId": "b3bdcbc1-70d5-472e-aea2-42c74a42efde",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'statmike-mlops-349915'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8aa97f05-66e9-4276-b2e6-83b5a91ca50c",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1683726390712,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "IxWrFtqYMfku",
    "tags": []
   },
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "SERIES = 'applied-genai'\n",
    "EXPERIMENT = 'retrieval-memorystore-redis'\n",
    "\n",
    "# Redis names\n",
    "REDIS_INSTANCE_NAME = EXPERIMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bbf65b-5d29-4a72-84ae-d977b9a743a6",
   "metadata": {
    "id": "LuajVwCiO6Yg"
   },
   "source": [
    "Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "559f6e60-a594-4789-893b-295a8381b670",
   "metadata": {
    "executionInfo": {
     "elapsed": 17761,
     "status": "ok",
     "timestamp": 1683726409304,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "LVC7zzSLRk2C",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, json, time, glob, datetime, tempfile\n",
    "\n",
    "import numpy as np\n",
    "import redis\n",
    "\n",
    "# Vertex AI\n",
    "from google.cloud import aiplatform\n",
    "import vertexai.language_models # for embeddings API\n",
    "import vertexai.generative_models # for Gemini Models\n",
    "from vertexai.resources.preview import feature_store\n",
    "\n",
    "# memorystore\n",
    "from google.cloud import redis_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3fef31f-928f-45f2-a3f4-292ee242232c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.71.0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aiplatform.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5758c07e-f064-40fb-a0ef-de6cbde5cd0a",
   "metadata": {
    "id": "EyAVFG9TO9H-"
   },
   "source": [
    "Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b72f3bb-176b-4678-ba6b-df9b2de14997",
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1683726409306,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "L0RPE13LOZce",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vertex ai clients\n",
    "vertexai.init(project = PROJECT_ID, location = REGION)\n",
    "\n",
    "# memorystore clients\n",
    "redis_client = redis_v1.CloudRedisClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8579282f-2723-4294-b72a-a65cc0831f44",
   "metadata": {},
   "source": [
    "---\n",
    "## Text & Embeddings For Examples\n",
    "\n",
    "This repository contains a [section for document processing (chunking)](../Chunking/readme.md) that includes an example of processing mulitple large pdfs (over 1000 pages) into chunks: [Large Document Processing - Document AI Layout Parser](../Chunking/Large%20Document%20Processing%20-%20Document%20AI%20Layout%20Parser.ipynb).  The chunks of text from that workflow are stored with this repository and loaded by another companion workflow that augments the chunks with text embeddings: [Vertex AI Text Embeddings API](../Embeddings/Vertex%20AI%20Text%20Embeddings%20API.ipynb).\n",
    "\n",
    "The following code will load the version of the chunks that includes text embeddings and prepare it for a local example of retrival augmented generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e12cbe2-3ca6-4656-9e73-c0db5c63bf50",
   "metadata": {},
   "source": [
    "### Get The Documents\n",
    "\n",
    "If you are working from a clone of this notebooks [repository](https://github.com/statmike/vertex-ai-mlops) then the documents are already present. The following cell checks for the documents folder and if it is missing gets it (`git clone`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f4e77ed-43f7-42be-9575-6a491c0d6cba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "local_dir = '../Embeddings/files/embeddings-api'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63ebe7c3-e72c-4394-91c3-d60c05bc0ce2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents Found in folder `../Embeddings/files/embeddings-api`\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(local_dir):\n",
    "    print('Retrieving documents...')\n",
    "    parent_dir = os.path.dirname(local_dir)\n",
    "    temp_dir = os.path.join(parent_dir, 'temp')\n",
    "    if not os.path.exists(temp_dir):\n",
    "        os.makedirs(temp_dir)\n",
    "    !git clone https://www.github.com/statmike/vertex-ai-mlops {temp_dir}/vertex-ai-mlops\n",
    "    shutil.copytree(f'{temp_dir}/vertex-ai-mlops/Applied GenAI/Embeddings/files/embeddings-api', local_dir)\n",
    "    shutil.rmtree(temp_dir)\n",
    "    print(f'Documents are now in folder `{local_dir}`')\n",
    "else:\n",
    "    print(f'Documents Found in folder `{local_dir}`')             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e68a84-9f88-4590-9ff1-e01c8a953ccf",
   "metadata": {},
   "source": [
    "### Load The Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58d04382-a74a-44ac-8824-3b46c86aa148",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0000.jsonl',\n",
       " '../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0001.jsonl',\n",
       " '../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0002.jsonl',\n",
       " '../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0003.jsonl',\n",
       " '../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0004.jsonl',\n",
       " '../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0005.jsonl',\n",
       " '../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0006.jsonl',\n",
       " '../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0007.jsonl',\n",
       " '../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0008.jsonl',\n",
       " '../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0009.jsonl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonl_files = glob.glob(f\"{local_dir}/large-files*.jsonl\")\n",
    "jsonl_files.sort()\n",
    "jsonl_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a54c6c96-6c28-49bb-80be-5d46797dfe77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9040"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = []\n",
    "for file in jsonl_files:\n",
    "    with open(file, 'r') as f:\n",
    "        chunks.extend([json.loads(line) for line in f])\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70115ec-6d60-41df-b7e6-9e2e5b463b1d",
   "metadata": {},
   "source": [
    "### Review A Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc20423e-e3d6-4e90-9e98-a5248508c82d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['instance', 'predictions', 'status'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1955ea39-4ffc-4d30-b653-a5a9911f2dab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fannie_part_0_c17'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0]['instance']['chunk_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3537982c-4a0e-456c-a652-19ea7507873b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Selling Guide Fannie Mae Single Family\n",
      "\n",
      "## Fannie Mae Copyright Notice\n",
      "\n",
      "### Fannie Mae Copyright Notice\n",
      "\n",
      "|-|\n",
      "| Section B3-4.2, Verification of Depository Assets 402 |\n",
      "| B3-4.2-01, Verification of Deposits and Assets (05/04/2022) 403 |\n",
      "| B3-4.2-02, Depository Accounts (12/14/2022) 405 |\n",
      "| B3-4.2-03, Individual Development Accounts (02/06/2019) 408 |\n",
      "| B3-4.2-04, Pooled Savings (Community Savings Funds) (04/01/2009) 411 |\n",
      "| B3-4.2-05, Foreign Assets (05/04/2022) 411 |\n",
      "| Section B3-4.3, Verification of Non-Depository Assets 412 |\n",
      "| B3-4.3-01, Stocks, Stock Options, Bonds, and Mutual Funds (06/30/2015) 412 |\n",
      "| B3-4.3-02, Trust Accounts (04/01/2009) 413 |\n",
      "| B3-4.3-03, Retirement Accounts (06/30/2015) 414 |\n",
      "| B3-4.3-04, Personal Gifts (09/06/2023) 415 |\n",
      "| B3-4.3-05, Gifts of Equity (10/07/2020) 418 |\n",
      "| B3-4.3-06, Grants and Lender Contributions (12/14/2022) 419 |\n",
      "| B3-4.3-07, Disaster Relief Grants or Loans (04/01/2009) 423 |\n",
      "| B3-4.3-08, Employer Assistance (09/29/2015) 423 |\n",
      "| B3-4.3-09, Earnest Money Deposit (05/04/2022) 425 |\n",
      "| B3-4.3-10, Anticipated Sales Proceeds (02/23/2016) B3-4.3-11, Trade Equity (12/16/2020) 426 428 |\n",
      "| B3-4.3-12, Rent-Related Credits (08/07/2024) 429 |\n",
      "| B3-4.3-13, Sweat Equity (04/15/2014) 430 |\n",
      "| B3-4.3-14, Bridge/Swing Loans (04/01/2009) 431 |\n",
      "| B3-4.3-15, Borrowed Funds Secured by an Asset (10/30/2009) 431 |\n",
      "|  |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(chunks[0]['instance']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49f06293-a439-436b-bc93-cd6cd3fb4aff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.031277116388082504,\n",
       " 0.03056905046105385,\n",
       " 0.010865348391234875,\n",
       " 0.0623614676296711,\n",
       " 0.03228681534528732,\n",
       " 0.05066155269742012,\n",
       " 0.046544693410396576,\n",
       " 0.05509665608406067,\n",
       " -0.014074751175940037,\n",
       " 0.008380400016903877]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0]['predictions'][0]['embeddings']['values'][0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f977358d-d9ea-4172-9eca-66079bb6087d",
   "metadata": {},
   "source": [
    "### Prepare Chunk Structure\n",
    "\n",
    "Make a list of dictionaries with information for each chunk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be9fa708-130c-4343-b179-dbde0b09a972",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "content_chunks = [\n",
    "    dict(\n",
    "        gse = chunk['instance']['gse'],\n",
    "        chunk_id = chunk['instance']['chunk_id'],\n",
    "        content = chunk['instance']['content'],\n",
    "        embedding = chunk['predictions'][0]['embeddings']['values']\n",
    "    ) for chunk in chunks\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6619605-7b10-444e-a131-db06e56a4be8",
   "metadata": {},
   "source": [
    "### Query Embedding\n",
    "\n",
    "Create a query, or prompt, and get the embedding for it:\n",
    "\n",
    "Connect to models for text embeddings. Learn more about the model API:\n",
    "- [Vertex AI Text Embeddings API](../Embeddings/Vertex%20AI%20Text%20Embeddings%20API.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3da5d30c-3dfb-42ba-a133-83dceb252787",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question = \"Does a lender have to perform servicing functions directly?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7992c26f-d058-4920-80a3-a157b88733e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedder = vertexai.language_models.TextEmbeddingModel.from_pretrained('text-embedding-004')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbe6fda7-9cea-49a2-9e2f-9222d50677af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.0005117303808219731,\n",
       " 0.009651427157223225,\n",
       " 0.01768726110458374,\n",
       " 0.014538003131747246,\n",
       " -0.01829824410378933,\n",
       " 0.027877431362867355,\n",
       " -0.021124685183167458,\n",
       " 0.008830446749925613,\n",
       " -0.02669006586074829,\n",
       " 0.06414774805307388]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_embedding = embedder.get_embeddings([question])[0].values\n",
    "question_embedding[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6ec209-b34a-4837-8c54-a991ad831764",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup Memorystore (Redis)\n",
    "\n",
    "**Memorystore - Choosing and engine**\n",
    "\n",
    "Memorystore offers multiple caching engines as a service: [Valkey](https://cloud.google.com/memorystore/docs/valkey/), [Redis](https://cloud.google.com/memorystore/docs/redis), [Redis Cluster](https://cloud.google.com/memorystore/docs/cluster), and [Memcached](https://cloud.google.com/memorystore/docs/memcached). Redis is offered as a single instance or a clustered instance where the instance is a series of shards that contains subsets of the cached data.\n",
    "\n",
    "This workflow will use a single instance of [Redis](https://cloud.google.com/memorystore/docs/redis) because it [supports vector search](https://cloud.google.com/memorystore/docs/redis/about-vector-search).\n",
    "\n",
    "**Memorystore data structure**\n",
    "\n",
    "Memorystore, Redis in this case, is a key-value pair database.  In this case think of the key as the value that would be used to requests or retrieve data with, like a primary key in a database, or an entity id.  And data is actually a flexible, multi-parameter, object with multiple [possible data types](https://redis.io/docs/latest/develop/data-types/).  Beyond retriving data based on the key there are also querying capabilties across the data elements, including vector search across elements stored as embedding.\n",
    "\n",
    "**Memorystore and Redis Data Types**\n",
    "\n",
    "Redis has a concept called [modules](https://redis.io/docs/latest/develop/reference/modules/) which can extend the functionality of Redis. For instance, the [JSON data type module extension](https://redis.io/docs/latest/develop/data-types/json/) allows for storing values as JSON data.  Many examples found on the web for using this vector search capability  in Redis use it with the JSON module, like [this one](https://redis.io/docs/latest/develop/get-started/vector-database/).  In the [supported functionality](https://cloud.google.com/memorystore/docs/redis/supported-versions) for Memorystore Redis **modules are not supported**.  For this reason, the native [HASH data type](https://redis.io/docs/latest/develop/data-types/#hashes) is best to use for vector search feature.  While a Python dictionary is comparable to [a HASH](https://redis.io/docs/latest/develop/data-types/hashes/) it requires coverting vector embeddings to a [serialized form as bytes](https://cloud.google.com/memorystore/docs/redis/indexing-vectors) rather than an array of floats.\n",
    "\n",
    "**Notes on Redis And The HASH Data Type**\n",
    "\n",
    "[Redis Hashes](https://redis.io/docs/latest/develop/data-types/hashes/) are a native data type.  There is not a practical limit to the number of field that can be present in a value field other than available memory.  Redis has multiple databases and each connnection defaults to the database indexed 0.  Making use of more than one database is and advantaced topic - [read more here](https://redis.io/docs/latest/commands/select/).  With a database data is stored by key.  There is a practice of using prefixes within key values that is commonly referred to as a namespace. Redis offers TTL or expiration features for [keys](https://redis.io/docs/latest/develop/use/keyspace/#key-expiration) and individual [field expriation](https://redis.io/docs/latest/develop/data-types/hashes/#field-expiration). \n",
    "\n",
    "**Vector Search With Redis**\n",
    "\n",
    "Google Cloud Memorystore Redis support these [versions of Redis](https://cloud.google.com/memorystore/docs/redis/supported-versions).  This [includes version 7.2](https://cloud.google.com/memorystore/docs/redis/supported-versions#redis_version_72) which is the first to offer built-in vector search functionality.\n",
    "\n",
    "**Understanding Memorystore Costs**\n",
    "\n",
    "[Pricing for Memorystore for Redis](https://cloud.google.com/memorystore/docs/redis/pricing) is straightforward and based on these parameters that are part of the instance creation:\n",
    "- **Service Tier**: [read more about service tiers](https://cloud.google.com/memorystore/docs/redis/redis-tiers)\n",
    "    - Basic - a simple Redis cache with a standalone instance (**Used in this workflow.**)\n",
    "    - Standard - A high availability instance with cross-zone replication and automatic failover\n",
    "- **Provisioned capacity**: \n",
    "    - Size in GB priced in $ per GB per hour. Capacity tiers make additional capacity progressively cheaper. (**The Minimum of 1 GB is used in this workflow.**)\n",
    "- **Region**: \n",
    "    - Pricing varies by the region choosen for the instance.\n",
    "- **Replicas**: \n",
    "    - For the Standard Service Tier you have the option to enable read replicas for distributed reads."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011332b0-52a5-4d3b-a211-00e6d82feaae",
   "metadata": {},
   "source": [
    "### Create/Retrieve An Instance\n",
    "\n",
    "The startying point for using Redis on Memorystore is an instance.  This is where the engine (Redis), tier, memory limits, and version are all selected and launched.\n",
    "\n",
    "Documentation References:\n",
    "- [Create and managed Redis instances](https://cloud.google.com/memorystore/docs/redis/create-manage-instances)\n",
    "- [Redis tier capabilities](https://cloud.google.com/memorystore/docs/redis/redis-tiers)\n",
    "- [Pythond SDK for Memorystore Redis Admin](https://cloud.google.com/python/docs/reference/redis/latest/google.cloud.redis_v1.services.cloud_redis.CloudRedisClient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28fd8700-78cc-4ccb-be99-040f1f19e3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Redis instance: projects/statmike-mlops-349915/locations/us-central1/instances/retrieval-memorystore-redis\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    redis_instance = redis_client.get_instance(\n",
    "        name = f\"projects/{PROJECT_ID}/locations/{REGION}/instances/{REDIS_INSTANCE_NAME}\"\n",
    "    )\n",
    "    print(f\"Retrieved Redis instance: {redis_instance.name}\")\n",
    "except Exception:\n",
    "    print(f\"Creating Redis instance ...\")\n",
    "    create_instance = redis_client.create_instance(\n",
    "        parent = f\"projects/{PROJECT_ID}/locations/{REGION}\",\n",
    "        instance_id = REDIS_INSTANCE_NAME,\n",
    "        instance = redis_v1.Instance(\n",
    "            name = f\"projects/{PROJECT_ID}/locations/{REGION}/instances/{REDIS_INSTANCE_NAME}\",\n",
    "            tier = redis_v1.Instance.Tier.BASIC,\n",
    "            memory_size_gb = 1,\n",
    "            redis_version = 'REDIS_7_2',\n",
    "            transit_encryption_mode=redis_v1.Instance.TransitEncryptionMode.SERVER_AUTHENTICATION  # Enable TLS\n",
    "        )\n",
    "    )\n",
    "    response = create_instance.result()\n",
    "    redis_instance = redis_client.get_instance(\n",
    "        name = f\"projects/{PROJECT_ID}/locations/{REGION}/instances/{REDIS_INSTANCE_NAME}\"\n",
    "    )\n",
    "    print(f\"Created Redis instance: {redis_instance.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6dcab470-b73d-4c37-ac76-97abf4d7bbab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/statmike-mlops-349915/locations/us-central1/instances/retrieval-memorystore-redis'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redis_instance.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3968fbd7-a732-4f2d-a17d-957027c955fb",
   "metadata": {},
   "source": [
    "---\n",
    "## Working With Memory Store Redis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcc856f-4557-4fd0-acdb-f72891cf2594",
   "metadata": {},
   "source": [
    "### Connect To Memorystore Redis Instance\n",
    "\n",
    "Connect to the Redis instance using the [redis-py](https://redis-py.readthedocs.io/en/stable/) Python package. The following code creates two clients using [redis.Redis()](https://redis-py.readthedocs.io/en/stable/connections.html#generic-client):\n",
    "- `decode_client` with `decode_responses = True`\n",
    "- `bytes_client` with `decode_responses = False`\n",
    "\n",
    "**Why two clients?**  We will be storing data in the [Redis Hashes](https://redis.io/docs/latest/develop/data-types/hashes/) data type which is like a Python dictionary. When using a Redis client to retrieve information its default form is bytes.  Adding the option `decode_responses = True` to the client setup will automatically decode responses.  In this workflow we are usinng vector embeddings which will need to be encoded as bytes prior to being sent to Redis.  This causes an issues on retrieval unless the client uses the default `decode_responses = Falses`.  For this reason two clients are setup.  The `bytes_client` is only needed when retrieving embedding values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5972975c-1637-4f56-ab58-a7965e8f7f98",
   "metadata": {},
   "source": [
    "Store the certificate for connecting to the the instance in a temp file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da76f3de-a1e3-4b9e-a9f7-53f0d57210a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tempfile.NamedTemporaryFile(delete=False) as cert_file:\n",
    "    cert_file.write(redis_instance.server_ca_certs[0].cert.encode())  # Write certificate content\n",
    "    cert_path = cert_file.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1d3dc9-c680-42a1-87be-c061545eb180",
   "metadata": {},
   "source": [
    "Create the `decode_client` that will decode responses from bytes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1571c6f5-da7f-4686-aafb-2be39c461af5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "decode_client = redis.Redis(\n",
    "    host = redis_instance.host,\n",
    "    port = redis_instance.port,\n",
    "    ssl = True,\n",
    "    ssl_ca_certs = cert_path,\n",
    "    decode_responses = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31eb4c99-f3c3-4e72-bd44-0638fcbf4025",
   "metadata": {},
   "source": [
    "Create the `bytes_client` that will not decode responses from bytes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "09306dd9-8e8f-4bca-a076-9c4d21e878c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bytes_client = redis.Redis(\n",
    "    host = redis_instance.host,\n",
    "    port = redis_instance.port,\n",
    "    ssl = True,\n",
    "    ssl_ca_certs = cert_path,\n",
    "    decode_responses = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf1a214-fc13-4b3a-85c0-78892a27c728",
   "metadata": {},
   "source": [
    "Test the connections with the `.ping()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ebbb366-b419-4dc8-83e9-705e4428752c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Redis successfully!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    decode_client.ping() and bytes_client.ping()\n",
    "    print(\"Connected to Redis successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error connecting to Redis: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee9bc18-4279-44a5-8ec9-699628b2a1e2",
   "metadata": {},
   "source": [
    "### Prepare Data For Redis\n",
    "\n",
    "There are multiple storage [data formats](https://redis.io/docs/latest/develop/data-types/) possible with Redis.  [Hashing](https://redis.io/docs/latest/develop/data-types/hashes/) is like a Python dictionary and offers many advantages, like the vector search capability that will be used here.  To use the hash data type the embeddings [need to be serialized as bytes before inserting](https://cloud.google.com/memorystore/docs/redis/indexing-vectors)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2598ea71-4387-49ba-814a-7cc1b700e416",
   "metadata": {},
   "source": [
    "#### Get A Record\n",
    "\n",
    "Dictionaries for each record/row are stored in `content_chunks` from earlier in this workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6e3e7558-4974-4ee7-8895-e26c864cef19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "first_record = content_chunks[0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "07816d44-6ac5-441d-a3a9-aae672deede3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['gse', 'chunk_id', 'content', 'embedding'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_record.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f8eae42a-fd7b-47ad-9e62-234671e2a991",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fannie_part_0_c17'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_record['chunk_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dee08b5-53c3-4b07-8fd4-2e49662c7eb7",
   "metadata": {},
   "source": [
    "#### Prepare The Record\n",
    "\n",
    "Use Numpy to convert the list of floats to an array and then to bytes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4026ccec-59e2-44c8-81d7-49c41d17a075",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "first_record['embedding'] = np.array(first_record['embedding']).astype('float32').tobytes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aba5ebce-b791-4498-8368-60a838c9f517",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(first_record['embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5c29255e-e99c-4ab9-9712-d58eea8fdf64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3072"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(first_record['embedding'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a72b632-b01f-4ba5-8e8b-9ab8785f6eb3",
   "metadata": {},
   "source": [
    "### Add, Retrive, And Delete Records To The Instance\n",
    "\n",
    "Learn about inserting, retrieving, and deleting records/rows with the following simple examples.\n",
    "\n",
    "This uses the client to execute [Hash Commands](https://redis.io/docs/latest/commands/?group=hash)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa2d4e4-307b-4f67-9ca6-6c4d8c488ae5",
   "metadata": {},
   "source": [
    "#### Insert Row\n",
    "\n",
    "Hash command [HSET](https://redis.io/docs/latest/commands/hset/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e6a36677-d8e5-47fc-b1d4-237282bcb0fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['gse', 'chunk_id', 'content', 'embedding'])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_record.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d2463d83-aa30-434c-92fd-76244fef318d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fannie_part_0_c17'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_record['chunk_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5aa7454c-2c13-4478-84e5-a9c417398d82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding the record to the database: fannie_part_0_c17\n"
     ]
    }
   ],
   "source": [
    "if decode_client.exists(first_record['chunk_id']):\n",
    "    print(f\"Found this record already in the database: {first_record['chunk_id']}\")\n",
    "else:\n",
    "    print(f\"Adding the record to the database: {first_record['chunk_id']}\")\n",
    "    decode_client.hset(first_record['chunk_id'], mapping = first_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e05208-c0c3-42d3-85ea-cccd358b5377",
   "metadata": {
    "tags": []
   },
   "source": [
    "Verify the record count after the insertion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "afab4a57-0e94-45f7-ad15-e270b57ffa24",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_client.dbsize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0365e6dd-9cef-451d-9b09-ef005350392a",
   "metadata": {},
   "source": [
    "#### Check For Values In The Row\n",
    "\n",
    "There are multiple helpful command to check rows:\n",
    "\n",
    "- Check for a specific value on a row by key: [HEXISTS](https://redis.io/docs/latest/commands/hexists/)\n",
    "- List all keys for a record: [HKEYS](https://redis.io/docs/latest/commands/hkeys/)\n",
    "- Get a count of keys for a record: [HLEN](https://redis.io/docs/latest/commands/hlen/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e468fda7-2ad2-46e2-8b2c-82c31821e138",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_client.hexists(first_record['chunk_id'], 'chunk_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ace2961c-3fa6-466b-96c9-638548d8eef8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_client.hlen(first_record['chunk_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c8c6d9bc-52c1-44f7-a292-72efd52ebf33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['embedding', 'chunk_id', 'content', 'gse']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_client.hkeys(first_record['chunk_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73be7342-5a3e-4295-aa19-6a7bdca7436a",
   "metadata": {},
   "source": [
    "#### Execute Commands Directly\n",
    "\n",
    "In this section the client are being used with native methods to interact with Redis.  It is also possible to use the `.execute_command()` method to directly execute commands.  This can be helpful as we will see later on in this workflow when creating and using vector indexes. \n",
    "\n",
    "Here is a comparison using the previous `hkeys` requests for all keys available for a specific record:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a6c27e93-5ed6-46b2-94ee-5c1492df8616",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['embedding', 'chunk_id', 'content', 'gse']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_client.hkeys(first_record['chunk_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5ca97940-8120-4a84-8f36-553057939069",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['embedding', 'chunk_id', 'content', 'gse']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_client.execute_command(f\"HKEYS {first_record['chunk_id']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd696af-a0c8-4c9d-847b-aa5bc5001565",
   "metadata": {},
   "source": [
    "#### Retrieve Values From Row\n",
    "\n",
    "There are multiple helpful ways to retrieve rows:\n",
    "- Get a single value from a row with [HGET](https://redis.io/docs/latest/commands/hget/)\n",
    "- Get multiple values from a row with [HMGET](https://redis.io/docs/latest/commands/hmget/)\n",
    "- Get all values from a row with [HGETALL](https://redis.io/docs/latest/commands/hgetall/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fa6f7e-2380-4119-80ce-52cfc77792ac",
   "metadata": {},
   "source": [
    "Retrieve the value of `gse` for the record key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b706da4a-8154-4ee0-b541-2f50c20e5f16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fannie'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_client.hget(first_record['chunk_id'], 'gse')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d030b8-73e6-4ce6-9ac2-44fb4303bdb8",
   "metadata": {},
   "source": [
    "Retrieve the value of `gse` for the record key using the bytes client:\n",
    "Note that the response is not decoded to a string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7df79924-a642-4ce7-ab08-4faf152a6fdd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'fannie'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bytes_client.hget(first_record['chunk_id'], 'gse')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b52d40d-6b92-42b3-a119-f2b2d90864c9",
   "metadata": {},
   "source": [
    "Retrieve the value of `content` for the record key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7e152d41-d1e2-420e-8713-9e57633c00d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Selling Guide Fannie Mae Single Family\\n\\n## Fannie Mae Copyright Notice\\n\\n### Fannie Mae Copyright Notice\\n\\n|-|\\n| Section B3-4.2, Verification of Depository Assets 402 |\\n| B3-4.2-01, Verification of Deposits and Assets (05/04/2022) 403 |\\n| B3-4.2-02, Depository Accounts (12/14/2022) 405 |\\n| B3-4.2-03, Individual Development Accounts (02/06/2019) 408 |\\n| B3-4.2-04, Pooled Savings (Community Savings Funds) (04/01/2009) 411 |\\n| B3-4.2-05, Foreign Assets (05/04/2022) 411 |\\n| Section B3-4.3, Verification of Non-Depository Assets 412 |\\n| B3-4.3-01, Stocks, Stock Options, Bonds, and Mutual Funds (06/30/2015) 412 |\\n| B3-4.3-02, Trust Accounts (04/01/2009) 413 |\\n| B3-4.3-03, Retirement Accounts (06/30/2015) 414 |\\n| B3-4.3-04, Personal Gifts (09/06/2023) 415 |\\n| B3-4.3-05, Gifts of Equity (10/07/2020) 418 |\\n| B3-4.3-06, Grants and Lender Contributions (12/14/2022) 419 |\\n| B3-4.3-07, Disaster Relief Grants or Loans (04/01/2009) 423 |\\n| B3-4.3-08, Employer Assistance (09/29/2015) 423 |\\n| B3-4.3-09, Earnest Money Deposit (05/04/2022) 425 |\\n| B3-4.3-10, Anticipated Sales Proceeds (02/23/2016) B3-4.3-11, Trade Equity (12/16/2020) 426 428 |\\n| B3-4.3-12, Rent-Related Credits (08/07/2024) 429 |\\n| B3-4.3-13, Sweat Equity (04/15/2014) 430 |\\n| B3-4.3-14, Bridge/Swing Loans (04/01/2009) 431 |\\n| B3-4.3-15, Borrowed Funds Secured by an Asset (10/30/2009) 431 |\\n|  |\\n\\n'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_client.hget(first_record['chunk_id'], 'content')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0040d220-8c17-4c7a-b9b2-1cf40d8864c6",
   "metadata": {},
   "source": [
    "Retrieve multiple values, `gse` and `chunk_id`, for the record key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "52dc1493-1111-41be-aa4c-2be6b881b370",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fannie', 'fannie_part_0_c17']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_client.hmget(first_record['chunk_id'], ['gse', 'chunk_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ed6475-2abe-474a-9fcb-2f9bc97fcd79",
   "metadata": {},
   "source": [
    "Retrieve all values using the record key.  Note that the embedding was converted to bytes prior to storage and need to be returned as bytes and decoded locally. This requires using the `bytes_client`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "867ad480-6627-4b00-8a89-f7acb0ce364a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = bytes_client.hgetall(first_record['chunk_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b7465d38-eee7-4949-80c3-d862fea4bcab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([b'embedding', b'chunk_id', b'content', b'gse'])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7003fbe6-528b-4690-9cfb-29e761366bb5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'fannie_part_0_c17'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[b'chunk_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122e35f7-937d-42b3-8b6d-bfe695b18c26",
   "metadata": {},
   "source": [
    "Retrieve the value of `embedding` using the `bytes_client` since it was converted to bytes prior to be stored:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2a5e86d6-afd0-43ba-a533-eb5022573a5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = bytes_client.hget(first_record['chunk_id'], 'embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ce631767-4ff8-421a-9932-12825a4ed3b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ba97ed69-e949-49e2-9a36-ef92dd51f996",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'o\\x1c\\x00=\\xf2k\\xfa<\\x93\\x042<\\xbdn\\x7f=.?\\x04='"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdc0b2c-bf66-4a39-a873-3e2f9f74415f",
   "metadata": {
    "tags": []
   },
   "source": [
    "Convert the `embedding` value back to a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "616ce15e-0811-4d3a-baa4-a39fc9ee6254",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.866788208941463e-15,\n",
       " 1.7867350394357162e-12,\n",
       " 2.238900525478732e-13,\n",
       " 5.023794965100525e-13,\n",
       " 1.7146986224190288e-19]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = np.frombuffer(result).astype('float32').tolist()\n",
    "result[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7609108e-bf6c-437f-bf85-f63620ca124b",
   "metadata": {},
   "source": [
    "#### Delete Row\n",
    "\n",
    "Delete the row added here.  Verify the action by counting the rows before and after the deletion.\n",
    "\n",
    "Hash Command [HDEL](https://redis.io/docs/latest/commands/hdel/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "43132829-7d82-4859-86b4-1f69e7908fc0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_client.dbsize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1bdd656a-7781-4bc4-95d6-7ccbb5c075cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_client.delete(first_record['chunk_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2491ed92-b551-404d-8f35-82621c1ee513",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_client.dbsize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38b9077-ac0f-4884-8b10-5522a7f008d3",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "\n",
    "In the single record example above a record was inserted using `HSET`.  Now all the records need to be inserted.  Redis has a usefull construct called [Redis pipelining](https://redis.io/docs/latest/develop/use/pipelining/) that allows for issuing mutiple commands all at once and note needing to wait for each individual command squentially which can drastically improve performance.  Check out [this example](https://redis-py.readthedocs.io/en/stable/examples/pipeline_examples.html).\n",
    "\n",
    "This section do 4 things:\n",
    "- Prepare the embedding value as bytes for all the records\n",
    "- Use a pipeline to check for presence of each value in the database\n",
    "- Use a pipeline to load all the records that were not found in the database\n",
    "- Verify the record count of the database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a63a11-8ee3-4a7f-9ba7-0df9eddfc54d",
   "metadata": {},
   "source": [
    "Get the starting record count of the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9fecd549-0c4f-482a-8033-3b4aada487b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_client.dbsize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9750cbc1-45fe-40c8-9506-ebab23f6c9b5",
   "metadata": {},
   "source": [
    "Prepare the embedding values as bytes for all records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "777d9d8a-35cf-4376-8da3-7d57f157482e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for chunk in content_chunks:\n",
    "    if type(chunk['embedding']) != bytes:\n",
    "        chunk['embedding'] = np.array(chunk['embedding']).astype('float32').tobytes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e14d896-62f4-49a0-8c8c-035e5f4f8567",
   "metadata": {},
   "source": [
    "Use a pipeline to check for the existance of each record in the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ccfacb9d-0189-428f-9e8b-e6e21248c6a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with decode_client.pipeline() as pipe:\n",
    "    for chunk in content_chunks:\n",
    "        pipe.exists(chunk['chunk_id'])\n",
    "    exists_results = pipe.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "43165e6a-6671-4c66-bde7-8a3ceeb4f6a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  records already in database\n"
     ]
    }
   ],
   "source": [
    "print(sum(exists_results), ' records already in database')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e3a0c9-f5e6-485d-b9d2-0057196938db",
   "metadata": {},
   "source": [
    "Use a pipeline to load all records that were not already in the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c4e57635-ca6a-438b-b8b4-052a740015bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with decode_client.pipeline() as pipe:\n",
    "    load_indexes = []\n",
    "    for i, (chunk, exists) in enumerate(zip(content_chunks, exists_results)):\n",
    "        if not exists:\n",
    "            load_indexes.append(i)\n",
    "            pipe.hset(chunk['chunk_id'], mapping=chunk)\n",
    "    load_results = pipe.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d376b172-205d-4414-b837-4f9dfae2ec56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All chunks(9040) loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# check for loading issues and give first failure id info for diagnostic\n",
    "if all(load_results):\n",
    "    print(f'All chunks({len(load_results)}) loaded successfully.')\n",
    "else:\n",
    "    print(f\"During loading {load_results.count(0)} records were not successfully loaded.\")\n",
    "    first_fail_index = load_indexes[load_results.index(0)]\n",
    "    print(f\"Start troubleshooting with the record at index {first_fail_index} which as has 'chunk_id' = {content_chunks[first_fail_index]['chunk_id']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4720282-2e81-4554-b650-32ddab741167",
   "metadata": {},
   "source": [
    "Verify the record count of the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cfddd4e2-72e1-4a25-950c-f8bd0ae9f5f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9040"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_client.dbsize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd33a8ea-8b7a-4424-9aed-85c16a68215c",
   "metadata": {},
   "source": [
    "---\n",
    "## Vector Similarity Search, Matching\n",
    "\n",
    "This section covers the operation of using a vector similarity metric calculation to find nearest neighbors for a query vector while also taking advantage of indexing.  To understand similarity metrics and motivate the intution for choosing one (choose dot product), check out [The Math of Similarity](../Embeddings/The%20Math%20of%20Similarity.ipynb).\n",
    "\n",
    "**Notes On [Vector Search](https://cloud.google.com/memorystore/docs/redis/about-vector-search) With Redis**\n",
    "\n",
    "The workflow below shows setting up indexes and using them for vector search.  Searching requires an index to be created. Multiple indexes can be created and the search parameters require specifying the desired index to search.  The distance measure is part of the index."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d499076-0b52-48f8-9b37-2739d801f4ac",
   "metadata": {},
   "source": [
    "### Check For Vector Indexes\n",
    "\n",
    "At this point in the workflow no vector indexes have been created.  The following cells show how to check for indexes and will be reused later in the workflow to verify the details of indexes after they are created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9de6563e-15bc-4034-aa09-6a3ef59458d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_client.execute_command(\n",
    "    'FT._LIST'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b729b1-c93e-4a85-b97c-1f3737998c28",
   "metadata": {},
   "source": [
    "### Create And Use An Index\n",
    "\n",
    "Indexes are the only way to search in Redis.  Usually indexes make search across many rows more efficient by first matching partitions or rows and then only comparing to rows within the selected partions.  This is still true with the HNSW partion type.  Brute force searches across all rows are also achieved through an index type of FLAT in Redis.  Since everything in Redis is in-memory, even these FLAT index searches across all rows are incredibly fast.\n",
    "\n",
    "Details for [creating indexes](https://cloud.google.com/memorystore/docs/redis/ftcreate) with `FT.CREATE`:\n",
    "- FLAT: Brute Force\n",
    "    - an index of all records with embeddings that match the `PREFIX`\n",
    "- HNSW: Hierarchical Navigable Small World\n",
    "    - create a multilayer graph\n",
    "    - faster queries across a smaller range or records retrieved using the graph\n",
    "\n",
    "The index is specified during the search making it possible to have multiple indexes.  In fact, to do pre-filtered queries it would require a separate index for each desired pre-filter condition.\n",
    "\n",
    "**Distance Metric Choices**\n",
    "- `DISTANCE_METRIC IP` for inner product or dot product\n",
    "- `DISTANCE_METRIC COSINE` for cosine similarity\n",
    "- `DISTANCE_METRIC L2` for Euclidean distance\n",
    "\n",
    "Documentation Links For This Section:\n",
    "- [Google Cloud Memorystore Documentation For Vector Search Command](https://cloud.google.com/memorystore/docs/redis/vector-commands)\n",
    "- [Redis Documentation For Vectors](https://redis.io/docs/latest/develop/interact/search-and-query/advanced-concepts/vectors/)\n",
    "- [Redis Documentation Examples for Vector Similarity](https://redis-py.readthedocs.io/en/stable/examples/search_vector_similarity_examples.htm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98595803-e9cf-48de-beea-04fea1563bbb",
   "metadata": {},
   "source": [
    "#### Define Functions For Search and Parsing Responses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d409a896-3ee3-4e24-be08-0e89df6cdc4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_matches(results, include_embed = False):\n",
    "    encoding = bytes_client.get_encoder().encoding\n",
    "    responses = []\n",
    "    for i in range(2, len(results), 2):\n",
    "        response = {}\n",
    "        for j in range(0, len(results[i]), 2):\n",
    "            key = results[i][j].decode(encoding)\n",
    "            value = results[i][j+1]\n",
    "            if key == 'embedding':\n",
    "                if include_embed:\n",
    "                    response[key] = np.frombuffer(value, dtype='float32').tolist()\n",
    "            elif key == 'distance':\n",
    "                response[key] = float(value.decode(encoding))\n",
    "            else:\n",
    "                response[key] = value.decode(encoding)\n",
    "        responses.append(response)\n",
    "    responses.reverse()    \n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "9ab0e989-985a-4cf5-af3e-b1c7741eb0ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def vector_search(index_name, query_embedding, n_matches = 5):\n",
    "\n",
    "    query_args = [\n",
    "        f\"FT.SEARCH {index_name}\",\n",
    "        f\"*=>[KNN {n_matches} @embedding $query_embedding AS distance]\",\n",
    "        \"PARAMS\",\n",
    "        2,\n",
    "        \"query_embedding\",\n",
    "        np.array(query_embedding).astype('float32').tobytes(),\n",
    "        \"DIALECT\",\n",
    "        2,\n",
    "    ]\n",
    "\n",
    "    return bytes_client.execute_command(*query_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe3c5a6-a9ce-4276-8319-edd118e6de46",
   "metadata": {},
   "source": [
    "#### Index: Flat (Brute Force)\n",
    "\n",
    "**References**\n",
    "- [Redis: FLAT Index](https://redis.io/docs/latest/develop/interact/search-and-query/advanced-concepts/vectors/#flat-index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a7daf8-ea58-441f-bf89-97858648f88d",
   "metadata": {},
   "source": [
    "Create the index:\n",
    "\n",
    "This index is a `FLAT` index with three options used (`TYPE`, `DIM`, `DISTANCE_METRIC`) so the attributed count is 3*2 = 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "ef2cd9d0-9c2f-4062-8edf-8b6cf4da25a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This index already exists: flat-index\n"
     ]
    }
   ],
   "source": [
    "INDEX_NAME = 'flat-index'\n",
    "\n",
    "try:\n",
    "    check_index = decode_client.ft(INDEX_NAME).info()\n",
    "    print(f\"This index already exists: {check_index['index_name']}\")\n",
    "except Exception:\n",
    "    print(f'Create the index ...')\n",
    "\n",
    "    command = (\n",
    "        f\"FT.CREATE {INDEX_NAME} ON HASH \"\n",
    "        f\"SCHEMA embedding VECTOR FLAT 6 \"\n",
    "        f\"TYPE FLOAT32 \"\n",
    "        f\"DIM {len(question_embedding)} \"\n",
    "        f\"DISTANCE_METRIC IP\"\n",
    "    )\n",
    "\n",
    "    decode_client.execute_command(command)\n",
    "    \n",
    "    print(f'Checking for index backfill ...')\n",
    "    while True:\n",
    "        check_index = decode_client.ft(INDEX_NAME).info()\n",
    "        if check_index['backfill_in_progress'] == '1':\n",
    "            complete_pct = 100*float(check_index['backfill_complete_percent'])\n",
    "            print(f\"Backfill still in progress with {complete_pct:.2f} percent complete ...\")\n",
    "            time.sleep(1)\n",
    "        else:\n",
    "            print(f\"Backfill complete.\")\n",
    "            print(f\"Index created and covers {check_index['num_docs']} records\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0454aa9f-53cc-4bac-8c8c-a190e244b181",
   "metadata": {},
   "source": [
    "Review the index details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "5227e5d6-35ba-4c09-ac5b-c1ca251668d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['flat-index']"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_client.execute_command('FT._LIST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "585e948b-b53e-4980-ac94-8bd638c40518",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index_name': 'flat-index',\n",
       " 'index_options': [],\n",
       " 'index_definition': ['key_type',\n",
       "  'HASH',\n",
       "  'prefixes',\n",
       "  [''],\n",
       "  'default_score',\n",
       "  '1'],\n",
       " 'attributes': [['identifier',\n",
       "   'embedding',\n",
       "   'attribute',\n",
       "   'embedding',\n",
       "   'type',\n",
       "   'VECTOR',\n",
       "   'index',\n",
       "   ['capacity',\n",
       "    10240,\n",
       "    'dimensions',\n",
       "    768,\n",
       "    'distance_metric',\n",
       "    'IP',\n",
       "    'data_type',\n",
       "    'FLOAT32',\n",
       "    'algorithm',\n",
       "    ['name', 'FLAT', 'block_size', 1024]]]],\n",
       " 'num_docs': '9040',\n",
       " 'num_terms': '0',\n",
       " 'num_records': '9040',\n",
       " 'hash_indexing_failures': '0',\n",
       " 'backfill_in_progress': '0',\n",
       " 'backfill_complete_percent': '1.000000',\n",
       " 'mutation_queue_size': '0',\n",
       " 'recent_mutations_queue_delay': '0 sec'}"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_client.ft(INDEX_NAME).info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae77c3a-702e-4c9a-99c7-2aeb86ab9d22",
   "metadata": {},
   "source": [
    "Query the index for matches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "895f2adb-7148-4c72-b10a-d4da47831612",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "matches = parse_matches(vector_search(INDEX_NAME, question_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "ab06ccaa-f252-474b-af27-c86c2c7614f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'distance': 0.290015816689,\n",
       " 'chunk_id': 'fannie_part_0_c352',\n",
       " 'content': '# A3-3-03, Other Servicing Arrangements (12/15/2015)\\n\\nIntroduction This topic provides an overview of other servicing arrangements, including: • Subservicing • General Requirements for Subservicing Arrangements • Pledge of Servicing Rights and Transfer of Interest in Servicing Income\\n\\n## Subservicing\\n\\nA lender may use other organizations to perform some or all of its servicing functions. Fannie Mae refers to these arrangements as “subservicing” arrangements, meaning that a servicer (the “subservicer”) other than the contractually responsible servicer (the “master” servicer) is performing the servicing functions. The following are not considered to be subservicing arrangements: • when a computer service bureau is used to perform accounting and reporting functions; • when the originating lender sells and assigns servicing to another lender, unless the originating lender continues to be the contractually responsible servicer.',\n",
       " 'gse': 'fannie'}"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8c337d-676c-45fb-9e7b-d97d6514c4cf",
   "metadata": {},
   "source": [
    "#### Index: HNSW\n",
    "\n",
    "**References**\n",
    "- [Redis: HNSW Index](https://redis.io/docs/latest/develop/interact/search-and-query/advanced-concepts/vectors/#hnsw-index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51339b49-70d0-4042-a13f-b041da0f780d",
   "metadata": {},
   "source": [
    "Create the index:\n",
    "\n",
    "This index is a `HNSW` index with five options used (`TYPE`, `DIM`, `DISTANCE_METRIC`, `M`, `EF_CONSTRUCTION`) so the attributed count is 5*2 = 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "04b367e2-62ce-4d3f-8473-36d7de5d7212",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create the index ...\n",
      "Checking for index backfill ...\n",
      "Backfill still in progress with 0.00 percent complete ...\n",
      "Backfill still in progress with 52.91 percent complete ...\n",
      "Backfill complete.\n",
      "Index created and covers 9040 records\n"
     ]
    }
   ],
   "source": [
    "INDEX_NAME = 'hnsw-index'\n",
    "\n",
    "try:\n",
    "    check_index = decode_client.ft(INDEX_NAME).info()\n",
    "    print(f\"This index already exists: {check_index['index_name']}\")\n",
    "except Exception:\n",
    "    print(f'Create the index ...')\n",
    "\n",
    "    command = (\n",
    "        f\"FT.CREATE {INDEX_NAME} ON HASH \"\n",
    "        f\"SCHEMA embedding VECTOR HNSW 10 \"\n",
    "        f\"TYPE FLOAT32 \"\n",
    "        f\"DIM {len(question_embedding)} \"\n",
    "        f\"DISTANCE_METRIC IP \"\n",
    "        f\"M 10 \"\n",
    "        f\"EF_CONSTRUCTION 40\"\n",
    "    )\n",
    "\n",
    "    decode_client.execute_command(command)\n",
    "    \n",
    "    print(f'Checking for index backfill ...')\n",
    "    while True:\n",
    "        check_index = decode_client.ft(INDEX_NAME).info()\n",
    "        if check_index['backfill_in_progress'] == '1':\n",
    "            complete_pct = 100*float(check_index['backfill_complete_percent'])\n",
    "            print(f\"Backfill still in progress with {complete_pct:.2f} percent complete ...\")\n",
    "            time.sleep(1)\n",
    "        else:\n",
    "            print(f\"Backfill complete.\")\n",
    "            print(f\"Index created and covers {check_index['num_docs']} records\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106002e2-30ad-43b4-aacc-a0c46fe60058",
   "metadata": {},
   "source": [
    "Review the index details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "9770f2c8-01f3-463c-8f87-a662404b5556",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hnsw-index', 'flat-index']"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_client.execute_command('FT._LIST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "cdd01d7e-2c51-4193-8633-18695cd117e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index_name': 'hnsw-index',\n",
       " 'index_options': [],\n",
       " 'index_definition': ['key_type',\n",
       "  'HASH',\n",
       "  'prefixes',\n",
       "  [''],\n",
       "  'default_score',\n",
       "  '1'],\n",
       " 'attributes': [['identifier',\n",
       "   'embedding',\n",
       "   'attribute',\n",
       "   'embedding',\n",
       "   'type',\n",
       "   'VECTOR',\n",
       "   'index',\n",
       "   ['capacity',\n",
       "    10240,\n",
       "    'dimensions',\n",
       "    768,\n",
       "    'distance_metric',\n",
       "    'IP',\n",
       "    'data_type',\n",
       "    'FLOAT32',\n",
       "    'algorithm',\n",
       "    ['name', 'HNSW', 'm', 10, 'ef_construction', 40, 'ef_runtime', 10]]]],\n",
       " 'num_docs': '9040',\n",
       " 'num_terms': '0',\n",
       " 'num_records': '9040',\n",
       " 'hash_indexing_failures': '0',\n",
       " 'backfill_in_progress': '0',\n",
       " 'backfill_complete_percent': '1.000000',\n",
       " 'mutation_queue_size': '0',\n",
       " 'recent_mutations_queue_delay': '0 sec'}"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_client.ft(INDEX_NAME).info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf9b28c-34aa-46df-88dd-7f5ec9cab421",
   "metadata": {},
   "source": [
    "Query the index for matches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "632a3100-9aef-48f1-a2d9-3f65e522b73d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "matches = parse_matches(vector_search(INDEX_NAME, question_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "60b8dc30-a909-4747-b238-e876eb821a7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'distance': 0.319473981857,\n",
       " 'chunk_id': 'freddie_part_4_c509',\n",
       " 'content': \"# (1) Notice requirements\\n\\nThe notice must advise the Borrower of the following: 1. The date the new Servicing Agent or Master Servicer undertakes the performance of the Servicing obligations 2. The name and address of the Servicer undertaking the performance of the Servicing obligations 3. The names and telephone numbers of the contact persons or departments where the Borrowers' inquiries relating to the transfer should be directed. (If toll-free numbers are not available, the letter must indicate that collect calls will be accepted.) Such names and telephone numbers must be provided for the party previously performing the Servicing obligations as well as the new Servicing Agent or Master Servicer undertaking the performance of the Servicing obligations. 4. The date when the party previously performing the Servicing obligation will no longer collect the Borrowers' payments and when the new Servicing Agent or Master Servicer undertaking the performance of the Servicing obligations will begin to collect them 5. Procedures for maintenance of automatic draft payments, if applicable. Every effort must be made to continue, without interruption, electronic payments on the Borrower's Mortgage, to the extent permitted by applicable law.\",\n",
       " 'gse': 'freddie'}"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b208848-a5e2-4f99-8ab0-4ec34b619450",
   "metadata": {},
   "source": [
    "---\n",
    "## Retrieval Augmented Generation (RAG)\n",
    "\n",
    "Build a simple retrieval augmented generation process that enhances a query by retrieving context.  This is done here by constructing three functions for the stages:\n",
    "- `retrieve` - a function that uses an embedding to search for matching context parts, pieces of texts\n",
    "    - this uses the system built earlier in this workflow!\n",
    "- `augment` - prepare chunks into a prompt\n",
    "- `generate` - make the llm request with the augmented prompt\n",
    "\n",
    "A final function is used to execute the workflow of rag:\n",
    "- `rag` - a function that receives the query an orchestrates the workflow through `retrieve` > `augment` > `generate`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7102e46e-7eed-4a6e-9c4a-6444377da18e",
   "metadata": {},
   "source": [
    "### Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "2dfdb65e-df7a-454f-93cd-6f100156f329",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedder = vertexai.language_models.TextEmbeddingModel.from_pretrained('text-embedding-004')\n",
    "llm = vertexai.generative_models.GenerativeModel(\"gemini-1.5-flash-002\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b887ba78-868c-4bff-b446-59381c655dee",
   "metadata": {},
   "source": [
    "### Retrieve Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "55120ce7-f3dd-4ac0-a914-35275ee322f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def retrieve_memorystore(query_embedding, n_matches = 5):\n",
    "    \n",
    "    matches = parse_matches(vector_search('flat-index', query_embedding))\n",
    "    \n",
    "    return matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4615a880-db74-428a-8591-dcb658d10c48",
   "metadata": {},
   "source": [
    "### Augment Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "119b1c49-19b1-4267-b07d-e2903fc26705",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def augment(matches):\n",
    "\n",
    "    prompt = ''\n",
    "    for m, match in enumerate(matches):\n",
    "        prompt += f\"Context {m+1}:\\n{match['content']}\\n\\n\"\n",
    "    prompt += f'Answer the following question using the provided contexts:\\n'\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c4a9b0-b12c-4f96-a7eb-f6af257cab1c",
   "metadata": {},
   "source": [
    "### Generate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "ff0765af-8d37-44bf-ba3f-9facd706c68d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate(prompt):\n",
    "\n",
    "    result = llm.generate_content(prompt)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c31a67a-a5e7-42c0-874f-ee5b3f42ae1c",
   "metadata": {},
   "source": [
    "### RAG Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "b649457c-4d0e-4217-8881-cae226c6a4ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    \n",
    "    query_embedding = embedder.get_embeddings([query])[0].values\n",
    "    matches = retrieve_memorystore(query_embedding)\n",
    "    prompt = augment(matches) + query\n",
    "    result = generate(prompt)\n",
    "    \n",
    "    return result.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed82fe8-e67d-4e03-aebe-ee34d66089e2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Example In Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "34bda408-ca39-4ef9-b24f-e82a36591b6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Does a lender have to perform servicing functions directly?'"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "0e4dea0b-969f-4d14-b4da-649e3416e1ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No, a lender does not have to perform servicing functions directly.  Context 1 explicitly states that a lender may use other organizations (\"subservicing arrangements\") to perform some or all of its servicing functions.  However,  the lender remains contractually responsible (the \"master servicer\") unless they sell and assign servicing to another lender and relinquish that responsibility.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(rag(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3847415-6593-48d9-8e27-4e2c483c97a6",
   "metadata": {},
   "source": [
    "---\n",
    "### Profiling Performance\n",
    "\n",
    "Profile the timing of each step in the RAG function for sequential calls. The environment choosen for this workflow is a minimal testing enviornment so load testing (simoultaneous requests) would not be helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "2f015cbc-ee9a-4bad-b9c8-f37a91b3a5c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "profile = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "d6dc8f8b-fc87-4c3e-9699-d74d824026b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rag(query, profile = profile):\n",
    "    \n",
    "    timings = {}\n",
    "    start_time = time.time()\n",
    "    \n",
    "    \n",
    "    # 1. Get embeddings\n",
    "    embedding_start = time.time()\n",
    "    query_embedding = embedder.get_embeddings([query])[0].values\n",
    "    timings['embedding'] = time.time() - embedding_start\n",
    "\n",
    "    # 2. Retrieve from Bigtable\n",
    "    retrieval_start = time.time()\n",
    "    matches = retrieve_memorystore(query_embedding)\n",
    "    timings['retrieval_memorystore'] = time.time() - retrieval_start\n",
    "\n",
    "    # 3. Augment the prompt\n",
    "    augment_start = time.time()\n",
    "    prompt = augment(matches) + query\n",
    "    timings['augment'] = time.time() - augment_start\n",
    "\n",
    "    # 4. Generate text\n",
    "    generate_start = time.time()\n",
    "    result = generate(prompt)\n",
    "    timings['generate'] = time.time() - generate_start\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    timings['total'] = total_time\n",
    "    \n",
    "    profile.append(timings)\n",
    "    \n",
    "    return result.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "dda651f6-be3c-47fc-8f52-9fa02e969338",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.  A lender may use other organizations to perform some or all of its servicing functions through subservicing arrangements (Context 1).  However, the lender (master servicer) remains contractually responsible (Context 1).  The use of a subservicer must not interfere with the lender's ability to meet Fannie Mae's requirements (Context 4).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(rag(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "7c234824-f7c9-4986-9be5-cfbe7ba9f86a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'embedding': 0.1565110683441162,\n",
       "  'retrieval_memorystore': 0.030549049377441406,\n",
       "  'augment': 3.9577484130859375e-05,\n",
       "  'generate': 0.6989932060241699,\n",
       "  'total': 0.8860993385314941}]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "cd52e956-7672-409c-a604-14ea70043918",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    response = rag(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a36c11-7077-45ec-8797-e947f1283371",
   "metadata": {},
   "source": [
    "### Report From Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "8dc9529b-5ade-4f1f-a7ad-7350bc794f1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_timings = {}\n",
    "for timings in profile:\n",
    "    for key, value in timings.items():\n",
    "        if key not in all_timings:\n",
    "            all_timings[key] = []\n",
    "        all_timings[key].append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "83132703-fce1-47f5-8c18-37d777f413e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for 'embedding':\n",
      "  Min: 0.0479 seconds\n",
      "  Max: 0.1565 seconds\n",
      "  Mean: 0.0556 seconds\n",
      "  Median: 0.0522 seconds\n",
      "  Std Dev: 0.0126 seconds\n",
      "  P95: 0.0745 seconds\n",
      "  P99: 0.0926 seconds\n",
      "\n",
      "Statistics for 'retrieval_memorystore':\n",
      "  Min: 0.0052 seconds\n",
      "  Max: 0.0305 seconds\n",
      "  Mean: 0.0068 seconds\n",
      "  Median: 0.0067 seconds\n",
      "  Std Dev: 0.0025 seconds\n",
      "  P95: 0.0076 seconds\n",
      "  P99: 0.0108 seconds\n",
      "\n",
      "Statistics for 'augment':\n",
      "  Min: 0.0000 seconds\n",
      "  Max: 0.0001 seconds\n",
      "  Mean: 0.0000 seconds\n",
      "  Median: 0.0000 seconds\n",
      "  Std Dev: 0.0000 seconds\n",
      "  P95: 0.0000 seconds\n",
      "  P99: 0.0000 seconds\n",
      "\n",
      "Statistics for 'generate':\n",
      "  Min: 0.5160 seconds\n",
      "  Max: 1.0820 seconds\n",
      "  Mean: 0.7345 seconds\n",
      "  Median: 0.7339 seconds\n",
      "  Std Dev: 0.1026 seconds\n",
      "  P95: 0.9450 seconds\n",
      "  P99: 1.0642 seconds\n",
      "\n",
      "Statistics for 'total':\n",
      "  Min: 0.5742 seconds\n",
      "  Max: 1.1403 seconds\n",
      "  Mean: 0.7969 seconds\n",
      "  Median: 0.7938 seconds\n",
      "  Std Dev: 0.1029 seconds\n",
      "  P95: 1.0023 seconds\n",
      "  P99: 1.1225 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, values in all_timings.items():\n",
    "    arr = np.array(values)\n",
    "    print(f\"Statistics for '{key}':\")\n",
    "    print(f\"  Min: {np.min(arr):.4f} seconds\")\n",
    "    print(f\"  Max: {np.max(arr):.4f} seconds\")\n",
    "    print(f\"  Mean: {np.mean(arr):.4f} seconds\")\n",
    "    print(f\"  Median: {np.median(arr):.4f} seconds\")\n",
    "    print(f\"  Std Dev: {np.std(arr):.4f} seconds\")\n",
    "    print(f\"  P95: {np.percentile(arr, 95):.4f} seconds\")\n",
    "    print(f\"  P99: {np.percentile(arr, 99):.4f} seconds\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bff763-1270-4c32-b930-67b0f0ef9faf",
   "metadata": {},
   "source": [
    "## Remove Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "3635fbbf-1627-4987-b1dd-54239a83282b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#decode_client.execute_command('FT.DROPINDEX flat-index')\n",
    "#decode_client.execute_command('FT.DROPINDEX hnsw-index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6557d8bd-8582-4453-9a52-2f1a889c380c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#decode_client.flushall() # empty all records in the instance, across all databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "059a56c2-82c4-4b68-8dbe-3d157a556d68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#redis_client.delete_instance(name = redis_instance.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437fcd09-b32a-4f6a-9359-d4e9c2e5dce4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
