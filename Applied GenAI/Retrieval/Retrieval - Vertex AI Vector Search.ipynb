{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1104e83",
   "metadata": {},
   "source": [
    "![tracker](https://us-central1-vertex-ai-mlops-369716.cloudfunctions.net/pixel-tracking?path=statmike%2Fvertex-ai-mlops%2FApplied+GenAI%2FRetrieval&file=Retrieval+-+Vertex+AI+Vector+Search.ipynb)\n",
    "<!--- header table --->\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/statmike/vertex-ai-mlops/blob/main/Applied%20GenAI/Retrieval/Retrieval%20-%20Vertex%20AI%20Vector%20Search.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\">\n",
    "      <br>Run in<br>Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https%3A%2F%2Fraw.githubusercontent.com%2Fstatmike%2Fvertex-ai-mlops%2Fmain%2FApplied%2520GenAI%2FRetrieval%2FRetrieval%2520-%2520Vertex%2520AI%2520Vector%2520Search.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\">\n",
    "      <br>Run in<br>Colab Enterprise\n",
    "    </a>\n",
    "  </td>      \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/statmike/vertex-ai-mlops/blob/main/Applied%20GenAI/Retrieval/Retrieval%20-%20Vertex%20AI%20Vector%20Search.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      <br>View on<br>GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/statmike/vertex-ai-mlops/main/Applied%20GenAI/Retrieval/Retrieval%20-%20Vertex%20AI%20Vector%20Search.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      <br>Open in<br>Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b0e8e6-d761-4540-9d09-8f0c4ce9a020",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Retrieval - Vertex AI Vector Search\n",
    "\n",
    "In prior workflows, a series of documents was [processed into chunks](../Chunking/readme.md), and for each chunk, [embeddings](../Embeddings/readme.md) were created:\n",
    "\n",
    "- Process: [Large Document Processing - Document AI Layout Parser](../Chunking/Large%20Document%20Processing%20-%20Document%20AI%20Layout%20Parser.ipynb)\n",
    "- Embed: [Vertex AI Text Embeddings API](../Embeddings/Vertex%20AI%20Text%20Embeddings%20API.ipynb)\n",
    "\n",
    "Retrieving chunks for a query involves calculating the embedding for the query and then using similarity metrics to find relevant chunks. A thorough review of similarity matching can be found in [The Math of Similarity](../Embeddings/The%20Math%20of%20Similarity.ipynb) - use dot product! As development moves from experiment to application, the process of storing and computing similarity is migrated to a [retrieval](./readme.md) system. This workflow is part of a [series of workflows exploring many retrieval systems](./readme.md).  \n",
    "\n",
    "A detailed [comparison of many retrieval systems](./readme.md#comparison-of-vector-database-solutions) can be found in the readme as well.\n",
    "\n",
    "---\n",
    "\n",
    "**Vertex AI Vector Search For Storage, Indexing, And Search**\n",
    "\n",
    "[Vertex AI Vector Search](https://cloud.google.com/vertex-ai/docs/vector-search/overview) is a vector similarity search solution built for scale, offering enhanced features such as:\n",
    "\n",
    "- Support for sparse embeddings, including those used for keyword searches.\n",
    "- Hybrid search capabilities that combine dense and sparse embeddings.\n",
    "- Batch and streaming indexing options to match update latency requirements.\n",
    "- Inclusion of vector attributes (metadata) that can be used for filtering searches (allowlisting and denylisting).\n",
    "- Crowding attributes to limit the number of responses within groups.\n",
    "\n",
    "---\n",
    "\n",
    "**Use Case Data**\n",
    "\n",
    "Buying a home usually involves borrowing money from a lending institution, typically through a mortgage secured by the home's value. But how do these institutions manage the risks associated with such large loans, and how are lending standards established?\n",
    "\n",
    "In the United States, two government-sponsored enterprises (GSEs) play a vital role in the housing market:\n",
    "\n",
    "- Federal National Mortgage Association ([Fannie Mae](https://www.fanniemae.com/))\n",
    "- Federal Home Loan Mortgage Corporation ([Freddie Mac](https://www.freddiemac.com/))\n",
    "\n",
    "These GSEs purchase mortgages from lenders, enabling those lenders to offer more loans. This process also allows Fannie Mae and Freddie Mac to set standards for mortgages, ensuring they are responsible and borrowers are more likely to repay them. This system makes homeownership more affordable and stabilizes the housing market by maintaining a steady flow of liquidity for lenders and keeping interest rates controlled.\n",
    "\n",
    "However, navigating the complexities of these GSEs and their extensive servicing guides can be challenging.\n",
    "\n",
    "**Approaches**\n",
    "\n",
    "[This series](../readme.md) covers many generative AI workflows. These documents are used directly as long context for Gemini in the workflow [Long Context Retrieval With The Vertex AI Gemini API](../Generate/Long%20Context%20Retrieval%20With%20The%20Vertex%20AI%20Gemini%20API.ipynb). The workflow below uses a [retrieval](./readme.md) approach with the already generated chunks and embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be889472-69b0-416c-9cf1-edc9706fa5c5",
   "metadata": {
    "id": "od_UkDpvRmgD"
   },
   "source": [
    "---\n",
    "## Colab Setup\n",
    "\n",
    "When running this notebook in [Colab](https://colab.google/) or [Colab Enterprise](https://cloud.google.com/colab/docs/introduction), this section will authenticate to GCP (follow prompts in the popup) and set the current project for the session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21f75ba8-df50-466e-a5ec-f2a6dd88eb26",
   "metadata": {
    "executionInfo": {
     "elapsed": 195,
     "status": "ok",
     "timestamp": 1683726184843,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "8UO9FnqyKBlF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'statmike-mlops-349915' # replace with project ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c325515-1ea0-45cc-82d3-a1bfb1c52155",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68869,
     "status": "ok",
     "timestamp": 1683726253709,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "N98-KK7LRkjm",
    "outputId": "09ec5008-0def-4e1a-c349-c598ee752f78",
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    !gcloud config set project {PROJECT_ID}\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055a4bd7-7b47-43ef-ba14-636c955e44e3",
   "metadata": {},
   "source": [
    "---\n",
    "## Installs and API Enablement\n",
    "\n",
    "The clients packages may need installing in this environment. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410502ee-6fe3-4624-a69a-960ad7105f10",
   "metadata": {},
   "source": [
    "### Installs (If Needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4dbdb83-3170-430c-b60d-3d686222a168",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tuples of (import name, install name, min_version)\n",
    "packages = [\n",
    "    ('google.cloud.aiplatform', 'google-cloud-aiplatform', '1.69.0'),\n",
    "    ('google.cloud.storage', 'google-cloud-storage')\n",
    "]\n",
    "\n",
    "import importlib\n",
    "install = False\n",
    "for package in packages:\n",
    "    if not importlib.util.find_spec(package[0]):\n",
    "        print(f'installing package {package[1]}')\n",
    "        install = True\n",
    "        !pip install {package[1]} -U -q --user\n",
    "    elif len(package) == 3:\n",
    "        if importlib.metadata.version(package[0]) < package[2]:\n",
    "            print(f'updating package {package[1]}')\n",
    "            install = True\n",
    "            !pip install {package[1]} -U -q --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25374857-7d37-4c84-8cbb-a3c2fc7bb065",
   "metadata": {},
   "source": [
    "### API Enablement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b7300a8-7e3a-4a08-95c0-91186237753f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gcloud services enable aiplatform.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157d09ba-9774-495f-8ced-3382bf75be8f",
   "metadata": {},
   "source": [
    "### Restart Kernel (If Installs Occured)\n",
    "\n",
    "After a kernel restart the code submission can start with the next cell after this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9864153-66c8-43e1-ae96-1179632ccf7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if install:\n",
    "    import IPython\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)\n",
    "    IPython.display.display(IPython.display.Markdown(\"\"\"<div class=\\\"alert alert-block alert-warning\\\">\n",
    "        <b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. The previous cells do not need to be run again⚠️</b>\n",
    "        </div>\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a1ab41-cb32-4398-86dc-d30effb88a36",
   "metadata": {
    "id": "appt8-yVRtJ1"
   },
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cebe11b-9ca1-4f3e-aa78-78640ff01ec8",
   "metadata": {
    "id": "63mx2EozRxFP"
   },
   "source": [
    "Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab2239cd-40ab-416d-bac0-0c6953d911b6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 2124,
     "status": "ok",
     "timestamp": 1683726390544,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "xzcoXjM5Rky5",
    "outputId": "b3bdcbc1-70d5-472e-aea2-42c74a42efde",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'statmike-mlops-349915'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8aa97f05-66e9-4276-b2e6-83b5a91ca50c",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1683726390712,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "IxWrFtqYMfku",
    "tags": []
   },
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "SERIES = 'applied-genai'\n",
    "EXPERIMENT = 'retrieval-vertex-vector-search'\n",
    "\n",
    "# GCS storage bucket name\n",
    "GCS_BUCKET = PROJECT_ID\n",
    "\n",
    "# Vertex AI Vector Search Names\n",
    "VS_INDEX_NAME = f\"{SERIES}-{EXPERIMENT}\"\n",
    "VS_ENDPOINT_NAME = PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bbf65b-5d29-4a72-84ae-d977b9a743a6",
   "metadata": {
    "id": "LuajVwCiO6Yg"
   },
   "source": [
    "Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "559f6e60-a594-4789-893b-295a8381b670",
   "metadata": {
    "executionInfo": {
     "elapsed": 17761,
     "status": "ok",
     "timestamp": 1683726409304,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "LVC7zzSLRk2C",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, json, time, glob\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Vertex AI\n",
    "from google.cloud import aiplatform\n",
    "import vertexai.language_models # for embeddings API\n",
    "import vertexai.generative_models # for Gemini Models\n",
    "\n",
    "# gcs client\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3fef31f-928f-45f2-a3f4-292ee242232c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.71.0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aiplatform.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5758c07e-f064-40fb-a0ef-de6cbde5cd0a",
   "metadata": {
    "id": "EyAVFG9TO9H-"
   },
   "source": [
    "Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b72f3bb-176b-4678-ba6b-df9b2de14997",
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1683726409306,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "L0RPE13LOZce",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vertex ai clients\n",
    "vertexai.init(project = PROJECT_ID, location = REGION)\n",
    "\n",
    "# gcs client\n",
    "gcs = storage.Client(project = PROJECT_ID)\n",
    "bucket = gcs.bucket(GCS_BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8579282f-2723-4294-b72a-a65cc0831f44",
   "metadata": {},
   "source": [
    "---\n",
    "## Text & Embeddings For Examples\n",
    "\n",
    "This repository contains a [section for document processing (chunking)](../Chunking/readme.md) that includes an example of processing mulitple large pdfs (over 1000 pages) into chunks: [Large Document Processing - Document AI Layout Parser](../Chunking/Large%20Document%20Processing%20-%20Document%20AI%20Layout%20Parser.ipynb).  The chunks of text from that workflow are stored with this repository and loaded by another companion workflow that augments the chunks with text embeddings: [Vertex AI Text Embeddings API](../Embeddings/Vertex%20AI%20Text%20Embeddings%20API.ipynb).\n",
    "\n",
    "The following code will load the version of the chunks that includes text embeddings and prepare it for a local example of retrival augmented generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e12cbe2-3ca6-4656-9e73-c0db5c63bf50",
   "metadata": {},
   "source": [
    "### Get The Documents\n",
    "\n",
    "If you are working from a clone of this notebooks [repository](https://github.com/statmike/vertex-ai-mlops) then the documents are already present. The following cell checks for the documents folder and if it is missing gets it (`git clone`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f4e77ed-43f7-42be-9575-6a491c0d6cba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "local_dir = '../Embeddings/files/embeddings-api'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63ebe7c3-e72c-4394-91c3-d60c05bc0ce2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents Found in folder `../Embeddings/files/embeddings-api`\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(local_dir):\n",
    "    print('Retrieving documents...')\n",
    "    parent_dir = os.path.dirname(local_dir)\n",
    "    temp_dir = os.path.join(parent_dir, 'temp')\n",
    "    if not os.path.exists(temp_dir):\n",
    "        os.makedirs(temp_dir)\n",
    "    !git clone https://www.github.com/statmike/vertex-ai-mlops {temp_dir}/vertex-ai-mlops\n",
    "    shutil.copytree(f'{temp_dir}/vertex-ai-mlops/Applied GenAI/Embeddings/files/embeddings-api', local_dir)\n",
    "    shutil.rmtree(temp_dir)\n",
    "    print(f'Documents are now in folder `{local_dir}`')\n",
    "else:\n",
    "    print(f'Documents Found in folder `{local_dir}`')             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e68a84-9f88-4590-9ff1-e01c8a953ccf",
   "metadata": {},
   "source": [
    "### Load The Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58d04382-a74a-44ac-8824-3b46c86aa148",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0000.jsonl',\n",
       " '../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0001.jsonl',\n",
       " '../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0002.jsonl',\n",
       " '../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0003.jsonl',\n",
       " '../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0004.jsonl',\n",
       " '../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0005.jsonl',\n",
       " '../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0006.jsonl',\n",
       " '../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0007.jsonl',\n",
       " '../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0008.jsonl',\n",
       " '../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0009.jsonl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonl_files = glob.glob(f\"{local_dir}/large-files*.jsonl\")\n",
    "jsonl_files.sort()\n",
    "jsonl_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a54c6c96-6c28-49bb-80be-5d46797dfe77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9040"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = []\n",
    "for file in jsonl_files:\n",
    "    with open(file, 'r') as f:\n",
    "        chunks.extend([json.loads(line) for line in f])\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70115ec-6d60-41df-b7e6-9e2e5b463b1d",
   "metadata": {},
   "source": [
    "### Review A Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc20423e-e3d6-4e90-9e98-a5248508c82d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['instance', 'predictions', 'status'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1955ea39-4ffc-4d30-b653-a5a9911f2dab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fannie_part_0_c17'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0]['instance']['chunk_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3537982c-4a0e-456c-a652-19ea7507873b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Selling Guide Fannie Mae Single Family\n",
      "\n",
      "## Fannie Mae Copyright Notice\n",
      "\n",
      "### Fannie Mae Copyright Notice\n",
      "\n",
      "|-|\n",
      "| Section B3-4.2, Verification of Depository Assets 402 |\n",
      "| B3-4.2-01, Verification of Deposits and Assets (05/04/2022) 403 |\n",
      "| B3-4.2-02, Depository Accounts (12/14/2022) 405 |\n",
      "| B3-4.2-03, Individual Development Accounts (02/06/2019) 408 |\n",
      "| B3-4.2-04, Pooled Savings (Community Savings Funds) (04/01/2009) 411 |\n",
      "| B3-4.2-05, Foreign Assets (05/04/2022) 411 |\n",
      "| Section B3-4.3, Verification of Non-Depository Assets 412 |\n",
      "| B3-4.3-01, Stocks, Stock Options, Bonds, and Mutual Funds (06/30/2015) 412 |\n",
      "| B3-4.3-02, Trust Accounts (04/01/2009) 413 |\n",
      "| B3-4.3-03, Retirement Accounts (06/30/2015) 414 |\n",
      "| B3-4.3-04, Personal Gifts (09/06/2023) 415 |\n",
      "| B3-4.3-05, Gifts of Equity (10/07/2020) 418 |\n",
      "| B3-4.3-06, Grants and Lender Contributions (12/14/2022) 419 |\n",
      "| B3-4.3-07, Disaster Relief Grants or Loans (04/01/2009) 423 |\n",
      "| B3-4.3-08, Employer Assistance (09/29/2015) 423 |\n",
      "| B3-4.3-09, Earnest Money Deposit (05/04/2022) 425 |\n",
      "| B3-4.3-10, Anticipated Sales Proceeds (02/23/2016) B3-4.3-11, Trade Equity (12/16/2020) 426 428 |\n",
      "| B3-4.3-12, Rent-Related Credits (08/07/2024) 429 |\n",
      "| B3-4.3-13, Sweat Equity (04/15/2014) 430 |\n",
      "| B3-4.3-14, Bridge/Swing Loans (04/01/2009) 431 |\n",
      "| B3-4.3-15, Borrowed Funds Secured by an Asset (10/30/2009) 431 |\n",
      "|  |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(chunks[0]['instance']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49f06293-a439-436b-bc93-cd6cd3fb4aff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.031277116388082504,\n",
       " 0.03056905046105385,\n",
       " 0.010865348391234875,\n",
       " 0.0623614676296711,\n",
       " 0.03228681534528732,\n",
       " 0.05066155269742012,\n",
       " 0.046544693410396576,\n",
       " 0.05509665608406067,\n",
       " -0.014074751175940037,\n",
       " 0.008380400016903877]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0]['predictions'][0]['embeddings']['values'][0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f977358d-d9ea-4172-9eca-66079bb6087d",
   "metadata": {},
   "source": [
    "### Prepare Chunk Structure\n",
    "\n",
    "Make a list of dictionaries with information for each chunk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be9fa708-130c-4343-b179-dbde0b09a972",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "content_chunks = [\n",
    "    dict(\n",
    "        gse = chunk['instance']['gse'],\n",
    "        chunk_id = chunk['instance']['chunk_id'],\n",
    "        content = chunk['instance']['content'],\n",
    "        embedding = chunk['predictions'][0]['embeddings']['values']\n",
    "    ) for chunk in chunks\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6619605-7b10-444e-a131-db06e56a4be8",
   "metadata": {},
   "source": [
    "### Query Embedding\n",
    "\n",
    "Create a query, or prompt, and get the embedding for it:\n",
    "\n",
    "Connect to models for text embeddings. Learn more about the model API:\n",
    "- [Vertex AI Text Embeddings API](../Embeddings/Vertex%20AI%20Text%20Embeddings%20API.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3da5d30c-3dfb-42ba-a133-83dceb252787",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question = \"Does a lender have to perform servicing functions directly?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7992c26f-d058-4920-80a3-a157b88733e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedder = vertexai.language_models.TextEmbeddingModel.from_pretrained('text-embedding-004')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbe6fda7-9cea-49a2-9e2f-9222d50677af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.0005117303808219731,\n",
       " 0.009651427157223225,\n",
       " 0.01768726110458374,\n",
       " 0.014538003131747246,\n",
       " -0.01829824410378933,\n",
       " 0.027877431362867355,\n",
       " -0.021124685183167458,\n",
       " 0.008830446749925613,\n",
       " -0.02669006586074829,\n",
       " 0.06414774805307388]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_embedding = embedder.get_embeddings([question])[0].values\n",
    "question_embedding[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3745dc92-0000-418f-a914-3bd4fa49cf5b",
   "metadata": {},
   "source": [
    "---\n",
    "## Retrieval With Vertex AI Vector Search\n",
    "\n",
    "[Vertex AI Vector Search](https://cloud.google.com/vertex-ai/docs/vector-search/overview) is a vector similarity search solution built for scale, offering many enhanced functions, like streaming inserts of new embeddings.\n",
    "\n",
    "The layout of Vertex AI Vector Search Is:\n",
    "- Create An Index - specify batch or online update method\n",
    "    - Load data to index\n",
    "- Create Endpoint\n",
    "    - Deploy index to endpoint\n",
    "- Query Endpoinnt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c301f984-bbe8-4e0f-b30f-dcbc620fe4aa",
   "metadata": {},
   "source": [
    "### Prepare Input Data In GCS\n",
    "\n",
    "A batch input for Vertex AI Vector Search are sourced from GCS directory with structure:\n",
    "```\n",
    "batch_root/\n",
    "├── features_1.csv\n",
    "├── features_2.csv\n",
    "└── delete/\n",
    "    └── deletes_1.txt\n",
    "```\n",
    "Where each `features*` files is `.csv`, `.json`, or `.avro` file of input feature data.  The `delete` folder has `.txt` files of record IDs to remove from the the index.  Each batch job will have a batch root folder like this.\n",
    "\n",
    "The `features` files have structs of input information for each input and requires a value for `id` and for `embedding` and/or `sparse_embedding`.  The `sparse_embedding` can be great for keyword search and hybrid search.  The example below focuses on embeddings which are also called dense embeddings.\n",
    "\n",
    "The `features` files can also have optional `restricts` with  `namespace` and `allow` tokens for use in filtering and crowding during search.  These will be used in the example below.\n",
    "\n",
    "**Reference:**\n",
    "- [Input data format and structure](https://cloud.google.com/vertex-ai/docs/vector-search/setup/format-structure)\n",
    "- [Filter vector matches](https://cloud.google.com/vertex-ai/docs/vector-search/filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9d49296-f176-4a83-8914-b7a1e2f522f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vs_data = [\n",
    "    dict(\n",
    "        id = chunk['chunk_id'],\n",
    "        content = chunk['content'],\n",
    "        embedding = chunk['embedding'],\n",
    "        restricts = [\n",
    "            dict(\n",
    "                namespace = 'gse',\n",
    "                allow = [chunk['gse']],\n",
    "                #deny = []\n",
    "            )\n",
    "        ],\n",
    "        #numeric_restricts = [],\n",
    "        crowding_tag = chunk['gse']\n",
    "    ) for chunk in content_chunks\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb70841-1c8d-4cdc-adb8-bda90602bea6",
   "metadata": {},
   "source": [
    "#### Save To GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6119ba51-bc70-426a-866b-bd7f0c075916",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Blob: statmike-mlops-349915, applied-genai/retrieval-vertex-vector-search/batches/initial/feature.json, 1731272345798879>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = bucket.blob(f'{SERIES}/{EXPERIMENT}/batches/initial/feature.json')\n",
    "jsonl_data = '\\n'.join(json.dumps(row) for row in vs_data)\n",
    "blob.upload_from_string(jsonl_data, content_type = 'application/json')\n",
    "list(bucket.list_blobs(prefix = f'{SERIES}/{EXPERIMENT}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dad38a-6f8c-43fe-8774-1e5e58844f7b",
   "metadata": {},
   "source": [
    "### Create/Retrieve An Index\n",
    "\n",
    "Before deploying an index for use on an endpoint with Vertex AI Vector Search, you first create the index and load the data.  The workflow here will create and load the data to two different indexes: one for treeAH approximate nearest neighbors search, and one for brute force full search.  Indexes can be created for batch updates or streaming updates.\n",
    "\n",
    "**Reference:**\n",
    "- [Create and managed your index](https://cloud.google.com/vertex-ai/docs/vector-search/create-manage-index)\n",
    "- [Index configuration parameters](https://cloud.google.com/vertex-ai/docs/vector-search/configuring-indexes)\n",
    "- [Python SDK: `aiplatform.MatchingEngineIndex`](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.MatchingEngineIndex#google_cloud_aiplatform_MatchingEngineIndex_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed2867a-8070-42ef-909e-44f8565c550b",
   "metadata": {},
   "source": [
    "#### Create Empty Indexes\n",
    "\n",
    "Check for the index and if missing create it:\n",
    "- a tree ah index for approximation nearest neightbors search\n",
    "- a brute force index for verifying results in testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "11da6e43-cd7b-4dfe-9c97-839a43d97a89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating index ...\n",
      "Creating MatchingEngineIndex\n",
      "Create MatchingEngineIndex backing LRO: projects/1026793852137/locations/us-central1/indexes/6040483786536255488/operations/6192088469863399424\n",
      "MatchingEngineIndex created. Resource name: projects/1026793852137/locations/us-central1/indexes/6040483786536255488\n",
      "To use this MatchingEngineIndex in another session:\n",
      "index = aiplatform.MatchingEngineIndex('projects/1026793852137/locations/us-central1/indexes/6040483786536255488')\n"
     ]
    }
   ],
   "source": [
    "check = aiplatform.MatchingEngineIndex.list(filter=f'display_name=\"{VS_INDEX_NAME}-tree-ah\"')\n",
    "if len(check) > 0:\n",
    "    print('Retrieved existing index with same name.')\n",
    "    vs_index_tree_ah = check[0]\n",
    "else:\n",
    "    print('Creating index ...')\n",
    "    vs_index_tree_ah = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
    "        display_name = VS_INDEX_NAME + '-tree-ah',\n",
    "        dimensions = len(question_embedding),\n",
    "        approximate_neighbors_count = 20,\n",
    "        distance_measure_type = 'DOT_PRODUCT_DISTANCE',\n",
    "        leaf_node_embedding_count = 250,\n",
    "        leaf_nodes_to_search_percent = 10,\n",
    "        index_update_method = 'BATCH_METHOD',\n",
    "        shard_size = 'SHARD_SIZE_SMALL'\n",
    "    )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "28b6af7e-8955-4be0-909c-74ee90604c77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating index ...\n",
      "Creating MatchingEngineIndex\n",
      "Create MatchingEngineIndex backing LRO: projects/1026793852137/locations/us-central1/indexes/2426345085571432448/operations/6733364850077990912\n",
      "MatchingEngineIndex created. Resource name: projects/1026793852137/locations/us-central1/indexes/2426345085571432448\n",
      "To use this MatchingEngineIndex in another session:\n",
      "index = aiplatform.MatchingEngineIndex('projects/1026793852137/locations/us-central1/indexes/2426345085571432448')\n"
     ]
    }
   ],
   "source": [
    "check = aiplatform.MatchingEngineIndex.list(filter=f'display_name=\"{VS_INDEX_NAME}-brute-force\"')\n",
    "if len(check) > 0:\n",
    "    print('Retrieved existing index with same name.')\n",
    "    vs_index_brute_force = check[0]\n",
    "else:\n",
    "    print('Creating index ...')\n",
    "    vs_index_brute_force = aiplatform.MatchingEngineIndex.create_brute_force_index(\n",
    "        display_name = VS_INDEX_NAME + '-brute-force',\n",
    "        dimensions = len(question_embedding),\n",
    "        distance_measure_type = 'DOT_PRODUCT_DISTANCE',\n",
    "        index_update_method = 'BATCH_METHOD',\n",
    "        shard_size = 'SHARD_SIZE_SMALL'\n",
    "    )  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b744d06d-f95d-4651-b53a-e19c008181ae",
   "metadata": {},
   "source": [
    "#### Load Data To Index\n",
    "\n",
    "Check to see if data is already loaded and if missing then load as a complete overwrite:\n",
    "\n",
    "**Note:** This can be a lengthy operation.  It is recommended to review the progress in the Vertex AI Console section for Vector Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f60990f3-fe2d-4ea5-ba63-2634360b2544",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'shardsCount': 1}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs_index_tree_ah.to_dict()['indexStats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55e73079-acb6-4177-b057-54fde25bb9cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'shardsCount': 1}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs_index_brute_force.to_dict()['indexStats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5ce275e2-3136-4250-ab6c-88f07d74bbe1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Embeddings...\n",
      "Updating MatchingEngineIndex index: projects/1026793852137/locations/us-central1/indexes/6040483786536255488\n",
      "Update MatchingEngineIndex index backing LRO: projects/1026793852137/locations/us-central1/indexes/6040483786536255488/operations/7548516382632050688\n",
      "MatchingEngineIndex index Updated. Resource name: projects/1026793852137/locations/us-central1/indexes/6040483786536255488\n"
     ]
    }
   ],
   "source": [
    "if 'vectorsCount' not in vs_index_tree_ah.to_dict()['indexStats']:\n",
    "    print('Loading Embeddings...')\n",
    "    vs_index_tree_ah.update_embeddings(\n",
    "        contents_delta_uri = f'gs://{bucket.name}/{SERIES}/{EXPERIMENT}/batches/initial',\n",
    "        is_complete_overwrite = True\n",
    "    )\n",
    "    vs_index_tree_ah = aiplatform.MatchingEngineIndex(index_name = vs_index_tree_ah.name)\n",
    "else:\n",
    "    print('Embeddings already loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aa61d578-db37-4ae0-9826-1423523365ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Embeddings...\n",
      "Updating MatchingEngineIndex index: projects/1026793852137/locations/us-central1/indexes/2426345085571432448\n",
      "Update MatchingEngineIndex index backing LRO: projects/1026793852137/locations/us-central1/indexes/2426345085571432448/operations/9011060361620619264\n",
      "MatchingEngineIndex index Updated. Resource name: projects/1026793852137/locations/us-central1/indexes/2426345085571432448\n"
     ]
    }
   ],
   "source": [
    "if 'vectorsCount' not in vs_index_brute_force.to_dict()['indexStats']:\n",
    "    print('Loading Embeddings...')\n",
    "    vs_index_brute_force.update_embeddings(\n",
    "        contents_delta_uri = f'gs://{bucket.name}/{SERIES}/{EXPERIMENT}/batches/initial',\n",
    "        is_complete_overwrite = True\n",
    "    )\n",
    "    vs_index_brute_force = aiplatform.MatchingEngineIndex(index_name = vs_index_brute_force.name)\n",
    "else:\n",
    "    print('Embeddings already loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e143963a-741d-499e-89c5-b0e212c3eb0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vectorsCount': '9040', 'shardsCount': 1}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs_index_tree_ah.to_dict()['indexStats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e20e992e-d66f-4d1f-9d5e-9c5b2a6051d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vectorsCount': '9040', 'shardsCount': 1}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs_index_brute_force.to_dict()['indexStats']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22261294-4b73-49fc-bb6a-8106fc193228",
   "metadata": {},
   "source": [
    "### Manage An Index\n",
    "\n",
    "Similar to loading data to the indexes in the previous section, batch updates can be carried out with incremental data or complete overwrites.  If the indexes are set up for streaming updates the upserts can be streamed to the indexes.\n",
    "\n",
    "**Reference:**\n",
    "- [Update and rebuild index](https://cloud.google.com/vertex-ai/docs/vector-search/update-rebuild-index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5727964-51c5-46ee-b8f6-da66963b5b39",
   "metadata": {},
   "source": [
    "### Create/Retrieve An Index Endpoint\n",
    "\n",
    "To make indexes available for serving nearest neighbors matches they need to be deployed to a Vertex AI Vector Search endpoints.  This section will create an endpoint (or retrieve it).  The work below creates a public endpoint but the endpoint can also be created with VPC peering or private service connect.  \n",
    "\n",
    "**Reference:**\n",
    "- [Deploy - Public Endpoint](https://cloud.google.com/vertex-ai/docs/vector-search/deploy-index-public)\n",
    "- [Deploy - Private services access(VPC peering)](https://cloud.google.com/vertex-ai/docs/vector-search/deploy-index-vpc)\n",
    "- [Deploy - Private Services Connect (PSC)](https://cloud.google.com/vertex-ai/docs/vector-search/setup/private-service-connect)\n",
    "- [Python SDK: `aiplatform.MatchingEngineIndexEndpoint`](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.MatchingEngineIndexEndpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e7cc655b-cbd4-4577-b555-f454b0c052bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating endpoint...\n",
      "Creating MatchingEngineIndexEndpoint\n",
      "Create MatchingEngineIndexEndpoint backing LRO: projects/1026793852137/locations/us-central1/indexEndpoints/5862398087208632320/operations/4331820348782673920\n",
      "MatchingEngineIndexEndpoint created. Resource name: projects/1026793852137/locations/us-central1/indexEndpoints/5862398087208632320\n",
      "To use this MatchingEngineIndexEndpoint in another session:\n",
      "index_endpoint = aiplatform.MatchingEngineIndexEndpoint('projects/1026793852137/locations/us-central1/indexEndpoints/5862398087208632320')\n"
     ]
    }
   ],
   "source": [
    "check = aiplatform.MatchingEngineIndexEndpoint.list(filter=f'display_name=\"{VS_ENDPOINT_NAME}\"')\n",
    "if len(check) > 0:\n",
    "    print('Retreived existing endpoint with same name.')\n",
    "    vs_endpoint = check[0]\n",
    "else:\n",
    "    print('Creating endpoint...')\n",
    "    vs_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n",
    "        display_name = VS_ENDPOINT_NAME,\n",
    "        public_endpoint_enabled = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce35ac1-5727-4f15-b244-04f591f72c5f",
   "metadata": {},
   "source": [
    "### Deploy Indexes To Index Endpoint\n",
    "\n",
    "Check for indexes on the endpoint and if missing deploy them\n",
    "\n",
    "This is the point where computing resources are started to hosts the endpoint. Choices here and the up time of the endpoint are important considerations for performance and [costs](https://cloud.google.com/vertex-ai/pricing#vectorsearch).\n",
    "\n",
    "**Notes**\n",
    "- Machine types should chosen to support the choosen shard size (see first reference below)\n",
    "- It is recommended to have two replicas per shard\n",
    "- min_replica_count and max_replica_count default to 2 (no autoscaling)\n",
    "- if min_replica_count is not set then it defaults to 2\n",
    "- if max_replica_count is not set then it defaults to the same value as min_replica_count\n",
    "\n",
    "**Reference:**\n",
    "- [Machine type options](https://cloud.google.com/vertex-ai/docs/vector-search/create-manage-index#create-index)\n",
    "- [Enable Autoscaling](https://cloud.google.com/vertex-ai/docs/vector-search/deploy-index-public#autoscaling)\n",
    "    - [Change autoscaling parameters for and endpoint](https://cloud.google.com/vertex-ai/docs/vector-search/deploy-index-public#mutate-deployed-index)\n",
    "- [Deployment settings that impact performance](https://cloud.google.com/vertex-ai/docs/vector-search/deploy-index-public#performance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "896ad94f-ea8f-4cf6-a639-f6f0e0c6f163",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying index: applied-genai-retrieval-vertex-vector-search-tree-ah\n",
      "Deploying index MatchingEngineIndexEndpoint index_endpoint: projects/1026793852137/locations/us-central1/indexEndpoints/5862398087208632320\n",
      "Deploy index MatchingEngineIndexEndpoint index_endpoint backing LRO: projects/1026793852137/locations/us-central1/indexEndpoints/5862398087208632320/operations/3030280056472600576\n",
      "MatchingEngineIndexEndpoint index_endpoint Deployed index. Resource name: projects/1026793852137/locations/us-central1/indexEndpoints/5862398087208632320\n",
      "Deploying index: applied-genai-retrieval-vertex-vector-search-brute-force\n",
      "Deploying index MatchingEngineIndexEndpoint index_endpoint: projects/1026793852137/locations/us-central1/indexEndpoints/5862398087208632320\n",
      "Deploy index MatchingEngineIndexEndpoint index_endpoint backing LRO: projects/1026793852137/locations/us-central1/indexEndpoints/5862398087208632320/operations/505449515378016256\n",
      "MatchingEngineIndexEndpoint index_endpoint Deployed index. Resource name: projects/1026793852137/locations/us-central1/indexEndpoints/5862398087208632320\n"
     ]
    }
   ],
   "source": [
    "for index in [vs_index_tree_ah, vs_index_brute_force]:\n",
    "    if index.display_name.replace('-', '_') not in [i.id for i in vs_endpoint.deployed_indexes]:\n",
    "        print(f'Deploying index: {index.display_name}')\n",
    "        vs_endpoint = vs_endpoint.deploy_index(\n",
    "            index = index,\n",
    "            deployed_index_id = index.display_name.replace('-', '_'),\n",
    "            machine_type = 'e2-standard-2',\n",
    "            min_replica_count = 2,\n",
    "            max_replica_count = 2, \n",
    "        )\n",
    "        # refresh endpoint\n",
    "        vs_endpoint = aiplatform.MatchingEngineIndexEndpoint(\n",
    "            index_endpoint_name = vs_endpoint.resource_name\n",
    "        )\n",
    "    else:\n",
    "        print(f'Found index already deployed to endpoint: {index.display_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "27df7d60-3ed0-40e7-8438-f5faaa08014c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[id: \"applied_genai_retrieval_vertex_vector_search_tree_ah\"\n",
       "index: \"projects/1026793852137/locations/us-central1/indexes/6040483786536255488\"\n",
       "create_time {\n",
       "  seconds: 1731278278\n",
       "  nanos: 219352000\n",
       "}\n",
       "index_sync_time {\n",
       "  seconds: 1731279760\n",
       "  nanos: 109866000\n",
       "}\n",
       "deployment_group: \"default\"\n",
       "dedicated_resources {\n",
       "  machine_spec {\n",
       "    machine_type: \"e2-standard-2\"\n",
       "  }\n",
       "  min_replica_count: 2\n",
       "  max_replica_count: 2\n",
       "}\n",
       ", id: \"applied_genai_retrieval_vertex_vector_search_brute_force\"\n",
       "index: \"projects/1026793852137/locations/us-central1/indexes/2426345085571432448\"\n",
       "create_time {\n",
       "  seconds: 1731279761\n",
       "  nanos: 6520000\n",
       "}\n",
       "index_sync_time {\n",
       "  seconds: 1731279945\n",
       "  nanos: 365521000\n",
       "}\n",
       "deployment_group: \"default\"\n",
       "dedicated_resources {\n",
       "  machine_spec {\n",
       "    machine_type: \"e2-standard-2\"\n",
       "  }\n",
       "  min_replica_count: 2\n",
       "  max_replica_count: 2\n",
       "}\n",
       "]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs_endpoint.deployed_indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1398008e-70fe-4b99-a389-77526d08a602",
   "metadata": {},
   "source": [
    "---\n",
    "### Query Endpoint\n",
    "\n",
    "Use the endpoint to query for data and matches.\n",
    "\n",
    "**Reference:**\n",
    "- [Query Documentation](https://cloud.google.com/vertex-ai/docs/vector-search/query-index-public-endpoint)\n",
    "- [Python SDK: `aiplatform.MatchingEngineIndexEndpoint.read_index_datapoinnts`](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.MatchingEngineIndexEndpoint#google_cloud_aiplatform_MatchingEngineIndexEndpoint_read_index_datapoints)\n",
    "- [Python SDK: `aiplatform.MatchingEngineIndexEndpoint.match`](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.MatchingEngineIndexEndpoint#google_cloud_aiplatform_MatchingEngineIndexEndpoint_match)\n",
    "- [Python SDK: `aiplatform.MatchingEngineIndexEndpoint.find_neighbors`](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.MatchingEngineIndexEndpoint#google_cloud_aiplatform_MatchingEngineIndexEndpoint_find_neighbors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8710008-7836-494f-a914-af38b90ee3bf",
   "metadata": {},
   "source": [
    "#### Retrieve: Embedding For Entity\n",
    "\n",
    "Retrieve the index entry for a specific id:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "05dbb73a-d500-43b8-8e23-8159cd0a872e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = vs_endpoint.read_index_datapoints(\n",
    "    deployed_index_id = vs_index_tree_ah.display_name.replace('-', '_'),\n",
    "    ids = ['fannie_part_0_c40']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ce85ac28-0c6a-4aa1-acd8-b86b15993bdd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3b1079ac-c973-47c7-95c6-5c3d5f697e81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fannie_part_0_c40'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].datapoint_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3fb981a6-a4f2-48b3-98db-24dd415b6738",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.027678849175572395,\n",
       " -0.007303171791136265,\n",
       " 0.03341332823038101,\n",
       " 0.06296615302562714,\n",
       " -0.014549952000379562]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].feature_vector[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cefbc423-3b96-4c2d-bc71-ebbd2a5e990e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[namespace: \"gse\"\n",
       "allow_list: \"fannie\"\n",
       "]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].restricts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2879b367-eac9-4115-a579-8c558dbef454",
   "metadata": {},
   "source": [
    "#### Retrieve: Embeddings For Entities\n",
    "\n",
    "Retrieve the index entry for a list of specific ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2a7dcf9f-947e-4a1f-b59e-40db0d437fac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = vs_endpoint.read_index_datapoints(\n",
    "    deployed_index_id = vs_index_tree_ah.display_name.replace('-', '_'),\n",
    "    ids = ['fannie_part_0_c40', 'freddie_part_0_c40']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "25fb0865-f004-44c7-977f-dd36eb4585ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9676359f-7b20-4286-9a09-b1da928785e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fannie_part_0_c40'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].datapoint_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "18015629-5c04-4188-963e-334cb7641586",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.027678849175572395,\n",
       " -0.007303171791136265,\n",
       " 0.03341332823038101,\n",
       " 0.06296615302562714,\n",
       " -0.014549952000379562]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].feature_vector[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8010ea07-9df0-470a-a809-f1f611a6414b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[namespace: \"gse\"\n",
       "allow_list: \"fannie\"\n",
       "]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].restricts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8257973e-2970-4eb6-9f57-094a4c5a6d7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[namespace: \"gse\"\n",
       "allow_list: \"freddie\"\n",
       "]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[1].restricts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aced3159-f6c8-4588-979c-1a3d8905e516",
   "metadata": {},
   "source": [
    "#### Matches: For Entity\n",
    "\n",
    "Return the embedding in the response by adding `return_full_datapoint = True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b4c581a7-54bb-4046-8486-a3fcc002cf97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = vs_endpoint.find_neighbors(\n",
    "    deployed_index_id = vs_index_tree_ah.display_name.replace('-', '_'),\n",
    "    num_neighbors = 2,\n",
    "    embedding_ids = ['fannie_part_0_c40']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4d5c012b-806c-4b92-8ca8-b450135f6e8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[MatchNeighbor(id='fannie_part_0_c40', distance=0.999954342842102, sparse_distance=None, feature_vector=[], crowding_tag='1074578924770667433', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[]),\n",
       "  MatchNeighbor(id='fannie_part_0_c39', distance=0.9096099138259888, sparse_distance=None, feature_vector=[], crowding_tag='1074578924770667433', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[])]]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203ad405-6c23-4937-aeb6-2dbbe02b15b5",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Matches: For Query Embedding\n",
    "\n",
    "Return the embedding in the response by adding `return_full_datapoint = True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b872543c-b3cb-4c99-b69e-9418a7ef7f1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = vs_endpoint.find_neighbors(\n",
    "    deployed_index_id = vs_index_tree_ah.display_name.replace('-', '_'),\n",
    "    queries = [question_embedding],\n",
    "    num_neighbors = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "591eac6b-858d-4903-baa1-81bb0036fdd2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[MatchNeighbor(id='fannie_part_0_c352', distance=0.7099842429161072, sparse_distance=None, feature_vector=[], crowding_tag='1074578924770667433', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[]),\n",
       "  MatchNeighbor(id='freddie_part_4_c509', distance=0.680526077747345, sparse_distance=None, feature_vector=[], crowding_tag='-353579237037459606', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[])]]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bc304e30-45cc-4dc3-9f23-cac3db793846",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fannie_part_0_c352', 0.7099842429161072),\n",
       " ('freddie_part_4_c509', 0.680526077747345)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(match.id, match.distance) for match in results[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858710de-ada5-4d0b-8fcf-89ee765fca13",
   "metadata": {},
   "source": [
    "#### Matches: For Query Embedding - Same Endpoint Different Index\n",
    "\n",
    "Above two indexes were deployed to the endpoint.  This example switches to the index with brute force search:\n",
    "\n",
    "Return the embedding in the response by adding `return_full_datapoint = True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a8d5ad8b-3952-47b3-a5dd-d7ecf1216e8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = vs_endpoint.find_neighbors(\n",
    "    deployed_index_id = vs_index_brute_force.display_name.replace('-', '_'),\n",
    "    queries = [question_embedding],\n",
    "    num_neighbors = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "460c86aa-9bc4-43d4-87f5-f436740171ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[MatchNeighbor(id='fannie_part_0_c352', distance=0.7099842429161072, sparse_distance=None, feature_vector=[], crowding_tag='1074578924770667433', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[]),\n",
       "  MatchNeighbor(id='freddie_part_4_c509', distance=0.680526077747345, sparse_distance=None, feature_vector=[], crowding_tag='-353579237037459606', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[])]]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5255d525-2e2b-40dd-8f33-cf04c3ba109c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fannie_part_0_c352', 0.7099842429161072),\n",
       " ('freddie_part_4_c509', 0.680526077747345)]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(match.id, match.distance) for match in results[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a749ba5f-68bb-41c7-a6b0-65495707a9de",
   "metadata": {},
   "source": [
    "#### Matches: For Query Embedding - Expand Search Candidates\n",
    "\n",
    "Return the embedding in the response by adding `return_full_datapoint = True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bcc05d84-9a97-4494-bede-915dfa30f4b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = vs_endpoint.find_neighbors(\n",
    "    deployed_index_id = vs_index_tree_ah.display_name.replace('-', '_'),\n",
    "    queries = [question_embedding],\n",
    "    num_neighbors = 4,\n",
    "    fraction_leaf_nodes_to_search_override = 0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cabdb4bb-093b-4288-aa45-3fc59bb0950c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[MatchNeighbor(id='fannie_part_0_c352', distance=0.7099842429161072, sparse_distance=None, feature_vector=[], crowding_tag='1074578924770667433', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[]),\n",
       "  MatchNeighbor(id='freddie_part_4_c509', distance=0.680526077747345, sparse_distance=None, feature_vector=[], crowding_tag='-353579237037459606', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[]),\n",
       "  MatchNeighbor(id='freddie_part_4_c510', distance=0.6753297448158264, sparse_distance=None, feature_vector=[], crowding_tag='-353579237037459606', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[]),\n",
       "  MatchNeighbor(id='fannie_part_0_c353', distance=0.6723706722259521, sparse_distance=None, feature_vector=[], crowding_tag='1074578924770667433', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[])]]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0f0ecec5-525f-4068-8275-da08c666c06c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fannie_part_0_c352', 0.7099842429161072),\n",
       " ('freddie_part_4_c509', 0.680526077747345),\n",
       " ('freddie_part_4_c510', 0.6753297448158264),\n",
       " ('fannie_part_0_c353', 0.6723706722259521)]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(match.id, match.distance) for match in results[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51cddc3-7149-4bd3-a02f-5b23538e3b11",
   "metadata": {},
   "source": [
    "#### Matches: For Query Embedding - Diversity of Responses\n",
    "\n",
    "Return the embedding in the response by adding `return_full_datapoint = True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b482433a-e1fb-47bf-b04e-2f34002b1c3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = vs_endpoint.find_neighbors(\n",
    "    deployed_index_id = vs_index_tree_ah.display_name.replace('-', '_'),\n",
    "    queries = [question_embedding],\n",
    "    num_neighbors = 4,\n",
    "    per_crowding_attribute_neighbor_count = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5f6cadf3-3b84-468b-91f5-b7f835296fd0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[MatchNeighbor(id='fannie_part_0_c352', distance=0.7099842429161072, sparse_distance=None, feature_vector=[], crowding_tag='1074578924770667433', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[]),\n",
       "  MatchNeighbor(id='freddie_part_4_c509', distance=0.680526077747345, sparse_distance=None, feature_vector=[], crowding_tag='-353579237037459606', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[]),\n",
       "  MatchNeighbor(id='freddie_part_4_c510', distance=0.6753297448158264, sparse_distance=None, feature_vector=[], crowding_tag='-353579237037459606', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[]),\n",
       "  MatchNeighbor(id='fannie_part_0_c353', distance=0.6723706722259521, sparse_distance=None, feature_vector=[], crowding_tag='1074578924770667433', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[])]]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "56d76ba0-b15e-4cf3-b8c3-f5446d1af0fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fannie_part_0_c352', 0.7099842429161072),\n",
       " ('freddie_part_4_c509', 0.680526077747345),\n",
       " ('freddie_part_4_c510', 0.6753297448158264),\n",
       " ('fannie_part_0_c353', 0.6723706722259521)]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(match.id, match.distance) for match in results[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953455c2-053a-400f-ac1d-8b222a419ac3",
   "metadata": {},
   "source": [
    "#### Matches: For Query Embedding - Limit Search Area With Allowlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ffe8128d-d206-4ffa-888a-99c57bf5f61a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = vs_endpoint.find_neighbors(\n",
    "    deployed_index_id = vs_index_tree_ah.display_name.replace('-', '_'),\n",
    "    queries = [question_embedding],\n",
    "    num_neighbors = 4,\n",
    "    filter = [\n",
    "        aiplatform.matching_engine.matching_engine_index_endpoint.Namespace('gse', ['fannie'], []) # Namespece, allow list, deny list\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9d24c5c2-c588-4aa6-90fd-3cd6b92dba01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[MatchNeighbor(id='fannie_part_0_c352', distance=0.7099842429161072, sparse_distance=None, feature_vector=[], crowding_tag='1074578924770667433', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[]),\n",
       "  MatchNeighbor(id='fannie_part_0_c353', distance=0.6723706722259521, sparse_distance=None, feature_vector=[], crowding_tag='1074578924770667433', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[]),\n",
       "  MatchNeighbor(id='fannie_part_0_c326', distance=0.6683496832847595, sparse_distance=None, feature_vector=[], crowding_tag='1074578924770667433', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[]),\n",
       "  MatchNeighbor(id='fannie_part_0_c92', distance=0.661433756351471, sparse_distance=None, feature_vector=[], crowding_tag='1074578924770667433', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[])]]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "daae6903-a31c-48d3-831a-0275dc227d3d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fannie_part_0_c352', 0.7099842429161072),\n",
       " ('fannie_part_0_c353', 0.6723706722259521),\n",
       " ('fannie_part_0_c326', 0.6683496832847595),\n",
       " ('fannie_part_0_c92', 0.661433756351471)]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(match.id, match.distance) for match in results[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4a5911-cfb6-4fab-b812-0565ed4e7a64",
   "metadata": {},
   "source": [
    "#### Matches: For Query Embedding - Limit Search Area With Denylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "66210503-176a-41b8-8729-5b8fccd9ad43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = vs_endpoint.find_neighbors(\n",
    "    deployed_index_id = vs_index_tree_ah.display_name.replace('-', '_'),\n",
    "    queries = [question_embedding],\n",
    "    num_neighbors = 4,\n",
    "    filter = [\n",
    "        aiplatform.matching_engine.matching_engine_index_endpoint.Namespace('gse', [], ['fannie']) # Namespece, allow list, deny list\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1d1ac727-e1a7-42c4-bc20-6a6e264ef8dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[MatchNeighbor(id='freddie_part_4_c509', distance=0.680526077747345, sparse_distance=None, feature_vector=[], crowding_tag='-353579237037459606', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[]),\n",
       "  MatchNeighbor(id='freddie_part_4_c510', distance=0.6753297448158264, sparse_distance=None, feature_vector=[], crowding_tag='-353579237037459606', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[]),\n",
       "  MatchNeighbor(id='freddie_part_4_c472', distance=0.6619843244552612, sparse_distance=None, feature_vector=[], crowding_tag='-353579237037459606', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[]),\n",
       "  MatchNeighbor(id='freddie_part_6_c439', distance=0.6604534983634949, sparse_distance=None, feature_vector=[], crowding_tag='-353579237037459606', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[])]]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d309b761-5f5f-42ba-b5db-4b235b312a4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('freddie_part_4_c509', 0.680526077747345),\n",
       " ('freddie_part_4_c510', 0.6753297448158264),\n",
       " ('freddie_part_4_c472', 0.6619843244552612),\n",
       " ('freddie_part_6_c439', 0.6604534983634949)]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(match.id, match.distance) for match in results[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc7427a-7319-4183-9bcc-7b4ccdf6a0ea",
   "metadata": {},
   "source": [
    "### Get Text For Matches\n",
    "\n",
    "The results from Vertex AI Vector Search do not include the text related to the embedding.  A separate retrieval system will be needed for this of which the others in the [retrieval series](./readme.md) are great considerations even with the matching workload moved to Vertex AI Vector Search for low latency at scale.\n",
    "\n",
    "To complete this workflow a local lookup is create to retrieve the text from the matching results. Make a dictionary for each lookup of chunk content by chunk id:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d18f1eb4-8c65-451b-a551-496a67845a6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chunk_lookup = {}\n",
    "for chunk in content_chunks:\n",
    "    chunk_lookup[chunk['chunk_id']] = chunk['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "704584ed-8fc6-4ebf-9f88-d5108ea3fa90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Selling Guide Fannie Mae Single Family\n",
      "\n",
      "## Fannie Mae Copyright Notice\n",
      "\n",
      "### Fannie Mae Copyright Notice\n",
      "\n",
      "|-|\n",
      "| Section B3-4.2, Verification of Depository Assets 402 |\n",
      "| B3-4.2-01, Verification of Deposits and Assets (05/04/2022) 403 |\n",
      "| B3-4.2-02, Depository Accounts (12/14/2022) 405 |\n",
      "| B3-4.2-03, Individual Development Accounts (02/06/2019) 408 |\n",
      "| B3-4.2-04, Pooled Savings (Community Savings Funds) (04/01/2009) 411 |\n",
      "| B3-4.2-05, Foreign Assets (05/04/2022) 411 |\n",
      "| Section B3-4.3, Verification of Non-Depository Assets 412 |\n",
      "| B3-4.3-01, Stocks, Stock Options, Bonds, and Mutual Funds (06/30/2015) 412 |\n",
      "| B3-4.3-02, Trust Accounts (04/01/2009) 413 |\n",
      "| B3-4.3-03, Retirement Accounts (06/30/2015) 414 |\n",
      "| B3-4.3-04, Personal Gifts (09/06/2023) 415 |\n",
      "| B3-4.3-05, Gifts of Equity (10/07/2020) 418 |\n",
      "| B3-4.3-06, Grants and Lender Contributions (12/14/2022) 419 |\n",
      "| B3-4.3-07, Disaster Relief Grants or Loans (04/01/2009) 423 |\n",
      "| B3-4.3-08, Employer Assistance (09/29/2015) 423 |\n",
      "| B3-4.3-09, Earnest Money Deposit (05/04/2022) 425 |\n",
      "| B3-4.3-10, Anticipated Sales Proceeds (02/23/2016) B3-4.3-11, Trade Equity (12/16/2020) 426 428 |\n",
      "| B3-4.3-12, Rent-Related Credits (08/07/2024) 429 |\n",
      "| B3-4.3-13, Sweat Equity (04/15/2014) 430 |\n",
      "| B3-4.3-14, Bridge/Swing Loans (04/01/2009) 431 |\n",
      "| B3-4.3-15, Borrowed Funds Secured by an Asset (10/30/2009) 431 |\n",
      "|  |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(chunk_lookup['fannie_part_0_c17'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a57123d-54e9-42bd-b715-bc3b7e5cdcff",
   "metadata": {},
   "source": [
    "---\n",
    "## Retrieval Augmented Generation (RAG)\n",
    "\n",
    "Build a simple retrieval augmented generation process that enhances a query by retrieving context.  This is done here by constructing three functions for the stages:\n",
    "- `retrieve` - a function that uses an embedding to search for matching context parts, pieces of texts\n",
    "    - this uses the system built earlier in this workflow!\n",
    "- `augment` - prepare chunks into a prompt\n",
    "- `generate` - make the llm request with the augmented prompt\n",
    "\n",
    "A final function is used to execute the workflow of rag:\n",
    "- `rag` - a function that receives the query an orchestrates the workflow through `retrieve` > `augment` > `generate`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21f505d-9623-4010-aea7-28bd03dec019",
   "metadata": {},
   "source": [
    "### Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ce694739-21c9-4822-9560-d1b218dd6658",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedder = vertexai.language_models.TextEmbeddingModel.from_pretrained('text-embedding-004')\n",
    "llm = vertexai.generative_models.GenerativeModel(\"gemini-1.5-flash-002\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e62d3e-9051-4c81-ac44-2b35cf25dc71",
   "metadata": {},
   "source": [
    "### Retrieve Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3e9c0686-4ced-42a8-b1ff-7967d06199f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def retrieve_vectorsearch(query_embedding, n_matches = 5):\n",
    "\n",
    "    results = vs_endpoint.find_neighbors(\n",
    "        deployed_index_id = vs_index_tree_ah.display_name.replace('-', '_'),\n",
    "        queries = [query_embedding],\n",
    "        num_neighbors = n_matches\n",
    "    )\n",
    "    matches = []\n",
    "    for result in results[0]:\n",
    "        matches.append(dict(chunk_id = result.id, content = chunk_lookup[result.id]))\n",
    "    \n",
    "    return matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421a34f3-b72c-4363-8eef-f2d9299e9d62",
   "metadata": {},
   "source": [
    "### Augment Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c76bbfae-c518-430e-8098-b062c24cd87b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def augment(matches):\n",
    "\n",
    "    prompt = ''\n",
    "    for m, match in enumerate(matches):\n",
    "        prompt += f\"Context {m+1}:\\n{match['content']}\\n\\n\"\n",
    "    prompt += f'Answer the following question using the provided contexts:\\n'\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103e0c14-d4b2-4c5d-8f63-24d1e991658c",
   "metadata": {},
   "source": [
    "### Generate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "415c568c-66ab-4258-87bb-f6d422d57852",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate(prompt):\n",
    "\n",
    "    result = llm.generate_content(prompt)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55514bf2-983c-435e-9f62-7b7c1827fad6",
   "metadata": {},
   "source": [
    "### RAG Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "435bbc24-3435-4625-a835-79f88cfa8dd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    \n",
    "    query_embedding = embedder.get_embeddings([query])[0].values\n",
    "    matches = retrieve_vectorsearch(query_embedding)\n",
    "    prompt = augment(matches) + query\n",
    "    result = generate(prompt)\n",
    "    \n",
    "    return result.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a4a75d-30de-4781-b118-45dc0756f428",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Example In Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "bb606305-db98-40d4-8e2a-ed78e761775b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Does a lender have to perform servicing functions directly?'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6f1a0363-6960-4915-95d8-730617e2654a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No, a lender does not have to perform servicing functions directly.  Context 1 explicitly states that a lender \"may use other organizations to perform some or all of its servicing functions,\" referring to these arrangements as \"subservicing.\"  This is further elaborated upon in Context 4, which details the requirements for such subservicing arrangements, including the involvement of a \"master servicer\" and \"subservicer.\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(rag(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa660f4-ed0a-41a7-a29d-89f80d5099e4",
   "metadata": {},
   "source": [
    "---\n",
    "### Profiling Performance\n",
    "\n",
    "Profile the timing of each step in the RAG function for sequential calls. The environment choosen for this workflow is a minimal testing enviornment so load testing (simoultaneous requests) would not be helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "26d6e2ce-42ed-45a6-882f-b065d53fe3cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "profile = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f389636b-1ef9-4a24-aa19-b2f3d8a6e229",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rag(query, profile = profile):\n",
    "    \n",
    "    timings = {}\n",
    "    start_time = time.time()\n",
    "    \n",
    "    \n",
    "    # 1. Get embeddings\n",
    "    embedding_start = time.time()\n",
    "    query_embedding = embedder.get_embeddings([query])[0].values\n",
    "    timings['embedding'] = time.time() - embedding_start\n",
    "\n",
    "    # 2. Retrieve from Bigtable\n",
    "    retrieval_start = time.time()\n",
    "    matches = retrieve_vectorsearch(query_embedding)\n",
    "    timings['retrieve_vectorsearch'] = time.time() - retrieval_start\n",
    "\n",
    "    # 3. Augment the prompt\n",
    "    augment_start = time.time()\n",
    "    prompt = augment(matches) + query\n",
    "    timings['augment'] = time.time() - augment_start\n",
    "\n",
    "    # 4. Generate text\n",
    "    generate_start = time.time()\n",
    "    result = generate(prompt)\n",
    "    timings['generate'] = time.time() - generate_start\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    timings['total'] = total_time\n",
    "    \n",
    "    profile.append(timings)\n",
    "    \n",
    "    return result.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "64cfe518-9eb1-412b-b92e-09238bfe2f32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No, a lender does not have to perform servicing functions directly.  Context 1 explicitly states that a lender may use other organizations (subservicers) to perform some or all of its servicing functions.  However, the lender (master servicer) remains contractually responsible.  The contexts also detail the requirements and regulations surrounding these subservicing arrangements.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(rag(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ebec47f1-3408-4179-bc3c-ff91752d98a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'embedding': 0.12130165100097656,\n",
       "  'retrieve_vectorsearch': 0.1281721591949463,\n",
       "  'augment': 8.392333984375e-05,\n",
       "  'generate': 0.6835165023803711,\n",
       "  'total': 0.9330816268920898}]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "af940f34-c651-4d1c-9b02-02c1f0f4c20b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    response = rag(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276361d0-a68c-402f-b424-0141d37ffe7b",
   "metadata": {},
   "source": [
    "### Report From Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "84ff3366-1d8c-4a08-9cd1-3e12bda46e8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_timings = {}\n",
    "for timings in profile:\n",
    "    for key, value in timings.items():\n",
    "        if key not in all_timings:\n",
    "            all_timings[key] = []\n",
    "        all_timings[key].append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ed1770df-2367-432b-9b12-11d04a77896a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for 'embedding':\n",
      "  Min: 0.0486 seconds\n",
      "  Max: 0.2425 seconds\n",
      "  Mean: 0.0594 seconds\n",
      "  Median: 0.0539 seconds\n",
      "  Std Dev: 0.0261 seconds\n",
      "  P95: 0.0686 seconds\n",
      "  P99: 0.2007 seconds\n",
      "\n",
      "Statistics for 'retrieve_vectorsearch':\n",
      "  Min: 0.0144 seconds\n",
      "  Max: 0.1282 seconds\n",
      "  Mean: 0.0281 seconds\n",
      "  Median: 0.0170 seconds\n",
      "  Std Dev: 0.0222 seconds\n",
      "  P95: 0.0681 seconds\n",
      "  P99: 0.0945 seconds\n",
      "\n",
      "Statistics for 'augment':\n",
      "  Min: 0.0000 seconds\n",
      "  Max: 0.0002 seconds\n",
      "  Mean: 0.0000 seconds\n",
      "  Median: 0.0000 seconds\n",
      "  Std Dev: 0.0000 seconds\n",
      "  P95: 0.0000 seconds\n",
      "  P99: 0.0001 seconds\n",
      "\n",
      "Statistics for 'generate':\n",
      "  Min: 0.5378 seconds\n",
      "  Max: 1.0081 seconds\n",
      "  Mean: 0.7164 seconds\n",
      "  Median: 0.6899 seconds\n",
      "  Std Dev: 0.0876 seconds\n",
      "  P95: 0.8760 seconds\n",
      "  P99: 0.9957 seconds\n",
      "\n",
      "Statistics for 'total':\n",
      "  Min: 0.6034 seconds\n",
      "  Max: 1.3015 seconds\n",
      "  Mean: 0.8039 seconds\n",
      "  Median: 0.7798 seconds\n",
      "  Std Dev: 0.1014 seconds\n",
      "  P95: 0.9703 seconds\n",
      "  P99: 1.0836 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, values in all_timings.items():\n",
    "    arr = np.array(values)\n",
    "    print(f\"Statistics for '{key}':\")\n",
    "    print(f\"  Min: {np.min(arr):.4f} seconds\")\n",
    "    print(f\"  Max: {np.max(arr):.4f} seconds\")\n",
    "    print(f\"  Mean: {np.mean(arr):.4f} seconds\")\n",
    "    print(f\"  Median: {np.median(arr):.4f} seconds\")\n",
    "    print(f\"  Std Dev: {np.std(arr):.4f} seconds\")\n",
    "    print(f\"  P95: {np.percentile(arr, 95):.4f} seconds\")\n",
    "    print(f\"  P99: {np.percentile(arr, 99):.4f} seconds\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226cad1b-18f5-4120-87e5-b6af492988ed",
   "metadata": {},
   "source": [
    "---\n",
    "## Remove Resources\n",
    "\n",
    "The resources created above in GCS and Vertex AI Vector Search will persist unless deleted.  The Vector Search Endpoint deployments have ongoing costs even if not used so it might be desirable to remove it here.  Uncomment lines in the following cells to remove resources:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a036f5a-7d73-4ac3-98ca-00a61693d698",
   "metadata": {},
   "source": [
    "Undeploy Indexes created above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "be79bbdf-0af6-4af4-ad16-6eda0e0c3ead",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undeploying index MatchingEngineIndexEndpoint index_endpoint: projects/1026793852137/locations/us-central1/indexEndpoints/5654176973186924544\n",
      "Undeploy index MatchingEngineIndexEndpoint index_endpoint backing LRO: projects/1026793852137/locations/us-central1/indexEndpoints/5654176973186924544/operations/8009166674693455872\n",
      "MatchingEngineIndexEndpoint index_endpoint Undeployed index. Resource name: projects/1026793852137/locations/us-central1/indexEndpoints/5654176973186924544\n",
      "Undeploying index MatchingEngineIndexEndpoint index_endpoint: projects/1026793852137/locations/us-central1/indexEndpoints/5654176973186924544\n",
      "Undeploy index MatchingEngineIndexEndpoint index_endpoint backing LRO: projects/1026793852137/locations/us-central1/indexEndpoints/5654176973186924544/operations/1938314376998027264\n",
      "MatchingEngineIndexEndpoint index_endpoint Undeployed index. Resource name: projects/1026793852137/locations/us-central1/indexEndpoints/5654176973186924544\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.matching_engine.matching_engine_index_endpoint.MatchingEngineIndexEndpoint object at 0x7f6c9185d270> \n",
       "resource name: projects/1026793852137/locations/us-central1/indexEndpoints/5654176973186924544"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vs_endpoint.undeploy_index(deployed_index_id = vs_index_tree_ah.display_name.replace('-', '_'))\n",
    "#vs_endpoint.undeploy_index(deployed_index_id = vs_index_brute_force.display_name.replace('-', '_'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611aec36-5206-4d14-86bd-cbe62cfcb7e2",
   "metadata": {},
   "source": [
    "Delete the Vertex AI Vector Search Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ecf02fcd-5577-439f-8a29-a5843e67c07b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting MatchingEngineIndexEndpoint : projects/1026793852137/locations/us-central1/indexEndpoints/5654176973186924544\n",
      "MatchingEngineIndexEndpoint deleted. . Resource name: projects/1026793852137/locations/us-central1/indexEndpoints/5654176973186924544\n",
      "Deleting MatchingEngineIndexEndpoint resource: projects/1026793852137/locations/us-central1/indexEndpoints/5654176973186924544\n",
      "Delete MatchingEngineIndexEndpoint backing LRO: projects/1026793852137/locations/us-central1/indexEndpoints/5654176973186924544/operations/7011619357230891008\n",
      "MatchingEngineIndexEndpoint resource projects/1026793852137/locations/us-central1/indexEndpoints/5654176973186924544 deleted.\n"
     ]
    }
   ],
   "source": [
    "#vs_endpoint.delete(force = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ccbe71-7763-4514-8f65-79759fd90d18",
   "metadata": {},
   "source": [
    "Delete the indexes created above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8f0265db-d840-484d-987b-9a0e79d983e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting MatchingEngineIndex : projects/1026793852137/locations/us-central1/indexes/2418270272177045504\n",
      "MatchingEngineIndex deleted. . Resource name: projects/1026793852137/locations/us-central1/indexes/2418270272177045504\n",
      "Deleting MatchingEngineIndex resource: projects/1026793852137/locations/us-central1/indexes/2418270272177045504\n",
      "Delete MatchingEngineIndex backing LRO: projects/1026793852137/locations/us-central1/indexes/2418270272177045504/operations/3193692773127553024\n",
      "MatchingEngineIndex resource projects/1026793852137/locations/us-central1/indexes/2418270272177045504 deleted.\n",
      "Deleting MatchingEngineIndex : projects/1026793852137/locations/us-central1/indexes/1855742531220799488\n",
      "MatchingEngineIndex deleted. . Resource name: projects/1026793852137/locations/us-central1/indexes/1855742531220799488\n",
      "Deleting MatchingEngineIndex resource: projects/1026793852137/locations/us-central1/indexes/1855742531220799488\n",
      "Delete MatchingEngineIndex backing LRO: projects/1026793852137/locations/us-central1/indexes/1855742531220799488/operations/4755315943918272512\n",
      "MatchingEngineIndex resource projects/1026793852137/locations/us-central1/indexes/1855742531220799488 deleted.\n"
     ]
    }
   ],
   "source": [
    "#vs_index_tree_ah.delete()\n",
    "#vs_index_brute_force.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b536529d-e7d9-4f29-8c95-6bb0e556bb47",
   "metadata": {
    "tags": []
   },
   "source": [
    "Delete the gcs content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a5c54fe3-52b9-4cec-97cf-6032c188f9ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#blobs = bucket.list_blobs(prefix = f\"{SERIES}/{EXPERIMENT}\")\n",
    "#for blob in blobs:\n",
    "#    blob.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc881805-3553-46f7-97f4-e7c2c20fc34e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
