{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e89180c9",
   "metadata": {},
   "source": [
    "![tracker](https://us-central1-vertex-ai-mlops-369716.cloudfunctions.net/pixel-tracking?path=statmike%2Fvertex-ai-mlops%2FApplied+GenAI%2FRetrieval&file=Retrieval+-+Firestore.ipynb)\n",
    "<!--- header table --->\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/statmike/vertex-ai-mlops/blob/main/Applied%20GenAI/Retrieval/Retrieval%20-%20Firestore.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\">\n",
    "      <br>Run in<br>Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https%3A%2F%2Fraw.githubusercontent.com%2Fstatmike%2Fvertex-ai-mlops%2Fmain%2FApplied%2520GenAI%2FRetrieval%2FRetrieval%2520-%2520Firestore.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\">\n",
    "      <br>Run in<br>Colab Enterprise\n",
    "    </a>\n",
    "  </td>      \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/statmike/vertex-ai-mlops/blob/main/Applied%20GenAI/Retrieval/Retrieval%20-%20Firestore.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      <br>View on<br>GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/statmike/vertex-ai-mlops/main/Applied%20GenAI/Retrieval/Retrieval%20-%20Firestore.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      <br>Open in<br>Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b0e8e6-d761-4540-9d09-8f0c4ce9a020",
   "metadata": {},
   "source": [
    "# Retrieval - Firestore\n",
    "\n",
    "In prior workflows, a series of documents was [processed into chunks](../Chunking/readme.md), and for each chunk, [embeddings](../Embeddings/readme.md) were created:\n",
    "\n",
    "- Process: [Large Document Processing - Document AI Layout Parser](../Chunking/Large%20Document%20Processing%20-%20Document%20AI%20Layout%20Parser.ipynb)\n",
    "- Embed: [Vertex AI Text Embeddings API](../Embeddings/Vertex%20AI%20Text%20Embeddings%20API.ipynb)\n",
    "\n",
    "Retrieving chunks for a query involves calculating the embedding for the query and then using similarity metrics to find relevant chunks. A thorough review of similarity matching can be found in [The Math of Similarity](../Embeddings/The%20Math%20of%20Similarity.ipynb) - use dot product! As development moves from experiment to application, the process of storing and computing similarity is migrated to a [retrieval](./readme.md) system. This workflow is part of a [series of workflows exploring many retrieval systems](./readme.md).  \n",
    "\n",
    "A detailed [comparison of many retrieval systems](./readme.md#comparison-of-vector-database-solutions) can be found in the readme as well.\n",
    "\n",
    "---\n",
    "\n",
    "**Firestore For Storage, Indexing, And Search**\n",
    "\n",
    "[Firestore](https://cloud.google.com/firestore) is a fully managed, serverless document database on Google Cloud that scales automatically to meet any demand, without requiring partitioning or incurring downtime. It's ideal for mobile, web, and server development because it keeps data in sync across client apps with real-time listeners and offers offline support for mobile and web.\n",
    "\n",
    "- **Data Model:**  Firestore stores data in documents (similar to JSON) comprised of key-value pairs.  Keys (fields) are mapped to values of various supported data types. ([see the full list here](https://cloud.google.com/firestore/docs/concepts/data-types?hl=en)) ([Learn more about the data model](https://cloud.google.com/firestore/docs/data-model?hl=en))\n",
    "- **Flexible Structure:** Data is organized in a hierarchical structure where collections contain documents. Documents can be nested objects, and collections can have subcollections, providing flexibility in how you structure your data.\n",
    "- **BigQuery Integration:**  Firestore integrates directly with BigQuery, allowing you to stream data into BigQuery or export query results to Firestore. ([Learn more about BigQuery integration](https://cloud.google.com/firestore/docs/solutions/bigquery?hl=en))\n",
    "- **Generative AI Features:** Firestore offers integrated GenAI features, such as generating text embeddings and seamless integration with LangChain.\n",
    "- **Vector Similarity Search:** Firestore provides built-in vector similarity search with indexing for efficient nearest neighbor matching. ([Learn more about vector search](https://cloud.google.com/firestore/docs/vector-search?hl=en))\n",
    "\n",
    "---\n",
    "\n",
    "**Use Case Data**\n",
    "\n",
    "Buying a home usually involves borrowing money from a lending institution, typically through a mortgage secured by the home's value. But how do these institutions manage the risks associated with such large loans, and how are lending standards established?\n",
    "\n",
    "In the United States, two government-sponsored enterprises (GSEs) play a vital role in the housing market:\n",
    "\n",
    "- Federal National Mortgage Association ([Fannie Mae](https://www.fanniemae.com/))\n",
    "- Federal Home Loan Mortgage Corporation ([Freddie Mac](https://www.freddiemac.com/))\n",
    "\n",
    "These GSEs purchase mortgages from lenders, enabling those lenders to offer more loans. This process also allows Fannie Mae and Freddie Mac to set standards for mortgages, ensuring they are responsible and borrowers are more likely to repay them. This system makes homeownership more affordable and stabilizes the housing market by maintaining a steady flow of liquidity for lenders and keeping interest rates controlled.\n",
    "\n",
    "However, navigating the complexities of these GSEs and their extensive servicing guides can be challenging.\n",
    "\n",
    "**Approaches**\n",
    "\n",
    "[This series](../readme.md) covers many generative AI workflows. These documents are used directly as long context for Gemini in the workflow [Long Context Retrieval With The Vertex AI Gemini API](../Generate/Long%20Context%20Retrieval%20With%20The%20Vertex%20AI%20Gemini%20API.ipynb). The workflow below uses a [retrieval](./readme.md) approach with the already generated chunks and embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be889472-69b0-416c-9cf1-edc9706fa5c5",
   "metadata": {
    "id": "od_UkDpvRmgD"
   },
   "source": [
    "---\n",
    "## Colab Setup\n",
    "\n",
    "When running this notebook in [Colab](https://colab.google/) or [Colab Enterprise](https://cloud.google.com/colab/docs/introduction), this section will authenticate to GCP (follow prompts in the popup) and set the current project for the session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21f75ba8-df50-466e-a5ec-f2a6dd88eb26",
   "metadata": {
    "executionInfo": {
     "elapsed": 195,
     "status": "ok",
     "timestamp": 1683726184843,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "8UO9FnqyKBlF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'statmike-mlops-349915' # replace with project ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c325515-1ea0-45cc-82d3-a1bfb1c52155",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68869,
     "status": "ok",
     "timestamp": 1683726253709,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "N98-KK7LRkjm",
    "outputId": "09ec5008-0def-4e1a-c349-c598ee752f78",
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    !gcloud config set project {PROJECT_ID}\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055a4bd7-7b47-43ef-ba14-636c955e44e3",
   "metadata": {},
   "source": [
    "---\n",
    "## Installs and API Enablement\n",
    "\n",
    "The clients packages may need installing in this environment. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410502ee-6fe3-4624-a69a-960ad7105f10",
   "metadata": {},
   "source": [
    "### Installs (If Needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4dbdb83-3170-430c-b60d-3d686222a168",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tuples of (import name, install name, min_version)\n",
    "packages = [\n",
    "    ('google.cloud.aiplatform', 'google-cloud-aiplatform', '1.69.0'),\n",
    "    ('google.cloud.firestore', 'google-cloud-firestore')\n",
    "]\n",
    "\n",
    "import importlib\n",
    "install = False\n",
    "for package in packages:\n",
    "    if not importlib.util.find_spec(package[0]):\n",
    "        print(f'installing package {package[1]}')\n",
    "        install = True\n",
    "        !pip install {package[1]} -U -q --user\n",
    "    elif len(package) == 3:\n",
    "        if importlib.metadata.version(package[0]) < package[2]:\n",
    "            print(f'updating package {package[1]}')\n",
    "            install = True\n",
    "            !pip install {package[1]} -U -q --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25374857-7d37-4c84-8cbb-a3c2fc7bb065",
   "metadata": {},
   "source": [
    "### API Enablement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b7300a8-7e3a-4a08-95c0-91186237753f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gcloud services enable aiplatform.googleapis.com\n",
    "!gcloud services enable firestore.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157d09ba-9774-495f-8ced-3382bf75be8f",
   "metadata": {},
   "source": [
    "### Restart Kernel (If Installs Occured)\n",
    "\n",
    "After a kernel restart the code submission can start with the next cell after this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9864153-66c8-43e1-ae96-1179632ccf7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if install:\n",
    "    import IPython\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)\n",
    "    IPython.display.display(IPython.display.Markdown(\"\"\"<div class=\\\"alert alert-block alert-warning\\\">\n",
    "        <b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. The previous cells do not need to be run again⚠️</b>\n",
    "        </div>\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a1ab41-cb32-4398-86dc-d30effb88a36",
   "metadata": {
    "id": "appt8-yVRtJ1"
   },
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cebe11b-9ca1-4f3e-aa78-78640ff01ec8",
   "metadata": {
    "id": "63mx2EozRxFP"
   },
   "source": [
    "Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab2239cd-40ab-416d-bac0-0c6953d911b6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 2124,
     "status": "ok",
     "timestamp": 1683726390544,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "xzcoXjM5Rky5",
    "outputId": "b3bdcbc1-70d5-472e-aea2-42c74a42efde",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'statmike-mlops-349915'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8aa97f05-66e9-4276-b2e6-83b5a91ca50c",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1683726390712,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "IxWrFtqYMfku",
    "tags": []
   },
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "SERIES = 'applied-genai'\n",
    "EXPERIMENT = 'retrieval-firestore'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bbf65b-5d29-4a72-84ae-d977b9a743a6",
   "metadata": {
    "id": "LuajVwCiO6Yg"
   },
   "source": [
    "Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "559f6e60-a594-4789-893b-295a8381b670",
   "metadata": {
    "executionInfo": {
     "elapsed": 17761,
     "status": "ok",
     "timestamp": 1683726409304,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "LVC7zzSLRk2C",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, json, time, glob, datetime, asyncio\n",
    "\n",
    "# Vertex AI\n",
    "from google.cloud import aiplatform\n",
    "import vertexai.language_models # for embeddings API\n",
    "import vertexai.generative_models # for Gemini Models\n",
    "from vertexai.resources.preview import feature_store\n",
    "\n",
    "# firestore\n",
    "from google.cloud import firestore\n",
    "from google.cloud import firestore_v1\n",
    "from google.cloud import firestore_admin_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3fef31f-928f-45f2-a3f4-292ee242232c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.71.0'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aiplatform.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5758c07e-f064-40fb-a0ef-de6cbde5cd0a",
   "metadata": {
    "id": "EyAVFG9TO9H-"
   },
   "source": [
    "Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "3b72f3bb-176b-4678-ba6b-df9b2de14997",
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1683726409306,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "L0RPE13LOZce",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vertex ai clients\n",
    "vertexai.init(project = PROJECT_ID, location = REGION)\n",
    "\n",
    "# firestore clients\n",
    "fs = firestore.Client(project = PROJECT_ID)\n",
    "fs_async = firestore.AsyncClient(project = PROJECT_ID)\n",
    "fs_admin = firestore_admin_v1.FirestoreAdminClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8579282f-2723-4294-b72a-a65cc0831f44",
   "metadata": {},
   "source": [
    "---\n",
    "## Text & Embeddings For Examples\n",
    "\n",
    "This repository contains a [section for document processing (chunking)](../Chunking/readme.md) that includes an example of processing mulitple large pdfs (over 1000 pages) into chunks: [Large Document Processing - Document AI Layout Parser](../Chunking/Large%20Document%20Processing%20-%20Document%20AI%20Layout%20Parser.ipynb).  The chunks of text from that workflow are stored with this repository and loaded by another companion workflow that augments the chunks with text embeddings: [Vertex AI Text Embeddings API](../Embeddings/Vertex%20AI%20Text%20Embeddings%20API.ipynb).\n",
    "\n",
    "The following code will load the version of the chunks that includes text embeddings and prepare it for a local example of retrival augmented generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e12cbe2-3ca6-4656-9e73-c0db5c63bf50",
   "metadata": {},
   "source": [
    "### Get The Documents\n",
    "\n",
    "If you are working from a clone of this notebooks [repository](https://github.com/statmike/vertex-ai-mlops) then the documents are already present. The following cell checks for the documents folder and if it is missing gets it (`git clone`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "6f4e77ed-43f7-42be-9575-6a491c0d6cba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "local_dir = '../Embeddings/files/embeddings-api'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "63ebe7c3-e72c-4394-91c3-d60c05bc0ce2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents Found in folder `../Embeddings/files/embeddings-api`\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(local_dir):\n",
    "    print('Retrieving documents...')\n",
    "    parent_dir = os.path.dirname(local_dir)\n",
    "    temp_dir = os.path.join(parent_dir, 'temp')\n",
    "    if not os.path.exists(temp_dir):\n",
    "        os.makedirs(temp_dir)\n",
    "    !git clone https://www.github.com/statmike/vertex-ai-mlops {temp_dir}/vertex-ai-mlops\n",
    "    shutil.copytree(f'{temp_dir}/vertex-ai-mlops/Applied GenAI/Embeddings/files/embeddings-api', local_dir)\n",
    "    shutil.rmtree(temp_dir)\n",
    "    print(f'Documents are now in folder `{local_dir}`')\n",
    "else:\n",
    "    print(f'Documents Found in folder `{local_dir}`')             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e68a84-9f88-4590-9ff1-e01c8a953ccf",
   "metadata": {},
   "source": [
    "### Load The Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "58d04382-a74a-44ac-8824-3b46c86aa148",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0000.jsonl',\n",
       " '../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0001.jsonl',\n",
       " '../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0002.jsonl',\n",
       " '../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0003.jsonl',\n",
       " '../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0004.jsonl',\n",
       " '../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0005.jsonl',\n",
       " '../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0006.jsonl',\n",
       " '../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0007.jsonl',\n",
       " '../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0008.jsonl',\n",
       " '../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0009.jsonl']"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonl_files = glob.glob(f\"{local_dir}/large-files*.jsonl\")\n",
    "jsonl_files.sort()\n",
    "jsonl_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "a54c6c96-6c28-49bb-80be-5d46797dfe77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9040"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = []\n",
    "for file in jsonl_files:\n",
    "    with open(file, 'r') as f:\n",
    "        chunks.extend([json.loads(line) for line in f])\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70115ec-6d60-41df-b7e6-9e2e5b463b1d",
   "metadata": {},
   "source": [
    "### Review A Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "fc20423e-e3d6-4e90-9e98-a5248508c82d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['instance', 'predictions', 'status'])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "1955ea39-4ffc-4d30-b653-a5a9911f2dab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fannie_part_0_c17'"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0]['instance']['chunk_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "3537982c-4a0e-456c-a652-19ea7507873b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Selling Guide Fannie Mae Single Family\n",
      "\n",
      "## Fannie Mae Copyright Notice\n",
      "\n",
      "### Fannie Mae Copyright Notice\n",
      "\n",
      "|-|\n",
      "| Section B3-4.2, Verification of Depository Assets 402 |\n",
      "| B3-4.2-01, Verification of Deposits and Assets (05/04/2022) 403 |\n",
      "| B3-4.2-02, Depository Accounts (12/14/2022) 405 |\n",
      "| B3-4.2-03, Individual Development Accounts (02/06/2019) 408 |\n",
      "| B3-4.2-04, Pooled Savings (Community Savings Funds) (04/01/2009) 411 |\n",
      "| B3-4.2-05, Foreign Assets (05/04/2022) 411 |\n",
      "| Section B3-4.3, Verification of Non-Depository Assets 412 |\n",
      "| B3-4.3-01, Stocks, Stock Options, Bonds, and Mutual Funds (06/30/2015) 412 |\n",
      "| B3-4.3-02, Trust Accounts (04/01/2009) 413 |\n",
      "| B3-4.3-03, Retirement Accounts (06/30/2015) 414 |\n",
      "| B3-4.3-04, Personal Gifts (09/06/2023) 415 |\n",
      "| B3-4.3-05, Gifts of Equity (10/07/2020) 418 |\n",
      "| B3-4.3-06, Grants and Lender Contributions (12/14/2022) 419 |\n",
      "| B3-4.3-07, Disaster Relief Grants or Loans (04/01/2009) 423 |\n",
      "| B3-4.3-08, Employer Assistance (09/29/2015) 423 |\n",
      "| B3-4.3-09, Earnest Money Deposit (05/04/2022) 425 |\n",
      "| B3-4.3-10, Anticipated Sales Proceeds (02/23/2016) B3-4.3-11, Trade Equity (12/16/2020) 426 428 |\n",
      "| B3-4.3-12, Rent-Related Credits (08/07/2024) 429 |\n",
      "| B3-4.3-13, Sweat Equity (04/15/2014) 430 |\n",
      "| B3-4.3-14, Bridge/Swing Loans (04/01/2009) 431 |\n",
      "| B3-4.3-15, Borrowed Funds Secured by an Asset (10/30/2009) 431 |\n",
      "|  |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(chunks[0]['instance']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "49f06293-a439-436b-bc93-cd6cd3fb4aff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.031277116388082504,\n",
       " 0.03056905046105385,\n",
       " 0.010865348391234875,\n",
       " 0.0623614676296711,\n",
       " 0.03228681534528732,\n",
       " 0.05066155269742012,\n",
       " 0.046544693410396576,\n",
       " 0.05509665608406067,\n",
       " -0.014074751175940037,\n",
       " 0.008380400016903877]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0]['predictions'][0]['embeddings']['values'][0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f977358d-d9ea-4172-9eca-66079bb6087d",
   "metadata": {},
   "source": [
    "### Prepare Chunk Structure\n",
    "\n",
    "Make a list of dictionaries with information for each chunk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "be9fa708-130c-4343-b179-dbde0b09a972",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "content_chunks = [\n",
    "    dict(\n",
    "        gse = chunk['instance']['gse'],\n",
    "        chunk_id = chunk['instance']['chunk_id'],\n",
    "        content = chunk['instance']['content'],\n",
    "        embedding = chunk['predictions'][0]['embeddings']['values']\n",
    "    ) for chunk in chunks\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6619605-7b10-444e-a131-db06e56a4be8",
   "metadata": {},
   "source": [
    "### Query Embedding\n",
    "\n",
    "Create a query, or prompt, and get the embedding for it:\n",
    "\n",
    "Connect to models for text embeddings. Learn more about the model API:\n",
    "- [Vertex AI Text Embeddings API](../Embeddings/Vertex%20AI%20Text%20Embeddings%20API.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "3da5d30c-3dfb-42ba-a133-83dceb252787",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question = \"Does a lender have to perform servicing functions directly?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "7992c26f-d058-4920-80a3-a157b88733e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedder = vertexai.language_models.TextEmbeddingModel.from_pretrained('text-embedding-004')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "bbe6fda7-9cea-49a2-9e2f-9222d50677af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.0005117303808219731,\n",
       " 0.009651427157223225,\n",
       " 0.01768726110458374,\n",
       " 0.014538003131747246,\n",
       " -0.01829824410378933,\n",
       " 0.027877431362867355,\n",
       " -0.021124685183167458,\n",
       " 0.008830446749925613,\n",
       " -0.02669006586074829,\n",
       " 0.06414774805307388]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_embedding = embedder.get_embeddings([question])[0].values\n",
    "question_embedding[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56acb8bf-d0cc-4613-81f4-6d9a74c5a6d3",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup Firestore\n",
    "\n",
    "Firestore is a scalable database for mobile, web, and server development. Scalable because:\n",
    "- there is no need to pre-provision storage, just add documents and pay for what you use\n",
    "- flexibile data model supporting hierarchical structures\n",
    "- multi-region data replication\n",
    "- data synchronization to update data on connected devices\n",
    "- much more!\n",
    "\n",
    "**Firestore Databases**\n",
    "\n",
    "Firestore as a service hosts databases.  Setting up a new database starts with choosing between two modes:\n",
    "- Firestore in Native mode (**used below**)\n",
    "    - scales to millions of concurrent clients.  Great for mobile and web apps.\n",
    "- Firestore in Datastore Mode\n",
    "    - scales to millions of writes per seconds\n",
    "    - backwards compatible with datastore APIs\n",
    "    - no real-time capabilities from Firestore\n",
    "\n",
    "The first database created can be named `(default)` and will have a [free quota tier](https://cloud.google.com/firestore/quotas) for getting started (see pricing next).\n",
    "    \n",
    "**Firestore Pricing**\n",
    "\n",
    "Regardless of the mode choosen [the pricing](https://cloud.google.com/firestore/pricing) is the same and based on size of data stored and network usage (read, write, delete, transfer).  For the `(default)` database you get a [free tier](https://cloud.google.com/firestore/pricing) for stored data, reads, writes, deletes, and data transfers with daily limits. This free tier covers this demonstration workflow as long as the database is named `(default)` and the createion of the database below uses this name.\n",
    "\n",
    "**Firestore Data Structure**\n",
    "\n",
    "Within a database data is stored as **documents**. Think of a document as a dictionary or JSON where there can be many field with values, including nested fields and values (nesting is referred to as a map).  These documents are limits in size to 1MB.  A document has [these supported data types](https://cloud.google.com/firestore/docs/concepts/data-types) which are more expansive than JSON and even include a type for vectors which is used in this workflow.\n",
    "\n",
    "Documents are store in **collections** which are just named containers for a group of documents that make queries simple.  \n",
    "\n",
    "Hierarchies of upto 100 levels can be created in a specific way.  A document can contain a **subcollection** which is just a nested container for group of documents.  The key concept here is that the subcollection must be contained within a document, not directly under a collection or another subcollection.\n",
    "\n",
    "Remember that Firestore is schemaless so documents can have different fields or even the same fields with different data types even if they are in the same collection.  Documents just need unique keys, the name, like an id, and Firestore can create random IDs automatically if needed.\n",
    "\n",
    "**Working With Firestore**\n",
    "\n",
    "Firestore has rich ecosystem of [client libraries](https://cloud.google.com/firestore/docs/reference/libraries) as well as direct HTTP and RPC calls.  There are mobile and web SDK for common environments (Web, iOS+, Android, Flutter).  Then there are server client libraries  in many common languages (C#, Go, Java, Node.js, PHP, Python, and Ruby).  These are accompanied by the Firebase Admin SDK.\n",
    "\n",
    "Here the [Google Cloud Python Client Library for Firestore](https://cloud.google.com/python/docs/reference/firestore/latest/index.html) is used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7840c0-ae8c-4243-9005-0c77db26d699",
   "metadata": {},
   "source": [
    "### Create/Retrieve A Database\n",
    "\n",
    "The starting point for using Firestore is a database.  No preplanning is need for storage size or compute so creating the database is the key point and involved choosing a mode (covered above) and using the name `(default)` for free tier quota.\n",
    "\n",
    "Documentation References:\n",
    "- [Create and manage databases](https://cloud.google.com/firestore/docs/manage-databases)\n",
    "- [Choosing between Native mode and Datastore mode](https://cloud.google.com/firestore/docs/firestore-or-datastore)\n",
    "- [Python Client for Cloud Firestore API](https://cloud.google.com/python/docs/reference/firestore/latest)\n",
    "    - [FirestoreAdminClient](https://cloud.google.com/python/docs/reference/firestore/latest/google.cloud.firestore_admin_v1.services.firestore_admin.client.FirestoreAdminClient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "0efd9f98-2e88-4c2f-b7c8-626981dc2012",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the `default` database: projects/statmike-mlops-349915/databases/(default)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    database = fs_admin.get_database(name = f'projects/{PROJECT_ID}/databases/(default)')\n",
    "    print(f\"Found the `default` database: {database.name}\")\n",
    "except Exception:\n",
    "    print(f\"Creating the `default` database...\")\n",
    "    create_db = fs_admin.create_database(\n",
    "        request = firestore_admin_v1.types.CreateDatabaseRequest(\n",
    "            parent = f\"projects/{PROJECT_ID}\",\n",
    "            database_id = '(default)',\n",
    "            database = firestore_admin_v1.types.database.Database(\n",
    "                type_ = firestore_admin_v1.types.database.Database.DatabaseType.FIRESTORE_NATIVE,\n",
    "                location_id = REGION\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    print('Waiting on creation to complete...')\n",
    "    create_db.result()\n",
    "    database = fs_admin.get_database(name = f'projects/{PROJECT_ID}/databases/(default)')\n",
    "    print(f'Created the `default` database: {database.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "ad91fcf2-7bf2-4ef8-8745-532099b7226a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"projects/statmike-mlops-349915/databases/(default)\"\n",
       "uid: \"b29a6d74-7ad0-4232-9850-519e3471912b\"\n",
       "create_time {\n",
       "  seconds: 1729703138\n",
       "  nanos: 163054000\n",
       "}\n",
       "update_time {\n",
       "  seconds: 1729703138\n",
       "  nanos: 163054000\n",
       "}\n",
       "location_id: \"us-central1\"\n",
       "type_: FIRESTORE_NATIVE\n",
       "concurrency_mode: PESSIMISTIC\n",
       "version_retention_period {\n",
       "  seconds: 3600\n",
       "}\n",
       "earliest_version_time {\n",
       "  seconds: 1731779065\n",
       "  nanos: 660085000\n",
       "}\n",
       "app_engine_integration_mode: DISABLED\n",
       "point_in_time_recovery_enablement: POINT_IN_TIME_RECOVERY_DISABLED\n",
       "delete_protection_state: DELETE_PROTECTION_DISABLED\n",
       "etag: \"IMrH9ZTB4YkDMInatbn+pIkD\""
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ac6c14-e015-461e-9168-f6586359bdeb",
   "metadata": {},
   "source": [
    "---\n",
    "## Working With Firestore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0f59cb-0b88-46ea-90a1-aaaa28af3c98",
   "metadata": {},
   "source": [
    "### Create/Retrieve Collection\n",
    "\n",
    "The client is setup above without a specific database reference which will defer to the `default` database.  Collection can be directly referenced even if they don't exists yet.\n",
    "\n",
    "Documentation References:\n",
    "- [Use a server client library](https://cloud.google.com/firestore/docs/create-database-server-client-library)\n",
    "- [Python Client for Cloud Firestore API](https://cloud.google.com/python/docs/reference/firestore/latest)\n",
    "    - [Firestore Client](https://cloud.google.com/python/docs/reference/firestore/latest/google.cloud.firestore_v1.client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "ee1904dd-fa16-4c31-8814-7afb9af44223",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "collection = fs.collection(f'{SERIES}-{EXPERIMENT}')\n",
    "doc_list = collection.limit(1).get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "62f81b0a-94d6-44fc-9731-fb834a194ddb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'applied-genai-retrieval-firestore' exists.\n"
     ]
    }
   ],
   "source": [
    "if doc_list:\n",
    "    print(f\"Collection '{collection.id}' exists.\")\n",
    "else:\n",
    "    print(f\"Collection '{collection.id}' does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e1039b-28bc-48ba-8e0c-ccf0c2805a02",
   "metadata": {},
   "source": [
    "Delete content from the environment to start this workflow fresh:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "44cee36c-f6f5-45f0-b66b-62707c1d0447",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if doc_list:\n",
    "    clear_collection = fs.recursive_delete(collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe908f65-720e-4135-8bce-4405a3b24f87",
   "metadata": {},
   "source": [
    "### Prepare Data For Firestore\n",
    "\n",
    "Basically, think dictionary or JSON, with `key:value` pairs and nesting is supported (and referred to as a map).  Read more about [data structure](https://cloud.google.com/firestore/docs/concepts/structure-data) and [supported data types](https://cloud.google.com/firestore/docs/concepts/data-types), specifically the vector type that is used to store the embedding vector rather than array which is also supported."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a1b43c-7f8d-4dee-a8fb-1bcc742a9073",
   "metadata": {},
   "source": [
    "#### Get A Record/Document\n",
    "\n",
    "Dictionaries for each record/row are stored in `content_chunks` from earlier in this workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "04ad30ba-0716-48ed-81c9-c8d3001f7362",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "first_record = content_chunks[0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "c7c7ceb2-a99c-4eda-b5cf-0eb02a1fc6e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['gse', 'chunk_id', 'content', 'embedding'])"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_record.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "987e68dc-4f05-48b9-afd4-69600885334f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fannie_part_0_c17'"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_record['chunk_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "6ea922cb-fb36-4995-b1e8-09732467e505",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(first_record['embedding'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da63a19-2529-4ccd-a264-6e0c2baabd69",
   "metadata": {},
   "source": [
    "#### Prepare The Document\n",
    "\n",
    "Convert the embedding array (list of floats) into the `Vector` data type for Firestore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "e62dbbda-150b-4740-bac6-69230a5a07d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "first_record['embedding'] = firestore_v1.vector.Vector(first_record['embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "530ef16a-e94b-44be-b550-bd91e23f8ca0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "google.cloud.firestore_v1.vector.Vector"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(first_record['embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "f38b7ecf-694f-4c04-acb0-3e8e98a2a205",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(first_record['embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "d5850e91-9016-4a6e-b3ad-b5726a8da8f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.031277116388082504,\n",
       " 0.03056905046105385,\n",
       " 0.010865348391234875,\n",
       " 0.0623614676296711,\n",
       " 0.03228681534528732)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_record['embedding'][0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109dcd60-4158-4469-ad9f-7eff2e2e308c",
   "metadata": {},
   "source": [
    "### Add, Retrive, And Delete Documents To The Database>Collection\n",
    "\n",
    "Learn about inserting, retrieving, and deleting records/rows with the following simple examples.\n",
    "\n",
    "From the collection object you can refer to a `.document('name')` object by name, even prior to creating it.  From this document object you can add its data to the database with `.set()`, update its contents with `.update` and remove the document with `.delete()`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7000d3b-7612-44ba-8f24-cf88a52f9cfc",
   "metadata": {},
   "source": [
    "#### Insert Document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "8c526541-112f-465c-a739-9c0af2bd35c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "update_time {\n",
       "  seconds: 1731782673\n",
       "  nanos: 262245000\n",
       "}"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document = collection.document(first_record['chunk_id'])\n",
    "document.set(first_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "8bc00a37-b154-4de1-b368-371195124aaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# alternative - combined steps\n",
    "#collection.document(first_record['chunk_id']).set(first_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0561aaa3-cba0-48f6-81a0-2dcc527aab1e",
   "metadata": {},
   "source": [
    "#### Retrieve Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "e20967b6-d2cf-4c26-94af-f7fb72764c0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "local_document = document.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "706f6394-e3f3-4582-a2b9-7a8f5009424b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['content', 'embedding', 'chunk_id', 'gse'])"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_document = local_document.to_dict()\n",
    "local_document.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "32edb448-d92a-4ba6-8d28-3cef592e6710",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fannie\n"
     ]
    }
   ],
   "source": [
    "print(local_document['gse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "c5b9e434-c40a-4ec3-945c-4d5a19ba48d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "google.cloud.firestore_v1.vector.Vector"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(local_document['embedding'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8ef819-461a-4732-8f39-fb71bbbb1f1e",
   "metadata": {},
   "source": [
    "#### Delete Document Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "ad2c62a8-3eb2-4bb1-8ffb-f9385f665575",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "update_time {\n",
       "  seconds: 1731783297\n",
       "  nanos: 799459000\n",
       "}"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document.update(dict(content = firestore.DELETE_FIELD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "5859551c-2eb0-4138-b5fd-60025ea18b7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "local_document = document.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "d28bc33e-13da-47ed-acf7-b742e20cb5ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['chunk_id', 'embedding', 'gse'])"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_document = local_document.to_dict()\n",
    "local_document.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97e3fed-5ffa-4053-b17b-ecf2753a46a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Delete Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "8cc0a3a4-3a89-43aa-8cb2-02796f0da560",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeWithNanoseconds(2024, 11, 16, 18, 55, 1, 455058, tzinfo=datetime.timezone.utc)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "197184a2-1fb1-497f-9db2-a831db627629",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document.get().exists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95802938-fc31-4343-8666-11076bc0b2b6",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "\n",
    "There are a lot of rows to load but [using `asyncio`](https://docs.python.org/3/library/asyncio.html) with the async connection makes this easy to orchestrate:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8f0373-8cb4-41b0-8937-a26fde3a2b5b",
   "metadata": {},
   "source": [
    "Verify the collection is empty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "f413c76a-e080-44a9-9f4e-e537f52112d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "async_collection = fs_async.collection(f'{SERIES}-{EXPERIMENT}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "c200785b-5cc1-4ed0-bccd-2a0fd74affe4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_list = await async_collection.limit(1).get()\n",
    "len(doc_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120d5c1f-1eb0-4b21-80a3-63bdf50233c9",
   "metadata": {},
   "source": [
    "Prepare the embedding values as `Vector` type for all records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "094e13f7-4de6-4ba7-9c66-57c47de2f0ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for chunk in content_chunks:\n",
    "    if type(chunk['embedding']) == list:\n",
    "        chunk['embedding'] = firestore_v1.vector.Vector(chunk['embedding'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0aa5b93-83e9-4c60-ad98-dc8ac30bd379",
   "metadata": {},
   "source": [
    "Create a list of tasks that will add documents to the collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610db77e-592a-43c7-a160-e2e7549de4ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tasks = [async_collection.document(chunk['chunk_id']).set(chunk) for chunk in content_chunks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc834871-b72a-4028-9fd4-a48d87d7711f",
   "metadata": {},
   "source": [
    "Run all the tasks with `asyncio.gather` and `await` the results: `results = await asyncio.gather(*tasks)`\n",
    "\n",
    "Here, the tasks are run in batches with the following for loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "ca51bcc3-6527-4044-b883-17bbb896a71c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running tasks 1 through 1000...\n",
      "Running tasks 1001 through 2000...\n",
      "Running tasks 2001 through 3000...\n",
      "Running tasks 3001 through 4000...\n",
      "Running tasks 4001 through 5000...\n",
      "Running tasks 5001 through 6000...\n",
      "Running tasks 6001 through 7000...\n",
      "Running tasks 7001 through 8000...\n",
      "Running tasks 8001 through 9000...\n",
      "Running tasks 9001 through 9040...\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for b in range(0, len(tasks), 1000):\n",
    "    batch = tasks[b:b+1000]\n",
    "    print(f\"Running tasks {len(results)+1} through {len(results)+len(batch)}...\")\n",
    "    batch_results = await asyncio.gather(*batch)\n",
    "    results.extend(batch_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f3a8c1-a37c-4831-b615-38be6555aac2",
   "metadata": {},
   "source": [
    "Verify the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "7b055898-5a06-4b81-8114-fcb55d8bb8c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_list = collection.limit(1).get()\n",
    "len(doc_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb052de-bc7d-4f91-a65e-f88d324fd615",
   "metadata": {},
   "source": [
    "---\n",
    "## Vector Similarity Search, Matching\n",
    "\n",
    "This section covers the operation of using a vector similarity metric calculation to find nearest neighbors for a query vector while also taking advantage of indexing.  To understand similarity metrics and motivate the intution for choosing one (choose dot product), check out [The Math of Similarity](../Embeddings/The%20Math%20of%20Similarity.ipynb).\n",
    "\n",
    "\n",
    "**Notes On [Vector Search](https://firebase.google.com/docs/firestore/vector-search) With Firestore**\n",
    "\n",
    "The workflow below shows setting up indexes and using them for vector search.  Searching requires an index to be created. Multiple indexes can be created.  The distance measure is part of the search query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a5c0e6-b8e8-4644-8544-f438a4818cec",
   "metadata": {},
   "source": [
    "### Check For Vector Indexes\n",
    "\n",
    "At this point in the workflow no vector indexes have been created.  The following cells show how to check for indexes and will be reused later in the workflow to verify the details of indexes after they are created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "9de6563e-15bc-4034-aa09-6a3ef59458d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes = list(fs_admin.list_indexes(\n",
    "    parent = f\"{database.name}/collectionGroups/{collection.id}\"\n",
    "))\n",
    "indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27af7d3a-8da5-405e-8fa5-82c4eeff079a",
   "metadata": {},
   "source": [
    "### Create And Use An Index\n",
    "\n",
    "Indexes are the only way to use vector search in Firestore.  Firestore does not offer approximate search methods (IVF, HNSW, ScaNN, etc.) but does offer an index for brute force searches across all rows with an index type named `flat`.\n",
    "\n",
    "Indexes are created on the database with the admin client.  Then, they can be used allong with colletion and the [.find_nearest()](https://firebase.google.com/docs/firestore/vector-search#make_a_nearest-neighbor_query) method.\n",
    "\n",
    "To do pre-filter, searching for neighbors in a subset or documents, a composite index will be needed that includes the field(s) to be used for subsetting as well as the embedding field. The query will automatically use the index matches the query parameters and error out if a suitable index is not available.  The workflow here creates indexs for just embedding as well as embedding with a pre-filter field of `gse`.\n",
    "\n",
    "**Distance Metric Choices**\n",
    "- `DOT_PRODUCT` for inner product or dot product\n",
    "- `COSINE` for cosine similarity\n",
    "- `EUCLIDEAN` for Euclidean distance\n",
    "\n",
    "Documentation Links For This Section:\n",
    "- [Search with vector embeddings](https://firebase.google.com/docs/firestore/vector-search#create_and_manage_vector_indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bd5793-05cb-499a-8b5a-9c4afb4ec612",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Index: Flat (Brute Force) - Just Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9586ec7d-a943-468f-a888-fb4e3082c91f",
   "metadata": {},
   "source": [
    "Check for existing index that has just the embedding field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "81971e4e-591e-4795-ad81-0f12275e1edd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "indexes = list(fs_admin.list_indexes(\n",
    "    parent = f\"{database.name}/collectionGroups/{collection.id}\"\n",
    "))\n",
    "\n",
    "vector_index = next(\n",
    "    (index for index in indexes if {'embedding'} == {field.field_path for field in index.fields if field.field_path != '__name__'}),\n",
    "    None\n",
    ")\n",
    "\n",
    "vector_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8918a2cf-7ee9-4e9c-a3f3-a5a78721d4ec",
   "metadata": {},
   "source": [
    "Create The index if not yet created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "31b71f46-56db-4d28-a94a-58bcce5622c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating an index for just the embedding ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if vector_index:\n",
    "    print(f'Found an index for just the embedding:\\n')\n",
    "else:\n",
    "    print(f'Creating an index for just the embedding ...\\n')\n",
    "    create_index = fs_admin.create_index(\n",
    "        request = firestore_admin_v1.types.CreateIndexRequest(\n",
    "            parent = f\"{database.name}/collectionGroups/{collection.id}\",\n",
    "            index = firestore_admin_v1.types.Index(\n",
    "                query_scope = firestore_admin_v1.types.Index.QueryScope.COLLECTION,\n",
    "                fields = [\n",
    "                    firestore_admin_v1.types.Index.IndexField(\n",
    "                        field_path = 'embedding',\n",
    "                        vector_config = firestore_admin_v1.types.Index.IndexField.VectorConfig(\n",
    "                            dimension = len(question_embedding),\n",
    "                            flat = firestore_admin_v1.types.Index.IndexField.VectorConfig.FlatIndex()\n",
    "                        )\n",
    "                    ),\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    index = create_index.result()\n",
    "    vector_index = fs_admin.get_index(name = index.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cbb788-9cba-439f-851e-d1a21a8da8c9",
   "metadata": {},
   "source": [
    "Review the index details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "b72f0444-3f36-4c44-802e-902732d73e79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"projects/statmike-mlops-349915/databases/(default)/collectionGroups/applied-genai-retrieval-firestore/indexes/CICAgNi47oMK\"\n",
       "query_scope: COLLECTION\n",
       "fields {\n",
       "  field_path: \"__name__\"\n",
       "  order: ASCENDING\n",
       "}\n",
       "fields {\n",
       "  field_path: \"embedding\"\n",
       "  vector_config {\n",
       "    dimension: 768\n",
       "    flat {\n",
       "    }\n",
       "  }\n",
       "}\n",
       "state: READY"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de84bfa-1ca9-47cd-bca6-5f2c29318fac",
   "metadata": {},
   "source": [
    "Query the index for matches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "ce7e1724-4428-4ead-8e0e-b828a9c92492",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "matches = collection.find_nearest(\n",
    "    vector_field = 'embedding',\n",
    "    query_vector = firestore_v1.vector.Vector(question_embedding),\n",
    "    limit = 5,\n",
    "    distance_measure = firestore_v1.base_vector_query.DistanceMeasure.DOT_PRODUCT,\n",
    "    distance_result_field = \"dot_product\"\n",
    ").get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "089dfdb3-4ce9-490b-aa44-a24a25303429",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fannie_part_0_c352', 0.7099842015202704),\n",
       " ('freddie_part_4_c509', 0.6805260859043879),\n",
       " ('freddie_part_4_c510', 0.6753296984114657),\n",
       " ('fannie_part_0_c353', 0.6723706814818051),\n",
       " ('fannie_part_0_c326', 0.6683496311110355)]"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(match.id, match.get('dot_product')) for match in matches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "60a4598b-6964-41e0-80ba-0f8e1a765ce5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fannie'"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches[0].get('gse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "1972b814-6ad6-42c3-87b5-b984d52d8a6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# A3-3-03, Other Servicing Arrangements (12/15/2015)\\n\\nIntroduction This topic provides an overview of other servicing arrangements, including: • Subservicing • General Requirements for Subservicing Arrangements • Pledge of Servicing Rights and Transfer of Interest in Servicing Income\\n\\n## Subservicing\\n\\nA lender may use other organizations to perform some or all of its servicing functions. Fannie Mae refers to these arrangements as “subservicing” arrangements, meaning that a servicer (the “subservicer”) other than the contractually responsible servicer (the “master” servicer) is performing the servicing functions. The following are not considered to be subservicing arrangements: • when a computer service bureau is used to perform accounting and reporting functions; • when the originating lender sells and assigns servicing to another lender, unless the originating lender continues to be the contractually responsible servicer.'"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches[0].to_dict()['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6071580-d6d9-4355-985a-43f8e392746b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Index: Flat (Brute Force) - Composite with Field = `gse`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c493f52-c1f4-4c83-b023-d0bba8a87d0e",
   "metadata": {},
   "source": [
    "Check for existing index that has the embedding field and the gse field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "76165d7c-2dc4-4f88-8aac-40ccc88daf01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "indexes = list(fs_admin.list_indexes(\n",
    "    parent = f\"{database.name}/collectionGroups/{collection.id}\"\n",
    "))\n",
    "\n",
    "composite_index = next(\n",
    "    (index for index in indexes if {'embedding', 'gse'} == {field.field_path for field in index.fields if field.field_path != '__name__'}),\n",
    "    None\n",
    ")\n",
    "\n",
    "composite_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dae059b-72eb-4b13-b494-98a1816e584e",
   "metadata": {},
   "source": [
    "Create The index if not yet created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "b5d4ce86-c59f-444a-beec-d5f73af20a75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a composite index for just the embedding and gse ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if composite_index:\n",
    "    print(f'Found a composite index for the embedding and gse:\\n')\n",
    "else:\n",
    "    print(f'Creating a composite index for just the embedding and gse ...\\n')\n",
    "    create_index = fs_admin.create_index(\n",
    "        request = firestore_admin_v1.types.CreateIndexRequest(\n",
    "            parent = f\"{database.name}/collectionGroups/{collection.id}\",\n",
    "            index = firestore_admin_v1.types.Index(\n",
    "                query_scope = firestore_admin_v1.types.Index.QueryScope.COLLECTION,\n",
    "                fields = [\n",
    "                    firestore_admin_v1.types.Index.IndexField(\n",
    "                        field_path = 'gse',\n",
    "                        order = firestore_admin_v1.types.Index.IndexField.Order.ASCENDING\n",
    "                    ),\n",
    "                    firestore_admin_v1.types.Index.IndexField(\n",
    "                        field_path = 'embedding',\n",
    "                        vector_config = firestore_admin_v1.types.Index.IndexField.VectorConfig(\n",
    "                            dimension = len(question_embedding),\n",
    "                            flat = firestore_admin_v1.types.Index.IndexField.VectorConfig.FlatIndex()\n",
    "                        )\n",
    "                    ),\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    index = create_index.result()\n",
    "    composite_index = fs_admin.get_index(name = index.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01449862-ab52-4e88-b81f-0a7afe55a062",
   "metadata": {},
   "source": [
    "Review the index details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "08326ed7-c62e-4146-9868-342bdb7d10d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"projects/statmike-mlops-349915/databases/(default)/collectionGroups/applied-genai-retrieval-firestore/indexes/CICAgOi36pgK\"\n",
       "query_scope: COLLECTION\n",
       "fields {\n",
       "  field_path: \"gse\"\n",
       "  order: ASCENDING\n",
       "}\n",
       "fields {\n",
       "  field_path: \"__name__\"\n",
       "  order: ASCENDING\n",
       "}\n",
       "fields {\n",
       "  field_path: \"embedding\"\n",
       "  vector_config {\n",
       "    dimension: 768\n",
       "    flat {\n",
       "    }\n",
       "  }\n",
       "}\n",
       "state: READY"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "composite_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21f11f3-0adc-42f0-9327-cde4c9088a07",
   "metadata": {},
   "source": [
    "Query the index for matches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "7348a663-e774-4692-9793-83daaf7c1392",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "matches = collection.find_nearest(\n",
    "    vector_field = 'embedding',\n",
    "    query_vector = firestore_v1.vector.Vector(question_embedding),\n",
    "    limit = 5,\n",
    "    distance_measure = firestore_v1.base_vector_query.DistanceMeasure.DOT_PRODUCT,\n",
    "    distance_result_field = \"dot_product\"\n",
    ").get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "495d3e89-ab47-4a96-a6b6-e77e43bf4161",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fannie_part_0_c352', 0.7099842015202704),\n",
       " ('freddie_part_4_c509', 0.6805260859043879),\n",
       " ('freddie_part_4_c510', 0.6753296984114657),\n",
       " ('fannie_part_0_c353', 0.6723706814818051),\n",
       " ('fannie_part_0_c326', 0.6683496311110355)]"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(match.id, match.get('dot_product')) for match in matches]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eba7089-553e-43ef-b227-c3bb999dda86",
   "metadata": {},
   "source": [
    "Query the index for matches with pre-filtering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "a262aa75-260b-4b98-ba9c-a0c7143c9d11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "matches = collection.where(filter = firestore_v1.base_query.FieldFilter('gse', '==', 'fannie')).find_nearest(\n",
    "    vector_field = 'embedding',\n",
    "    query_vector = firestore_v1.vector.Vector(question_embedding),\n",
    "    limit = 5,\n",
    "    distance_measure = firestore_v1.base_vector_query.DistanceMeasure.DOT_PRODUCT,\n",
    "    distance_result_field = \"dot_product\"\n",
    ").get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "6ac08c6a-89d2-44b4-9654-8a09b8838c55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fannie_part_0_c352', 0.7099842015202704),\n",
       " ('fannie_part_0_c353', 0.6723706814818051),\n",
       " ('fannie_part_0_c326', 0.6683496311110355),\n",
       " ('fannie_part_0_c92', 0.6614337345375677),\n",
       " ('fannie_part_0_c240', 0.6608578617010461)]"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(match.id, match.get('dot_product')) for match in matches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "b7966d20-a91c-4a91-a88c-b6f0b4509441",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fannie'"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches[0].get('gse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "fcbffbd2-207c-4c41-9b7b-252986d3d2f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# A3-3-03, Other Servicing Arrangements (12/15/2015)\\n\\nIntroduction This topic provides an overview of other servicing arrangements, including: • Subservicing • General Requirements for Subservicing Arrangements • Pledge of Servicing Rights and Transfer of Interest in Servicing Income\\n\\n## Subservicing\\n\\nA lender may use other organizations to perform some or all of its servicing functions. Fannie Mae refers to these arrangements as “subservicing” arrangements, meaning that a servicer (the “subservicer”) other than the contractually responsible servicer (the “master” servicer) is performing the servicing functions. The following are not considered to be subservicing arrangements: • when a computer service bureau is used to perform accounting and reporting functions; • when the originating lender sells and assigns servicing to another lender, unless the originating lender continues to be the contractually responsible servicer.'"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches[0].to_dict()['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ece88e-e40f-4a62-a943-192ce4aa0dc9",
   "metadata": {},
   "source": [
    "---\n",
    "## Retrieval Augmented Generation (RAG)\n",
    "\n",
    "Build a simple retrieval augmented generation process that enhances a query by retrieving context.  This is done here by constructing three functions for the stages:\n",
    "- `retrieve` - a function that uses an embedding to search for matching context parts, pieces of texts\n",
    "    - this uses the system built earlier in this workflow!\n",
    "- `augment` - prepare chunks into a prompt\n",
    "- `generate` - make the llm request with the augmented prompt\n",
    "\n",
    "A final function is used to execute the workflow of rag:\n",
    "- `rag` - a function that receives the query an orchestrates the workflow through `retrieve` > `augment` > `generate`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ee73e5-e371-4b2b-9746-fba0c8c470b2",
   "metadata": {},
   "source": [
    "### Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "220a7cea-d225-46d6-8484-e562083c624a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedder = vertexai.language_models.TextEmbeddingModel.from_pretrained('text-embedding-004')\n",
    "llm = vertexai.generative_models.GenerativeModel(\"gemini-1.5-flash-002\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addead45-83dc-4fbd-b0e1-879dae1d5e11",
   "metadata": {},
   "source": [
    "### Retrieve Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "1503e027-b4ac-4a0a-a83d-3fdc0918fa09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def retrieve_firestore(query_embedding, n_matches = 5):\n",
    "\n",
    "    matches = collection.find_nearest(\n",
    "        vector_field = 'embedding',\n",
    "        query_vector = firestore_v1.vector.Vector(query_embedding),\n",
    "        limit = n_matches,\n",
    "        distance_measure = firestore_v1.base_vector_query.DistanceMeasure.DOT_PRODUCT,\n",
    "        distance_result_field = \"dot_product\"\n",
    "    ).get()\n",
    "    matches = [match.to_dict() for match in matches]\n",
    "    \n",
    "    return matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba1e8d4-677f-4c01-b43f-3bbc8898a17b",
   "metadata": {},
   "source": [
    "### Augment Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "5b358751-e058-47a1-a5b4-6c2ac8c8de99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def augment(matches):\n",
    "\n",
    "    prompt = ''\n",
    "    for m, match in enumerate(matches):\n",
    "        prompt += f\"Context {m+1}:\\n{match['content']}\\n\\n\"\n",
    "    prompt += f'Answer the following question using the provided contexts:\\n'\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06090c3-9ec3-4b61-88c3-2a2faa378e17",
   "metadata": {},
   "source": [
    "### Generate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "db657644-6422-4dd5-9650-1d5dc19c49d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate(prompt):\n",
    "\n",
    "    result = llm.generate_content(prompt)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a052d7-eef2-4e97-946c-fd990f1b9a30",
   "metadata": {},
   "source": [
    "### RAG Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "38dd5c9b-6018-42d6-9314-82312ab9c49e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    \n",
    "    query_embedding = embedder.get_embeddings([query])[0].values\n",
    "    matches = retrieve_firestore(query_embedding)\n",
    "    prompt = augment(matches) + query\n",
    "    result = generate(prompt)\n",
    "    \n",
    "    return result.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f816fa-5c15-4591-9881-6819b592fb3f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Example In Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "dcc0238f-eeee-4ecf-b961-e61311a73ddb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Does a lender have to perform servicing functions directly?'"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "b240dde3-2d19-4310-89f6-39de7a6dceaf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No, a lender does not have to perform servicing functions directly.  Context 1 explicitly states that a lender may use other organizations to perform some or all of its servicing functions, referring to this as \"subservicing.\"  The contexts also detail the requirements and regulations surrounding these subservicing arrangements, including the roles of master servicers and subservicers.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(rag(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb2e562-f56d-498c-9259-0edd8d1d4da0",
   "metadata": {},
   "source": [
    "---\n",
    "### Profiling Performance\n",
    "\n",
    "Profile the timing of each step in the RAG function for sequential calls. The environment choosen for this workflow is a minimal testing enviornment so load testing (simoultaneous requests) would not be helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "86066f6c-ab37-4d1b-a5d3-a23ea1744f04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "profile = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "155ad85e-1f8d-4968-8798-b655514283ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rag(query, profile = profile):\n",
    "    \n",
    "    timings = {}\n",
    "    start_time = time.time()\n",
    "    \n",
    "    \n",
    "    # 1. Get embeddings\n",
    "    embedding_start = time.time()\n",
    "    query_embedding = embedder.get_embeddings([query])[0].values\n",
    "    timings['embedding'] = time.time() - embedding_start\n",
    "\n",
    "    # 2. Retrieve from Bigtable\n",
    "    retrieval_start = time.time()\n",
    "    matches = retrieve_firestore(query_embedding)\n",
    "    timings['retrieval_firestore'] = time.time() - retrieval_start\n",
    "\n",
    "    # 3. Augment the prompt\n",
    "    augment_start = time.time()\n",
    "    prompt = augment(matches) + query\n",
    "    timings['augment'] = time.time() - augment_start\n",
    "\n",
    "    # 4. Generate text\n",
    "    generate_start = time.time()\n",
    "    result = generate(prompt)\n",
    "    timings['generate'] = time.time() - generate_start\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    timings['total'] = total_time\n",
    "    \n",
    "    profile.append(timings)\n",
    "    \n",
    "    return result.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "f9753363-66bc-4dff-b619-65598cdebb31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No, a lender does not have to perform servicing functions directly.  Context 1 explicitly states that a lender may use other organizations to perform some or all of its servicing functions, referring to this as \"subservicing.\"  This involves a \"master servicer\" and a \"subservicer,\" where the subservicer performs the functions on behalf of the master servicer.  However, there are stipulations and requirements around these arrangements, as detailed in the provided texts.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(rag(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "000d101f-23ca-45f8-80cf-2f7ddddeabda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'embedding': 0.17287921905517578,\n",
       "  'retrieval_firestore': 1.753068447113037,\n",
       "  'augment': 0.00027871131896972656,\n",
       "  'generate': 0.8971724510192871,\n",
       "  'total': 2.82340669631958}]"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "6b56d234-46bb-4fa9-96fc-53f0f002f288",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    response = rag(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8893794-f5a5-4ebb-a73e-9a63bfb00ddc",
   "metadata": {},
   "source": [
    "### Report From Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "d0bdd28d-dbe9-4416-8cfd-514322cceef3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_timings = {}\n",
    "for timings in profile:\n",
    "    for key, value in timings.items():\n",
    "        if key not in all_timings:\n",
    "            all_timings[key] = []\n",
    "        all_timings[key].append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "b583f12f-f197-40b2-a6e1-447abd1694b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for 'embedding':\n",
      "  Min: 0.0466 seconds\n",
      "  Max: 10.0823 seconds\n",
      "  Mean: 0.1069 seconds\n",
      "  Median: 0.0523 seconds\n",
      "  Std Dev: 0.7057 seconds\n",
      "  P95: 0.0744 seconds\n",
      "  P99: 0.2228 seconds\n",
      "\n",
      "Statistics for 'retrieval_firestore':\n",
      "  Min: 0.1388 seconds\n",
      "  Max: 1.7531 seconds\n",
      "  Mean: 0.2297 seconds\n",
      "  Median: 0.2286 seconds\n",
      "  Std Dev: 0.1299 seconds\n",
      "  P95: 0.2787 seconds\n",
      "  P99: 0.5592 seconds\n",
      "\n",
      "Statistics for 'augment':\n",
      "  Min: 0.0000 seconds\n",
      "  Max: 0.0003 seconds\n",
      "  Mean: 0.0000 seconds\n",
      "  Median: 0.0000 seconds\n",
      "  Std Dev: 0.0000 seconds\n",
      "  P95: 0.0001 seconds\n",
      "  P99: 0.0001 seconds\n",
      "\n",
      "Statistics for 'generate':\n",
      "  Min: 0.5483 seconds\n",
      "  Max: 1.1185 seconds\n",
      "  Mean: 0.7176 seconds\n",
      "  Median: 0.6960 seconds\n",
      "  Std Dev: 0.0992 seconds\n",
      "  P95: 0.8972 seconds\n",
      "  P99: 1.0408 seconds\n",
      "\n",
      "Statistics for 'total':\n",
      "  Min: 0.7528 seconds\n",
      "  Max: 11.1640 seconds\n",
      "  Mean: 1.0542 seconds\n",
      "  Median: 0.9677 seconds\n",
      "  Std Dev: 0.7379 seconds\n",
      "  P95: 1.2523 seconds\n",
      "  P99: 1.7210 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, values in all_timings.items():\n",
    "    arr = np.array(values)\n",
    "    print(f\"Statistics for '{key}':\")\n",
    "    print(f\"  Min: {np.min(arr):.4f} seconds\")\n",
    "    print(f\"  Max: {np.max(arr):.4f} seconds\")\n",
    "    print(f\"  Mean: {np.mean(arr):.4f} seconds\")\n",
    "    print(f\"  Median: {np.median(arr):.4f} seconds\")\n",
    "    print(f\"  Std Dev: {np.std(arr):.4f} seconds\")\n",
    "    print(f\"  P95: {np.percentile(arr, 95):.4f} seconds\")\n",
    "    print(f\"  P99: {np.percentile(arr, 99):.4f} seconds\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bff763-1270-4c32-b930-67b0f0ef9faf",
   "metadata": {},
   "source": [
    "## Remove Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "74a19005-2b7a-49d0-8d09-fe72bfd4b694",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# delete all documents in the collection\n",
    "#fs.recursive_delete(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "059a56c2-82c4-4b68-8dbe-3d157a556d68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#for index in list(fs_admin.list_indexes(parent = f\"{database.name}/collectionGroups/{collection.id}\")):\n",
    "#    fs_admin.delete_index(name = index.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "437fcd09-b32a-4f6a-9359-d4e9c2e5dce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the database - be careful in case the database was being used for work prior to this workflow\n",
    "#fs_admin.delete_database(name = database.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467aa3bc-d79c-440c-8730-566ceb07a5c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
