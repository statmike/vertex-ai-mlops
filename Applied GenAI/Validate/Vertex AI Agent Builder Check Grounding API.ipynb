{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27dac832",
   "metadata": {},
   "source": [
    "![tracker](https://us-central1-vertex-ai-mlops-369716.cloudfunctions.net/pixel-tracking?path=statmike%2Fvertex-ai-mlops%2FApplied+GenAI%2FValidate&file=Vertex+AI+Agent+Builder+Check+Grounding+API.ipynb)\n",
    "<!--- header table --->\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/statmike/vertex-ai-mlops/blob/main/Applied%20GenAI/Validate/Vertex%20AI%20Agent%20Builder%20Check%20Grounding%20API.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\">\n",
    "      <br>Run in<br>Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https%3A%2F%2Fraw.githubusercontent.com%2Fstatmike%2Fvertex-ai-mlops%2Fmain%2FApplied%2520GenAI%2FValidate%2FVertex%2520AI%2520Agent%2520Builder%2520Check%2520Grounding%2520API.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\">\n",
    "      <br>Run in<br>Colab Enterprise\n",
    "    </a>\n",
    "  </td>      \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/statmike/vertex-ai-mlops/blob/main/Applied%20GenAI/Validate/Vertex%20AI%20Agent%20Builder%20Check%20Grounding%20API.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      <br>View on<br>GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/statmike/vertex-ai-mlops/main/Applied%20GenAI/Validate/Vertex%20AI%20Agent%20Builder%20Check%20Grounding%20API.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      <br>Open in<br>Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899e68e2-5e2a-447d-b304-5625891b97a2",
   "metadata": {},
   "source": [
    "# Vertex AI Agent Builder Check Grounding API\n",
    "\n",
    "Large Language Models (LLMs) are powerful tools for generating human-like text, but they can sometimes generate inaccurate information. To ensure your LLM provides grounded and factual responses, you need to provide it with relevant context.  Retrieval augemented generation (RAG) help [find the relevant context](../Retrieval/readme.md) and [Ranking](../Ranking/readme.md) can help filter and sort the retrieved context. But how can you be sure the LLM is actually using that context effectively?\n",
    "\n",
    "That's where the Vertex AI Agent Builder [Check Grounding API](https://cloud.google.com/generative-ai-app-builder/docs/check-grounding) comes in. This API helps you analyze how well an LLM's response is grounded in the context you provided.\n",
    "\n",
    "Here's how it works:\n",
    "\n",
    "- Input: You provide the Check Grounding API with the LLM's response and the context chunks you included in the prompt.\n",
    "- Analysis: The API breaks down the LLM's response and maps phrases to supporting evidence within the context.\n",
    "- Output: The API returns a detailed report, including:\n",
    "    - Citations: Links between specific phrases in the response and the supporting context.\n",
    "    - Support Score: An overall score (0 to 1) indicating how well the response is supported by the context.\n",
    "\n",
    "The Check Grounding API enables you to build more reliable and trustworthy LLM applications. You can use the support scores and citations to:\n",
    "- Set thresholds for response quality: Ensure that only factually grounded responses are provided to users.\n",
    "- Trigger advanced prompting techniques: If a response is poorly grounded, automatically retrieve additional context or reword the question to improve accuracy.\n",
    "- Gain insights into LLM behavior: Understand how the LLM utilizes context and identify areas for improvement in your prompting strategy.\n",
    "\n",
    "**References:**\n",
    "\n",
    "- [Discoveryengine Python Grounded Generation Service Client](https://cloud.google.com/python/docs/reference/discoveryengine/latest/google.cloud.discoveryengine_v1.services.grounded_generation_service)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2191b8ef-6748-4672-869c-506f27972f3e",
   "metadata": {
    "id": "od_UkDpvRmgD",
    "tags": []
   },
   "source": [
    "---\n",
    "## Colab Setup\n",
    "\n",
    "To run this notebook in Colab run the cells in this section.  Otherwise, skip this section.\n",
    "\n",
    "This cell will authenticate to GCP (follow prompts in the popup)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d67168c9-3b59-4d91-aed7-2ceb849e4901",
   "metadata": {
    "executionInfo": {
     "elapsed": 195,
     "status": "ok",
     "timestamp": 1683726184843,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "8UO9FnqyKBlF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'statmike-mlops-349915' # replace with project ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8aeeb07e-1339-4367-b667-3c399dbd2450",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68869,
     "status": "ok",
     "timestamp": 1683726253709,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "N98-KK7LRkjm",
    "outputId": "09ec5008-0def-4e1a-c349-c598ee752f78",
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    !gcloud config set project {PROJECT_ID}\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c3b590-a724-4a4a-8e97-227a4d417a9c",
   "metadata": {},
   "source": [
    "---\n",
    "## Installs\n",
    "\n",
    "The list `packages` contains tuples of package import names and install names.  If the import name is not found then the install name is used to install quitely for the current user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdfd89e2-b788-49ef-8163-ecbb049ed462",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tuples of (import name, install name, min_version)\n",
    "packages = [\n",
    "    ('google.cloud.aiplatform', 'google-cloud-aiplatform', '1.66.0'),\n",
    "    ('google.cloud.discoveryengine', 'google-cloud-discoveryengine', '0.12.2')\n",
    "]\n",
    "\n",
    "import importlib\n",
    "install = False\n",
    "for package in packages:\n",
    "    if not importlib.util.find_spec(package[0]):\n",
    "        print(f'installing package {package[1]}')\n",
    "        install = True\n",
    "        !pip install {package[1]} -U -q --user\n",
    "    elif len(package) == 3:\n",
    "        if importlib.metadata.version(package[0]) < package[2]:\n",
    "            print(f'updating package {package[1]}')\n",
    "            install = True\n",
    "            !pip install {package[1]} -U -q --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e30518c-412f-4801-b6ee-9f06caa48a4d",
   "metadata": {},
   "source": [
    "### API Enablement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a17f1234-ca45-4a05-9006-264c736b3e41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gcloud services enable aiplatform.googleapis.com\n",
    "!gcloud services enable discoveryengine.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09be0301-9f80-4fe4-936b-3e37d4a1c956",
   "metadata": {},
   "source": [
    "### Restart Kernel (If Installs Occured)\n",
    "\n",
    "After a kernel restart the code submission can start with the next cell after this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05cfc9cb-c935-4f44-aa76-2b9bc19dc13c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if install:\n",
    "    import IPython\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)\n",
    "    IPython.display.display(IPython.display.Markdown(\"\"\"<div class=\\\"alert alert-block alert-warning\\\">\n",
    "        <b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. The previous cells do not need to be run again⚠️</b>\n",
    "        </div>\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a16c26-1549-4cf6-8266-4638ee4e32b1",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d43aab-507b-45ac-8826-4e28b4f6fa80",
   "metadata": {},
   "source": [
    "inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee7473a5-c227-41ae-9cd7-93f3a55c6a32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'statmike-mlops-349915'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fe52e56-33d4-48a4-9fda-4d697296c1c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "SERIES = 'applied-genai'\n",
    "EXPERIMENT = 'validate-check-grounding'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848467c7-2145-4307-aa7e-30009478b114",
   "metadata": {},
   "source": [
    "packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3ea265d-2111-4311-a466-4f646e6cfb8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, shutil, json\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from IPython.display import Markdown\n",
    "\n",
    "import google.cloud.discoveryengine_v1 as discoveryengine\n",
    "from google.cloud import aiplatform\n",
    "import vertexai.generative_models # for Gemini Models\n",
    "import vertexai.language_models # for text embedding models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d557aad7-0ddd-4e52-8b92-63e78d799eba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.69.0'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aiplatform.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45f08a71-cf75-4aeb-a25b-e8828e2363c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.12.3'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discoveryengine.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78eea6a2-2826-414a-ba0a-826627b2bebb",
   "metadata": {},
   "source": [
    "clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60943fc8-5538-43bc-9315-672afff02e7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Vertex AI\n",
    "vertexai.init(project = PROJECT_ID, location = REGION)\n",
    "\n",
    "# Vertex AI Agent Builder APIs\n",
    "check_grounding_client = discoveryengine.GroundedGenerationServiceClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec5628b-d7e9-4ed8-a512-05e7149fa3a2",
   "metadata": {},
   "source": [
    "---\n",
    "## Text & Embeddings For Examples\n",
    "\n",
    "This repository contains a [section for document processing (chunking)](../Chunking/readme.md) that includes an [example of processing a PDF with the Document AI Layout Parser](../Chunking/Process%20Documents%20-%20Document%20AI%20Layout%20Parser.ipynb).  The chunks of text from that workflow are stored with this repository and loaded by another companion workflow that augments the chunks with text embeddings: [Vertex AI Text Embeddings API](../Embeddings/Vertex%20AI%20Text%20Embeddings%20API.ipynb).\n",
    "\n",
    "The following code will load the version of the chunks that includes text embeddings and prepare it for a local example of retrival augmented generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f95d922-9c8c-40df-a4be-3da87c997332",
   "metadata": {},
   "source": [
    "### Get The Documents\n",
    "\n",
    "If you are working from a clone of this notebooks [repository](https://github.com/statmike/vertex-ai-mlops) then the documents are already present. The following cell checks for the documents folder and if it is missing gets it (`git clone`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b0c3dcc-57f2-4b37-ad9d-575b0ceeeefb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "local_dir = '../Embeddings/files/embeddings-api'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ced8d0f0-c64b-4cef-920a-5130089e2d5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents Found in folder `../Embeddings/files/embeddings-api`\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(local_dir):\n",
    "    print('Retrieving documents...')\n",
    "    parent_dir = os.path.dirname(local_dir)\n",
    "    temp_dir = os.path.join(parent_dir, 'temp')\n",
    "    if not os.path.exists(temp_dir):\n",
    "        os.makedirs(temp_dir)\n",
    "    !git clone https://www.github.com/statmike/vertex-ai-mlops {temp_dir}/vertex-ai-mlops\n",
    "    shutil.copytree(f'{temp_dir}/vertex-ai-mlops/Applied GenAI/Embeddings/files/embeddings-api', local_dir)\n",
    "    shutil.rmtree(temp_dir)\n",
    "    print(f'Documents are now in folder `{local_dir}`')\n",
    "else:\n",
    "    print(f'Documents Found in folder `{local_dir}`')             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bf570d-c3aa-4d16-b2a1-5dd280096570",
   "metadata": {},
   "source": [
    "### Load The Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4972d78-f609-49e6-88d8-2dfc886d2292",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(local_dir+'/chunk-embeddings.jsonl', 'r') as f:\n",
    "    chunks = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fbdcc1-58a7-47a9-b43a-9b28776fb659",
   "metadata": {},
   "source": [
    "### Review A Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94801376-790f-4fcb-a924-8c4489ef4d40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['instance', 'predictions', 'status'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58ccb0f3-d28f-4239-adaa-5ff04b1113e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c2'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0]['instance']['chunk_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f231ecf2-d2a6-4e44-9d2b-6109a106a9b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# OFFICIAL BASEBALL RULES\n",
      "\n",
      "## Official Baseball Rules 2023 Edition\n",
      "\n",
      "### JOINT COMPETITION COMMITTEE\n",
      "\n",
      "|-|-|-|\n",
      "| Bill DeWitt | Whit Merrifield | Austin Slater |\n",
      "| Jack Flaherty | Bill Miller | John Stanton, Chair |\n",
      "| Tyler Glasnow | Dick Monfort | Tom Werner |\n",
      "| Greg Johnson | Mark Shapiro |  |\n",
      "\n",
      "Committee Secretary Paul V. Mifsud, Jr. Copyright © 2023 by the Office of the Commissioner of Baseball\n"
     ]
    }
   ],
   "source": [
    "print(chunks[0]['instance']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e76af8f-a194-46cf-8713-5c1fa551b186",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.008681542240083218,\n",
       " 0.06999468058347702,\n",
       " 0.003673204220831394,\n",
       " 0.019888797774910927,\n",
       " 0.016285404562950134,\n",
       " 0.035664502531290054,\n",
       " 0.06200747936964035,\n",
       " 0.05597030743956566,\n",
       " 0.0034793149679899216,\n",
       " -0.024485772475600243]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0]['predictions'][0]['embeddings']['values'][0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6ef980-f50b-4838-89b3-00a4968fdbc1",
   "metadata": {},
   "source": [
    "### Prepare Chunk Structure\n",
    "\n",
    "Make a dictionary for each lookup of chunk content by chunk id:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1796190b-8c76-40e2-98d7-bee485fa4a51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "content_chunks = {}\n",
    "for chunk in chunks:\n",
    "    content_chunks[chunk['instance']['chunk_id']] = chunk['instance']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f22e16a-2669-4cb5-b132-c26e9e7d9c87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# OFFICIAL BASEBALL RULES\\n\\n2023 Edition TM TM'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_chunks['c1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0e163c-22b7-46a7-b8d5-c49792800a06",
   "metadata": {},
   "source": [
    "---\n",
    "## Simple Retrieval Augmented Generation (RAG)\n",
    "\n",
    "Embeddings can be used with math to measure similarity.  For deeper details into this checkout the companion workflow here: [The Math of Similarity](../Embeddings/The%20Math%20of%20Similarity.ipynb).  Retrieval systems handle the storage and math of similarity as a service.  For an overview of Google Cloud based solutions for retrieval check out [this companion series](../Retrieval/readme.md).\n",
    "\n",
    "The content below motivates retrieval with the embeddings that accompany the text chunks using a local vector database with brute force matching using Numpy!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9370081-fe78-465a-9a43-19c756db2e80",
   "metadata": {},
   "source": [
    "### Vector DB With Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0df6097d-37a4-4690-842a-15f6d020b3ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vector_db = [\n",
    "    [\n",
    "        chunk['instance']['chunk_id'],\n",
    "        chunk['predictions'][0]['embeddings']['values'],\n",
    "    ]\n",
    "    for chunk in chunks\n",
    "]\n",
    "vector_index = np.array([row[1] for row in vector_db])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8236f34e-1798-426a-8fa4-c0d81a4e359f",
   "metadata": {},
   "source": [
    "### Models: Embeddings, Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f951a450-1824-4d70-9584-46c8a6c1703e",
   "metadata": {},
   "source": [
    "Connect to models for text embeddings and text generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e22e12d7-fba7-4445-8e3b-391b06dffa9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedder = vertexai.language_models.TextEmbeddingModel.from_pretrained('text-embedding-004')\n",
    "llm = vertexai.generative_models.GenerativeModel(\"gemini-1.5-flash-001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594fa358-2317-4d54-b4c1-4b9943c33b38",
   "metadata": {},
   "source": [
    "Define a question that is the start of our prompt to the LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7bf42fe6-4128-42f0-b0f0-2cd21f6252df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question = \"What are the dimensions of a base?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe76f44-ac2f-4c2e-a423-b024f623ba99",
   "metadata": {},
   "source": [
    "Get an ungrounded response to the question with the LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ced90d73-4dac-4c75-bc9a-e1b9fa813959",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The term \"base\" is very general, and its dimensions will depend on the context.  To answer your question accurately, I need more information. \n",
      "\n",
      "Please tell me:\n",
      "\n",
      "* **What kind of base are you talking about?**  Is it a base of a:\n",
      "    * **Geometric shape?** (like a triangle, rectangle, pyramid, etc.)\n",
      "    * **Object?** (like a table, a house, a building, etc.)\n",
      "    * **Mathematical concept?** (like a number system, a logarithm, etc.)\n",
      "* **What specific information are you looking for?**  Are you interested in:\n",
      "    * **Length and width?**\n",
      "    * **Area?**\n",
      "    * **Volume?** \n",
      "    * **Other specific dimensions?**\n",
      "\n",
      "Once you provide more context, I can help you determine the dimensions of the base you're interested in. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(llm.generate_content(question).text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbadcb12-0967-413d-b9a5-bcfe9aa185eb",
   "metadata": {},
   "source": [
    "Get an embedding for the question to use in retrieval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b6b8f8c1-a020-4307-980e-e9380ebc7a4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.026682045310735703,\n",
       " 0.011593513190746307,\n",
       " 0.028523651883006096,\n",
       " -0.0017065361607819796,\n",
       " 0.01946176588535309,\n",
       " 0.0031198114156723022,\n",
       " 0.07915323227643967,\n",
       " -0.005078596994280815,\n",
       " -0.006295712199062109,\n",
       " 0.04943541809916496]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_embedding = embedder.get_embeddings([question])[0].values\n",
    "question_embedding[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa0bc2c-4831-4a2c-986a-28a0beb926d9",
   "metadata": {},
   "source": [
    "### Retrieval: Matching With Numpy\n",
    "\n",
    "Use dot product to calculate similarity and find matches for a query embedding.  Why dot product?  Check out the companion workflow: [The Math of Similarity](../Embeddings/The%20Math%20of%20Similarity.ipynb)\n",
    "\n",
    "> **NOTE:**  This will calculate the similarity for all embeddings vectors stored in the local vector db which is just a Numpy array here.  This is very fast because there are <200 embeddings vectors.  As this scales it would be better to consider a solution that searches a subset of embeddings.  More details on retrieval solutions can be found in [Retrieval](../Retrieval/readme.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1b1892c6-ec04-4987-8ecd-d3dac129c12b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(38, 0.5843799337008113),\n",
       " (36, 0.5724333016720691),\n",
       " (836, 0.5244194362041271),\n",
       " (40, 0.5126844935129918),\n",
       " (26, 0.5033481946111171)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity = np.dot(question_embedding, vector_index.T)\n",
    "#matches = np.argsort(similarity)[::-1][:5].tolist()\n",
    "matches = np.argsort(similarity)[-5:].tolist()\n",
    "matches = [(match, similarity[match]) for match in matches]\n",
    "matches.reverse()\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f6a6ac1a-31ad-42b9-812c-558712e4cd05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match 1 (0.58) is chunk c38:\n",
      "# 2.00-THE PLAYING FIELD\n",
      "\n",
      "## 2.02 Home Base\n",
      "\n",
      "Home base shall be marked by a five-sided slab of whitened rubber. It shall be a 17-inch square with two of the corners removed so that one edge is 17 inches long, two adjacent sides are 8\\frac{1}{2} inches and the remaining two sides are 12 inches and set at an angle to make a point.\n",
      "###################################################\n",
      "Match 2 (0.57) is chunk c39:\n",
      "# 2.00-THE PLAYING FIELD\n",
      "\n",
      "## 2.02 Home Base\n",
      "\n",
      "It shall be set in the ground with the point at the intersection of the lines extending from home base to first base and to third base; with the 17-inch edge facing the pitcher's plate, and the two 12-inch edges coinciding with the first and third base lines. The top edges of home base shall be beveled and the base shall be fixed in the ground level with the ground surface. (See drawing D in Appendix 2.) 3\n",
      "###################################################\n",
      "Match 3 (0.52) is chunk c838:\n",
      "# APPENDICES\n",
      "\n",
      "## Appendix 2\n",
      "\n",
      "Diagram No. 2 Layout at Home Plate, 1st, 2nd, and 3rd Bases 18\" A 18\" 90° LAYOUT AT SECOND BASE FOR LAYOUT AT PITCHER'S PLATE SEE DIAGRAM NO. 3 90° 6\" 17\" 6\" D E 3'0\" 3'0\" 4'0\" 4 C 43\" LAYOUT AT HOME BASE DIAGRAM NO. 2 LEGEND A 1st, 2nd, 3rd BASES BATTER'S BOX B B C CATCHER'S BOX D HOME BASE E PITCHER'S PLATE Rev2023RW 161 90° 4 FOUL LINE LAYOUT AT FIRST BASE\n",
      "###################################################\n",
      "Match 4 (0.51) is chunk c40:\n",
      "# Rule 2.03 to 2.05\n",
      "\n",
      "## 2.03 The Bases\n",
      "\n",
      "First, second and third bases shall be marked by white canvas or rubber-covered bags, securely attached to the ground as indicated in Diagram 2. The first and third base bags shall be entirely within the infield. The second base bag shall be centered on second base. The bags shall be 18 inches square, not less than three nor more than five inches thick, and filled with soft material.\n",
      "###################################################\n",
      "Match 5 (0.50) is chunk c31:\n",
      "# 2.00-THE PLAYING FIELD\n",
      "\n",
      "## 2.01 Layout of the Field\n",
      "\n",
      "When location of home base is determined, with a steel tape measure 127 feet, 3\\frac{3}{8} inches in desired direction to establish second base. From home base, measure 90 feet toward first base; from second base, measure 90 feet toward first base; the intersection of these lines establishes first base. From home base, measure 90 feet toward third base; from second base, measure 90 feet toward third base; the intersection of these lines establishes third base.\n",
      "###################################################\n"
     ]
    }
   ],
   "source": [
    "for m, match in enumerate(matches):\n",
    "    print(f\"Match {m+1} ({match[1]:.2f}) is chunk {vector_db[match[0]][0]}:\\n{content_chunks[vector_db[match[0]][0]]}\\n###################################################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662b62da-51c7-4c9f-87b3-88bbfedaa2d8",
   "metadata": {},
   "source": [
    "### Generation: Q&A With Gemini Grounded With RAG\n",
    "\n",
    "Provide the matched chunks of text along with the question as a prompt to a generative model for a grounded answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56edcd6c-4a35-400a-8441-3e2e55fd8353",
   "metadata": {},
   "source": [
    "#### Prompt Building Function\n",
    "\n",
    "Use the matching chunks as context for the prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1c479c5a-1b49-44e1-9afb-ac4101bea6ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_prompt(question, top_n = 5):\n",
    "    # get embedding for question\n",
    "    question_embedding = embedder.get_embeddings([question])[0].values\n",
    "    # get top_n matches:\n",
    "    similarity = np.dot(question_embedding, vector_index.T)\n",
    "    matches = np.argsort(similarity)[-top_n:].tolist()\n",
    "    matches.reverse()\n",
    "    matches = [[match, similarity[match]] for match in matches]\n",
    "    # construct prompt:\n",
    "    prompt = ''\n",
    "    for m, match in enumerate(matches):\n",
    "        prompt += f\"Context {m+1}:\\n{content_chunks[vector_db[match[0]][0]]}\\n\\n\"\n",
    "    prompt += f'Answer the following question using the provided contexts:\\n{question}'\n",
    "    \n",
    "    return matches, prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "81afdf68-fc31-4418-9eb8-1eb5b1ecc4a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context 1:\n",
      "# 2.00-THE PLAYING FIELD\n",
      "\n",
      "## 2.02 Home Base\n",
      "\n",
      "Home base shall be marked by a five-sided slab of whitened rubber. It shall be a 17-inch square with two of the corners removed so that one edge is 17 inches long, two adjacent sides are 8\\frac{1}{2} inches and the remaining two sides are 12 inches and set at an angle to make a point.\n",
      "\n",
      "Context 2:\n",
      "# 2.00-THE PLAYING FIELD\n",
      "\n",
      "## 2.02 Home Base\n",
      "\n",
      "It shall be set in the ground with the point at the intersection of the lines extending from home base to first base and to third base; with the 17-inch edge facing the pitcher's plate, and the two 12-inch edges coinciding with the first and third base lines. The top edges of home base shall be beveled and the base shall be fixed in the ground level with the ground surface. (See drawing D in Appendix 2.) 3\n",
      "\n",
      "Context 3:\n",
      "# APPENDICES\n",
      "\n",
      "## Appendix 2\n",
      "\n",
      "Diagram No. 2 Layout at Home Plate, 1st, 2nd, and 3rd Bases 18\" A 18\" 90° LAYOUT AT SECOND BASE FOR LAYOUT AT PITCHER'S PLATE SEE DIAGRAM NO. 3 90° 6\" 17\" 6\" D E 3'0\" 3'0\" 4'0\" 4 C 43\" LAYOUT AT HOME BASE DIAGRAM NO. 2 LEGEND A 1st, 2nd, 3rd BASES BATTER'S BOX B B C CATCHER'S BOX D HOME BASE E PITCHER'S PLATE Rev2023RW 161 90° 4 FOUL LINE LAYOUT AT FIRST BASE\n",
      "\n",
      "Context 4:\n",
      "# Rule 2.03 to 2.05\n",
      "\n",
      "## 2.03 The Bases\n",
      "\n",
      "First, second and third bases shall be marked by white canvas or rubber-covered bags, securely attached to the ground as indicated in Diagram 2. The first and third base bags shall be entirely within the infield. The second base bag shall be centered on second base. The bags shall be 18 inches square, not less than three nor more than five inches thick, and filled with soft material.\n",
      "\n",
      "Context 5:\n",
      "# 2.00-THE PLAYING FIELD\n",
      "\n",
      "## 2.01 Layout of the Field\n",
      "\n",
      "When location of home base is determined, with a steel tape measure 127 feet, 3\\frac{3}{8} inches in desired direction to establish second base. From home base, measure 90 feet toward first base; from second base, measure 90 feet toward first base; the intersection of these lines establishes first base. From home base, measure 90 feet toward third base; from second base, measure 90 feet toward third base; the intersection of these lines establishes third base.\n",
      "\n",
      "Answer the following question using the provided contexts:\n",
      "What are the dimensions of a base?\n"
     ]
    }
   ],
   "source": [
    "matches, prompt = get_prompt(question) \n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878c4bc7-fa6f-4999-9abb-af7214575153",
   "metadata": {},
   "source": [
    "### Grounded Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3992c593-5404-4323-a7de-a19d1760058c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The dimensions of a base depend on which base you are referring to:\n",
       "\n",
       "* **Home Base:** It's a five-sided slab of whitened rubber with the following dimensions:\n",
       "    * One edge: 17 inches\n",
       "    * Two adjacent sides: 8 1/2 inches\n",
       "    * Two remaining sides: 12 inches \n",
       "* **First, Second, and Third Bases:** These are marked by white canvas or rubber-covered bags with the following dimensions:\n",
       "    * 18 inches square\n",
       "    * 3 to 5 inches thick \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = llm.generate_content(prompt).text\n",
    "Markdown(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e54ef7-5ee2-4d72-b989-70f3f40a99b8",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Check Grounding API\n",
    "\n",
    "Vertex AI Agent Builder has several helpful APIs for grounding, including:\n",
    "- [Check Grounding API](https://cloud.google.com/generative-ai-app-builder/docs/check-grounding)\n",
    "    - assess grounded-ness of responses\n",
    "    \n",
    "With this API you pass it the answer from an LLM along with chunks of context which all called facts in the API.  The response include an overall score, `support_score`, and a phrase by phrase breakdown of which chunk/fact is the citation for the phrase - if any.\n",
    "    \n",
    "**References:**\n",
    "\n",
    "- [Discoveryengine Python Grounded Generation Service Client](https://cloud.google.com/python/docs/reference/discoveryengine/latest/google.cloud.discoveryengine_v1.services.grounded_generation_service)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18beb7f-ac54-4056-bfff-3e88a080396a",
   "metadata": {},
   "source": [
    "### Use Check Grounding API\n",
    "\n",
    "Input LLM Answer and Context Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "062271e8-fb73-4b4e-86e8-b33202129d84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ground_check = check_grounding_client.check_grounding(\n",
    "    request = discoveryengine.CheckGroundingRequest(\n",
    "        grounding_config = check_grounding_client.grounding_config_path(\n",
    "            project = PROJECT_ID,\n",
    "            location = 'global',\n",
    "            grounding_config = \"default_grounding_config\",\n",
    "        ),\n",
    "        answer_candidate = answer,\n",
    "        facts = [\n",
    "            discoveryengine.GroundingFact(\n",
    "                fact_text = content_chunks[vector_db[match[0]][0]],\n",
    "                attributes = {'author': 'MLB', 'chunk_id': vector_db[match[0]][0]}\n",
    "            )\n",
    "            for match in matches\n",
    "        ],\n",
    "        grounding_spec = discoveryengine.CheckGroundingSpec(\n",
    "            citation_threshold = 0.6,\n",
    "            #enable_anti_citation = True,\n",
    "            #anti_citation_threshold = 0.75\n",
    "        ),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8ca9adc3-1788-451f-b510-49f9cd735fd5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "support_score: 0.854004442691803\n",
       "cited_chunks {\n",
       "  chunk_text: \"# 2.00-THE PLAYING FIELD\\n\\n## 2.02 Home Base\\n\\nHome base shall be marked by a five-sided slab of whitened rubber. It shall be a 17-inch square with two of the corners removed so that one edge is 17 inches long, two adjacent sides are 8\\\\frac{1}{2} inches and the remaining two sides are 12 inches and set at an angle to make a point.\"\n",
       "  source: \"0\"\n",
       "}\n",
       "cited_chunks {\n",
       "  chunk_text: \"# 2.00-THE PLAYING FIELD\\n\\n## 2.02 Home Base\\n\\nIt shall be set in the ground with the point at the intersection of the lines extending from home base to first base and to third base; with the 17-inch edge facing the pitcher\\'s plate, and the two 12-inch edges coinciding with the first and third base lines. The top edges of home base shall be beveled and the base shall be fixed in the ground level with the ground surface. (See drawing D in Appendix 2.) 3\"\n",
       "  source: \"1\"\n",
       "}\n",
       "cited_chunks {\n",
       "  chunk_text: \"# Rule 2.03 to 2.05\\n\\n## 2.03 The Bases\\n\\nFirst, second and third bases shall be marked by white canvas or rubber-covered bags, securely attached to the ground as indicated in Diagram 2. The first and third base bags shall be entirely within the infield. The second base bag shall be centered on second base. The bags shall be 18 inches square, not less than three nor more than five inches thick, and filled with soft material.\"\n",
       "  source: \"3\"\n",
       "}\n",
       "claims {\n",
       "  start_pos: 0\n",
       "  end_pos: 67\n",
       "  claim_text: \"The dimensions of a base depend on which base you are referring to:\"\n",
       "  grounding_check_required: false\n",
       "}\n",
       "claims {\n",
       "  start_pos: 69\n",
       "  end_pos: 158\n",
       "  claim_text: \"* **Home Base:** It\\'s a five-sided slab of whitened rubber with the following dimensions:\"\n",
       "  citation_indices: 0\n",
       "  grounding_check_required: true\n",
       "}\n",
       "claims {\n",
       "  start_pos: 163\n",
       "  end_pos: 184\n",
       "  claim_text: \"* One edge: 17 inches\"\n",
       "  citation_indices: 0\n",
       "  citation_indices: 1\n",
       "  grounding_check_required: true\n",
       "}\n",
       "claims {\n",
       "  start_pos: 189\n",
       "  end_pos: 223\n",
       "  claim_text: \"* Two adjacent sides: 8 1/2 inches\"\n",
       "  citation_indices: 0\n",
       "  grounding_check_required: true\n",
       "}\n",
       "claims {\n",
       "  start_pos: 228\n",
       "  end_pos: 260\n",
       "  claim_text: \"* Two remaining sides: 12 inches\"\n",
       "  citation_indices: 0\n",
       "  grounding_check_required: true\n",
       "}\n",
       "claims {\n",
       "  start_pos: 262\n",
       "  end_pos: 386\n",
       "  claim_text: \"* **First, Second, and Third Bases:** These are marked by white canvas or rubber-covered bags with the following dimensions:\"\n",
       "  citation_indices: 2\n",
       "  grounding_check_required: true\n",
       "}\n",
       "claims {\n",
       "  start_pos: 391\n",
       "  end_pos: 409\n",
       "  claim_text: \"* 18 inches square\"\n",
       "  grounding_check_required: false\n",
       "}\n",
       "claims {\n",
       "  start_pos: 414\n",
       "  end_pos: 435\n",
       "  claim_text: \"* 3 to 5 inches thick\"\n",
       "  citation_indices: 2\n",
       "  grounding_check_required: true\n",
       "}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b676b903-3b52-4cf1-8e9c-8a595c11b953",
   "metadata": {},
   "source": [
    "### Examine Check Grounding Results Phrase-by-Phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6e367635-7cad-41c4-b7b6-5ed3cddad7e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Grounding Support Score (0-1):** 0.85\n",
       "|Answer Phrases|Citations|\n",
       "|---|---|\n",
       "|The dimensions of a base depend on which base you are referring to:|[]|\n",
       "|* **Home Base:** It's a five-sided slab of whitened rubber with the following dimensions:|['c38']|\n",
       "|* One edge: 17 inches|['c38', 'c39']|\n",
       "|* Two adjacent sides: 8 1/2 inches|['c38']|\n",
       "|* Two remaining sides: 12 inches|['c38']|\n",
       "|* **First, Second, and Third Bases:** These are marked by white canvas or rubber-covered bags with the following dimensions:|['c40']|\n",
       "|* 18 inches square|[]|\n",
       "|* 3 to 5 inches thick|['c40']|\n",
       "--------------------------------------------------------------------------------\n",
       "**Chunk = c38:**\n",
       "\n",
       " 2.00-THE PLAYING FIELD\n",
       "\n",
       " 2.02 Home Base\n",
       "\n",
       "Home base shall be marked by a five-sided slab of whitened rubber. It shall be a 17-inch square with two of the corners removed so that one edge is 17 inches long, two adjacent sides are 8\\frac{1}{2} inches and the remaining two sides are 12 inches and set at an angle to make a point.\n",
       "\n",
       "--------------------------------------------------------------------------------\n",
       "**Chunk = c39:**\n",
       "\n",
       " 2.00-THE PLAYING FIELD\n",
       "\n",
       " 2.02 Home Base\n",
       "\n",
       "It shall be set in the ground with the point at the intersection of the lines extending from home base to first base and to third base; with the 17-inch edge facing the pitcher's plate, and the two 12-inch edges coinciding with the first and third base lines. The top edges of home base shall be beveled and the base shall be fixed in the ground level with the ground surface. (See drawing D in Appendix 2.) 3\n",
       "\n",
       "--------------------------------------------------------------------------------\n",
       "**Chunk = c40:**\n",
       "\n",
       " Rule 2.03 to 2.05\n",
       "\n",
       " 2.03 The Bases\n",
       "\n",
       "First, second and third bases shall be marked by white canvas or rubber-covered bags, securely attached to the ground as indicated in Diagram 2. The first and third base bags shall be entirely within the infield. The second base bag shall be centered on second base. The bags shall be 18 inches square, not less than three nor more than five inches thick, and filled with soft material.\n",
       "\n",
       "--------------------------------------------------------------------------------\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overview = f\"**Grounding Support Score (0-1):** {ground_check.support_score:.2f}\\n|Answer Phrases|Citations|\\n|---|---|\\n\"\n",
    "all_ref_chunks = []\n",
    "for claim in ground_check.claims:\n",
    "    citations = [c for c in claim.citation_indices] if hasattr(claim, 'citation_indices') else []\n",
    "    sources = [ground_check.cited_chunks[citation].source for citation in citations]\n",
    "    ref_chunks = [vector_db[matches[int(source)][0]][0] for source in sources]\n",
    "    if ref_chunks: all_ref_chunks += ref_chunks\n",
    "    overview += f\"|{claim.claim_text}|{ref_chunks}|\\n\"\n",
    "overview += '-'*80 +'\\n'    \n",
    "for chunk_id in sorted(list(set(all_ref_chunks))):\n",
    "    overview += f\"**Chunk = {chunk_id}:**\\n\\n{content_chunks[chunk_id]}\\n\\n\" + '-'*80 +'\\n'\n",
    "\n",
    "Markdown(overview.replace('#', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65c61b5-badd-4ecd-ac8e-b8750b65b6d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
