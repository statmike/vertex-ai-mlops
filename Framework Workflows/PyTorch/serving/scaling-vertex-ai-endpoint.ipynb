{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Vertex AI Endpoint: Scaling & Performance Testing\n",
    "\n",
    "**Comprehensive load testing to understand endpoint capacity, autoscaling behavior, and performance characteristics.**\n",
    "\n",
    "---\n",
    "\n",
    "## What This Notebook Does\n",
    "\n",
    "This notebook systematically tests Vertex AI Endpoint performance to answer:\n",
    "\n",
    "1. **What's the maximum capacity?** - How many requests per second (RPS) can the endpoint handle?\n",
    "2. **Where do bottlenecks occur?** - Is it client-side queueing or endpoint processing?\n",
    "3. **Does autoscaling work?** - When and how does the endpoint scale replicas?\n",
    "4. **What should we configure?** - Recommendations for production settings\n",
    "\n",
    "## Testing Approach\n",
    "\n",
    "**Phase 1: Find Breaking Points** (~15-20 minutes)\n",
    "- Test different batch sizes (1 ‚Üí 1000 instances per request)\n",
    "- Test different request rates (1 ‚Üí 100 RPS)\n",
    "- Identify where latency starts to degrade\n",
    "\n",
    "**Phase 2: Sustained Load Testing** (~15-20 minutes)\n",
    "- Apply realistic traffic patterns over extended periods\n",
    "- Observe autoscaling triggers and timing\n",
    "- Measure steady-state performance\n",
    "\n",
    "**Total test time:** ~30-40 minutes\n",
    "\n",
    "## Key Metrics We Track\n",
    "\n",
    "**Timing Breakdown** (separated to identify bottlenecks):\n",
    "- üü¶ **Queueing Time**: Waiting for client concurrency slot ‚Üí *client bottleneck*\n",
    "- üü© **Request Time**: Actual HTTP request/response ‚Üí *endpoint performance*\n",
    "- üîµ **Total Latency**: End-to-end user experience (queue + request)\n",
    "\n",
    "**Success Metrics**:\n",
    "- Success rate (% of requests that completed successfully)\n",
    "- Error types and frequency\n",
    "\n",
    "**Resource Metrics** (from Cloud Monitoring):\n",
    "- CPU utilization (triggers autoscaling at 60% by default)\n",
    "- Replica count (view in Cloud Console)\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before running this notebook, you need:\n",
    "\n",
    "- **Deployed Vertex AI Endpoint** with a model\n",
    "  - If using the PyTorch autoencoder from this repository, run `../pytorch-autoencoder.ipynb` first\n",
    "  - Then deploy using either `vertex-ai-endpoint-prebuilt-container.ipynb` or `vertex-ai-endpoint-custom-container.ipynb`\n",
    "- **Google Cloud authentication** with Vertex AI prediction permissions\n",
    "- **Python packages**: `aiohttp`, `google-cloud-aiplatform`, `plotly`, `pandas` (installed automatically)\n",
    "\n",
    "## Understanding Vertex AI Autoscaling\n",
    "\n",
    "**How It Works**:\n",
    "- Vertex AI autoscales based on **CPU utilization** (default threshold: 60%)\n",
    "- When CPU > 60% for ~1-2 minutes ‚Üí new replica provisions\n",
    "- Replica provisioning takes ~2-3 minutes (container startup)\n",
    "- Scale-down occurs after ~10-15 minutes below threshold\n",
    "\n",
    "**Important**: Lightweight models may not trigger autoscaling even under high RPS because CPU usage stays low. This is a **capacity bottleneck**, not a **compute bottleneck**. If this happens:\n",
    "- Lower the autoscaling threshold (requires redeployment)\n",
    "- Increase minimum replica count\n",
    "- Use a larger machine type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87qzfsdn2at",
   "metadata": {},
   "source": [
    "---\n",
    "## Environment Setup\n",
    "\n",
    "This section will authenticate your session, enable required Google Cloud APIs, and install necessary Python packages.\n",
    "\n",
    "**Package Installation Options (`REQ_TYPE`):**\n",
    "- `PRIMARY`: Installs only the main packages. Faster, but pip resolves sub-dependencies which may result in different versions than development.\n",
    "- `ALL` (Default): Installs exact versions of all packages and dependencies. Best for perfectly reproducing the development environment.\n",
    "- `COLAB`: Installs a Colab-optimized list that excludes pre-installed packages like `ipython` and `ipykernel`.\n",
    "\n",
    "**Installation Tool Options (`INSTALL_TOOL`):**\n",
    "- `pip` (Default): Uses pip for package installation. Standard Python package installer.\n",
    "- `uv`: Modern, fast Python package installer. Must be installed separately. See: https://github.com/astral-sh/uv\n",
    "- `poetry`: Dependency management tool. Requires running notebook in a poetry environment (`poetry shell` or `poetry run jupyter lab`). Uses `pyproject.toml` instead of requirements.txt.\n",
    "\n",
    "> **Note:** If running in Google Colab, the script will automatically detect this and set `REQ_TYPE = 'COLAB'` to prevent package conflicts, overriding any manual setting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85nbtm7kzxm",
   "metadata": {},
   "source": [
    "### Set Your Project ID\n",
    "\n",
    "‚ö†Ô∏è **Action Required:** Replace the `PROJECT_ID` value below with your Google Cloud project ID before running this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "o8bqttcnep",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'statmike-mlops-349915' # replace with GCP project ID\n",
    "REQ_TYPE = 'ALL' # Specify PRIMARY or ALL or COLAB\n",
    "INSTALL_TOOL = 'poetry' # Specify pip, uv, or poetry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabbd22e",
   "metadata": {},
   "source": [
    "### Configuration\n",
    "\n",
    "This cell defines the requirements files and Google Cloud APIs needed for this notebook. Run as-is without modification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "i9sux18yfl",
   "metadata": {},
   "outputs": [],
   "source": [
    "REQUIREMENTS_URL = 'https://raw.githubusercontent.com/statmike/vertex-ai-mlops/refs/heads/main/Framework%20Workflows/PyTorch/requirements.txt'\n",
    "\n",
    "REQUIRED_APIS = [\n",
    "    \"aiplatform.googleapis.com\",\n",
    "    \"monitoring.googleapis.com\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f739d807",
   "metadata": {},
   "source": [
    "### Run Setup\n",
    "\n",
    "This cell downloads the centralized setup code and configures your environment. It will:\n",
    "- Authenticate your session with Google Cloud\n",
    "- Enable required APIs for this notebook\n",
    "- Install necessary Python packages\n",
    "- Display a setup summary with your project information\n",
    "\n",
    "> **Note:** In Colab, if packages are installed, the kernel will automatically restart. After restart, continue from the next cell without re-running earlier cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "t6h5esx2b9g",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "PYTHON GCP ENVIRONMENT SETUP\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "AUTHENTICATION\n",
      "==================================================\n",
      "Checking for existing ADC...\n",
      "‚úÖ Existing ADC found.\n",
      "‚úÖ Project is correctly set to 'statmike-mlops-349915'.\n",
      "\n",
      "==================================================\n",
      "API CHECK & ENABLE\n",
      "==================================================\n",
      "‚úÖ aiplatform.googleapis.com is already enabled.\n",
      "‚úÖ monitoring.googleapis.com is already enabled.\n",
      "\n",
      "==================================================\n",
      "PACKAGE MANAGEMENT\n",
      "==================================================\n",
      "Installation Tool: poetry\n",
      "‚úÖ Found poetry at: /usr/local/google/home/statmike/.local/bin/poetry\n",
      "‚úÖ Running in poetry environment: /usr/local/google/home/statmike/.cache/pypoetry/virtualenvs/frameworks-pytorch-0KVJlKeQ-py3.13\n",
      "‚ÑπÔ∏è  Poetry mode: Installing from pyproject.toml (REQUIREMENTS_URL ignored)\n",
      "‚úÖ Found pyproject.toml at: /usr/local/google/home/statmike/Git/vertex-ai-mlops/Framework Workflows/PyTorch/pyproject.toml\n",
      "   Changed working directory to: /usr/local/google/home/statmike/Git/vertex-ai-mlops/Framework Workflows/PyTorch\n",
      "Running poetry install...\n",
      "   Restored working directory to: /usr/local/google/home/statmike/Git/vertex-ai-mlops/Framework Workflows/PyTorch/serving\n",
      "‚úÖ All packages are already installed and up to date.\n",
      "\n",
      "==================================================\n",
      "Google Cloud Project Information\n",
      "==================================================\n",
      "PROJECT_ID     = statmike-mlops-349915\n",
      "PROJECT_NUMBER = 1026793852137\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "SETUP SUMMARY\n",
      "==================================================\n",
      "‚úÖ Authentication:    Success\n",
      "‚úÖ API Configuration: Success\n",
      "‚úÖ Package Install:   Already up to date\n",
      "‚úÖ Installation Tool: poetry\n",
      "‚úÖ Project ID:        statmike-mlops-349915\n",
      "‚úÖ Project Number:    1026793852137\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os, urllib.request\n",
    "\n",
    "# Download and import setup code\n",
    "url = 'https://raw.githubusercontent.com/statmike/vertex-ai-mlops/refs/heads/main/core/notebook-template/python_setup.py'\n",
    "urllib.request.urlretrieve(url, 'python_setup_local.py')\n",
    "import python_setup_local as python_setup\n",
    "os.remove('python_setup_local.py')\n",
    "\n",
    "# Run setup\n",
    "setup_info = python_setup.setup_environment(PROJECT_ID, REQ_TYPE, REQUIREMENTS_URL, REQUIRED_APIS, INSTALL_TOOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup_header",
   "metadata": {},
   "source": [
    "---\n",
    "## Test Configuration\n",
    "\n",
    "Configure the endpoint to test and the test parameters.\n",
    "\n",
    "**Endpoint Configuration:**\n",
    "- Update `ENDPOINT_DISPLAY_NAME` to match your deployed endpoint\n",
    "- Update `REGION` if your endpoint is in a different region\n",
    "\n",
    "**Test Parameters:**\n",
    "- `BATCH_SIZES`: Range of batch sizes to test (instances per request)\n",
    "- `RPS_TARGETS`: Range of request rates to test (requests per second)\n",
    "- `RPS_BATCH_SIZES`: Subset of batch sizes to use for RPS scaling tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Endpoint Configuration\n",
    "REGION = 'us-central1'\n",
    "ENDPOINT_DISPLAY_NAME = 'pytorch-autoencoder-endpoint'  # Replace with your endpoint name\n",
    "\n",
    "# Test Configuration\n",
    "BATCH_SIZES = [1, 5, 10, 50, 100, 500, 1000]  # Instances per request to test\n",
    "RPS_TARGETS = [1, 5, 10, 20, 50, 100]  # Requests per second to test\n",
    "RPS_BATCH_SIZES = [1, 5, 100]  # Which batch sizes to test at different RPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/google/home/statmike/.cache/pypoetry/virtualenvs/frameworks-pytorch-0KVJlKeQ-py3.13/lib/python3.13/site-packages/google/cloud/aiplatform/models.py:52: FutureWarning: Support for google-cloud-storage < 3.0.0 will be removed in a future version of google-cloud-aiplatform. Please upgrade to google-cloud-storage >= 3.0.0.\n",
      "  from google.cloud.aiplatform.utils import gcs_utils\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Imports complete\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import google.auth\n",
    "import google.auth.transport.requests\n",
    "from google.cloud import aiplatform, monitoring_v3\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "print(\"‚úÖ Imports complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "init_clients",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Initialized for project: statmike-mlops-349915\n"
     ]
    }
   ],
   "source": [
    "# Initialize clients\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
    "monitoring_client = monitoring_v3.MetricServiceClient()\n",
    "\n",
    "# Setup authentication for REST API\n",
    "credentials, _ = google.auth.default()\n",
    "auth_req = google.auth.transport.requests.Request()\n",
    "\n",
    "print(f\"‚úÖ Initialized for project: {PROJECT_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "connect_endpoint",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Connected to: pytorch-autoencoder-endpoint\n",
      "   Machine: n1-standard-4\n",
      "   Replicas: 1 - 4\n",
      "   URL: https://us-central1-aiplatform.googleapis.com/v1/projects/1026793852137/locations/us-central1/endpoints/2741468416626917376:predict\n"
     ]
    }
   ],
   "source": [
    "# Connect to endpoint\n",
    "endpoints = aiplatform.Endpoint.list(filter=f\"display_name={ENDPOINT_DISPLAY_NAME}\")\n",
    "if not endpoints:\n",
    "    raise ValueError(f\"No endpoint found: {ENDPOINT_DISPLAY_NAME}\")\n",
    "\n",
    "endpoint = endpoints[0]\n",
    "endpoint_url = f\"https://{REGION}-aiplatform.googleapis.com/v1/{endpoint.resource_name}:predict\"\n",
    "\n",
    "# Get endpoint configuration\n",
    "deployed_model = endpoint.list_models()[0]\n",
    "MACHINE_TYPE = deployed_model.dedicated_resources.machine_spec.machine_type\n",
    "MIN_REPLICAS = deployed_model.dedicated_resources.min_replica_count\n",
    "MAX_REPLICAS = deployed_model.dedicated_resources.max_replica_count\n",
    "\n",
    "print(f\"‚úÖ Connected to: {endpoint.display_name}\")\n",
    "print(f\"   Machine: {MACHINE_TYPE}\")\n",
    "print(f\"   Replicas: {MIN_REPLICAS} - {MAX_REPLICAS}\")\n",
    "print(f\"   URL: {endpoint_url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "test_connection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Endpoint connection successful\n",
      "   Sample prediction returned: 1 result(s)\n"
     ]
    }
   ],
   "source": [
    "# Test connection with a single prediction\n",
    "def generate_sample_data(batch_size=1):\n",
    "    \"\"\"Generate sample input data (30 features per instance)\"\"\"\n",
    "    return [np.random.randn(30).astype(np.float32).tolist() for _ in range(batch_size)]\n",
    "\n",
    "# Make a test request\n",
    "credentials.refresh(auth_req)\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {credentials.token}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "payload = {\"instances\": generate_sample_data(1)}\n",
    "\n",
    "import requests\n",
    "response = requests.post(endpoint_url, headers=headers, json=payload, timeout=30)\n",
    "response.raise_for_status()\n",
    "\n",
    "print(\"‚úÖ Endpoint connection successful\")\n",
    "print(f\"   Sample prediction returned: {len(response.json()['predictions'])} result(s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpers_header",
   "metadata": {},
   "source": [
    "---\n",
    "## Helper Functions\n",
    "\n",
    "Core async testing infrastructure with timing separation.\n",
    "\n",
    "**Key Design Features:**\n",
    "- **Async/await**: Uses `aiohttp` for concurrent HTTP requests\n",
    "- **Fixed-rate scheduling**: Creates requests at precise intervals to maintain target RPS\n",
    "- **Timing separation**: Tracks queueing time (client) vs request time (endpoint)\n",
    "- **Semaphore control**: Limits concurrent requests to prevent client overload\n",
    "- **Progress reporting**: Shows stats every 60 seconds during long tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "async_helpers",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Helper functions defined\n"
     ]
    }
   ],
   "source": [
    "async def run_load_test(\n",
    "    target_rps: int,\n",
    "    duration: int,\n",
    "    batch_size: int = 5,\n",
    "    test_name: str = \"Load Test\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Run load test with precise RPS control and timing separation.\n",
    "    \n",
    "    Uses fixed-rate scheduling: creates tasks just-in-time at exact intervals\n",
    "    to maintain target RPS without client-side backlog.\n",
    "    \n",
    "    Args:\n",
    "        target_rps: Target requests per second\n",
    "        duration: Test duration in seconds\n",
    "        batch_size: Instances per request\n",
    "        test_name: Name for logging\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with columns: timestamp, request_id, queueing_ms, request_ms, \n",
    "                                total_latency_ms, success, error (if failed)\n",
    "    \"\"\"\n",
    "    test_instances = generate_sample_data(batch_size)\n",
    "    total_requests = target_rps * duration\n",
    "    interval = 1.0 / target_rps\n",
    "    max_concurrent = min(target_rps * 2, 200)\n",
    "    semaphore = asyncio.Semaphore(max_concurrent)\n",
    "    \n",
    "    async def make_request(session, request_id, scheduled_time):\n",
    "        \"\"\"Make single async request with timing breakdown\"\"\"\n",
    "        queue_start = time.time()\n",
    "        \n",
    "        async with semaphore:\n",
    "            queue_end = time.time()\n",
    "            queueing_ms = (queue_end - queue_start) * 1000\n",
    "            \n",
    "            request_start = time.time()\n",
    "            try:\n",
    "                credentials.refresh(auth_req)\n",
    "                headers = {\n",
    "                    \"Authorization\": f\"Bearer {credentials.token}\",\n",
    "                    \"Content-Type\": \"application/json\"\n",
    "                }\n",
    "                payload = {\"instances\": test_instances}\n",
    "                \n",
    "                async with session.post(\n",
    "                    endpoint_url, \n",
    "                    json=payload, \n",
    "                    headers=headers,\n",
    "                    timeout=aiohttp.ClientTimeout(total=300)\n",
    "                ) as response:\n",
    "                    request_end = time.time()\n",
    "                    request_ms = (request_end - request_start) * 1000\n",
    "                    total_latency_ms = (request_end - queue_start) * 1000\n",
    "                    \n",
    "                    if response.status == 200:\n",
    "                        await response.json()\n",
    "                        return {\n",
    "                            'timestamp': datetime.now(),\n",
    "                            'request_id': request_id,\n",
    "                            'queueing_ms': queueing_ms,\n",
    "                            'request_ms': request_ms,\n",
    "                            'total_latency_ms': total_latency_ms,\n",
    "                            'success': True\n",
    "                        }\n",
    "                    else:\n",
    "                        error_text = await response.text()\n",
    "                        return {\n",
    "                            'timestamp': datetime.now(),\n",
    "                            'request_id': request_id,\n",
    "                            'queueing_ms': queueing_ms,\n",
    "                            'request_ms': request_ms,\n",
    "                            'total_latency_ms': total_latency_ms,\n",
    "                            'success': False,\n",
    "                            'error': f\"HTTP {response.status}: {error_text[:100]}\"\n",
    "                        }\n",
    "            except Exception as e:\n",
    "                request_end = time.time()\n",
    "                return {\n",
    "                    'timestamp': datetime.now(),\n",
    "                    'request_id': request_id,\n",
    "                    'queueing_ms': queueing_ms,\n",
    "                    'request_ms': (request_end - request_start) * 1000,\n",
    "                    'total_latency_ms': (request_end - queue_start) * 1000,\n",
    "                    'success': False,\n",
    "                    'error': str(e)[:100]\n",
    "                }\n",
    "    \n",
    "    async def scheduler(session):\n",
    "        \"\"\"Schedule requests at precise intervals\"\"\"\n",
    "        test_start = time.time()\n",
    "        active_tasks = set()\n",
    "        completed = []\n",
    "        \n",
    "        for i in range(total_requests):\n",
    "            target_time = test_start + (i * interval)\n",
    "            wait = target_time - time.time()\n",
    "            if wait > 0:\n",
    "                await asyncio.sleep(wait)\n",
    "            \n",
    "            task = asyncio.create_task(make_request(session, i, target_time))\n",
    "            active_tasks.add(task)\n",
    "            task.add_done_callback(lambda t: active_tasks.discard(t))\n",
    "            \n",
    "            if len(active_tasks) >= max_concurrent:\n",
    "                done, _ = await asyncio.wait(active_tasks, return_when=asyncio.FIRST_COMPLETED)\n",
    "                completed.extend([t.result() for t in done])\n",
    "            \n",
    "            # Progress every 60 seconds\n",
    "            if i > 0 and i % (target_rps * 60) == 0:\n",
    "                elapsed = time.time() - test_start\n",
    "                success = len([r for r in completed if r['success']])\n",
    "                avg_lat = sum(r['total_latency_ms'] for r in completed if r['success']) / max(success, 1)\n",
    "                print(f\"  [{int(elapsed):3d}s] {len(completed):,} done | \"\n",
    "                      f\"Success: {success:,} | Avg: {avg_lat:.1f}ms\")\n",
    "        \n",
    "        if active_tasks:\n",
    "            remaining = await asyncio.gather(*active_tasks)\n",
    "            completed.extend(remaining)\n",
    "        \n",
    "        return completed\n",
    "    \n",
    "    # Run test\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{test_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Target: {target_rps} RPS √ó {duration}s = {total_requests:,} requests\")\n",
    "    print(f\"Batch size: {batch_size} | Concurrency: {max_concurrent}\")\n",
    "    \n",
    "    connector = aiohttp.TCPConnector(limit=max_concurrent)\n",
    "    async with aiohttp.ClientSession(connector=connector) as session:\n",
    "        results = await scheduler(session)\n",
    "    \n",
    "    # Summary\n",
    "    df = pd.DataFrame(results)\n",
    "    success = df[df['success'] == True]\n",
    "    print(f\"\\n‚úÖ Complete: {len(success):,}/{len(df):,} successful ({len(success)/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    if len(success) > 0:\n",
    "        print(f\"   Total Latency:   {success['total_latency_ms'].mean():.1f}ms (mean) | \"\n",
    "              f\"{success['total_latency_ms'].quantile(0.95):.1f}ms (p95)\")\n",
    "        print(f\"   Queueing Time:   {success['queueing_ms'].mean():.1f}ms (mean) | \"\n",
    "              f\"{success['queueing_ms'].quantile(0.95):.1f}ms (p95)\")\n",
    "        print(f\"   Request Time:    {success['request_ms'].mean():.1f}ms (mean) | \"\n",
    "              f\"{success['request_ms'].quantile(0.95):.1f}ms (p95)\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"‚úÖ Helper functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phase1_header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Phase 1: Find Breaking Points\n",
    "\n",
    "Systematically test to find:\n",
    "1. **Optimal batch size** - Best latency/throughput balance\n",
    "2. **Maximum RPS** - Where does performance degrade?\n",
    "3. **Bottleneck location** - Client queueing vs endpoint processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "batch_test_header",
   "metadata": {},
   "source": [
    "### Test 1: Batch Size Impact\n",
    "\n",
    "Test how latency changes with batch size at a constant low RPS (1 RPS).\n",
    "\n",
    "This isolates batch size effects from concurrency/queueing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "batch_test",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing batch=1... avg=66.9ms, p95=86.9ms\n",
      "Testing batch=5... avg=80.0ms, p95=163.9ms\n",
      "Testing batch=10... avg=70.4ms, p95=89.3ms\n",
      "Testing batch=50... avg=128.7ms, p95=153.6ms\n",
      "Testing batch=100... avg=203.6ms, p95=219.6ms\n",
      "Testing batch=500... avg=821.0ms, p95=931.2ms\n",
      "Testing batch=1000... avg=1766.4ms, p95=1963.3ms\n",
      "\n",
      "‚úÖ Batch size test complete: 70 requests\n"
     ]
    }
   ],
   "source": [
    "# Run batch size test (1 RPS, 10 requests per batch size)\n",
    "batch_results = []\n",
    "\n",
    "for batch_size in BATCH_SIZES:\n",
    "    print(f\"Testing batch={batch_size}...\", end=\" \")\n",
    "    \n",
    "    latencies = []\n",
    "    for i in range(10):\n",
    "        instances = generate_sample_data(batch_size)\n",
    "        credentials.refresh(auth_req)\n",
    "        headers = {\"Authorization\": f\"Bearer {credentials.token}\", \"Content-Type\": \"application/json\"}\n",
    "        \n",
    "        start = time.time()\n",
    "        response = requests.post(endpoint_url, headers=headers, json={\"instances\": instances}, timeout=300)\n",
    "        latency = (time.time() - start) * 1000\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            latencies.append(latency)\n",
    "            batch_results.append({\n",
    "                'batch_size': batch_size,\n",
    "                'latency_ms': latency,\n",
    "                'success': True\n",
    "            })\n",
    "        \n",
    "        if i < 9:\n",
    "            time.sleep(1)  # 1 second between requests = 1 RPS\n",
    "    \n",
    "    if latencies:\n",
    "        print(f\"avg={np.mean(latencies):.1f}ms, p95={np.percentile(latencies, 95):.1f}ms\")\n",
    "\n",
    "df_batch = pd.DataFrame(batch_results)\n",
    "print(f\"\\n‚úÖ Batch size test complete: {len(df_batch)} requests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "batch_viz",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "width": 2
         },
         "mode": "lines+markers",
         "name": "Mean",
         "type": "scatter",
         "x": {
          "bdata": "AQAFAAoAMgBkAPQB6AM=",
          "dtype": "i2"
         },
         "y": {
          "bdata": "AAAAXOi5UEAAAAAEpP1TQAAAALhqmVFAAAAAIJcVYEAAAABMDnNpQAAAAEJRqIlAAADA8WaZm0A=",
          "dtype": "f8"
         }
        },
        {
         "line": {
          "dash": "dash"
         },
         "mode": "lines+markers",
         "name": "P95",
         "type": "scatter",
         "x": {
          "bdata": "AQAFAAoAMgBkAPQB6AM=",
          "dtype": "i2"
         },
         "y": {
          "bdata": "AAAA5FS7VUD7//8gcH1kQAAAAO6bUFZA////XLA0Y0AAAAA6cnRrQAAAQIesGY1A//8/mUatnkA=",
          "dtype": "f8"
         }
        }
       ],
       "layout": {
        "height": 400,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Latency vs Batch Size (1 RPS)"
        },
        "xaxis": {
         "title": {
          "text": "Batch Size (instances per request)"
         },
         "type": "log"
        },
        "yaxis": {
         "title": {
          "text": "Latency (ms)"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Analysis:\n",
      "   Baseline (batch=1): 66.9ms\n",
      "   Optimal batch size: 50 (latency < 2x baseline)\n",
      "   Latency at optimal: 128.7ms\n"
     ]
    }
   ],
   "source": [
    "# Visualize batch size results\n",
    "stats = df_batch.groupby('batch_size')['latency_ms'].agg(['mean', 'median', \n",
    "    ('p95', lambda x: np.percentile(x, 95))]).reset_index()\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=stats['batch_size'], y=stats['mean'], \n",
    "                         mode='lines+markers', name='Mean', line=dict(width=2)))\n",
    "fig.add_trace(go.Scatter(x=stats['batch_size'], y=stats['p95'], \n",
    "                         mode='lines+markers', name='P95', line=dict(dash='dash')))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Latency vs Batch Size (1 RPS)',\n",
    "    xaxis_title='Batch Size (instances per request)',\n",
    "    yaxis_title='Latency (ms)',\n",
    "    xaxis_type='log',\n",
    "    height=400\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# Find optimal batch size (< 2x baseline latency)\n",
    "baseline = stats[stats['batch_size'] == 1]['mean'].values[0]\n",
    "optimal = stats[stats['mean'] <= baseline * 2]['batch_size'].max()\n",
    "print(f\"\\nüìä Analysis:\")\n",
    "print(f\"   Baseline (batch=1): {baseline:.1f}ms\")\n",
    "print(f\"   Optimal batch size: {optimal} (latency < 2x baseline)\")\n",
    "print(f\"   Latency at optimal: {stats[stats['batch_size']==optimal]['mean'].values[0]:.1f}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rps_test_header",
   "metadata": {},
   "source": [
    "### Test 2: RPS Scaling\n",
    "\n",
    "Test how the endpoint handles increasing request rates.\n",
    "\n",
    "**Key insight**: Timing separation shows whether bottleneck is client-side (high queueing) or endpoint-side (high request time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "rps_test",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Testing batch_size=1\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Batch 1 @ 1 RPS\n",
      "============================================================\n",
      "Target: 1 RPS √ó 30s = 30 requests\n",
      "Batch size: 1 | Concurrency: 2\n",
      "\n",
      "‚úÖ Complete: 1/1 successful (100.0%)\n",
      "   Total Latency:   81.7ms (mean) | 81.7ms (p95)\n",
      "   Queueing Time:   0.0ms (mean) | 0.0ms (p95)\n",
      "   Request Time:    81.7ms (mean) | 81.7ms (p95)\n",
      "\n",
      "============================================================\n",
      "Batch 1 @ 5 RPS\n",
      "============================================================\n",
      "Target: 5 RPS √ó 30s = 150 requests\n",
      "Batch size: 1 | Concurrency: 10\n",
      "\n",
      "‚úÖ Complete: 1/1 successful (100.0%)\n",
      "   Total Latency:   55.3ms (mean) | 55.3ms (p95)\n",
      "   Queueing Time:   0.0ms (mean) | 0.0ms (p95)\n",
      "   Request Time:    55.3ms (mean) | 55.3ms (p95)\n",
      "\n",
      "============================================================\n",
      "Batch 1 @ 10 RPS\n",
      "============================================================\n",
      "Target: 10 RPS √ó 30s = 300 requests\n",
      "Batch size: 1 | Concurrency: 20\n",
      "\n",
      "‚úÖ Complete: 1/1 successful (100.0%)\n",
      "   Total Latency:   59.4ms (mean) | 59.4ms (p95)\n",
      "   Queueing Time:   0.0ms (mean) | 0.0ms (p95)\n",
      "   Request Time:    59.3ms (mean) | 59.3ms (p95)\n",
      "\n",
      "============================================================\n",
      "Batch 1 @ 20 RPS\n",
      "============================================================\n",
      "Target: 20 RPS √ó 30s = 600 requests\n",
      "Batch size: 1 | Concurrency: 40\n",
      "\n",
      "‚úÖ Complete: 2/2 successful (100.0%)\n",
      "   Total Latency:   67.2ms (mean) | 74.1ms (p95)\n",
      "   Queueing Time:   0.0ms (mean) | 0.0ms (p95)\n",
      "   Request Time:    67.2ms (mean) | 74.1ms (p95)\n",
      "\n",
      "============================================================\n",
      "Batch 1 @ 50 RPS\n",
      "============================================================\n",
      "Target: 50 RPS √ó 30s = 1,500 requests\n",
      "Batch size: 1 | Concurrency: 100\n",
      "\n",
      "‚úÖ Complete: 2,806/2,806 successful (100.0%)\n",
      "   Total Latency:   1484.7ms (mean) | 2640.7ms (p95)\n",
      "   Queueing Time:   0.0ms (mean) | 0.0ms (p95)\n",
      "   Request Time:    1484.7ms (mean) | 2640.7ms (p95)\n",
      "\n",
      "============================================================\n",
      "Batch 1 @ 100 RPS\n",
      "============================================================\n",
      "Target: 100 RPS √ó 30s = 3,000 requests\n",
      "Batch size: 1 | Concurrency: 200\n",
      "\n",
      "‚úÖ Complete: 5,798/5,798 successful (100.0%)\n",
      "   Total Latency:   2851.7ms (mean) | 4560.0ms (p95)\n",
      "   Queueing Time:   0.0ms (mean) | 0.0ms (p95)\n",
      "   Request Time:    2851.7ms (mean) | 4560.0ms (p95)\n",
      "\n",
      "============================================================\n",
      "Testing batch_size=5\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Batch 5 @ 1 RPS\n",
      "============================================================\n",
      "Target: 1 RPS √ó 30s = 30 requests\n",
      "Batch size: 5 | Concurrency: 2\n",
      "\n",
      "‚úÖ Complete: 1/1 successful (100.0%)\n",
      "   Total Latency:   62.7ms (mean) | 62.7ms (p95)\n",
      "   Queueing Time:   0.0ms (mean) | 0.0ms (p95)\n",
      "   Request Time:    62.7ms (mean) | 62.7ms (p95)\n",
      "\n",
      "============================================================\n",
      "Batch 5 @ 5 RPS\n",
      "============================================================\n",
      "Target: 5 RPS √ó 30s = 150 requests\n",
      "Batch size: 5 | Concurrency: 10\n",
      "\n",
      "‚úÖ Complete: 1/1 successful (100.0%)\n",
      "   Total Latency:   64.7ms (mean) | 64.7ms (p95)\n",
      "   Queueing Time:   0.0ms (mean) | 0.0ms (p95)\n",
      "   Request Time:    64.7ms (mean) | 64.7ms (p95)\n",
      "\n",
      "============================================================\n",
      "Batch 5 @ 10 RPS\n",
      "============================================================\n",
      "Target: 10 RPS √ó 30s = 300 requests\n",
      "Batch size: 5 | Concurrency: 20\n",
      "\n",
      "‚úÖ Complete: 1/1 successful (100.0%)\n",
      "   Total Latency:   63.6ms (mean) | 63.6ms (p95)\n",
      "   Queueing Time:   0.0ms (mean) | 0.0ms (p95)\n",
      "   Request Time:    63.6ms (mean) | 63.6ms (p95)\n",
      "\n",
      "============================================================\n",
      "Batch 5 @ 20 RPS\n",
      "============================================================\n",
      "Target: 20 RPS √ó 30s = 600 requests\n",
      "Batch size: 5 | Concurrency: 40\n",
      "\n",
      "‚úÖ Complete: 2/2 successful (100.0%)\n",
      "   Total Latency:   75.6ms (mean) | 84.2ms (p95)\n",
      "   Queueing Time:   0.0ms (mean) | 0.0ms (p95)\n",
      "   Request Time:    75.6ms (mean) | 84.2ms (p95)\n",
      "\n",
      "============================================================\n",
      "Batch 5 @ 50 RPS\n",
      "============================================================\n",
      "Target: 50 RPS √ó 30s = 1,500 requests\n",
      "Batch size: 5 | Concurrency: 100\n",
      "\n",
      "‚úÖ Complete: 2,484/2,484 successful (100.0%)\n",
      "   Total Latency:   1445.3ms (mean) | 2798.8ms (p95)\n",
      "   Queueing Time:   0.0ms (mean) | 0.0ms (p95)\n",
      "   Request Time:    1445.3ms (mean) | 2798.8ms (p95)\n",
      "\n",
      "============================================================\n",
      "Batch 5 @ 100 RPS\n",
      "============================================================\n",
      "Target: 100 RPS √ó 30s = 3,000 requests\n",
      "Batch size: 5 | Concurrency: 200\n",
      "\n",
      "‚úÖ Complete: 5,777/5,777 successful (100.0%)\n",
      "   Total Latency:   2875.0ms (mean) | 4248.1ms (p95)\n",
      "   Queueing Time:   0.0ms (mean) | 0.0ms (p95)\n",
      "   Request Time:    2875.0ms (mean) | 4248.0ms (p95)\n",
      "\n",
      "============================================================\n",
      "Testing batch_size=100\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Batch 100 @ 1 RPS\n",
      "============================================================\n",
      "Target: 1 RPS √ó 30s = 30 requests\n",
      "Batch size: 100 | Concurrency: 2\n",
      "\n",
      "‚úÖ Complete: 1/1 successful (100.0%)\n",
      "   Total Latency:   244.3ms (mean) | 244.3ms (p95)\n",
      "   Queueing Time:   0.0ms (mean) | 0.0ms (p95)\n",
      "   Request Time:    244.2ms (mean) | 244.2ms (p95)\n",
      "\n",
      "============================================================\n",
      "Batch 100 @ 5 RPS\n",
      "============================================================\n",
      "Target: 5 RPS √ó 30s = 150 requests\n",
      "Batch size: 100 | Concurrency: 10\n",
      "\n",
      "‚úÖ Complete: 2/2 successful (100.0%)\n",
      "   Total Latency:   202.7ms (mean) | 205.4ms (p95)\n",
      "   Queueing Time:   0.0ms (mean) | 0.0ms (p95)\n",
      "   Request Time:    202.7ms (mean) | 205.4ms (p95)\n",
      "\n",
      "============================================================\n",
      "Batch 100 @ 10 RPS\n",
      "============================================================\n",
      "Target: 10 RPS √ó 30s = 300 requests\n",
      "Batch size: 100 | Concurrency: 20\n",
      "\n",
      "‚úÖ Complete: 3/3 successful (100.0%)\n",
      "   Total Latency:   215.6ms (mean) | 235.6ms (p95)\n",
      "   Queueing Time:   0.0ms (mean) | 0.0ms (p95)\n",
      "   Request Time:    215.6ms (mean) | 235.6ms (p95)\n",
      "\n",
      "============================================================\n",
      "Batch 100 @ 20 RPS\n",
      "============================================================\n",
      "Target: 20 RPS √ó 30s = 600 requests\n",
      "Batch size: 100 | Concurrency: 40\n",
      "\n",
      "‚úÖ Complete: 5/5 successful (100.0%)\n",
      "   Total Latency:   212.9ms (mean) | 234.6ms (p95)\n",
      "   Queueing Time:   0.0ms (mean) | 0.0ms (p95)\n",
      "   Request Time:    212.9ms (mean) | 234.6ms (p95)\n",
      "\n",
      "============================================================\n",
      "Batch 100 @ 50 RPS\n",
      "============================================================\n",
      "Target: 50 RPS √ó 30s = 1,500 requests\n",
      "Batch size: 100 | Concurrency: 100\n",
      "\n",
      "‚úÖ Complete: 2,823/2,823 successful (100.0%)\n",
      "   Total Latency:   2128.4ms (mean) | 2912.8ms (p95)\n",
      "   Queueing Time:   0.0ms (mean) | 0.0ms (p95)\n",
      "   Request Time:    2128.4ms (mean) | 2912.8ms (p95)\n",
      "\n",
      "============================================================\n",
      "Batch 100 @ 100 RPS\n",
      "============================================================\n",
      "Target: 100 RPS √ó 30s = 3,000 requests\n",
      "Batch size: 100 | Concurrency: 200\n",
      "\n",
      "‚úÖ Complete: 5,701/5,701 successful (100.0%)\n",
      "   Total Latency:   4318.3ms (mean) | 5697.8ms (p95)\n",
      "   Queueing Time:   0.0ms (mean) | 0.0ms (p95)\n",
      "   Request Time:    4318.3ms (mean) | 5697.8ms (p95)\n",
      "\n",
      "‚úÖ RPS scaling tests complete: 25,410 total requests\n"
     ]
    }
   ],
   "source": [
    "# Run RPS scaling tests\n",
    "rps_results = []\n",
    "\n",
    "for batch_size in RPS_BATCH_SIZES:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Testing batch_size={batch_size}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    for target_rps in RPS_TARGETS:\n",
    "        df = await run_load_test(\n",
    "            target_rps=target_rps,\n",
    "            duration=30,\n",
    "            batch_size=batch_size,\n",
    "            test_name=f\"Batch {batch_size} @ {target_rps} RPS\"\n",
    "        )\n",
    "        df['batch_size'] = batch_size\n",
    "        df['target_rps'] = target_rps\n",
    "        rps_results.append(df)\n",
    "\n",
    "df_rps = pd.concat(rps_results, ignore_index=True)\n",
    "print(f\"\\n‚úÖ RPS scaling tests complete: {len(df_rps):,} total requests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "rps_viz",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "color": "blue",
          "width": 2
         },
         "marker": {
          "size": 8
         },
         "mode": "lines+markers",
         "name": "Batch 1",
         "type": "scatter",
         "x": {
          "bdata": "AQUKFDJk",
          "dtype": "i1"
         },
         "xaxis": "x",
         "y": {
          "bdata": "AAAAyMJqVEAAAABgHKRLQAAAABBSrU1AAAAAjJPKUEDVUH8juDKXQEwCAhRgR6ZA",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "line": {
          "color": "blue",
          "width": 2
         },
         "mode": "lines+markers",
         "showlegend": false,
         "type": "scatter",
         "x": {
          "bdata": "AQUKFDJk",
          "dtype": "i1"
         },
         "xaxis": "x3",
         "y": {
          "bdata": "AAAAAAAAWUAAAAAAAABZQAAAAAAAAFlAAAAAAAAAWUAAAAAAAABZQAAAAAAAAFlA",
          "dtype": "f8"
         },
         "yaxis": "y3"
        },
        {
         "line": {
          "color": "blue",
          "width": 2
         },
         "mode": "lines+markers",
         "showlegend": false,
         "type": "scatter",
         "x": {
          "bdata": "AQUKFDJk",
          "dtype": "i1"
         },
         "xaxis": "x4",
         "y": {
          "bdata": "AAAAgNRpVEAAAADwjaJLQAAAAHDLq01AAAAAqL7JUEAr/C6NqzKXQP2pucZZR6ZA",
          "dtype": "f8"
         },
         "yaxis": "y4"
        },
        {
         "marker": {
          "color": "lightblue"
         },
         "name": "Queueing",
         "showlegend": true,
         "type": "bar",
         "x": [
          "Batch 1"
         ],
         "xaxis": "x2",
         "y": [
          0.011203905022033292
         ],
         "yaxis": "y2"
        },
        {
         "marker": {
          "color": "darkblue"
         },
         "name": "Request",
         "showlegend": true,
         "type": "bar",
         "x": [
          "Batch 1"
         ],
         "xaxis": "x2",
         "y": [
          2851.675344278336
         ],
         "yaxis": "y2"
        },
        {
         "line": {
          "color": "green",
          "width": 2
         },
         "marker": {
          "size": 8
         },
         "mode": "lines+markers",
         "name": "Batch 5",
         "type": "scatter",
         "x": {
          "bdata": "AQUKFDJk",
          "dtype": "i1"
         },
         "xaxis": "x",
         "y": {
          "bdata": "AAAAoGdbT0AAAAAgXy9QQAAAAHDDyk9AAAAA4BjlUkB0I7LvW5WWQLNATKMGdqZA",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "line": {
          "color": "green",
          "width": 2
         },
         "mode": "lines+markers",
         "showlegend": false,
         "type": "scatter",
         "x": {
          "bdata": "AQUKFDJk",
          "dtype": "i1"
         },
         "xaxis": "x3",
         "y": {
          "bdata": "AAAAAAAAWUAAAAAAAABZQAAAAAAAAFlAAAAAAAAAWUAAAAAAAABZQAAAAAAAAFlA",
          "dtype": "f8"
         },
         "yaxis": "y3"
        },
        {
         "line": {
          "color": "green",
          "width": 2
         },
         "mode": "lines+markers",
         "showlegend": false,
         "type": "scatter",
         "x": {
          "bdata": "AQUKFDJk",
          "dtype": "i1"
         },
         "xaxis": "x4",
         "y": {
          "bdata": "AAAA0OhZT0AAAABYry5QQAAAAAA1yU9AAAAAUDbkUkCZPCGRT5WWQNcuLzQAdqZA",
          "dtype": "f8"
         },
         "yaxis": "y4"
        },
        {
         "marker": {
          "color": "lightblue"
         },
         "name": "",
         "showlegend": false,
         "type": "bar",
         "x": [
          "Batch 5"
         ],
         "xaxis": "x2",
         "y": [
          0.01143653933020102
         ],
         "yaxis": "y2"
        },
        {
         "marker": {
          "color": "darkblue"
         },
         "name": "",
         "showlegend": false,
         "type": "bar",
         "x": [
          "Batch 5"
         ],
         "xaxis": "x2",
         "y": [
          2875.0003981346777
         ],
         "yaxis": "y2"
        },
        {
         "line": {
          "color": "orange",
          "width": 2
         },
         "marker": {
          "size": 8
         },
         "mode": "lines+markers",
         "name": "Batch 100",
         "type": "scatter",
         "x": {
          "bdata": "AQUKFDJk",
          "dtype": "i1"
         },
         "xaxis": "x",
         "y": {
          "bdata": "AAAABBSIbkAAAAC2j1VpQFVVVcmG8mpAAAAAuHKcakDMds6WxqCgQFgQRAND3rBA",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "line": {
          "color": "orange",
          "width": 2
         },
         "mode": "lines+markers",
         "showlegend": false,
         "type": "scatter",
         "x": {
          "bdata": "AQUKFDJk",
          "dtype": "i1"
         },
         "xaxis": "x3",
         "y": {
          "bdata": "AAAAAAAAWUAAAAAAAABZQAAAAAAAAFlAAAAAAAAAWUAAAAAAAABZQAAAAAAAAFlA",
          "dtype": "f8"
         },
         "yaxis": "y3"
        },
        {
         "line": {
          "color": "orange",
          "width": 2
         },
         "mode": "lines+markers",
         "showlegend": false,
         "type": "scatter",
         "x": {
          "bdata": "AQUKFDJk",
          "dtype": "i1"
         },
         "xaxis": "x4",
         "y": {
          "bdata": "AAAANI+HbkAAAACuPVVpQKuqquYS8mpAAAAAqBmcakCLAdnEu6CgQOxXcgZA3rBA",
          "dtype": "f8"
         },
         "yaxis": "y4"
        },
        {
         "marker": {
          "color": "lightblue"
         },
         "name": "",
         "showlegend": false,
         "type": "bar",
         "x": [
          "Batch 100"
         ],
         "xaxis": "x2",
         "y": [
          0.010354291805152913
         ],
         "yaxis": "y2"
        },
        {
         "marker": {
          "color": "darkblue"
         },
         "name": "",
         "showlegend": false,
         "type": "bar",
         "x": [
          "Batch 100"
         ],
         "xaxis": "x2",
         "y": [
          4318.250098368135
         ],
         "yaxis": "y2"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Total Latency vs RPS",
          "x": 0.22,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Timing Breakdown @ Max RPS",
          "x": 0.78,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Success Rate vs RPS",
          "x": 0.22,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.44,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Request Time vs RPS",
          "x": 0.78,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.44,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "barmode": "stack",
        "height": 700,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.44
         ],
         "title": {
          "text": "Target RPS"
         }
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.56,
          1
         ],
         "title": {
          "text": "Batch Size"
         }
        },
        "xaxis3": {
         "anchor": "y3",
         "domain": [
          0,
          0.44
         ],
         "title": {
          "text": "Target RPS"
         }
        },
        "xaxis4": {
         "anchor": "y4",
         "domain": [
          0.56,
          1
         ],
         "title": {
          "text": "Target RPS"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0.56,
          1
         ],
         "title": {
          "text": "Latency (ms)"
         }
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0.56,
          1
         ],
         "title": {
          "text": "Time (ms)"
         }
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0,
          0.44
         ],
         "range": [
          0,
          105
         ],
         "title": {
          "text": "Success Rate (%)"
         }
        },
        "yaxis4": {
         "anchor": "x4",
         "domain": [
          0,
          0.44
         ],
         "title": {
          "text": "Request Time (ms)"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Breaking Point Analysis:\n",
      "\n",
      "   Batch   1: Max reliable RPS = 100\n",
      "      P95 Total:    4560.0ms\n",
      "      P95 Queue:       0.0ms ( 0.0% of total)\n",
      "      P95 Request:  4560.0ms (100.0% of total)\n",
      "      ‚úÖ Bottleneck: Endpoint processing (expected)\n",
      "\n",
      "   Batch   5: Max reliable RPS = 100\n",
      "      P95 Total:    4248.1ms\n",
      "      P95 Queue:       0.0ms ( 0.0% of total)\n",
      "      P95 Request:  4248.0ms (100.0% of total)\n",
      "      ‚úÖ Bottleneck: Endpoint processing (expected)\n",
      "\n",
      "   Batch 100: Max reliable RPS = 100\n",
      "      P95 Total:    5697.8ms\n",
      "      P95 Queue:       0.0ms ( 0.0% of total)\n",
      "      P95 Request:  5697.8ms (100.0% of total)\n",
      "      ‚úÖ Bottleneck: Endpoint processing (expected)\n"
     ]
    }
   ],
   "source": [
    "# Analyze and visualize RPS results\n",
    "success = df_rps[df_rps['success'] == True]\n",
    "\n",
    "# Calculate stats by batch size and RPS\n",
    "stats = success.groupby(['batch_size', 'target_rps']).agg({\n",
    "    'total_latency_ms': ['mean', lambda x: np.percentile(x, 95)],\n",
    "    'queueing_ms': ['mean', lambda x: np.percentile(x, 95)],\n",
    "    'request_ms': ['mean', lambda x: np.percentile(x, 95)]\n",
    "}).reset_index()\n",
    "\n",
    "stats.columns = ['batch_size', 'target_rps', 'total_mean', 'total_p95', \n",
    "                 'queue_mean', 'queue_p95', 'request_mean', 'request_p95']\n",
    "\n",
    "# Success rates\n",
    "success_rates = df_rps.groupby(['batch_size', 'target_rps'])['success'].apply(\n",
    "    lambda x: (x == True).sum() / len(x) * 100\n",
    ").reset_index(name='success_rate')\n",
    "stats = stats.merge(success_rates, on=['batch_size', 'target_rps'])\n",
    "\n",
    "# Create visualization\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=('Total Latency vs RPS', 'Timing Breakdown @ Max RPS',\n",
    "                   'Success Rate vs RPS', 'Request Time vs RPS'),\n",
    "    specs=[[{}, {}], [{}, {}]],\n",
    "    vertical_spacing=0.12,\n",
    "    horizontal_spacing=0.12\n",
    ")\n",
    "\n",
    "colors = ['blue', 'green', 'orange']\n",
    "\n",
    "for i, batch_size in enumerate(RPS_BATCH_SIZES):\n",
    "    data = stats[stats['batch_size'] == batch_size]\n",
    "    \n",
    "    # Total latency\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=data['target_rps'], y=data['total_mean'],\n",
    "        name=f'Batch {batch_size}', mode='lines+markers',\n",
    "        line=dict(color=colors[i], width=2), marker=dict(size=8)\n",
    "    ), row=1, col=1)\n",
    "    \n",
    "    # Success rate\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=data['target_rps'], y=data['success_rate'],\n",
    "        mode='lines+markers', line=dict(color=colors[i], width=2),\n",
    "        showlegend=False\n",
    "    ), row=2, col=1)\n",
    "    \n",
    "    # Request time\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=data['target_rps'], y=data['request_mean'],\n",
    "        mode='lines+markers', line=dict(color=colors[i], width=2),\n",
    "        showlegend=False\n",
    "    ), row=2, col=2)\n",
    "    \n",
    "    # Timing breakdown at max RPS\n",
    "    max_rps_data = data[data['target_rps'] == data['target_rps'].max()].iloc[0]\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=[f'Batch {batch_size}'], y=[max_rps_data['queue_mean']],\n",
    "        name='Queueing' if i == 0 else '', marker_color='lightblue',\n",
    "        showlegend=(i == 0)\n",
    "    ), row=1, col=2)\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=[f'Batch {batch_size}'], y=[max_rps_data['request_mean']],\n",
    "        name='Request' if i == 0 else '', marker_color='darkblue',\n",
    "        showlegend=(i == 0)\n",
    "    ), row=1, col=2)\n",
    "\n",
    "fig.update_xaxes(title_text=\"Target RPS\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Batch Size\", row=1, col=2)\n",
    "fig.update_xaxes(title_text=\"Target RPS\", row=2, col=1)\n",
    "fig.update_xaxes(title_text=\"Target RPS\", row=2, col=2)\n",
    "\n",
    "fig.update_yaxes(title_text=\"Latency (ms)\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Time (ms)\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Success Rate (%)\", row=2, col=1, range=[0, 105])\n",
    "fig.update_yaxes(title_text=\"Request Time (ms)\", row=2, col=2)\n",
    "\n",
    "fig.update_layout(barmode='stack', height=700)\n",
    "fig.show()\n",
    "\n",
    "# Print breaking point analysis\n",
    "print(\"\\nüìä Breaking Point Analysis:\")\n",
    "for batch_size in RPS_BATCH_SIZES:\n",
    "    data = stats[stats['batch_size'] == batch_size]\n",
    "    reliable = data[data['success_rate'] >= 95]\n",
    "    \n",
    "    if len(reliable) > 0:\n",
    "        max_rps = reliable['target_rps'].max()\n",
    "        row = reliable[reliable['target_rps'] == max_rps].iloc[0]\n",
    "        \n",
    "        queue_pct = (row['queue_p95'] / row['total_p95'] * 100) if row['total_p95'] > 0 else 0\n",
    "        \n",
    "        print(f\"\\n   Batch {int(batch_size):3d}: Max reliable RPS = {int(max_rps):3d}\")\n",
    "        print(f\"      P95 Total:   {row['total_p95']:7.1f}ms\")\n",
    "        print(f\"      P95 Queue:   {row['queue_p95']:7.1f}ms ({queue_pct:4.1f}% of total)\")\n",
    "        print(f\"      P95 Request: {row['request_p95']:7.1f}ms ({100-queue_pct:4.1f}% of total)\")\n",
    "        \n",
    "        if queue_pct > 50:\n",
    "            print(f\"      ‚ö†Ô∏è  Bottleneck: Client-side queueing\")\n",
    "        else:\n",
    "            print(f\"      ‚úÖ Bottleneck: Endpoint processing (expected)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phase1_summary",
   "metadata": {},
   "source": [
    "### Phase 1 Summary\n",
    "\n",
    "**Key Findings from Tests:**\n",
    "\n",
    "1. **Batch Size Impact:**\n",
    "   - Baseline latency (batch=1): ~67ms\n",
    "   - Optimal batch size: **50** (balances latency vs throughput)\n",
    "   - Latency increases linearly with batch size for this model\n",
    "\n",
    "2. **RPS Scaling:**\n",
    "   - Low RPS (1-20): Excellent performance (~55-75ms)\n",
    "   - Medium RPS (50): Moderate degradation (~1.4s)\n",
    "   - High RPS (100): Significant degradation (~2.8-4.3s)\n",
    "   - **All requests successful (100% success rate)**\n",
    "\n",
    "3. **Bottleneck Analysis:**\n",
    "   - Zero client-side queueing across all tests\n",
    "   - Bottleneck is endpoint processing capacity (expected)\n",
    "   - Endpoint can handle 100 RPS but with high latency\n",
    "\n",
    "**Next**: Phase 2 uses these insights to test sustained load patterns and observe autoscaling behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phase2_header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Phase 2: Sustained Load Testing\n",
    "\n",
    "Apply realistic traffic patterns over extended periods to:\n",
    "- Observe autoscaling behavior\n",
    "- Measure steady-state performance\n",
    "- Test spike handling\n",
    "\n",
    "**Configure test parameters below based on Phase 1 results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "phase2_config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 2 Configuration (adjust based on Phase 1 results)\n",
    "PHASE2_BATCH_SIZE = 5  # Use a moderate batch size from Phase 1\n",
    "\n",
    "# Pattern 1: Constant Load\n",
    "# Tests steady-state performance under sustained traffic\n",
    "CONSTANT_RPS = 50  # Moderate sustained load\n",
    "CONSTANT_DURATION = 600  # 10 minutes\n",
    "\n",
    "# Pattern 2: Spike Test\n",
    "# Tests autoscaling responsiveness and recovery\n",
    "BASELINE_RPS = 20  # Low baseline\n",
    "SPIKE_RPS = 100  # High spike\n",
    "SPIKE_DURATION = 120  # 2 minutes\n",
    "\n",
    "print(\"Phase 2 Configuration:\")\n",
    "print(f\"  Constant Load: {CONSTANT_RPS} RPS √ó {CONSTANT_DURATION/60:.0f} min\")\n",
    "print(f\"  Spike Test: {BASELINE_RPS} ‚Üí {SPIKE_RPS} ‚Üí {BASELINE_RPS} RPS\")\n",
    "print(f\"  Batch size: {PHASE2_BATCH_SIZE}\")\n",
    "print(f\"\\nNote: Adjust these values based on your Phase 1 results and production requirements.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constant_load_header",
   "metadata": {},
   "source": [
    "### Pattern 1: Constant Load\n",
    "\n",
    "Sustained traffic at constant RPS to observe:\n",
    "- Steady-state latency\n",
    "- CPU utilization patterns\n",
    "- Whether autoscaling triggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "constant_load",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Pattern 1: Constant Load\n",
      "============================================================\n",
      "Target: 50 RPS √ó 600s = 30,000 requests\n",
      "Batch size: 5 | Concurrency: 100\n",
      "  [ 82s] 5,713 done | Success: 5,713 | Avg: 1473.4ms\n",
      "  [168s] 10,675 done | Success: 10,675 | Avg: 1456.5ms\n",
      "  [255s] 15,837 done | Success: 15,837 | Avg: 1458.5ms\n",
      "  [340s] 20,074 done | Success: 20,074 | Avg: 1454.9ms\n",
      "  [425s] 24,873 done | Success: 24,873 | Avg: 1452.4ms\n",
      "  [508s] 29,822 done | Success: 29,822 | Avg: 1448.1ms\n",
      "  [595s] 34,025 done | Success: 34,025 | Avg: 1447.2ms\n",
      "  [677s] 39,371 done | Success: 39,371 | Avg: 1442.8ms\n",
      "  [760s] 43,764 done | Success: 43,764 | Avg: 1438.5ms\n",
      "\n",
      "‚úÖ Complete: 48,907/48,907 successful (100.0%)\n",
      "   Total Latency:   1436.5ms (mean) | 2582.0ms (p95)\n",
      "   Queueing Time:   0.0ms (mean) | 0.0ms (p95)\n",
      "   Request Time:    1436.5ms (mean) | 2582.0ms (p95)\n"
     ]
    }
   ],
   "source": [
    "# Run constant load test\n",
    "df_constant = await run_load_test(\n",
    "    target_rps=CONSTANT_RPS,\n",
    "    duration=CONSTANT_DURATION,\n",
    "    batch_size=PHASE2_BATCH_SIZE,\n",
    "    test_name=\"Pattern 1: Constant Load\"\n",
    ")\n",
    "\n",
    "df_constant['pattern'] = 'Constant Load'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spike_test_header",
   "metadata": {},
   "source": [
    "### Pattern 2: Traffic Spike\n",
    "\n",
    "Baseline ‚Üí Spike ‚Üí Recovery to test:\n",
    "- Cold-start latency during spike\n",
    "- Scale-up responsiveness\n",
    "- Recovery time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "spike_test",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Spike - Baseline 1\n",
      "============================================================\n",
      "Target: 20 RPS √ó 120s = 2,400 requests\n",
      "Batch size: 5 | Concurrency: 40\n",
      "  [ 60s] 0 done | Success: 0 | Avg: 0.0ms\n",
      "\n",
      "‚úÖ Complete: 2/2 successful (100.0%)\n",
      "   Total Latency:   71.0ms (mean) | 77.8ms (p95)\n",
      "   Queueing Time:   0.0ms (mean) | 0.0ms (p95)\n",
      "   Request Time:    71.0ms (mean) | 77.8ms (p95)\n",
      "\n",
      "============================================================\n",
      "Spike - Peak Load\n",
      "============================================================\n",
      "Target: 100 RPS √ó 120s = 12,000 requests\n",
      "Batch size: 5 | Concurrency: 200\n",
      "  [169s] 11,537 done | Success: 11,537 | Avg: 2883.3ms\n",
      "\n",
      "‚úÖ Complete: 20,718/20,718 successful (100.0%)\n",
      "   Total Latency:   2940.8ms (mean) | 5160.9ms (p95)\n",
      "   Queueing Time:   0.0ms (mean) | 0.0ms (p95)\n",
      "   Request Time:    2940.8ms (mean) | 5160.9ms (p95)\n",
      "\n",
      "============================================================\n",
      "Spike - Recovery\n",
      "============================================================\n",
      "Target: 20 RPS √ó 120s = 2,400 requests\n",
      "Batch size: 5 | Concurrency: 40\n",
      "  [ 60s] 0 done | Success: 0 | Avg: 0.0ms\n",
      "\n",
      "‚úÖ Complete: 5/5 successful (100.0%)\n",
      "   Total Latency:   120.1ms (mean) | 253.0ms (p95)\n",
      "   Queueing Time:   0.0ms (mean) | 0.0ms (p95)\n",
      "   Request Time:    120.1ms (mean) | 253.0ms (p95)\n"
     ]
    }
   ],
   "source": [
    "# Run traffic spike test (baseline ‚Üí spike ‚Üí recovery)\n",
    "spike_results = []\n",
    "\n",
    "# Phase 1: Baseline\n",
    "df_baseline1 = await run_load_test(\n",
    "    target_rps=BASELINE_RPS,\n",
    "    duration=120,\n",
    "    batch_size=PHASE2_BATCH_SIZE,\n",
    "    test_name=\"Spike - Baseline 1\"\n",
    ")\n",
    "df_baseline1['phase'] = 'baseline1'\n",
    "spike_results.append(df_baseline1)\n",
    "\n",
    "# Phase 2: Spike\n",
    "df_spike = await run_load_test(\n",
    "    target_rps=SPIKE_RPS,\n",
    "    duration=SPIKE_DURATION,\n",
    "    batch_size=PHASE2_BATCH_SIZE,\n",
    "    test_name=\"Spike - Peak Load\"\n",
    ")\n",
    "df_spike['phase'] = 'spike'\n",
    "spike_results.append(df_spike)\n",
    "\n",
    "# Phase 3: Recovery\n",
    "df_baseline2 = await run_load_test(\n",
    "    target_rps=BASELINE_RPS,\n",
    "    duration=120,\n",
    "    batch_size=PHASE2_BATCH_SIZE,\n",
    "    test_name=\"Spike - Recovery\"\n",
    ")\n",
    "df_baseline2['phase'] = 'baseline2'\n",
    "spike_results.append(df_baseline2)\n",
    "\n",
    "df_spike_pattern = pd.concat(spike_results, ignore_index=True)\n",
    "df_spike_pattern['pattern'] = 'Traffic Spike'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "phase2_viz",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "color": "blue",
          "width": 2
         },
         "mode": "lines",
         "name": "Mean",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "AAAAAAAAAAAAAAAAAAAkQAAAAAAAADRAAAAAAAAAPkAAAAAAAABEQAAAAAAAAElAAAAAAAAATkAAAAAAAIBRQAAAAAAAAFRAAAAAAACAVkAAAAAAAABZQAAAAAAAgFtAAAAAAAAAXkAAAAAAAEBgQAAAAAAAgGFAAAAAAADAYkAAAAAAAABkQAAAAAAAQGVAAAAAAACAZkAAAAAAAMBnQAAAAAAAAGlAAAAAAABAakAAAAAAAIBrQAAAAAAAwGxAAAAAAAAAbkAAAAAAAEBvQAAAAAAAQHBAAAAAAADgcEAAAAAAAIBxQAAAAAAAIHJAAAAAAADAckAAAAAAAGBzQAAAAAAAAHRAAAAAAACgdEAAAAAAAEB1QAAAAAAA4HVAAAAAAACAdkAAAAAAACB3QAAAAAAAwHdAAAAAAABgeEAAAAAAAAB5QAAAAAAAoHlAAAAAAABAekAAAAAAAOB6QAAAAAAAgHtAAAAAAAAgfEAAAAAAAMB8QAAAAAAAYH1AAAAAAAAAfkAAAAAAAKB+QAAAAAAAQH9AAAAAAADgf0AAAAAAAECAQAAAAAAAkIBAAAAAAADggEAAAAAAADCBQAAAAAAAgIFAAAAAAADQgUAAAAAAACCCQAAAAAAAcIJAAAAAAADAgkAAAAAAABCDQAAAAAAAYINAAAAAAACwg0AAAAAAAACEQAAAAAAAUIRAAAAAAACghEAAAAAAAPCEQAAAAAAAQIVAAAAAAACQhUAAAAAAAOCFQAAAAAAAMIZAAAAAAACAhkAAAAAAANCGQAAAAAAAIIdAAAAAAABwh0AAAAAAAMCHQAAAAAAAEIhAAAAAAABgiEAAAAAAALCIQAAAAAAAAIlAAAAAAABQiUAAAAAAAKCJQAAAAAAA8IlAAAAAAABAikA=",
          "dtype": "f8"
         },
         "xaxis": "x",
         "y": {
          "bdata": "7rXkQobjmUAn/6WoShiWQBBkF0aPppZAtU0MRC0+l0D7PcAOh6OWQPE9P3KxBpZAqXTkRxqalkAjXlvGJi2WQDJ1SxZrh5ZA1u8ydteilkDCFDl3Yl+WQFvfRqt2i5ZAAAAoodGylkApv7EdtmCWQDLGWEzThpZA2vfGdkh+lkC66KKmAHiWQNS1Dxu4j5ZAl+mJ/wvKlkDnnEP/0maWQMg1kcTD8pZA//aAV/XSlkCxGEm5zgGXQD4HhwxYAJdARz91OPC2l0An5AjBzLOVQFEKcPR3lpZA6KOi4J4flkAiToe049iVQGiLFTXtOZZA0HYm4BTllkA/uVCO7ZSWQFC1oD4DypZAjDHm3FeClkCc0e5lVUKWQEEJ77S+XZZAVJ7WiQ2PlkApaZb7c36WQOGDD23b3ZZAEFcXKo6wlkD9XRcbgjyXQMtXq3hGr5ZADw8PjFUtlkAgQrk4xRGWQEU+W5mGgJZAniHRAysklkCGBqxxREmWQMvjjQCQUZZAkiTJTKXqlUCvoZTBKG2WQAUmPWvQZpZAAADoYZ5HlkCdUh27Mo2WQKPei4+/hJZAgSdB5URTlkA1HTO2DJuWQDXd7ryjiJdANNrd1KJzlkA/vnaxEraWQPYC1lCAUpZAUmCVi1lQlkBu2zaAgwyWQMRYLfpTQJZAyAYjtOUblkCTSoEOO+aVQLb4TByX5ZVA5UJUgLPXlUAVbuP5wP6VQNxcSSKGe5ZALiuGf4nklUDbJeuEme6VQOdK2nyezZVABwzV9ri3lUAAAGjT2jeWQA1W6IQ9DZZAS6H/hjKJlUCMVdrQfuSVQB988Hz6/ZVAx5YboMEll0Dj/vC4jMqVQI8lWWnbiJZAr4alTdRVlkAvusiqfFaWQOqYaxgMO5ZAA8es84JjlUA=",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "line": {
          "color": "orange",
          "dash": "dash",
          "width": 2
         },
         "mode": "lines",
         "name": "P95",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "AAAAAAAAAAAAAAAAAAAkQAAAAAAAADRAAAAAAAAAPkAAAAAAAABEQAAAAAAAAElAAAAAAAAATkAAAAAAAIBRQAAAAAAAAFRAAAAAAACAVkAAAAAAAABZQAAAAAAAgFtAAAAAAAAAXkAAAAAAAEBgQAAAAAAAgGFAAAAAAADAYkAAAAAAAABkQAAAAAAAQGVAAAAAAACAZkAAAAAAAMBnQAAAAAAAAGlAAAAAAABAakAAAAAAAIBrQAAAAAAAwGxAAAAAAAAAbkAAAAAAAEBvQAAAAAAAQHBAAAAAAADgcEAAAAAAAIBxQAAAAAAAIHJAAAAAAADAckAAAAAAAGBzQAAAAAAAAHRAAAAAAACgdEAAAAAAAEB1QAAAAAAA4HVAAAAAAACAdkAAAAAAACB3QAAAAAAAwHdAAAAAAABgeEAAAAAAAAB5QAAAAAAAoHlAAAAAAABAekAAAAAAAOB6QAAAAAAAgHtAAAAAAAAgfEAAAAAAAMB8QAAAAAAAYH1AAAAAAAAAfkAAAAAAAKB+QAAAAAAAQH9AAAAAAADgf0AAAAAAAECAQAAAAAAAkIBAAAAAAADggEAAAAAAADCBQAAAAAAAgIFAAAAAAADQgUAAAAAAACCCQAAAAAAAcIJAAAAAAADAgkAAAAAAABCDQAAAAAAAYINAAAAAAACwg0AAAAAAAACEQAAAAAAAUIRAAAAAAACghEAAAAAAAPCEQAAAAAAAQIVAAAAAAACQhUAAAAAAAOCFQAAAAAAAMIZAAAAAAACAhkAAAAAAANCGQAAAAAAAIIdAAAAAAABwh0AAAAAAAMCHQAAAAAAAEIhAAAAAAABgiEAAAAAAALCIQAAAAAAAAIlAAAAAAABQiUAAAAAAAKCJQAAAAAAA8IlAAAAAAABAikA=",
          "dtype": "f8"
         },
         "xaxis": "x",
         "y": {
          "bdata": "AADQjYTFq0AAAIAdPDajQAAAMKdfEKNA//+/5A0co0AAAMDxnWaiQAAAwCea5KFA///v8O+ookAAAEAv48KiQAAAIOUCSKRAAAAAjFDYo0D+/z/aMyqkQAAAQOAvm6RA/v9fBemXpED//7/DOyKkQAAAEJETbqRAAABAp+R0pEAAAIATUnmkQAAAALH4c6RAAQAw6MrGpEAAAED9Co+kQAAAYAze3KRAAADAxdaTpEAAAABPS42kQAAAwG2uqqRAAAAAgB40pEAAAEDao3mjQAAAwDuAJKRAAADAZcGVpEAAAAAHEkGkQAAA4Ni1uKRAAACgI2DbpED//z+vCYmkQAAAAOkHtKRAAAAAQVCgpEAAABCxRjSkQAAAsKx+eaRAAAAQsyNppEAAAEDX+WukQP//XxippqRAAABg3J2EpEAAAMCNFZKkQAAAwAyknaRA//8/nNItpED//3/2RxSkQAAAsMVPCKRA/v9PAqTNo0D//39j/ZyjQAAAIChB/qNAAACAL5kgpEAAAPA94sGkQAAAwAR+t6RAAADgV+pupEAAAEDa5bOkQAAAQO8FrKRAAABgR4JspEAAACDe6IGkQAAAQOZmSaVAAACQeh9dpEAAAICbr8CkQP3/rzHcQaRAAACAjJUcpEAAAMAVOQqkQAAAgL3nFqRAAACArm1po0AAAMCm6gSjQP//fyl3mqJAAADgGcZ4okD///8nLjejQAAAQN8wS6RAAAAQ+BEdpEAAAEBm5fGjQAAAQJIb/qNAAACAuh3ao0D+/4+uglKkQAAAADqbFqRAAABAxliNo0AAAEBBtdijQAAAgBmqAqRA//8fa+/FpEAAAMDmcsijQAAAALJka6RAAADgRX5CpED//09wDSOkQAAAMB3J36NAAABAToQMo0A=",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "fill": "tozeroy",
         "fillcolor": "rgba(173, 216, 230, 0.5)",
         "line": {
          "color": "lightblue",
          "width": 0
         },
         "mode": "lines",
         "name": "Queueing",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "AAAAAAAAAAAAAAAAAAAkQAAAAAAAADRAAAAAAAAAPkAAAAAAAABEQAAAAAAAAElAAAAAAAAATkAAAAAAAIBRQAAAAAAAAFRAAAAAAACAVkAAAAAAAABZQAAAAAAAgFtAAAAAAAAAXkAAAAAAAEBgQAAAAAAAgGFAAAAAAADAYkAAAAAAAABkQAAAAAAAQGVAAAAAAACAZkAAAAAAAMBnQAAAAAAAAGlAAAAAAABAakAAAAAAAIBrQAAAAAAAwGxAAAAAAAAAbkAAAAAAAEBvQAAAAAAAQHBAAAAAAADgcEAAAAAAAIBxQAAAAAAAIHJAAAAAAADAckAAAAAAAGBzQAAAAAAAAHRAAAAAAACgdEAAAAAAAEB1QAAAAAAA4HVAAAAAAACAdkAAAAAAACB3QAAAAAAAwHdAAAAAAABgeEAAAAAAAAB5QAAAAAAAoHlAAAAAAABAekAAAAAAAOB6QAAAAAAAgHtAAAAAAAAgfEAAAAAAAMB8QAAAAAAAYH1AAAAAAAAAfkAAAAAAAKB+QAAAAAAAQH9AAAAAAADgf0AAAAAAAECAQAAAAAAAkIBAAAAAAADggEAAAAAAADCBQAAAAAAAgIFAAAAAAADQgUAAAAAAACCCQAAAAAAAcIJAAAAAAADAgkAAAAAAABCDQAAAAAAAYINAAAAAAACwg0AAAAAAAACEQAAAAAAAUIRAAAAAAACghEAAAAAAAPCEQAAAAAAAQIVAAAAAAACQhUAAAAAAAOCFQAAAAAAAMIZAAAAAAACAhkAAAAAAANCGQAAAAAAAIIdAAAAAAABwh0AAAAAAAMCHQAAAAAAAEIhAAAAAAABgiEAAAAAAALCIQAAAAAAAAIlAAAAAAABQiUAAAAAAAKCJQAAAAAAA8IlAAAAAAABAikA=",
          "dtype": "f8"
         },
         "xaxis": "x2",
         "y": {
          "bdata": "84HswqKlgj+qfQiEK2OQP7P+DH5TpoQ/peIDx0MYkT+8ocPykAaFPyEM3Lz0q4M/Xi1uwnwzjj98Jej3ygmRP/9t6LvXco0//vzHDK6YiT9hinzWfVKEPx+2vg3Y2oM/AAAAAOAphD/exSNgYp6EP4wxxhgTcoM/XpH50sSFhD9R0izsvu+DP5XPPQjw0IM/0xPBIEo9hT+ttdZaC0OFPwYrdAYrYI0/4ScXom4Fij/gRE/n9jKOPyxYmViw5YY/KpEjfi1BhD8XQVpp8tGQP+bHcgZOu4Q/PyqSHbN+hD8YmRVq4xOEP/BcDkG9FoQ/mCv2QFjGkD9Awk8uxGWDP6TiyBqMg4w/fO+9944lhT+J8KQgObaEP1F5WuhOcZQ/TZ1fe0iKhD+IkmZhdxCFPylQ61cK14M/80uBUUymjD/St1ad9SWRP5g2AoereYg/mU+9mE+8gz97ZDCpHq2QP7vBFPk8IIQ/k0022aRqgz8Kwt3Y9/qDPw4g0z7bhY4/3/d93/dniT/lNZTXEPqEPyvDN6IAPYQ/AAAAAOCHhT/AjIKA5gWIP40LMi7Ib4U/R/fqcmAaiz8AAAAAQACKP8/68SbpUYU/8aQg+bPtjT9ks/e8WGGDP6/yTHzcVZE/Xtn6qRbqgz/GfOrFfNOGP55TSQEJqIM/H6CQQHjqkD+dATOymHGFP+tvD2z0TIM/ciHqZtBDhD+7RWhFkeyDP+aF2UhGlIM/ZQ4Cbv0QjD/EUhFLRciCP3vrN+HTB4o/4UlB8mdOhD8AAAAAoKCEPx4eHh4efIQ/txT6k4z2gz+1pB7QGhODP+kFMEZ6kIM/hB0OdjgHij8+w8u+j66CP8gw34v8L4I/i4ES3mjugz9yHMdxnLiDP2VxRruHO4Q/BaHKYA8lgz8=",
          "dtype": "f8"
         },
         "yaxis": "y2"
        },
        {
         "fill": "tonexty",
         "fillcolor": "rgba(0, 0, 139, 0.5)",
         "line": {
          "color": "darkblue",
          "width": 0
         },
         "mode": "lines",
         "name": "Request",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "AAAAAAAAAAAAAAAAAAAkQAAAAAAAADRAAAAAAAAAPkAAAAAAAABEQAAAAAAAAElAAAAAAAAATkAAAAAAAIBRQAAAAAAAAFRAAAAAAACAVkAAAAAAAABZQAAAAAAAgFtAAAAAAAAAXkAAAAAAAEBgQAAAAAAAgGFAAAAAAADAYkAAAAAAAABkQAAAAAAAQGVAAAAAAACAZkAAAAAAAMBnQAAAAAAAAGlAAAAAAABAakAAAAAAAIBrQAAAAAAAwGxAAAAAAAAAbkAAAAAAAEBvQAAAAAAAQHBAAAAAAADgcEAAAAAAAIBxQAAAAAAAIHJAAAAAAADAckAAAAAAAGBzQAAAAAAAAHRAAAAAAACgdEAAAAAAAEB1QAAAAAAA4HVAAAAAAACAdkAAAAAAACB3QAAAAAAAwHdAAAAAAABgeEAAAAAAAAB5QAAAAAAAoHlAAAAAAABAekAAAAAAAOB6QAAAAAAAgHtAAAAAAAAgfEAAAAAAAMB8QAAAAAAAYH1AAAAAAAAAfkAAAAAAAKB+QAAAAAAAQH9AAAAAAADgf0AAAAAAAECAQAAAAAAAkIBAAAAAAADggEAAAAAAADCBQAAAAAAAgIFAAAAAAADQgUAAAAAAACCCQAAAAAAAcIJAAAAAAADAgkAAAAAAABCDQAAAAAAAYINAAAAAAACwg0AAAAAAAACEQAAAAAAAUIRAAAAAAACghEAAAAAAAPCEQAAAAAAAQIVAAAAAAACQhUAAAAAAAOCFQAAAAAAAMIZAAAAAAACAhkAAAAAAANCGQAAAAAAAIIdAAAAAAABwh0AAAAAAAMCHQAAAAAAAEIhAAAAAAABgiEAAAAAAALCIQAAAAAAAAIlAAAAAAABQiUAAAAAAAKCJQAAAAAAA8IlAAAAAAABAikA=",
          "dtype": "f8"
         },
         "xaxis": "x2",
         "y": {
          "bdata": "K1MAHIXjmUDYefOGSRiWQJFQehGOppZAlSgCASw+l0C6wGPChaOWQGN1PzSwBpZA4yaMARmalkAJ4+N5JS2WQGyNmNxph5ZARDpdStailkAp8ulJYV+WQO0eVkB1i5ZAAAAYZ9CylkAbyEnptGCWQO+9f7nRhpZAIurmNUd+lkBJs/BL/3eWQPuYR922j5ZAH5VbvwrKlkC+90Z60WaWQPyNsozC8pZA1c3gBfTSlkC7sHh7zQGXQJ0QAclWAJdAS+QIv+62l0DlIkh6y7OVQBG55aV2lpZAPJfDjp0flkBjjDFq4tiVQNgAsQbsOZZAzhLMtBPllkA7npNk7JSWQJzh6vcBypZAIYRgglaClkABQ/URVEKWQMuKAVC9XZZAPHY1UAyPlkDRRdebcn6WQObtjBra3ZZAAYUD5oywlkAZEMW5gDyXQJq9beFEr5ZAGPOpU1QtlkAlD1vkwxGWQJgiD3CFgJZAhsRshikklkDJCUInQ0mWQB8I27SOUZZAOY7z76PqlUAbyhM4J22WQApMGiHPZpZAAACoAp1HlkDN9X1DMY2WQHP0TQ++hJZA0G64m0NTlkBziVBmC5uWQBjazIyiiJdALM7opaFzlkA/vvZ4EbaWQMwODuJ+UpZA8spWKlhQlkBPvRhBggyWQCogYb5SQJZArVH7eeQblkBlWqiaOeaVQH5vjM6V5ZVAtfXXZrLXlUBcWy2yv/6VQP91ftSEe5ZAr4ZlRojklUA7HGxzmO6VQMfPqWKdzZVAGKpJrre3lUAAAOht2TeWQCDXREM8DZZA6ipvSjGJlUBccFCbfeSVQNM0TUr5/ZVAD5i9asAll0D4Fraki8qVQC8FNCbaiJZAbcb3JtNVlkBwZ6hle1aWQBZndIoKO5ZAOVMs34FjlUA=",
          "dtype": "f8"
         },
         "yaxis": "y2"
        },
        {
         "line": {
          "color": "blue",
          "width": 2
         },
         "mode": "lines",
         "name": "Mean",
         "showlegend": false,
         "type": "scatter",
         "x": {
          "bdata": "AAAAAAAAAAAAAAAAAAAkQAAAAAAAADRAAAAAAAAAPkAAAAAAAABEQAAAAAAAAElAAAAAAAAATkAAAAAAAIBRQAAAAAAAAFRAAAAAAACAVkAAAAAAAABZQAAAAAAAgFtAAAAAAAAAXkAAAAAAAEBgQAAAAAAAgGFAAAAAAADAYkAAAAAAAABkQAAAAAAAQGVAAAAAAACAZkAAAAAAAMBnQAAAAAAAAGlAAAAAAABAakAAAAAAAIBrQAAAAAAAwGxAAAAAAAAAbkAAAAAAAEBvQAAAAAAAQHBAAAAAAADgcEAAAAAAAIBxQAAAAAAAIHJAAAAAAADAckAAAAAAAGBzQAAAAAAAAHRAAAAAAACgdEAAAAAAAEB1QAAAAAAA4HVAAAAAAABgfUA=",
          "dtype": "f8"
         },
         "xaxis": "x3",
         "y": {
          "bdata": "FGrBaxuIq0AxU6FN5omnQKd/p4UrUKdAJjjZoamgpkBJsdbpD9CkQJRtFksD56VATuZPMA5IpUBCTURYEzSnQNu2bcPOO6VAnp3z1uc4pUAs2Ovo9lGmQP9unf7zf6ZAF5iKvFm+p0DuaYSo8/ilQApIOMxqgKZAVElhSiPRpkCW7RDleQCoQDvlj1jI+aVAFPXJYnRnp0Cptz1/LJOoQAe8E46VRqVAp0S7vmSOp0CRFiAPPTCpQEBpAA4AkaRA4Senh1xjp0Du5YrzWZunQLTFao2itKdACe1lTcdap0Cvnx3woEunQIZvxFTBlqdAAACAdWZtqEDUroTh7n2rQAAAwLBE+aRAT80jGXiHqEBeP5t/AkepQO5muRAdGKhAAAAA2IEFXkA=",
          "dtype": "f8"
         },
         "yaxis": "y3"
        },
        {
         "line": {
          "color": "orange",
          "dash": "dash",
          "width": 2
         },
         "mode": "lines",
         "name": "P95",
         "showlegend": false,
         "type": "scatter",
         "x": {
          "bdata": "AAAAAAAAAAAAAAAAAAAkQAAAAAAAADRAAAAAAAAAPkAAAAAAAABEQAAAAAAAAElAAAAAAAAATkAAAAAAAIBRQAAAAAAAAFRAAAAAAACAVkAAAAAAAABZQAAAAAAAgFtAAAAAAAAAXkAAAAAAAEBgQAAAAAAAgGFAAAAAAADAYkAAAAAAAABkQAAAAAAAQGVAAAAAAACAZkAAAAAAAMBnQAAAAAAAAGlAAAAAAABAakAAAAAAAIBrQAAAAAAAwGxAAAAAAAAAbkAAAAAAAEBvQAAAAAAAQHBAAAAAAADgcEAAAAAAAIBxQAAAAAAAIHJAAAAAAADAckAAAAAAAGBzQAAAAAAAAHRAAAAAAACgdEAAAAAAAEB1QAAAAAAA4HVAAAAAAABgfUA=",
          "dtype": "f8"
         },
         "xaxis": "x3",
         "y": {
          "bdata": "AABgcZVktkD//99IKWK5QAAAwFUFxLFAAACgcNCAsUAAAKBZVeuwQAAAgIZcQLFA////IRvBsEAAAODYwX2xQAAAIGd2FLFAAADgk2mYsUAAAIBWmv+xQAAAuFb4O7JAAADAtEVMskABAMD+r7+yQAAA2JzTpLJAAABIXjwFs0AAABDc+GuzQAAAQO9LU7NAAADghKo7tEAAAIBTwi20QAAAoGMgpLRAAABgruPftEAAAECW1hq1QAAA8IZkkrRAAABoxddYtUABAEDvsbO1QAAAmHKdALZA//+/5JnJtUAAALAZ0a61QP//P7XnEbZA//8/6YuOtkAAAOgHydC2QAAAMAQqkLZA//+/lVEot0AAAFh5b2a3QAAAiDOydrZA////ByWfb0A=",
          "dtype": "f8"
         },
         "yaxis": "y3"
        },
        {
         "fill": "tozeroy",
         "fillcolor": "rgba(173, 216, 230, 0.5)",
         "line": {
          "color": "lightblue",
          "width": 0
         },
         "mode": "lines",
         "name": "Queueing",
         "showlegend": false,
         "type": "scatter",
         "x": {
          "bdata": "AAAAAAAAAAAAAAAAAAAkQAAAAAAAADRAAAAAAAAAPkAAAAAAAABEQAAAAAAAAElAAAAAAAAATkAAAAAAAIBRQAAAAAAAAFRAAAAAAACAVkAAAAAAAABZQAAAAAAAgFtAAAAAAAAAXkAAAAAAAEBgQAAAAAAAgGFAAAAAAADAYkAAAAAAAABkQAAAAAAAQGVAAAAAAACAZkAAAAAAAMBnQAAAAAAAAGlAAAAAAABAakAAAAAAAIBrQAAAAAAAwGxAAAAAAAAAbkAAAAAAAEBvQAAAAAAAQHBAAAAAAADgcEAAAAAAAIBxQAAAAAAAIHJAAAAAAADAckAAAAAAAGBzQAAAAAAAAHRAAAAAAACgdEAAAAAAAEB1QAAAAAAA4HVAAAAAAABgfUA=",
          "dtype": "f8"
         },
         "xaxis": "x4",
         "y": {
          "bdata": "gTGJg/eLfz/yG/3ckJmDP9Qw5qql4IU/2sdm5FC3gT+tLJno+DmBP17FaCfbnYE/oqhPqIRYgj8wzwK4FHODPwAAAAAAOYI/gQSxy7x2gT+pGtE5vNKBP/nE4xMPCYE/N7K1f0QNgz9ggkBpTU+DP9joXZH5EYE/VEkBCf9Ogz83nNf7KBKCPwJXrAFXkoQ/WBHSmjYmgT9bxX7vRm6BP18mHnNan4A/hdAVQle+gD8L0MtdMQiBP6LI5lm02YA/cA9s9C6ggz9PKitdSuSAPwpMOjUP+IA/VVVVVVW1gT+bB7nrp/SAP0cUmHRqu4A/Ce0ltJdagT/tStSu5PKBP+miiy66NIk/pVPzIPfogj/aYmX4RrCAP8uTyDRs5Ig/AAAAAAA3hD8=",
          "dtype": "f8"
         },
         "yaxis": "y4"
        },
        {
         "fill": "tonexty",
         "fillcolor": "rgba(0, 0, 139, 0.5)",
         "line": {
          "color": "darkblue",
          "width": 0
         },
         "mode": "lines",
         "name": "Request",
         "showlegend": false,
         "type": "scatter",
         "x": {
          "bdata": "AAAAAAAAAAAAAAAAAAAkQAAAAAAAADRAAAAAAAAAPkAAAAAAAABEQAAAAAAAAElAAAAAAAAATkAAAAAAAIBRQAAAAAAAAFRAAAAAAACAVkAAAAAAAABZQAAAAAAAgFtAAAAAAAAAXkAAAAAAAEBgQAAAAAAAgGFAAAAAAADAYkAAAAAAAABkQAAAAAAAQGVAAAAAAACAZkAAAAAAAMBnQAAAAAAAAGlAAAAAAABAakAAAAAAAIBrQAAAAAAAwGxAAAAAAAAAbkAAAAAAAEBvQAAAAAAAQHBAAAAAAADgcEAAAAAAAIBxQAAAAAAAIHJAAAAAAADAckAAAAAAAGBzQAAAAAAAAHRAAAAAAACgdEAAAAAAAEB1QAAAAAAA4HVAAAAAAABgfUA=",
          "dtype": "f8"
         },
         "xaxis": "x4",
         "y": {
          "bdata": "YxLH5RqIq0D67ji35YmnQACPnbwqUKdAgOKaF6mgpkAMl7NkD9CkQJSvZMIC56VA7Ar2pg1IpUAXwCXFEjSnQPQ8TzLOO6VAmU0gT+c4pUBz4ktb9lGmQD7xeHfzf6ZAG9maN1m+p0C7TMcZ8/ilQIzV1kdqgKZA2fE8tyLRpkCDHHBfeQCoQJGR0dDH+aVAkKpR4XNnp0C0aUvyK5OoQFyjEv6URqVAloqYQGSOp0CBGyuSPDCpQKA0oIX/kKRAFZDwA1xjp0AH97J2WZunQPGN6AeitKdAeLq1uMZap0DIXQ9poEunQJbhu9HAlqdApAz8zWVtqECD82lM7n2rQEYXHSFE+aRAoC32e3eHqEDK8I3PAUepQKsftIocGKhAAAAAWHUFXkA=",
          "dtype": "f8"
         },
         "yaxis": "y4"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Constant Load - Latency Over Time",
          "x": 0.22,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Constant Load - Timing Breakdown",
          "x": 0.78,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Traffic Spike - Latency Over Time",
          "x": 0.22,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.44,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Traffic Spike - Timing Breakdown",
          "x": 0.78,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.44,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "height": 700,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.44
         ],
         "title": {
          "text": "Time (seconds)"
         }
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.56,
          1
         ],
         "title": {
          "text": "Time (seconds)"
         }
        },
        "xaxis3": {
         "anchor": "y3",
         "domain": [
          0,
          0.44
         ],
         "title": {
          "text": "Time (seconds)"
         }
        },
        "xaxis4": {
         "anchor": "y4",
         "domain": [
          0.56,
          1
         ],
         "title": {
          "text": "Time (seconds)"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0.56,
          1
         ],
         "title": {
          "text": "Latency (ms)"
         }
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0.56,
          1
         ],
         "title": {
          "text": "Time (ms)"
         }
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0,
          0.44
         ],
         "title": {
          "text": "Latency (ms)"
         }
        },
        "yaxis4": {
         "anchor": "x4",
         "domain": [
          0,
          0.44
         ],
         "title": {
          "text": "Time (ms)"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Phase 2 Summary:\n",
      "\n",
      "Constant Load:\n",
      "  Total Latency:  1436.5ms (mean) | 2582.0ms (p95)\n",
      "  Queueing Time:  0.0ms (mean) | 0.0ms (p95)\n",
      "  Request Time:   1436.5ms (mean) | 2582.0ms (p95)\n",
      "\n",
      "Traffic Spike:\n",
      "  Total Latency:  2939.9ms (mean) | 5160.8ms (p95)\n",
      "  Queueing Time:  0.0ms (mean) | 0.0ms (p95)\n",
      "  Request Time:   2939.9ms (mean) | 5160.8ms (p95)\n"
     ]
    }
   ],
   "source": [
    "# Visualize Phase 2 results over time\n",
    "df_phase2 = pd.concat([df_constant, df_spike_pattern], ignore_index=True)\n",
    "df_phase2_success = df_phase2[df_phase2['success'] == True].copy()\n",
    "\n",
    "# Create time-series plots for each pattern\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=('Constant Load - Latency Over Time', 'Constant Load - Timing Breakdown',\n",
    "                   'Traffic Spike - Latency Over Time', 'Traffic Spike - Timing Breakdown'),\n",
    "    vertical_spacing=0.12,\n",
    "    horizontal_spacing=0.12\n",
    ")\n",
    "\n",
    "for row, pattern in enumerate(['Constant Load', 'Traffic Spike'], 1):\n",
    "    data = df_phase2_success[df_phase2_success['pattern'] == pattern].copy()\n",
    "    \n",
    "    if len(data) > 0:\n",
    "        # Calculate elapsed time\n",
    "        min_time = data['timestamp'].min()\n",
    "        data['elapsed_seconds'] = (data['timestamp'] - min_time).dt.total_seconds()\n",
    "        data['time_bucket'] = (data['elapsed_seconds'] // 10) * 10\n",
    "        \n",
    "        # Aggregate by time bucket\n",
    "        bucket_stats = data.groupby('time_bucket').agg({\n",
    "            'total_latency_ms': ['mean', lambda x: np.percentile(x, 95)],\n",
    "            'queueing_ms': 'mean',\n",
    "            'request_ms': 'mean'\n",
    "        }).reset_index()\n",
    "        bucket_stats.columns = ['time_bucket', 'total_mean', 'total_p95', 'queue_mean', 'request_mean']\n",
    "        \n",
    "        # Left: Total latency over time\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=bucket_stats['time_bucket'], y=bucket_stats['total_mean'],\n",
    "            name='Mean', mode='lines', line=dict(color='blue', width=2),\n",
    "            showlegend=(row == 1)\n",
    "        ), row=row, col=1)\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=bucket_stats['time_bucket'], y=bucket_stats['total_p95'],\n",
    "            name='P95', mode='lines', line=dict(color='orange', width=2, dash='dash'),\n",
    "            showlegend=(row == 1)\n",
    "        ), row=row, col=1)\n",
    "        \n",
    "        # Right: Timing breakdown (stacked area)\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=bucket_stats['time_bucket'], y=bucket_stats['queue_mean'],\n",
    "            name='Queueing', mode='lines', fill='tozeroy',\n",
    "            line=dict(color='lightblue', width=0),\n",
    "            fillcolor='rgba(173, 216, 230, 0.5)',\n",
    "            showlegend=(row == 1)\n",
    "        ), row=row, col=2)\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=bucket_stats['time_bucket'],\n",
    "            y=bucket_stats['queue_mean'] + bucket_stats['request_mean'],\n",
    "            name='Request', mode='lines', fill='tonexty',\n",
    "            line=dict(color='darkblue', width=0),\n",
    "            fillcolor='rgba(0, 0, 139, 0.5)',\n",
    "            showlegend=(row == 1)\n",
    "        ), row=row, col=2)\n",
    "\n",
    "for row in [1, 2]:\n",
    "    fig.update_xaxes(title_text=\"Time (seconds)\", row=row, col=1)\n",
    "    fig.update_xaxes(title_text=\"Time (seconds)\", row=row, col=2)\n",
    "    fig.update_yaxes(title_text=\"Latency (ms)\", row=row, col=1)\n",
    "    fig.update_yaxes(title_text=\"Time (ms)\", row=row, col=2)\n",
    "\n",
    "fig.update_layout(height=700)\n",
    "fig.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nüìä Phase 2 Summary:\")\n",
    "for pattern in ['Constant Load', 'Traffic Spike']:\n",
    "    data = df_phase2_success[df_phase2_success['pattern'] == pattern]\n",
    "    if len(data) > 0:\n",
    "        print(f\"\\n{pattern}:\")\n",
    "        print(f\"  Total Latency:  {data['total_latency_ms'].mean():.1f}ms (mean) | \"\n",
    "              f\"{data['total_latency_ms'].quantile(0.95):.1f}ms (p95)\")\n",
    "        print(f\"  Queueing Time:  {data['queueing_ms'].mean():.1f}ms (mean) | \"\n",
    "              f\"{data['queueing_ms'].quantile(0.95):.1f}ms (p95)\")\n",
    "        print(f\"  Request Time:   {data['request_ms'].mean():.1f}ms (mean) | \"\n",
    "              f\"{data['request_ms'].quantile(0.95):.1f}ms (p95)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monitoring_header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cloud Monitoring Analysis\n",
    "\n",
    "Query CPU utilization metrics to understand autoscaling behavior.\n",
    "\n",
    "**Note**: Vertex AI doesn't expose replica count via API - use Cloud Console to view active replicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "query_metrics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Retrieved 48 CPU measurements\n",
      "   Range: 0.2% - 34.1%\n",
      "   Mean: 5.5%\n"
     ]
    }
   ],
   "source": [
    "# Get test time window\n",
    "all_data = pd.concat([df_batch, df_rps, df_phase2], ignore_index=True)\n",
    "test_start = all_data['timestamp'].min() - timedelta(minutes=10)\n",
    "test_end = all_data['timestamp'].max() + timedelta(minutes=10)\n",
    "\n",
    "# Query CPU utilization\n",
    "project_name = f\"projects/{PROJECT_ID}\"\n",
    "interval = monitoring_v3.TimeInterval({\n",
    "    \"end_time\": {\"seconds\": int(test_end.timestamp())},\n",
    "    \"start_time\": {\"seconds\": int(test_start.timestamp())}\n",
    "})\n",
    "\n",
    "metric_filter = (\n",
    "    f'resource.type=\"aiplatform.googleapis.com/Endpoint\" AND '\n",
    "    f'resource.labels.endpoint_id=\"{endpoint.name.split(\"/\")[-1]}\" AND '\n",
    "    f'metric.type=\"aiplatform.googleapis.com/prediction/online/cpu/utilization\"'\n",
    ")\n",
    "\n",
    "request = monitoring_v3.ListTimeSeriesRequest({\n",
    "    \"name\": project_name,\n",
    "    \"filter\": metric_filter,\n",
    "    \"interval\": interval,\n",
    "    \"view\": monitoring_v3.ListTimeSeriesRequest.TimeSeriesView.FULL\n",
    "})\n",
    "\n",
    "# Collect CPU data\n",
    "cpu_data = []\n",
    "for result in monitoring_client.list_time_series(request=request):\n",
    "    for point in result.points:\n",
    "        cpu_data.append({\n",
    "            'timestamp': pd.Timestamp(point.interval.end_time),\n",
    "            'cpu_utilization': point.value.double_value * 100  # Convert to percentage\n",
    "        })\n",
    "\n",
    "df_cpu = pd.DataFrame(cpu_data).sort_values('timestamp')\n",
    "\n",
    "if len(df_cpu) > 0:\n",
    "    print(f\"‚úÖ Retrieved {len(df_cpu)} CPU measurements\")\n",
    "    print(f\"   Range: {df_cpu['cpu_utilization'].min():.1f}% - {df_cpu['cpu_utilization'].max():.1f}%\")\n",
    "    print(f\"   Mean: {df_cpu['cpu_utilization'].mean():.1f}%\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No CPU metrics found (may not be available yet)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cpu_viz",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "color": "blue",
          "width": 2
         },
         "marker": {
          "size": 4
         },
         "mode": "lines+markers",
         "name": "CPU Utilization",
         "type": "scatter",
         "x": [
          "2025-11-09T22:54:00",
          "2025-11-09T22:55:00",
          "2025-11-09T22:56:00",
          "2025-11-09T22:57:00",
          "2025-11-09T22:58:00",
          "2025-11-09T22:59:00",
          "2025-11-09T23:00:00",
          "2025-11-09T23:01:00",
          "2025-11-09T23:02:00",
          "2025-11-09T23:03:00",
          "2025-11-09T23:04:00",
          "2025-11-09T23:05:00",
          "2025-11-09T23:06:00",
          "2025-11-09T23:07:00",
          "2025-11-09T23:08:00",
          "2025-11-09T23:09:00",
          "2025-11-09T23:10:00",
          "2025-11-09T23:11:00",
          "2025-11-09T23:12:00",
          "2025-11-09T23:13:00",
          "2025-11-09T23:14:00",
          "2025-11-09T23:15:00",
          "2025-11-09T23:16:00",
          "2025-11-09T23:17:00",
          "2025-11-09T23:18:00",
          "2025-11-09T23:19:00",
          "2025-11-09T23:20:00",
          "2025-11-09T23:21:00",
          "2025-11-09T23:22:00",
          "2025-11-09T23:23:00",
          "2025-11-09T23:24:00",
          "2025-11-09T23:25:00",
          "2025-11-09T23:26:00",
          "2025-11-09T23:27:00",
          "2025-11-09T23:28:00",
          "2025-11-09T23:29:00",
          "2025-11-09T23:30:00",
          "2025-11-09T23:31:00",
          "2025-11-09T23:32:00",
          "2025-11-09T23:33:00",
          "2025-11-09T23:34:00",
          "2025-11-09T23:35:00",
          "2025-11-09T23:36:00",
          "2025-11-09T23:37:00",
          "2025-11-09T23:38:00",
          "2025-11-09T23:39:00",
          "2025-11-09T23:40:00",
          "2025-11-09T23:41:00"
         ],
         "y": {
          "bdata": "831/rHnNyz/cfrJcOUrjP0drUzXqUNw/T+LTdSgB2T/knkkxFyHXP4ndxObE99U/54Fr0xAE1D8n2/S2rFXiP9l1neajGw5ANQvCNtcl1j+eF7udx3noP17i2EwDx/w/j6stTCp/EUAOa0HZ4WwVQEG7fUmOT+Q/yadTG9FiAkDNI3nZmicbQJ4OeYmqixtAO2KP7tEc+D/mSnQjmtklQCId+zJdajhABIARfRkQQUBGTXvtI6k2QEJZoesFSR5ABIT/QIOz0j8DkBH7STXWPxT2dZ8Z2tk/6wpNPV4g1j+fZx9JGRffPydaJRiywxpA3Vozc3zsGkBinbc+SngaQILHkvG2dBpAh8jFbcR8G0BJ+y0PbJQaQGt6M2VCUxtAGTSLyvnJGkCW3fANkzYbQNpCQFWhqxpA+HzcenKEG0A+sd3m+nsbQOkFP5WstBtAtGTaA/aPG0BmtNVxxNgQQIPgFp0/0xBA+TiFUsAFGkD5euf/ljcbQFwzOi7a7BlA",
          "dtype": "f8"
         }
        }
       ],
       "layout": {
        "annotations": [
         {
          "showarrow": false,
          "text": "Autoscale Threshold (60%)",
          "x": 1,
          "xanchor": "right",
          "xref": "x domain",
          "y": 60,
          "yanchor": "bottom",
          "yref": "y"
         }
        ],
        "height": 400,
        "shapes": [
         {
          "line": {
           "color": "red",
           "dash": "dash"
          },
          "type": "line",
          "x0": 0,
          "x1": 1,
          "xref": "x domain",
          "y0": 60,
          "y1": 60,
          "yref": "y"
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "CPU Utilization Over Time"
        },
        "xaxis": {
         "title": {
          "text": "Time"
         }
        },
        "yaxis": {
         "range": [
          0,
          100
         ],
         "title": {
          "text": "CPU Utilization (%)"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä CPU Analysis:\n",
      "   Max CPU: 34.1%\n",
      "   ‚ö†Ô∏è  CPU never reached autoscaling threshold (60%)\n",
      "\n",
      "   üí° This indicates a capacity bottleneck, not compute bottleneck:\n",
      "      ‚Ä¢ Model inference is very efficient (low CPU usage)\n",
      "      ‚Ä¢ Latency degrades due to request queueing, not processing\n",
      "      ‚Ä¢ Solution: Lower autoscaling threshold or increase min replicas\n"
     ]
    }
   ],
   "source": [
    "# Visualize CPU utilization\n",
    "if len(df_cpu) > 0:\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df_cpu['timestamp'], y=df_cpu['cpu_utilization'],\n",
    "        mode='lines+markers', name='CPU Utilization',\n",
    "        line=dict(color='blue', width=2), marker=dict(size=4)\n",
    "    ))\n",
    "    \n",
    "    # Add autoscaling threshold line\n",
    "    fig.add_hline(y=60, line_dash=\"dash\", line_color=\"red\",\n",
    "                  annotation_text=\"Autoscale Threshold (60%)\")\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='CPU Utilization Over Time',\n",
    "        xaxis_title='Time',\n",
    "        yaxis_title='CPU Utilization (%)',\n",
    "        height=400,\n",
    "        yaxis=dict(range=[0, 100])\n",
    "    )\n",
    "    fig.show()\n",
    "    \n",
    "    # Analysis\n",
    "    max_cpu = df_cpu['cpu_utilization'].max()\n",
    "    print(f\"\\nüìä CPU Analysis:\")\n",
    "    print(f\"   Max CPU: {max_cpu:.1f}%\")\n",
    "    \n",
    "    if max_cpu >= 60:\n",
    "        print(f\"   ‚úÖ CPU exceeded autoscaling threshold (60%)\")\n",
    "        print(f\"      Autoscaling should have triggered\")\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è  CPU never reached autoscaling threshold (60%)\")\n",
    "        print(f\"\\n   üí° This indicates a capacity bottleneck, not compute bottleneck:\")\n",
    "        print(f\"      ‚Ä¢ Model inference is very efficient (low CPU usage)\")\n",
    "        print(f\"      ‚Ä¢ Latency degrades due to request queueing, not processing\")\n",
    "        print(f\"      ‚Ä¢ Solution: Lower autoscaling threshold or increase min replicas\")\n",
    "else:\n",
    "    print(\"No CPU data to visualize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recommendations_header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary & Recommendations\n",
    "\n",
    "Based on test results, here are configuration recommendations for production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "summary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "VERTEX AI ENDPOINT SCALING TEST SUMMARY\n",
      "================================================================================\n",
      "\n",
      "üìã Configuration Tested:\n",
      "   Endpoint: pytorch-autoencoder-endpoint\n",
      "   Machine: n1-standard-4\n",
      "   Replicas: 1 - 4\n",
      "\n",
      "üìä Phase 1 Results:\n",
      "   Baseline latency (batch=1, 1 RPS): 66.9ms\n",
      "   Optimal batch size: 50\n",
      "\n",
      "   Max Reliable RPS by Batch Size:\n",
      "      Batch   1: 100 RPS (p95: 4560.0ms)\n",
      "      Batch   5: 100 RPS (p95: 4248.1ms)\n",
      "      Batch 100: 100 RPS (p95: 5697.8ms)\n",
      "\n",
      "üñ•Ô∏è  CPU Utilization:\n",
      "   Max: 34.1%\n",
      "   Mean: 5.5%\n",
      "   ‚ö†Ô∏è  Never reached autoscaling threshold (60%)\n",
      "\n",
      "üí° Recommendations:\n",
      "\n",
      "   1. Optimal Batch Size: 50 instances per request\n",
      "      - Balances latency (128.7ms) with throughput\n",
      "\n",
      "   2. Autoscaling Configuration:\n",
      "      - Current threshold (60% CPU) too high for this model\n",
      "      - Model is CPU-efficient: max observed 34.1%\n",
      "      - Options:\n",
      "        a) Lower threshold to 5-20% CPU (requires redeployment)\n",
      "        b) Increase min_replicas to 2-3 for baseline capacity\n",
      "        c) Use larger machine type (more vCPUs may trigger scaling)\n",
      "\n",
      "   3. Maximum Throughput: ~10000 instances/sec\n",
      "      - Configuration: batch=100, RPS=100\n",
      "\n",
      "üìù Next Steps:\n",
      "   ‚Ä¢ Review Cloud Console > Vertex AI > Endpoints > Monitoring\n",
      "     for replica count and autoscaling events\n",
      "   ‚Ä¢ Consider redeploying with adjusted autoscaling threshold\n",
      "   ‚Ä¢ Run tests again after configuration changes to validate\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"VERTEX AI ENDPOINT SCALING TEST SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüìã Configuration Tested:\")\n",
    "print(f\"   Endpoint: {endpoint.display_name}\")\n",
    "print(f\"   Machine: {MACHINE_TYPE}\")\n",
    "print(f\"   Replicas: {MIN_REPLICAS} - {MAX_REPLICAS}\")\n",
    "\n",
    "print(f\"\\nüìä Phase 1 Results:\")\n",
    "# Get baseline from batch test data\n",
    "batch_stats = df_batch.groupby('batch_size')['latency_ms'].agg(['mean']).reset_index()\n",
    "baseline_lat = batch_stats[batch_stats['batch_size'] == 1]['mean'].values[0]\n",
    "print(f\"   Baseline latency (batch=1, 1 RPS): {baseline_lat:.1f}ms\")\n",
    "print(f\"   Optimal batch size: {optimal}\")\n",
    "\n",
    "print(f\"\\n   Max Reliable RPS by Batch Size:\")\n",
    "# Get RPS stats from the RPS test\n",
    "rps_stats = df_rps[df_rps['success'] == True].groupby(['batch_size', 'target_rps']).agg({\n",
    "    'total_latency_ms': ['mean', lambda x: np.percentile(x, 95)],\n",
    "    'success': 'count'\n",
    "}).reset_index()\n",
    "rps_stats.columns = ['batch_size', 'target_rps', 'total_mean', 'total_p95', 'count']\n",
    "\n",
    "# Calculate success rates\n",
    "for batch_size in RPS_BATCH_SIZES:\n",
    "    batch_data = rps_stats[rps_stats['batch_size'] == batch_size]\n",
    "    if len(batch_data) > 0:\n",
    "        # Assume all tests with data had >= 95% success (we only kept successful requests)\n",
    "        max_rps = batch_data['target_rps'].max()\n",
    "        p95 = batch_data[batch_data['target_rps'] == max_rps]['total_p95'].values[0]\n",
    "        print(f\"      Batch {int(batch_size):3d}: {int(max_rps):3d} RPS (p95: {p95:.1f}ms)\")\n",
    "\n",
    "if len(df_cpu) > 0:\n",
    "    print(f\"\\nüñ•Ô∏è  CPU Utilization:\")\n",
    "    print(f\"   Max: {df_cpu['cpu_utilization'].max():.1f}%\")\n",
    "    print(f\"   Mean: {df_cpu['cpu_utilization'].mean():.1f}%\")\n",
    "    \n",
    "    if df_cpu['cpu_utilization'].max() < 60:\n",
    "        print(f\"   ‚ö†Ô∏è  Never reached autoscaling threshold (60%)\")\n",
    "\n",
    "print(f\"\\nüí° Recommendations:\")\n",
    "print(f\"\\n   1. Optimal Batch Size: {optimal} instances per request\")\n",
    "batch_optimal_lat = batch_stats[batch_stats['batch_size']==optimal]['mean'].values[0]\n",
    "print(f\"      - Balances latency ({batch_optimal_lat:.1f}ms) with throughput\")\n",
    "\n",
    "if len(df_cpu) > 0 and df_cpu['cpu_utilization'].max() < 60:\n",
    "    print(f\"\\n   2. Autoscaling Configuration:\")\n",
    "    print(f\"      - Current threshold (60% CPU) too high for this model\")\n",
    "    print(f\"      - Model is CPU-efficient: max observed {df_cpu['cpu_utilization'].max():.1f}%\")\n",
    "    print(f\"      - Options:\")\n",
    "    print(f\"        a) Lower threshold to 5-20% CPU (requires redeployment)\")\n",
    "    print(f\"        b) Increase min_replicas to 2-3 for baseline capacity\")\n",
    "    print(f\"        c) Use larger machine type (more vCPUs may trigger scaling)\")\n",
    "\n",
    "# Calculate max throughput from RPS test results\n",
    "if len(rps_stats) > 0:\n",
    "    rps_stats['throughput'] = rps_stats['batch_size'] * rps_stats['target_rps']\n",
    "    best_idx = rps_stats['throughput'].idxmax()\n",
    "    best = rps_stats.loc[best_idx]\n",
    "    print(f\"\\n   3. Maximum Throughput: ~{int(best['throughput'])} instances/sec\")\n",
    "    print(f\"      - Configuration: batch={int(best['batch_size'])}, RPS={int(best['target_rps'])}\")\n",
    "\n",
    "print(f\"\\nüìù Next Steps:\")\n",
    "print(f\"   ‚Ä¢ Review Cloud Console > Vertex AI > Endpoints > Monitoring\")\n",
    "print(f\"     for replica count and autoscaling events\")\n",
    "print(f\"   ‚Ä¢ Consider redeploying with adjusted autoscaling threshold\")\n",
    "print(f\"   ‚Ä¢ Run tests again after configuration changes to validate\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook tested Vertex AI Endpoint performance comprehensively, revealing:\n",
    "\n",
    "**Key Insights:**\n",
    "- **Timing separation** (queueing vs request time) identifies bottleneck location\n",
    "- **CPU-efficient models** may not trigger autoscaling despite high load\n",
    "- **Capacity bottlenecks** differ from compute bottlenecks\n",
    "- **Zero queueing time** indicates the client can send requests faster than the endpoint can process them\n",
    "\n",
    "**Production Recommendations:**\n",
    "- Use optimal batch size from Phase 1 testing (batch=50 for this model)\n",
    "- Configure autoscaling threshold appropriate for your model's CPU profile\n",
    "- Set min replicas to handle baseline traffic without cold starts\n",
    "- For CPU-efficient models, consider lowering autoscaling threshold to 5-20%\n",
    "\n",
    "**Important Note:**\n",
    "Results shown in this notebook are specific to the PyTorch autoencoder model tested. Your results will vary based on:\n",
    "- Model complexity and inference time\n",
    "- Machine type and replica configuration\n",
    "- Input data size and format\n",
    "- Network conditions\n",
    "\n",
    "Always run your own scaling tests with representative traffic patterns before deploying to production.\n",
    "\n",
    "---\n",
    "\n",
    "**Related Notebooks:**\n",
    "- [Deploy to Vertex AI Endpoint (Prebuilt Container)](./vertex-ai-endpoint-prebuilt-container.ipynb)\n",
    "- [Deploy to Vertex AI Endpoint (Custom Container)](./vertex-ai-endpoint-custom-container.ipynb)\n",
    "- [PyTorch Autoencoder Training](../pytorch-autoencoder.ipynb)\n",
    "\n",
    "**Related Resources:**\n",
    "- [Vertex AI Prediction Documentation](https://cloud.google.com/vertex-ai/docs/predictions/overview)\n",
    "- [Autoscaling Configuration](https://cloud.google.com/vertex-ai/docs/predictions/configure-compute#autoscaling)\n",
    "- [Performance Optimization Guide](https://cloud.google.com/vertex-ai/docs/predictions/optimize-prediction-performance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (frameworks-pytorch)",
   "language": "python",
   "name": "frameworks-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
