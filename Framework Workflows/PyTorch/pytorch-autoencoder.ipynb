{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9cd9f98",
   "metadata": {},
   "source": [
    "![tracker](https://us-central1-vertex-ai-mlops-369716.cloudfunctions.net/pixel-tracking?path=statmike%2Fvertex-ai-mlops%2FFramework+Workflows%2FPyTorch&file=pytorch-autoencoder.ipynb)\n",
    "<!--- header table --->\n",
    "<table align=\"left\">\n",
    "<tr>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/statmike/vertex-ai-mlops/blob/main/Framework%20Workflows/PyTorch/pytorch-autoencoder.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://www.svgrepo.com/download/217753/github.svg\" alt=\"GitHub logo\">\n",
    "      <br>View on<br>GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/statmike/vertex-ai-mlops/blob/main/Framework%20Workflows/PyTorch/pytorch-autoencoder.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://www.gstatic.com/pantheon/images/bigquery/welcome_page/colab-logo.svg\" alt=\"Google Colaboratory logo\">\n",
    "      <br>Run in<br>Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https%3A%2F%2Fraw.githubusercontent.com%2Fstatmike%2Fvertex-ai-mlops%2Fmain%2FFramework%2520Workflows%2FPyTorch%2Fpytorch-autoencoder.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\">\n",
    "      <br>Run in<br>Colab Enterprise\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/bigquery/import?url=https://github.com/statmike/vertex-ai-mlops/blob/main/Framework%20Workflows/PyTorch/pytorch-autoencoder.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://www.gstatic.com/images/branding/gcpiconscolors/bigquery/v1/32px.svg\" alt=\"BigQuery logo\">\n",
    "      <br>Open in<br>BigQuery Studio\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/statmike/vertex-ai-mlops/main/Framework%20Workflows/PyTorch/pytorch-autoencoder.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://www.gstatic.com/images/branding/gcpiconscolors/vertexai/v1/32px.svg\" alt=\"Vertex AI logo\">\n",
    "      <br>Open in<br>Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td colspan=\"5\" style=\"text-align: right\">\n",
    "    <b>Share This On: </b> \n",
    "    <a href=\"https://www.linkedin.com/sharing/share-offsite/?url=https://github.com/statmike/vertex-ai-mlops/blob/main/Framework%2520Workflows/PyTorch/pytorch-autoencoder.ipynb\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"Linkedin Logo\" width=\"20px\"></a> \n",
    "    <a href=\"https://reddit.com/submit?url=https://github.com/statmike/vertex-ai-mlops/blob/main/Framework%2520Workflows/PyTorch/pytorch-autoencoder.ipynb\"><img src=\"https://redditinc.com/hubfs/Reddit%20Inc/Brand/Reddit_Logo.png\" alt=\"Reddit Logo\" width=\"20px\"></a> \n",
    "    <a href=\"https://bsky.app/intent/compose?text=https://github.com/statmike/vertex-ai-mlops/blob/main/Framework%2520Workflows/PyTorch/pytorch-autoencoder.ipynb\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"BlueSky Logo\" width=\"20px\"></a> \n",
    "    <a href=\"https://twitter.com/intent/tweet?url=https://github.com/statmike/vertex-ai-mlops/blob/main/Framework%2520Workflows/PyTorch/pytorch-autoencoder.ipynb\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/5/5a/X_icon_2.svg\" alt=\"X (Twitter) Logo\" width=\"20px\"></a> \n",
    "  </td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td colspan=\"5\" style=\"text-align: right\">\n",
    "    <b>Connect With Author On: </b> \n",
    "    <a href=\"https://www.linkedin.com/in/statmike\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"Linkedin Logo\" width=\"20px\"></a>\n",
    "    <a href=\"https://www.github.com/statmike\"><img src=\"https://www.svgrepo.com/download/217753/github.svg\" alt=\"GitHub Logo\" width=\"20px\"></a> \n",
    "    <a href=\"https://www.youtube.com/@statmike-channel\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/f/fd/YouTube_full-color_icon_%282024%29.svg\" alt=\"YouTube Logo\" width=\"20px\"></a>\n",
    "    <a href=\"https://bsky.app/profile/statmike.bsky.social\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"BlueSky Logo\" width=\"20px\"></a> \n",
    "    <a href=\"https://x.com/statmike\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/5/5a/X_icon_2.svg\" alt=\"X (Twitter) Logo\" width=\"20px\"></a>\n",
    "  </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7267b6c",
   "metadata": {},
   "source": [
    "# PyTorch Autoencoder Overview\n",
    "\n",
    "An overview of building an autoencoder for anomaly detection using pure PyTorch.\n",
    "\n",
    "This workflow demonstrates how to build, train, and deploy an autoencoder for anomaly detection using **pure PyTorch**, with a focus on:\n",
    "\n",
    "*   Building the **same model architecture** as the Keras JAX example for direct comparison\n",
    "*   Embedding **preprocessing and postprocessing** inside custom `nn.Module` layers\n",
    "*   Creating a robust model suitable for **TorchServe** deployment\n",
    "*   Structuring the model for clear outputs and easy analysis\n",
    "*   Handling data preprocessing within the PyTorch workflow\n",
    "*   Saving models in **.mar (Model Archive)** format for serving\n",
    "\n",
    "## Core Concepts\n",
    "\n",
    "**PyTorch:** An open-source machine learning framework that provides maximum flexibility and performance. PyTorch uses dynamic computation graphs and provides an intuitive, Pythonic API.\n",
    "\n",
    "**Autoencoders:** A type of neural network trained to *reconstruct* its input.  An autoencoder consists of two main parts:\n",
    "    *   **Encoder:** Compresses the input data into a lower-dimensional \"latent space\" representation.\n",
    "    *   **Decoder:** Reconstructs the original input from the latent space representation.\n",
    "\n",
    "**Anomaly Detection:** The principle is that anomalies (data points that deviate significantly from the norm) will have *higher reconstruction errors* than normal data points.  By training the autoencoder on \"normal\" data, we can use the reconstruction error as a measure of \"anomalousness.\"\n",
    "\n",
    "**TorchServe:** A flexible, easy-to-use tool for serving PyTorch models at scale. Models are packaged as `.mar` files (Model Archive) containing the model weights, custom handler code, and metadata.\n",
    "\n",
    "**Custom nn.Module Layers:** PyTorch allows embedding all preprocessing/postprocessing logic inside custom `nn.Module` layers, ensuring the entire pipeline is contained within the model graph - similar to Keras preprocessing layers.\n",
    "\n",
    "## Workflow Summary\n",
    "\n",
    "This workflow covers the following key steps:\n",
    "\n",
    "1.  **Data Loading and Preprocessing:**\n",
    "    *   Loading data from BigQuery using the `google-cloud-bigquery` library.\n",
    "    *   Converting the data to PyTorch `DataLoader` for efficient batching.\n",
    "    *   Creating custom `nn.Module` layers for preprocessing:\n",
    "        *   `Normalizer`: Stores mean/variance and normalizes inputs\n",
    "        *   `Denormalizer`: Inverts normalization back to original scale\n",
    "\n",
    "2.  **Autoencoder Model Definition:**\n",
    "    *   Defining the `Autoencoder` model using `nn.Module` with matching architecture to the Keras JAX version\n",
    "    *   Encoder: 30 \u2192 16 \u2192 8 \u2192 4 (latent)\n",
    "    *   Decoder: 4 \u2192 8 \u2192 16 \u2192 30\n",
    "    *   Using `nn.Dropout` for regularization\n",
    "    *   Custom loss function based on Mean Absolute Error (MAE)\n",
    "\n",
    "3.  **Training Loop:**\n",
    "    *   Implementing explicit training loop with PyTorch (more control than Keras `.fit()`)\n",
    "    *   Early stopping based on validation loss\n",
    "    *   Tracking metrics: RMSE, MSE, MAE, MSLE\n",
    "\n",
    "4.  **Encoder Model Extraction:**\n",
    "    *   Creating a separate encoder model for embedding extraction\n",
    "    *   Useful for vector similarity search and clustering\n",
    "\n",
    "5.  **PostProcessing Module (Custom Layer):**\n",
    "    *   Defining `PostProcessingModule` to encapsulate all post-processing logic *within* the model graph\n",
    "    *   This module:\n",
    "        *   Performs normalization, autoencoding, denormalization, and encoding\n",
    "        *   Calculates reconstruction errors and metrics per instance\n",
    "        *   Returns structured dictionary with normalized and denormalized outputs\n",
    "\n",
    "6.  **Model Composition:**\n",
    "    *   Creating `FinalModel` that combines all components\n",
    "    *   Single model containing: preprocessing \u2192 autoencoder \u2192 postprocessing\n",
    "    *   All stateful operations embedded in the model\n",
    "\n",
    "7.  **Saving Models:**\n",
    "    *   **PyTorch native format** (`.pt`/`.pth`): Standard PyTorch serialization\n",
    "    *   **Model Archive format** (`.mar`): TorchServe deployment format with custom handler\n",
    "\n",
    "8.  **Model Archive (.mar) Creation:**\n",
    "    *   Creating custom handler for TorchServe\n",
    "    *   Packaging model with `torch-model-archiver`\n",
    "    *   Verifying .mar file structure\n",
    "\n",
    "9.  **Prediction:**\n",
    "    *   Demonstrating predictions with the loaded PyTorch model\n",
    "    *   Showing how to verify .mar file contents\n",
    "\n",
    "**Key Advantages of This Workflow:**\n",
    "\n",
    "*   **Modularity:** Clean separation of concerns with custom modules\n",
    "*   **Flexibility:** Full control over training loop and model architecture\n",
    "*   **Portability:** PyTorch models can be deployed anywhere PyTorch runs\n",
    "*   **Deployability:** .mar format ready for production TorchServe deployment\n",
    "*   **Reproducibility:** All preprocessing logic embedded in the model\n",
    "*   **Efficiency:**  PyTorch's eager execution enables easy debugging\n",
    "*   **Comparison:** Direct architecture comparison with Keras JAX version\n",
    "\n",
    "## Comparison with Keras JAX Version\n",
    "\n",
    "This notebook implements the **exact same model architecture and workflow** as the Keras JAX example, allowing you to:\n",
    "*   Compare framework-specific approaches to the same problem\n",
    "*   Understand preprocessing layer implementation differences\n",
    "*   See how training loops differ (Keras `.fit()` vs PyTorch explicit loops)\n",
    "*   Compare serving formats (TensorFlow SavedModel vs TorchServe .mar)\n",
    "*   Evaluate which framework better suits your deployment environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96f2961",
   "metadata": {},
   "source": [
    "---\n",
    "## Environment Setup\n",
    "\n",
    "This section will authenticate your session, enable required Google Cloud APIs, and install necessary Python packages.\n",
    "\n",
    "**Package Installation Options (`REQ_TYPE`):**\n",
    "- `PRIMARY`: Installs only the main packages. Faster, but pip resolves sub-dependencies which may result in different versions than development.\n",
    "- `ALL` (Default): Installs exact versions of all packages and dependencies. Best for perfectly reproducing the development environment.\n",
    "- `COLAB`: Installs a Colab-optimized list that excludes pre-installed packages like `ipython` and `ipykernel`.\n",
    "\n",
    "**Installation Tool Options (`INSTALL_TOOL`):**\n",
    "- `pip` (Default): Uses pip for package installation. Standard Python package installer.\n",
    "- `uv`: Modern, fast Python package installer. Must be installed separately. See: https://github.com/astral-sh/uv\n",
    "- `poetry`: Dependency management tool. Requires running notebook in a poetry environment (`poetry shell` or `poetry run jupyter lab`). Uses `pyproject.toml` instead of requirements.txt.\n",
    "\n",
    "> **Note:** If running in Google Colab, the script will automatically detect this and set `REQ_TYPE = 'COLAB'` to prevent package conflicts, overriding any manual setting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ec0639",
   "metadata": {},
   "source": [
    "### Set Your Project ID\n",
    "\n",
    "\u26a0\ufe0f **Action Required:** Replace the `PROJECT_ID` value below with your Google Cloud project ID before running this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3637e3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'statmike-mlops-349915' # replace with GCP project ID\n",
    "REQ_TYPE = 'ALL' # Specify PRIMARY or ALL or COLAB\n",
    "INSTALL_TOOL = 'poetry' # Specify pip, uv, or poetry (all implemented)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f325f2",
   "metadata": {},
   "source": [
    "### Configuration\n",
    "\n",
    "This cell defines the requirements files and Google Cloud APIs needed for this notebook. Run as-is without modification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a96f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "REQUIREMENTS_URL = 'https://raw.githubusercontent.com/statmike/vertex-ai-mlops/refs/heads/main/Framework%20Workflows/PyTorch/requirements.txt'\n",
    "\n",
    "REQUIRED_APIS = [\n",
    "    \"bigquery.googleapis.com\",\n",
    "    \"storage.googleapis.com\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae571ce5",
   "metadata": {},
   "source": [
    "### Run Setup\n",
    "\n",
    "This cell downloads the centralized setup code and configures your environment. It will:\n",
    "- Authenticate your session with Google Cloud\n",
    "- Enable required APIs for this notebook\n",
    "- Install necessary Python packages\n",
    "- Display a setup summary with your project information\n",
    "\n",
    "> **Note:** In Colab, if packages are installed, the kernel will automatically restart. After restart, continue from the next cell without re-running earlier cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7b61c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, urllib.request\n",
    "\n",
    "# Download and import setup code\n",
    "url = 'https://raw.githubusercontent.com/statmike/vertex-ai-mlops/refs/heads/main/core/notebook-template/python_setup.py'\n",
    "urllib.request.urlretrieve(url, 'python_setup_local.py')\n",
    "import python_setup_local as python_setup\n",
    "os.remove('python_setup_local.py')\n",
    "\n",
    "# Run setup\n",
    "setup_info = python_setup.setup_environment(PROJECT_ID, REQ_TYPE, REQUIREMENTS_URL, REQUIRED_APIS, INSTALL_TOOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc873f8",
   "metadata": {},
   "source": [
    "---\n",
    "## Python Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8addd94",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10037c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from collections import OrderedDict\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Data & Visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# BigQuery\n",
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d5d03e",
   "metadata": {},
   "source": [
    "### Variables - User Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5d0897",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "SERIES = 'frameworks'\n",
    "EXPERIMENT = 'pytorch-autoencoder'\n",
    "\n",
    "# Data source - same as Keras version\n",
    "BQ_SOURCE = 'bigquery-public-data.ml_datasets.ulb_fraud_detection'\n",
    "\n",
    "# BigQuery destination for prepared data\n",
    "BQ_PROJECT = PROJECT_ID\n",
    "BQ_DATASET = SERIES.replace('-', '_')\n",
    "BQ_TABLE = SERIES\n",
    "BQ_REGION = REGION[0:2] # use a multi region"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef80c59",
   "metadata": {},
   "source": [
    "### Variables - Auto Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea465c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = subprocess.run(['gcloud', 'config', 'get-value', 'project'], capture_output=True, text=True, check=True).stdout.strip()\n",
    "PROJECT_NUMBER = subprocess.run(['gcloud', 'projects', 'describe', PROJECT_ID, '--format=value(projectNumber)'], capture_output=True, text=True, check=True).stdout.strip()\n",
    "\n",
    "print(f\"\\n{'='*50}\\nGoogle Cloud Project Information\\n{'='*50}\\nPROJECT_ID     = {PROJECT_ID}\\nPROJECT_NUMBER = {PROJECT_NUMBER}\\n{'='*50}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea09a322",
   "metadata": {},
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2977d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = f\"files/{EXPERIMENT}\"\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7efd45a",
   "metadata": {},
   "source": [
    "### Client Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0fe13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BigQuery client\n",
    "bq = bigquery.Client(project = PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea09a323",
   "metadata": {},
   "source": [
    "### Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2977d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(DIR):\n",
    "    os.makedirs(DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8565000f",
   "metadata": {},
   "source": [
    "---\n",
    "## Review Source Data\n",
    "\n",
    "This is a BigQuery public table of 284,807 credit card transactions classified as fraudulent or normal in the column `Class`.\n",
    "- The data can be researched further at this [Kaggle link](https://www.kaggle.com/mlg-ulb/creditcardfraud).\n",
    "- Read more about BigQuery public datasets [here](https://cloud.google.com/bigquery/public-data)\n",
    "\n",
    "In order to protect confidentiality, the original features have been transformed using [principle component analysis (PCA)](https://en.wikipedia.org/wiki/Principal_component_analysis) into 28 features named `V1, V2, ... V28` (float).  Two descriptive features are provided without transformation by PCA:\n",
    "- `Time` (integer) is the seconds elapsed between the transaction and the earliest transaction in the table\n",
    "- `Amount` (float) is the value of the transaction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "review_bq_1",
   "metadata": {},
   "source": [
    "### Review BigQuery Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "review_bq_2",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_data = bq.query(f\"SELECT * FROM `{BQ_SOURCE}` LIMIT 5\").to_dataframe()\n",
    "source_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prepare_data_1",
   "metadata": {},
   "source": [
    "---\n",
    "## Prepare Data Source\n",
    "\n",
    "The data preparation includes adding splits for machine learning with a column named  with 80% for training (), 10% for validation () and 10% for testing (). Additionally, a unique identifier was added to each transaction, ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prepare_data_2",
   "metadata": {},
   "source": [
    "### Create/Recall Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepare_data_3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = bigquery.Dataset(f\"{BQ_PROJECT}.{BQ_DATASET}\")\n",
    "dataset.location = BQ_REGION\n",
    "bq_dataset = bq.create_dataset(dataset, exists_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prepare_data_4",
   "metadata": {},
   "source": [
    "### Create/Recall Table With Preparation For ML\n",
    "\n",
    "Copy the data from the source while adding columns:\n",
    "-  as a unique identify for the row\n",
    "-  column to randomly assign rows to \"TRAIN\", \"VALIDATE\" and \"TEST\" groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepare_data_5",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = bq.query(f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS \n",
    "    `{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}` AS\n",
    "WITH\n",
    "    add_id AS (\n",
    "        SELECT *,\n",
    "            GENERATE_UUID() transaction_id,\n",
    "            ROW_NUMBER() OVER (PARTITION BY class ORDER BY RAND()) as rn\n",
    "            FROM `{BQ_SOURCE}`\n",
    "    )\n",
    "SELECT * EXCEPT(rn),\n",
    "    CASE \n",
    "        WHEN rn <= 0.8 * COUNT(*) OVER (PARTITION BY class) THEN \"TRAIN\"\n",
    "        WHEN rn <= 0.9 * COUNT(*) OVER (PARTITION BY class) THEN \"VALIDATE\"\n",
    "        ELSE \"TEST\"\n",
    "    END AS splits\n",
    "FROM add_id\n",
    "\"\"\")\n",
    "job.result()\n",
    "(job.ended-job.started).total_seconds()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_data_1",
   "metadata": {},
   "source": [
    "## Training An Autoencoder\n\n### Source Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_data_2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = bq.query(f\"SELECT * EXCEPT(splits) FROM `{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}` WHERE splits = 'TRAIN' AND Class = 0\").to_dataframe()\n",
    "test_df = bq.query(f\"SELECT * EXCEPT(splits) FROM `{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}` WHERE splits = 'TEST' AND Class = 0\").to_dataframe()\n",
    "validate_df = bq.query(f\"SELECT * EXCEPT(splits) FROM `{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}` WHERE splits = 'VALIDATE' AND Class = 0\").to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_data_3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column categories\n",
    "var_target = ['Class']\n",
    "var_omit = ['transaction_id']\n",
    "var_numeric = [x for x in train_df.columns.tolist() if x not in var_target + var_omit]\n",
    "print(f\"Number of features: {len(var_numeric)}\")\n",
    "print(f\"Features: {var_numeric}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pytorch_dataset_1",
   "metadata": {},
   "source": [
    "### PyTorch Dataset\n\nCreate a custom PyTorch `Dataset` class for loading data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pytorch_dataset_2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FraudDataset(Dataset):\n",
    "    \"\"\"Custom Dataset for fraud detection data\"\"\"\n",
    "    def __init__(self, dataframe, var_numeric, var_omit, var_target):\n",
    "        # Remove unwanted columns\n",
    "        df = dataframe.drop(columns=var_omit + var_target, errors='ignore')\n",
    "        \n",
    "        # Extract numeric features\n",
    "        self.data = torch.tensor(df[var_numeric].values, dtype=torch.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Return input and target (same for autoencoder)\n",
    "        return self.data[idx], self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pytorch_dataset_3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = FraudDataset(train_df, var_numeric, var_omit, var_target)\n",
    "val_dataset = FraudDataset(validate_df, var_numeric, var_omit, var_target)\n",
    "test_dataset = FraudDataset(test_df, var_numeric, var_omit, var_target)\n",
    "\n",
    "print(f\"Train size: {len(train_dataset)}\")\n",
    "print(f\"Val size: {len(val_dataset)}\")\n",
    "print(f\"Test size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pytorch_dataset_4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "batch_size = 100\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
    "\n",
    "print(f\"Number of batches in train_loader: {len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preproc_1",
   "metadata": {},
   "source": [
    "### Preprocessing Layers\n",
    "\n",
    "Create custom `nn.Module` layers for normalization and denormalization. These layers will be part of the model graph, similar to Keras preprocessing layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preproc_2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalizer(nn.Module):\n",
    "    \"\"\"Normalization layer that stores mean and variance\"\"\"\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        # Register buffers (non-trainable parameters that are saved with the model)\n",
    "        self.register_buffer('mean', torch.zeros(input_dim))\n",
    "        self.register_buffer('variance', torch.ones(input_dim))\n",
    "        self.input_dim = input_dim\n",
    "    \n",
    "    def adapt(self, data_loader):\n",
    "        \"\"\"Compute mean and variance from data (similar to Keras .adapt())\"\"\"\n",
    "        all_data = []\n",
    "        for batch, _ in data_loader:\n",
    "            all_data.append(batch)\n",
    "        all_data = torch.cat(all_data, dim=0)\n",
    "        \n",
    "        self.mean.copy_(all_data.mean(dim=0))\n",
    "        self.variance.copy_(all_data.var(dim=0, unbiased=False))\n",
    "        \n",
    "        print(f\"Adapted normalizer: mean shape {self.mean.shape}, variance shape {self.variance.shape}\")\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Normalize: (x - mean) / sqrt(variance)\n",
    "        std = torch.sqrt(self.variance + 1e-7)  # Small epsilon for numerical stability\n",
    "        return (x - self.mean) / std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preproc_3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Denormalizer(nn.Module):\n",
    "    \"\"\"Denormalization layer (inverts normalization)\"\"\"\n",
    "    def __init__(self, normalizer):\n",
    "        super().__init__()\n",
    "        # Share the same mean and variance buffers\n",
    "        self.register_buffer('mean', normalizer.mean)\n",
    "        self.register_buffer('variance', normalizer.variance)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Denormalize: x * sqrt(variance) + mean\n",
    "        std = torch.sqrt(self.variance + 1e-7)\n",
    "        return x * std + self.mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preproc_4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and adapt normalizer\n",
    "normalizer = Normalizer(len(var_numeric))\n",
    "normalizer.adapt(train_loader)\n",
    "\n",
    "# Create denormalizer\n",
    "denormalizer = Denormalizer(normalizer)\n",
    "\n",
    "print(f\"Normalizer created and adapted to training data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "autoencoder_1",
   "metadata": {},
   "source": [
    "### Autoencoder Model\n",
    "\n",
    "Define the autoencoder architecture matching the Keras JAX version:\n",
    "- Encoder: 30 \u2192 16 \u2192 8 \u2192 4 (latent)\n",
    "- Decoder: 4 \u2192 8 \u2192 16 \u2192 30\n",
    "- Dropout for regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "autoencoder_2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    \"\"\"Autoencoder matching Keras JAX architecture\"\"\"\n",
    "    def __init__(self, input_dim=30, latent_dim=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.enc_dense1 = nn.Linear(input_dim, 16)\n",
    "        self.enc_dropout1 = nn.Dropout(0.4)\n",
    "        self.enc_dense2 = nn.Linear(16, 8)\n",
    "        self.enc_dropout2 = nn.Dropout(0.4)\n",
    "        self.latent = nn.Linear(8, latent_dim)\n",
    "        \n",
    "        # Decoder\n",
    "        self.dec_dense1 = nn.Linear(latent_dim, 8)\n",
    "        self.dec_dropout1 = nn.Dropout(0.4)\n",
    "        self.dec_dense2 = nn.Linear(8, 16)\n",
    "        self.dec_dropout2 = nn.Dropout(0.4)\n",
    "        self.reconstructed = nn.Linear(16, input_dim)\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "    \n",
    "    def encode(self, x):\n",
    "        \"\"\"Encoder forward pass\"\"\"\n",
    "        x = torch.relu(self.enc_dense1(x))\n",
    "        x = self.enc_dropout1(x)\n",
    "        x = torch.relu(self.enc_dense2(x))\n",
    "        x = self.enc_dropout2(x)\n",
    "        x = torch.relu(self.latent(x))\n",
    "        return x\n",
    "    \n",
    "    def decode(self, x):\n",
    "        \"\"\"Decoder forward pass\"\"\"\n",
    "        x = torch.relu(self.dec_dense1(x))\n",
    "        x = self.dec_dropout1(x)\n",
    "        x = torch.relu(self.dec_dense2(x))\n",
    "        x = self.dec_dropout2(x)\n",
    "        x = self.reconstructed(x)  # No activation on output\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Full autoencoder forward pass\"\"\"\n",
    "        latent = self.encode(x)\n",
    "        reconstructed = self.decode(latent)\n",
    "        return reconstructed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "autoencoder_3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create autoencoder model\n",
    "autoencoder = Autoencoder(input_dim=len(var_numeric), latent_dim=4).to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in autoencoder.parameters())\n",
    "trainable_params = sum(p.numel() for p in autoencoder.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"\\nModel structure:\")\n",
    "print(autoencoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training_1",
   "metadata": {},
   "source": [
    "### Training Setup\n",
    "\n",
    "Define loss function, optimizer, and metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training_2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function (MAE matching Keras)\n",
    "def custom_loss(y_true, y_pred):\n",
    "    return torch.mean(torch.abs(y_true - y_pred))\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(autoencoder.parameters(), lr=0.0005)\n",
    "\n",
    "print(\"Loss function and optimizer configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training_3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics calculation\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    \"\"\"Calculate RMSE, MSE, MAE, MSLE\"\"\"\n",
    "    mae = torch.mean(torch.abs(y_true - y_pred))\n",
    "    mse = torch.mean((y_true - y_pred) ** 2)\n",
    "    rmse = torch.sqrt(mse)\n",
    "    \n",
    "    # MSLE (Mean Squared Log Error)\n",
    "    y_true_pos = torch.maximum(y_true, torch.zeros_like(y_true))\n",
    "    y_pred_pos = torch.maximum(y_pred, torch.zeros_like(y_pred))\n",
    "    msle = torch.mean((torch.log1p(y_pred_pos) - torch.log1p(y_true_pos)) ** 2)\n",
    "    \n",
    "    return {\n",
    "        'mae': mae.item(),\n",
    "        'mse': mse.item(),\n",
    "        'rmse': rmse.item(),\n",
    "        'msle': msle.item()\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training_4",
   "metadata": {},
   "source": [
    "### Training Loop with Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training_5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_epoch(model, loader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_metrics = {'mae': 0, 'mse': 0, 'rmse': 0, 'msle': 0}\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # Normalize data\n",
    "        data_normalized = normalizer(data)\n",
    "        target_normalized = normalizer(target)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data_normalized)\n",
    "        loss = custom_loss(target_normalized, output)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track metrics\n",
    "        total_loss += loss.item()\n",
    "        metrics = calculate_metrics(target_normalized, output)\n",
    "        for key in all_metrics:\n",
    "            all_metrics[key] += metrics[key]\n",
    "    \n",
    "    # Average metrics\n",
    "    num_batches = len(loader)\n",
    "    avg_loss = total_loss / num_batches\n",
    "    for key in all_metrics:\n",
    "        all_metrics[key] /= num_batches\n",
    "    \n",
    "    return avg_loss, all_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training_6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation function\n",
    "def validate_epoch(model, loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_metrics = {'mae': 0, 'mse': 0, 'rmse': 0, 'msle': 0}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            # Normalize\n",
    "            data_normalized = normalizer(data)\n",
    "            target_normalized = normalizer(target)\n",
    "            \n",
    "            # Forward pass\n",
    "            output = model(data_normalized)\n",
    "            loss = custom_loss(target_normalized, output)\n",
    "            \n",
    "            # Track metrics\n",
    "            total_loss += loss.item()\n",
    "            metrics = calculate_metrics(target_normalized, output)\n",
    "            for key in all_metrics:\n",
    "                all_metrics[key] += metrics[key]\n",
    "    \n",
    "    # Average metrics\n",
    "    num_batches = len(loader)\n",
    "    avg_loss = total_loss / num_batches\n",
    "    for key in all_metrics:\n",
    "        all_metrics[key] /= num_batches\n",
    "    \n",
    "    return avg_loss, all_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training_7",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training_8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "num_epochs = 10\n",
    "patience = 5\n",
    "best_val_loss = float('inf')\n",
    "epochs_without_improvement = 0\n",
    "best_model_state = None\n",
    "\n",
    "# History tracking\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'train_mae': [],\n",
    "    'val_mae': [],\n",
    "    'train_mse': [],\n",
    "    'val_mse': [],\n",
    "    'train_rmse': [],\n",
    "    'val_rmse': [],\n",
    "    'train_msle': [],\n",
    "    'val_msle': []\n",
    "}\n",
    "\n",
    "print(f\"Starting training for {num_epochs} epochs with early stopping (patience={patience})...\")\n",
    "print(f\"{'=\"*50}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training_9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Train\n",
    "    train_loss, train_metrics = train_epoch(autoencoder, train_loader, optimizer, device)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_metrics = validate_epoch(autoencoder, val_loader, device)\n",
    "    \n",
    "    # Store history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    for key in train_metrics:\n",
    "        history[f'train_{key}'].append(train_metrics[key])\n",
    "        history[f'val_{key}'].append(val_metrics[key])\n",
    "    \n",
    "    # Print progress\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "    print(f\"  Train - Loss: {train_loss:.6f}, MAE: {train_metrics['mae']:.6f}, \"\n",
    "          f\"RMSE: {train_metrics['rmse']:.6f}, MSE: {train_metrics['mse']:.6f}, MSLE: {train_metrics['msle']:.6f}\")\n",
    "    print(f\"  Val   - Loss: {val_loss:.6f}, MAE: {val_metrics['mae']:.6f}, \"\n",
    "          f\"RMSE: {val_metrics['rmse']:.6f}, MSE: {val_metrics['mse']:.6f}, MSLE: {val_metrics['msle']:.6f}\")\n",
    "    \n",
    "    # Early stopping logic\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model_state = autoencoder.state_dict().copy()\n",
    "        epochs_without_improvement = 0\n",
    "        print(f\"  \u2713 New best model (val_loss: {val_loss:.6f})\")\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        print(f\"  \u26a0 No improvement for {epochs_without_improvement} epoch(s)\")\n",
    "        \n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f\"\\nEarly stopping triggered after {epoch+1} epochs\")\n",
    "            break\n",
    "    \n",
    "    print()\n",
    "\n",
    "# Restore best model\n",
    "autoencoder.load_state_dict(best_model_state)\n",
    "print(f\"\\nTraining completed. Best validation loss: {best_val_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eval_1",
   "metadata": {},
   "source": [
    "### Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eval_2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_metrics = validate_epoch(autoencoder, test_loader, device)\n",
    "print(f\"Test Results:\")\n",
    "print(f\"  Loss: {test_loss:.6f}\")\n",
    "print(f\"  MAE: {test_metrics['mae']:.6f}\")\n",
    "print(f\"  RMSE: {test_metrics['rmse']:.6f}\")\n",
    "print(f\"  MSE: {test_metrics['mse']:.6f}\")\n",
    "print(f\"  MSLE: {test_metrics['msle']:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eval_3",
   "metadata": {},
   "source": [
    "### Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eval_4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(history['train_loss'], label='Training Loss')\n",
    "plt.plot(history['val_loss'], label='Validation Loss')\n",
    "plt.scatter(len(history['train_loss']) - 1, test_loss, color='red', label='Test Loss', zorder=5)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training, Validation, and Test Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "encoder_1",
   "metadata": {},
   "source": [
    "---\n",
    "## Create An Encoder Model\n",
    "\n",
    "Extract the encoder portion for creating embeddings (latent representations):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "encoder_2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"Standalone encoder model\"\"\"\n",
    "    def __init__(self, autoencoder):\n",
    "        super().__init__()\n",
    "        self.autoencoder = autoencoder\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.autoencoder.encode(x)\n",
    "\n",
    "encoder_model = Encoder(autoencoder).to(device)\n",
    "print(\"Encoder model created\")\n",
    "print(f\"Latent dimension: {autoencoder.latent_dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "encoder_3",
   "metadata": {},
   "source": [
    "### Predict With Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "encoder_4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a few test instances\n",
    "test_instances_tensor = next(iter(test_loader))[0][:3].to(device)\n",
    "\n",
    "# Encode\n",
    "encoder_model.eval()\n",
    "with torch.no_grad():\n",
    "    normalized_input = normalizer(test_instances_tensor)\n",
    "    encoded_output = encoder_model(normalized_input)\n",
    "\n",
    "print(f\"Encoded output shape: {encoded_output.shape}\")\n",
    "print(f\"Encoded representations:\\n{encoded_output.cpu().numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "postproc_1",
   "metadata": {},
   "source": [
    "---\n",
    "## Enhanced Model with Post-Processing\n",
    "\n",
    "Create a comprehensive model that includes preprocessing, autoencoding, and detailed post-processing - matching the Keras JAX output structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "postproc_2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PostProcessingModule(nn.Module):\n",
    "    \"\"\"Post-processing module that calculates all metrics and outputs\"\"\"\n",
    "    def __init__(self, autoencoder, normalizer, denormalizer, encoder):\n",
    "        super().__init__()\n",
    "        self.autoencoder = autoencoder\n",
    "        self.normalizer = normalizer\n",
    "        self.denormalizer = denormalizer\n",
    "        self.encoder = encoder\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Normalize input\n",
    "        x_normalized = self.normalizer(x)\n",
    "        \n",
    "        # Get reconstructions\n",
    "        reconstructed_normalized = self.autoencoder(x_normalized)\n",
    "        reconstructed_denormalized = self.denormalizer(reconstructed_normalized)\n",
    "        \n",
    "        # Get encoded representation\n",
    "        encoded = self.encoder(x_normalized)\n",
    "        \n",
    "        # Calculate reconstruction errors\n",
    "        normalized_errors = x_normalized - reconstructed_normalized\n",
    "        denormalized_errors = x - reconstructed_denormalized\n",
    "        \n",
    "        # Calculate metrics per instance (aggregated across features)\n",
    "        # Normalized metrics\n",
    "        norm_mae = torch.mean(torch.abs(normalized_errors), dim=-1)\n",
    "        norm_mse = torch.mean(normalized_errors ** 2, dim=-1)\n",
    "        norm_rmse = torch.sqrt(norm_mse)\n",
    "        \n",
    "        # MSLE for normalized\n",
    "        x_norm_pos = torch.maximum(x_normalized, torch.zeros_like(x_normalized))\n",
    "        recon_norm_pos = torch.maximum(reconstructed_normalized, torch.zeros_like(reconstructed_normalized))\n",
    "        norm_msle = torch.mean(\n",
    "            (torch.log1p(recon_norm_pos) - torch.log1p(x_norm_pos)) ** 2,\n",
    "            dim=-1\n",
    "        )\n",
    "        \n",
    "        # Denormalized metrics\n",
    "        denorm_mae = torch.mean(torch.abs(denormalized_errors), dim=-1)\n",
    "        denorm_mse = torch.mean(denormalized_errors ** 2, dim=-1)\n",
    "        denorm_rmse = torch.sqrt(denorm_mse)\n",
    "        \n",
    "        # MSLE for denormalized\n",
    "        x_denorm_pos = torch.maximum(x, torch.zeros_like(x))\n",
    "        recon_denorm_pos = torch.maximum(reconstructed_denormalized, torch.zeros_like(reconstructed_denormalized))\n",
    "        denorm_msle = torch.mean(\n",
    "            (torch.log1p(recon_denorm_pos) - torch.log1p(x_denorm_pos)) ** 2,\n",
    "            dim=-1\n",
    "        )\n",
    "        \n",
    "        # Return comprehensive output dictionary\n",
    "        return {\n",
    "            'normalized_reconstruction': reconstructed_normalized,\n",
    "            'normalized_reconstruction_errors': normalized_errors,\n",
    "            'normalized_MAE': norm_mae,\n",
    "            'normalized_RMSE': norm_rmse,\n",
    "            'normalized_MSE': norm_mse,\n",
    "            'normalized_MSLE': norm_msle,\n",
    "            'denormalized_reconstruction': reconstructed_denormalized,\n",
    "            'denormalized_reconstruction_errors': denormalized_errors,\n",
    "            'denormalized_MAE': denorm_mae,\n",
    "            'denormalized_RMSE': denorm_rmse,\n",
    "            'denormalized_MSE': denorm_mse,\n",
    "            'denormalized_MSLE': denorm_msle,\n",
    "            'encoded': encoded\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "postproc_3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinalModel(nn.Module):\n",
    "    \"\"\"Complete model with preprocessing, autoencoding, and postprocessing\"\"\"\n",
    "    def __init__(self, postprocessing_module):\n",
    "        super().__init__()\n",
    "        self.postprocessing = postprocessing_module\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.postprocessing(x)\n",
    "\n",
    "# Create the final comprehensive model\n",
    "postprocessing_module = PostProcessingModule(autoencoder, normalizer, denormalizer, encoder_model)\n",
    "final_model = FinalModel(postprocessing_module).to(device)\n",
    "\n",
    "print(\"Final model created with comprehensive post-processing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "postproc_4",
   "metadata": {},
   "source": [
    "### Test Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "postproc_5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with sample instances\n",
    "final_model.eval()\n",
    "with torch.no_grad():\n",
    "    sample_output = final_model(test_instances_tensor)\n",
    "\n",
    "print(\"Final model output keys:\")\n",
    "for key in sample_output.keys():\n",
    "    print(f\"  - {key}: shape {sample_output[key].shape}\")\n",
    "\n",
    "print(f\"\\nExample denormalized MAE (first 3 instances):\")\n",
    "print(sample_output['denormalized_MAE'][:3].cpu().numpy())\n",
    "\n",
    "print(f\"\\nExample encoded representation (first instance):\")\n",
    "print(sample_output['encoded'][0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saving_1",
   "metadata": {},
   "source": [
    "---\n",
    "## Model Saving and Serving\n",
    "\n",
    "Save models in multiple formats:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saving_2",
   "metadata": {},
   "source": [
    "### PyTorch Native Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving_3",
   "metadata": {},
   "outputs": [],
   "source": [
    "PYTORCH_DIR = os.path.join(DIR, \"pytorch\")\n",
    "os.makedirs(PYTORCH_DIR, exist_ok=True)\n",
    "\n",
    "# Save individual components\n",
    "torch.save(autoencoder.state_dict(), os.path.join(PYTORCH_DIR, \"autoencoder.pt\"))\n",
    "torch.save(encoder_model.state_dict(), os.path.join(PYTORCH_DIR, \"encoder.pt\"))\n",
    "torch.save(normalizer.state_dict(), os.path.join(PYTORCH_DIR, \"normalizer.pt\"))\n",
    "torch.save(denormalizer.state_dict(), os.path.join(PYTORCH_DIR, \"denormalizer.pt\"))\n",
    "\n",
    "# Save final model\n",
    "torch.save(final_model.state_dict(), os.path.join(PYTORCH_DIR, \"final_model.pt\"))\n",
    "\n",
    "print(\"Saved PyTorch models:\")\n",
    "print(f\"  - autoencoder.pt\")\n",
    "print(f\"  - encoder.pt\")\n",
    "print(f\"  - normalizer.pt\")\n",
    "print(f\"  - denormalizer.pt\")\n",
    "print(f\"  - final_model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saving_4",
   "metadata": {},
   "source": [
    "### Load and Test PyTorch Models\n",
    "\n",
    "Verify that saved models can be loaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving_5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fresh model instances\n",
    "loaded_autoencoder = Autoencoder(input_dim=len(var_numeric), latent_dim=4).to(device)\n",
    "loaded_autoencoder.load_state_dict(torch.load(os.path.join(PYTORCH_DIR, \"autoencoder.pt\"), weights_only=True))\n",
    "loaded_autoencoder.eval()\n",
    "\n",
    "# Test loaded model\n",
    "with torch.no_grad():\n",
    "    test_input = test_instances_tensor[0:1]\n",
    "    test_normalized = normalizer(test_input)\n",
    "    loaded_output = loaded_autoencoder(test_normalized)\n",
    "    \n",
    "print(\"\u2705 Successfully loaded and tested autoencoder\")\n",
    "print(f\"Output shape: {loaded_output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mar_1",
   "metadata": {},
   "source": [
    "---\n",
    "## Model Archive (.mar) for TorchServe\n",
    "\n",
    "Create a `.mar` file suitable for TorchServe deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mar_2",
   "metadata": {},
   "source": [
    "### Create Custom Handler\n\nThe handler converts HTTP requests to tensors and back:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mar_3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create handler code\n",
    "handler_code = \"\"\"import torch\n",
    "import torch.nn as nn\n",
    "import json\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class AutoencoderHandler:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.device = None\n",
    "        self.initialized = False\n",
    "    \n",
    "    def initialize(self, context):\n",
    "        \"\"\"Initialize model and device\"\"\"\n",
    "        properties = context.system_properties\n",
    "        self.device = torch.device(\n",
    "            \"cuda:\" + str(properties.get(\"gpu_id\"))\n",
    "            if torch.cuda.is_available()\n",
    "            else \"cpu\"\n",
    "        )\n",
    "        \n",
    "        # Load model\n",
    "        model_dir = properties.get(\"model_dir\")\n",
    "        model_path = f\"{model_dir}/final_model.pt\"\n",
    "        \n",
    "        # Note: This expects the model class to be available\n",
    "        # In production, you would include the model definition in the .mar\n",
    "        self.model = torch.jit.load(model_path, map_location=self.device)\n",
    "        self.model.eval()\n",
    "        \n",
    "        self.initialized = True\n",
    "        logger.info(\"Model initialized successfully\")\n",
    "    \n",
    "    def preprocess(self, requests):\n",
    "        \"\"\"Convert HTTP request to tensor\"\"\"\n",
    "        instances = []\n",
    "        for request in requests:\n",
    "            data = request.get(\"data\") or request.get(\"body\")\n",
    "            if isinstance(data, (bytes, bytearray)):\n",
    "                data = data.decode(\"utf-8\")\n",
    "            \n",
    "            # Parse JSON\n",
    "            if isinstance(data, str):\n",
    "                data = json.loads(data)\n",
    "            \n",
    "            # Extract instances\n",
    "            if \"instances\" in data:\n",
    "                instances.extend(data[\"instances\"])\n",
    "            else:\n",
    "                instances.append(data)\n",
    "        \n",
    "        # Convert to tensor\n",
    "        input_tensor = torch.tensor(instances, dtype=torch.float32, device=self.device)\n",
    "        return input_tensor\n",
    "    \n",
    "    def inference(self, input_tensor):\n",
    "        \"\"\"Run model inference\"\"\"\n",
    "        with torch.no_grad():\n",
    "            output = self.model(input_tensor)\n",
    "        return output\n",
    "    \n",
    "    def postprocess(self, inference_output):\n",
    "        \"\"\"Convert model output to JSON\"\"\"\n",
    "        # Convert all tensor values to lists\n",
    "        result = {}\n",
    "        for key, value in inference_output.items():\n",
    "            result[key] = value.cpu().numpy().tolist()\n",
    "        \n",
    "        return [result]\n",
    "\n",
    "# TorchServe entry point\n",
    "_service = AutoencoderHandler()\n",
    "\n",
    "def handle(data, context):\n",
    "    if not _service.initialized:\n",
    "        _service.initialize(context)\n",
    "    \n",
    "    if data is None:\n",
    "        return None\n",
    "    \n",
    "    input_tensor = _service.preprocess(data)\n",
    "    output = _service.inference(input_tensor)\n",
    "    return _service.postprocess(output)\n",
    "\"\"\"\n",
    "\n",
    "# Write handler to file\n",
    "with open(os.path.join(DIR, \"handler.py\"), \"w\") as f:\n",
    "    f.write(handler_code)\n",
    "\n",
    "print(\"\u2705 Created handler.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mar_4",
   "metadata": {},
   "source": [
    "### Save Model for MAR (TorchScript Format)\n\nWe need to use TorchScript for .mar compatibility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mar_5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model in TorchScript format for .mar\n",
    "final_model.eval()\n",
    "\n",
    "# Create example input for tracing\n",
    "example_input = torch.randn(1, len(var_numeric)).to(device)\n",
    "\n",
    "# Trace the model\n",
    "traced_model = torch.jit.trace(final_model, example_input)\n",
    "\n",
    "# Save traced model\n",
    "traced_model.save(os.path.join(DIR, \"final_model_traced.pt\"))\n",
    "\n",
    "print(\"\u2705 Saved TorchScript traced model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mar_6",
   "metadata": {},
   "source": [
    "### Create Model Archive (.mar) File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mar_7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create .mar file using torch-model-archiver\n",
    "import subprocess\n",
    "\n",
    "mar_command = [\n",
    "    \"torch-model-archiver\",\n",
    "    \"--model-name\", \"pytorch_autoencoder\",\n",
    "    \"--version\", \"1.0\",\n",
    "    \"--serialized-file\", os.path.join(DIR, \"final_model_traced.pt\"),\n",
    "    \"--handler\", os.path.join(DIR, \"handler.py\"),\n",
    "    \"--export-path\", DIR,\n",
    "    \"--force\"\n",
    "]\n",
    "\n",
    "result = subprocess.run(mar_command, capture_output=True, text=True)\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(\"\u2705 Successfully created .mar file\")\n",
    "    print(f\"Location: {os.path.join(DIR, 'pytorch_autoencoder.mar')}\")\n",
    "else:\n",
    "    print(\"\u274c Error creating .mar file:\")\n",
    "    print(result.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mar_8",
   "metadata": {},
   "source": [
    "### Verify MAR File\n\nLet's verify the contents of the .mar file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mar_9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "mar_path = os.path.join(DIR, \"pytorch_autoencoder.mar\")\n",
    "\n",
    "if os.path.exists(mar_path):\n",
    "    with zipfile.ZipFile(mar_path, 'r') as zip_ref:\n",
    "        print(\"Contents of .mar file:\")\n",
    "        for name in zip_ref.namelist():\n",
    "            info = zip_ref.getinfo(name)\n",
    "            print(f\"  - {name} ({info.file_size:,} bytes)\")\n",
    "    \n",
    "    # Get file size\n",
    "    file_size = os.path.getsize(mar_path)\n",
    "    print(f\"\\nTotal .mar file size: {file_size:,} bytes ({file_size / 1024:.2f} KB)\")\n",
    "else:\n",
    "    print(\"\u274c .mar file not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion_1",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "\u2705 **Data Loading**: Loading data from BigQuery and creating PyTorch DataLoaders\n",
    "\n",
    "\u2705 **Custom Preprocessing Layers**: Embedding normalization/denormalization in `nn.Module` layers\n",
    "\n",
    "\u2705 **Autoencoder Architecture**: Building the exact same architecture as the Keras JAX version\n",
    "\n",
    "\u2705 **Explicit Training Loop**: Full control over training with early stopping\n",
    "\n",
    "\u2705 **Encoder Extraction**: Creating standalone encoder for embeddings\n",
    "\n",
    "\u2705 **Comprehensive Post-Processing**: Matching Keras output structure with detailed metrics\n",
    "\n",
    "\u2705 **Model Saving**: Multiple formats (PyTorch native and TorchScript)\n",
    "\n",
    "\u2705 **TorchServe Deployment**: Creating .mar file with custom handler\n",
    "\n",
    "### Key Differences from Keras JAX:\n",
    "\n",
    "| Aspect | Keras JAX | PyTorch |\n",
    "|--------|-----------|----------|\n",
    "| Training | `.fit()` method | Explicit loop |\n",
    "| Preprocessing | `keras.layers.Normalization` | Custom `nn.Module` |\n",
    "| Backend | JAX (functional) | PyTorch (imperative) |\n",
    "| Serving | TensorFlow SavedModel | .mar for TorchServe |\n",
    "| Handler | Not needed (in graph) | Required (minimal) |\n",
    "\n",
    "### Advantages of PyTorch Approach:\n",
    "\n",
    "- More explicit control over training process\n",
    "- Easier debugging with Python-native code\n",
    "- Flexible dynamic computation graphs\n",
    "- Growing ecosystem for production deployment\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Deploy .mar file to TorchServe instance\n",
    "- Implement batch prediction endpoints\n",
    "- Compare performance with Keras JAX version\n",
    "- Explore ONNX export for cross-framework compatibility"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}